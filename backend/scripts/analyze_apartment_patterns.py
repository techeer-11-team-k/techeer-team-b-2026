"""
ì•„íŒŒíŠ¸ ë°ì´í„° íŒ¨í„´ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

ë¯¸ìŠ¤ë§¤ì¹­ì„ ì¤„ì´ê¸° ìœ„í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤:
1. ì„ëŒ€ ì•„íŒŒíŠ¸ ë¶„í¬
2. ê°™ì€ ì§€ì—­ ë‚´ ìœ ì‚¬ ì´ë¦„ ì•„íŒŒíŠ¸ (ë¯¸ìŠ¤ë§¤ì¹­ ìœ„í—˜)
3. ë‹¨ì§€ ë²ˆí˜¸/ì°¨ìˆ˜ íŒ¨í„´
4. ë¸Œëœë“œ ë¶„í¬
5. ì´ë¦„ ê¸¸ì´ ë° ë³µì¡ë„
"""
import csv
import re
from pathlib import Path
from typing import List, Dict, Set, Tuple
from collections import defaultdict, Counter
from difflib import SequenceMatcher


# ì„ëŒ€ í‚¤ì›Œë“œ
RENTAL_KEYWORDS = [
    'ì„ëŒ€', 'lh', 'ì£¼ê³µ', 'ë„ì‹œê³µì‚¬', 'ì˜êµ¬ì„ëŒ€', 'íœ´ë¨¼ì‹œì•„',
    'ë„ê°œê³µ', 'ë¶€ì‚°ë„ì‹œê³µì‚¬', 'ê°€ì–‘ë„ì‹œê°œë°œê³µì‚¬', 'ì„œìš¸ë„ì‹œê³µì‚¬',
    'ê³µê³µì„ëŒ€', 'ì‚¬ì›ì„ëŒ€', 'ì‚¬íšŒì£¼íƒ', 'ì„ëŒ€ë™',
]

# ì£¼ìš” ë¸Œëœë“œ
MAJOR_BRANDS = [
    'ìì´', 'ë˜ë¯¸ì•ˆ', 'í‘¸ë¥´ì§€ì˜¤', 'íìŠ¤í…Œì´íŠ¸', 'ë”ìƒµ', 
    'ì•„ì´íŒŒí¬', 'ìœ„ë¸Œ', 'ì„¼íŠ¸ë ˆë¹Œ', 'ë¡¯ë°ìºìŠ¬', 'í˜¸ë°˜ì¨ë°‹',
]


def is_rental(name: str) -> bool:
    """ì„ëŒ€ ì•„íŒŒíŠ¸ ì—¬ë¶€"""
    name_lower = name.lower().replace(' ', '')
    return any(kw.lower() in name_lower for kw in RENTAL_KEYWORDS)


def extract_danji_number(name: str) -> int:
    """ë‹¨ì§€ ë²ˆí˜¸ ì¶”ì¶œ"""
    match = re.search(r'(\d+)ë‹¨ì§€', name)
    if match:
        return int(match.group(1))
    return None


def extract_cha_number(name: str) -> int:
    """ì°¨ìˆ˜ ì¶”ì¶œ"""
    match = re.search(r'(\d+)ì°¨', name)
    if match:
        return int(match.group(1))
    return None


def extract_brand(name: str) -> str:
    """ë¸Œëœë“œ ì¶”ì¶œ"""
    name_lower = name.lower()
    for brand in MAJOR_BRANDS:
        if brand in name_lower:
            return brand
    return None


def calculate_similarity(str1: str, str2: str) -> float:
    """ë¬¸ìì—´ ìœ ì‚¬ë„"""
    return SequenceMatcher(None, str1, str2).ratio()


def normalize_name(name: str) -> str:
    """ì´ë¦„ ì •ê·œí™”"""
    # ê³µë°± ì œê±°, ì†Œë¬¸ì
    return re.sub(r'\s+', '', name).lower()


class ApartmentAnalyzer:
    """ì•„íŒŒíŠ¸ ë°ì´í„° ë¶„ì„ê¸°"""
    
    def __init__(self, csv_path: str):
        self.csv_path = Path(csv_path)
        self.apartments = []
        self.by_region = defaultdict(list)
        self.rental_apts = []
        self.non_rental_apts = []
        
    def load_data(self):
        """CSV ë¡œë“œ"""
        print(f"\nğŸ“‚ Loading data from {self.csv_path.name}...")
        
        with open(self.csv_path, 'r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                apt = {
                    'apt_id': int(row['apt_id']),
                    'region_id': int(row['region_id']),
                    'apt_name': row['apt_name'],
                    'kapt_code': row['kapt_code'],
                    'is_rental': is_rental(row['apt_name']),
                    'normalized_name': normalize_name(row['apt_name']),
                    'danji': extract_danji_number(row['apt_name']),
                    'cha': extract_cha_number(row['apt_name']),
                    'brand': extract_brand(row['apt_name']),
                }
                
                self.apartments.append(apt)
                self.by_region[apt['region_id']].append(apt)
                
                if apt['is_rental']:
                    self.rental_apts.append(apt)
                else:
                    self.non_rental_apts.append(apt)
        
        print(f"âœ… Loaded {len(self.apartments):,} apartments")
        print(f"   - ì„ëŒ€: {len(self.rental_apts):,}ê°œ")
        print(f"   - ë¶„ì–‘: {len(self.non_rental_apts):,}ê°œ")
    
    def analyze_rental_distribution(self):
        """ì„ëŒ€ ì•„íŒŒíŠ¸ ë¶„í¬ ë¶„ì„"""
        print(f"\n{'='*80}")
        print(f"{'1ï¸âƒ£  ì„ëŒ€ ì•„íŒŒíŠ¸ ë¶„í¬':^80}")
        print(f"{'='*80}")
        
        print(f"\nì „ì²´ ì•„íŒŒíŠ¸: {len(self.apartments):,}ê°œ")
        print(f"ì„ëŒ€ ì•„íŒŒíŠ¸: {len(self.rental_apts):,}ê°œ ({len(self.rental_apts)/len(self.apartments)*100:.2f}%)")
        print(f"ë¶„ì–‘ ì•„íŒŒíŠ¸: {len(self.non_rental_apts):,}ê°œ ({len(self.non_rental_apts)/len(self.apartments)*100:.2f}%)")
        
        # ì„ëŒ€ í‚¤ì›Œë“œë³„ ë¹ˆë„
        keyword_counts = Counter()
        for apt in self.rental_apts:
            name_lower = apt['apt_name'].lower()
            for keyword in RENTAL_KEYWORDS:
                if keyword.lower() in name_lower:
                    keyword_counts[keyword] += 1
        
        print(f"\nì„ëŒ€ í‚¤ì›Œë“œ ë¹ˆë„ (Top 10):")
        print(f"{'í‚¤ì›Œë“œ':20} | {'ë¹ˆë„':>10}")
        print(f"{'-'*20}-+-{'-'*10}")
        for keyword, count in keyword_counts.most_common(10):
            print(f"{keyword:20} | {count:>10,}")
    
    def analyze_same_region_similar_names(self, similarity_threshold: float = 0.85):
        """ê°™ì€ ì§€ì—­ ë‚´ ìœ ì‚¬ ì´ë¦„ ì•„íŒŒíŠ¸ (ë¯¸ìŠ¤ë§¤ì¹­ ìœ„í—˜)"""
        print(f"\n{'='*80}")
        print(f"{'2ï¸âƒ£  ê°™ì€ ì§€ì—­ ë‚´ ìœ ì‚¬ ì´ë¦„ ì•„íŒŒíŠ¸ (ë¯¸ìŠ¤ë§¤ì¹­ ìœ„í—˜)':^80}")
        print(f"{'='*80}")
        print(f"ìœ ì‚¬ë„ ì„ê³„ê°’: {similarity_threshold}")
        
        high_risk_pairs = []
        
        for region_id, apts in self.by_region.items():
            if len(apts) < 2:
                continue
            
            # ê°™ì€ ì§€ì—­ ë‚´ ëª¨ë“  ìŒ ë¹„êµ
            for i, apt1 in enumerate(apts):
                for apt2 in apts[i+1:]:
                    # ìœ ì‚¬ë„ ê³„ì‚°
                    sim = calculate_similarity(apt1['normalized_name'], apt2['normalized_name'])
                    
                    if sim >= similarity_threshold and apt1['apt_name'] != apt2['apt_name']:
                        # ì„ëŒ€ vs ë¶„ì–‘ ì—¬ë¶€ í™•ì¸
                        rental_mismatch = apt1['is_rental'] != apt2['is_rental']
                        
                        high_risk_pairs.append({
                            'region_id': region_id,
                            'apt1': apt1['apt_name'],
                            'apt2': apt2['apt_name'],
                            'similarity': sim,
                            'rental_mismatch': rental_mismatch,
                            'apt1_rental': apt1['is_rental'],
                            'apt2_rental': apt2['is_rental'],
                        })
        
        # ìœ ì‚¬ë„ ë†’ì€ ìˆœ ì •ë ¬
        high_risk_pairs.sort(key=lambda x: x['similarity'], reverse=True)
        
        print(f"\në°œê²¬ëœ ê³ ìœ„í—˜ ìŒ: {len(high_risk_pairs):,}ê°œ")
        
        # ì„ëŒ€ vs ë¶„ì–‘ ë¯¸ìŠ¤ë§¤ì¹­
        rental_mismatch_pairs = [p for p in high_risk_pairs if p['rental_mismatch']]
        print(f"  - ì„ëŒ€ vs ë¶„ì–‘ ë¯¸ìŠ¤ë§¤ì¹­ ìœ„í—˜: {len(rental_mismatch_pairs):,}ê°œ ğŸš¨")
        
        # ìƒìœ„ 30ê°œ ì¶œë ¥
        print(f"\nìƒìœ„ 30ê°œ (ìœ ì‚¬ë„ ë†’ì€ ìˆœ):")
        print(f"{'ìœ ì‚¬ë„':^8} | {'ì„ëŒ€?':^6} | {'ì•„íŒŒíŠ¸1':40} | {'ì•„íŒŒíŠ¸2':40}")
        print(f"{'-'*8}-+-{'-'*6}-+-{'-'*40}-+-{'-'*40}")
        
        for pair in high_risk_pairs[:30]:
            marker = "ğŸš¨" if pair['rental_mismatch'] else "âš ï¸"
            rental_status = f"{pair['apt1_rental']}/{pair['apt2_rental']}"
            print(f"{pair['similarity']:.4f}   | {marker} {rental_status:4} | {pair['apt1']:40} | {pair['apt2']:40}")
        
        return high_risk_pairs
    
    def analyze_danji_cha_patterns(self):
        """ë‹¨ì§€ ë²ˆí˜¸/ì°¨ìˆ˜ íŒ¨í„´ ë¶„ì„"""
        print(f"\n{'='*80}")
        print(f"{'3ï¸âƒ£  ë‹¨ì§€ ë²ˆí˜¸ / ì°¨ìˆ˜ íŒ¨í„´':^80}")
        print(f"{'='*80}")
        
        # ë‹¨ì§€ ë²ˆí˜¸ ë¶„í¬
        danji_apts = [apt for apt in self.apartments if apt['danji'] is not None]
        danji_counts = Counter(apt['danji'] for apt in danji_apts)
        
        print(f"\në‹¨ì§€ ë²ˆí˜¸ ìˆëŠ” ì•„íŒŒíŠ¸: {len(danji_apts):,}ê°œ ({len(danji_apts)/len(self.apartments)*100:.1f}%)")
        print(f"ë‹¨ì§€ ë²ˆí˜¸ ë²”ìœ„: {min(danji_counts.keys())} ~ {max(danji_counts.keys())}")
        
        print(f"\në‹¨ì§€ ë²ˆí˜¸ ë¶„í¬ (Top 10):")
        print(f"{'ë‹¨ì§€':^6} | {'ë¹ˆë„':>10}")
        print(f"{'-'*6}-+-{'-'*10}")
        for danji, count in danji_counts.most_common(10):
            print(f"{danji:^6} | {count:>10,}")
        
        # ì°¨ìˆ˜ ë¶„í¬
        cha_apts = [apt for apt in self.apartments if apt['cha'] is not None]
        cha_counts = Counter(apt['cha'] for apt in cha_apts)
        
        print(f"\nì°¨ìˆ˜ ìˆëŠ” ì•„íŒŒíŠ¸: {len(cha_apts):,}ê°œ ({len(cha_apts)/len(self.apartments)*100:.1f}%)")
        if cha_counts:
            print(f"ì°¨ìˆ˜ ë²”ìœ„: {min(cha_counts.keys())} ~ {max(cha_counts.keys())}")
            
            print(f"\nì°¨ìˆ˜ ë¶„í¬ (Top 10):")
            print(f"{'ì°¨ìˆ˜':^6} | {'ë¹ˆë„':>10}")
            print(f"{'-'*6}-+-{'-'*10}")
            for cha, count in cha_counts.most_common(10):
                print(f"{cha:^6} | {count:>10,}")
    
    def analyze_brand_distribution(self):
        """ë¸Œëœë“œ ë¶„í¬ ë¶„ì„"""
        print(f"\n{'='*80}")
        print(f"{'4ï¸âƒ£  ë¸Œëœë“œ ë¶„í¬':^80}")
        print(f"{'='*80}")
        
        branded_apts = [apt for apt in self.apartments if apt['brand'] is not None]
        brand_counts = Counter(apt['brand'] for apt in branded_apts)
        
        print(f"\në¸Œëœë“œ ìˆëŠ” ì•„íŒŒíŠ¸: {len(branded_apts):,}ê°œ ({len(branded_apts)/len(self.apartments)*100:.1f}%)")
        
        print(f"\në¸Œëœë“œë³„ ë¶„í¬:")
        print(f"{'ë¸Œëœë“œ':15} | {'ë¶„ì–‘':>10} | {'ì„ëŒ€':>10} | {'í•©ê³„':>10}")
        print(f"{'-'*15}-+-{'-'*10}-+-{'-'*10}-+-{'-'*10}")
        
        for brand in MAJOR_BRANDS:
            branded = [apt for apt in branded_apts if apt['brand'] == brand]
            rental = sum(1 for apt in branded if apt['is_rental'])
            non_rental = len(branded) - rental
            print(f"{brand:15} | {non_rental:>10,} | {rental:>10,} | {len(branded):>10,}")
    
    def analyze_name_complexity(self):
        """ì´ë¦„ ê¸¸ì´ ë° ë³µì¡ë„"""
        print(f"\n{'='*80}")
        print(f"{'5ï¸âƒ£  ì´ë¦„ ê¸¸ì´ ë° ë³µì¡ë„':^80}")
        print(f"{'='*80}")
        
        # ì´ë¦„ ê¸¸ì´ ë¶„í¬
        name_lengths = [len(apt['apt_name']) for apt in self.apartments]
        avg_length = sum(name_lengths) / len(name_lengths)
        
        length_bins = {
            'ë§¤ìš° ì§§ìŒ (1-5ì)': sum(1 for l in name_lengths if l <= 5),
            'ì§§ìŒ (6-10ì)': sum(1 for l in name_lengths if 6 <= l <= 10),
            'ë³´í†µ (11-15ì)': sum(1 for l in name_lengths if 11 <= l <= 15),
            'ê¹€ (16-20ì)': sum(1 for l in name_lengths if 16 <= l <= 20),
            'ë§¤ìš° ê¹€ (21ì+)': sum(1 for l in name_lengths if l >= 21),
        }
        
        print(f"\ní‰ê·  ì´ë¦„ ê¸¸ì´: {avg_length:.1f}ì")
        print(f"\nê¸¸ì´ë³„ ë¶„í¬:")
        print(f"{'ê¸¸ì´ ë²”ìœ„':20} | {'ë¹ˆë„':>10} | {'ë¹„ìœ¨':>8}")
        print(f"{'-'*20}-+-{'-'*10}-+-{'-'*8}")
        for category, count in length_bins.items():
            ratio = count / len(self.apartments) * 100
            print(f"{category:20} | {count:>10,} | {ratio:>7.2f}%")
        
        # íŠ¹ìˆ˜ë¬¸ì ì‚¬ìš©
        special_chars_count = sum(1 for apt in self.apartments if re.search(r'[^\wê°€-í£\s]', apt['apt_name']))
        print(f"\níŠ¹ìˆ˜ë¬¸ì í¬í•¨: {special_chars_count:,}ê°œ ({special_chars_count/len(self.apartments)*100:.1f}%)")
        
        # ê´„í˜¸ ì‚¬ìš©
        parentheses_count = sum(1 for apt in self.apartments if '(' in apt['apt_name'] or '[' in apt['apt_name'])
        print(f"ê´„í˜¸ í¬í•¨: {parentheses_count:,}ê°œ ({parentheses_count/len(self.apartments)*100:.1f}%)")
    
    def find_potential_duplicates(self):
        """ì¤‘ë³µ ê°€ëŠ¥ì„± ìˆëŠ” ì•„íŒŒíŠ¸ ì°¾ê¸° (kapt_codeëŠ” ë‹¤ë¥¸ë° ì´ë¦„ì´ ê°™ê±°ë‚˜ ë§¤ìš° ìœ ì‚¬)"""
        print(f"\n{'='*80}")
        print(f"{'6ï¸âƒ£  ì ì¬ì  ì¤‘ë³µ ì•„íŒŒíŠ¸ (kapt_code ë‹¤ë¥¸ë° ì´ë¦„ ìœ ì‚¬)':^80}")
        print(f"{'='*80}")
        
        # ì •ê·œí™”ëœ ì´ë¦„ìœ¼ë¡œ ê·¸ë£¹í™”
        by_normalized_name = defaultdict(list)
        for apt in self.apartments:
            by_normalized_name[apt['normalized_name']].append(apt)
        
        # 2ê°œ ì´ìƒ ìˆëŠ” ê²½ìš°ë§Œ
        duplicates = {name: apts for name, apts in by_normalized_name.items() if len(apts) >= 2}
        
        print(f"\nì •ê·œí™” í›„ ì´ë¦„ì´ ê°™ì€ ê·¸ë£¹: {len(duplicates):,}ê°œ")
        
        # ìƒìœ„ 20ê°œ
        sorted_duplicates = sorted(duplicates.items(), key=lambda x: len(x[1]), reverse=True)
        
        print(f"\nìƒìœ„ 20ê°œ (ë§ì€ ìˆœ):")
        print(f"{'ê°œìˆ˜':^6} | {'ì •ê·œí™”ëœ ì´ë¦„':30} | {'kapt_codeë“¤':50}")
        print(f"{'-'*6}-+-{'-'*30}-+-{'-'*50}")
        
        for norm_name, apts in sorted_duplicates[:20]:
            kapt_codes = ', '.join(apt['kapt_code'] for apt in apts[:5])
            if len(apts) > 5:
                kapt_codes += f", ... ({len(apts)-5}ê°œ ë”)"
            print(f"{len(apts):^6} | {norm_name:30} | {kapt_codes:50}")
    
    def generate_recommendations(self):
        """ê°œì„  ì œì•ˆ"""
        print(f"\n{'='*80}")
        print(f"{'ğŸ’¡ ë§¤ì¹­ ì •í™•ë„ ê°œì„  ì œì•ˆ':^80}")
        print(f"{'='*80}\n")
        
        print("1. **ì„ëŒ€ í‚¤ì›Œë“œ Veto ê°•í™”** âœ… (ì´ë¯¸ êµ¬í˜„ë¨)")
        print(f"   - ì„ëŒ€ ì•„íŒŒíŠ¸: {len(self.rental_apts):,}ê°œ ({len(self.rental_apts)/len(self.apartments)*100:.1f}%)")
        print(f"   - íš¨ê³¼: ì„ëŒ€ vs ë¶„ì–‘ ë¯¸ìŠ¤ë§¤ì¹­ ë°©ì§€")
        
        print("\n2. **ë‹¨ì§€ ë²ˆí˜¸/ì°¨ìˆ˜ ê²€ì¦ ê°•í™”**")
        danji_apts = sum(1 for apt in self.apartments if apt['danji'] is not None)
        cha_apts = sum(1 for apt in self.apartments if apt['cha'] is not None)
        print(f"   - ë‹¨ì§€ ë²ˆí˜¸ ìˆìŒ: {danji_apts:,}ê°œ ({danji_apts/len(self.apartments)*100:.1f}%)")
        print(f"   - ì°¨ìˆ˜ ìˆìŒ: {cha_apts:,}ê°œ ({cha_apts/len(self.apartments)*100:.1f}%)")
        print(f"   - ì œì•ˆ: ë‹¨ì§€/ì°¨ìˆ˜ê°€ ë‹¤ë¥´ë©´ ë¬´ì¡°ê±´ ë§¤ì¹­ ê±°ë¶€ (í˜„ì¬ êµ¬í˜„ ìƒíƒœ í™•ì¸ í•„ìš”)")
        
        print("\n3. **ë¸Œëœë“œ ê²€ì¦ ê°•í™”**")
        branded = sum(1 for apt in self.apartments if apt['brand'] is not None)
        print(f"   - ì£¼ìš” ë¸Œëœë“œ ìˆìŒ: {branded:,}ê°œ ({branded/len(self.apartments)*100:.1f}%)")
        print(f"   - ì œì•ˆ: ì£¼ìš” ë¸Œëœë“œ(ìì´, ë˜ë¯¸ì•ˆ ë“±)ê°€ APIì™€ DBì—ì„œ ë‹¤ë¥´ë©´ Veto")
        
        print("\n4. **ê°™ì€ ì§€ì—­ ë‚´ ìœ ì‚¬ ì´ë¦„ íŠ¹ë³„ ì²˜ë¦¬**")
        print(f"   - ì œì•ˆ: ìœ ì‚¬ë„ 0.85+ ì•„íŒŒíŠ¸ëŠ” ì¶”ê°€ ê²€ì¦ í•„ìˆ˜")
        print(f"     (ì§€ë²ˆ, ê±´ì¶•ë…„ë„, ë‹¨ì§€ ë²ˆí˜¸ ëª¨ë‘ ì¼ì¹˜í•´ì•¼ ë§¤ì¹­)")
        
        print("\n5. **ì •ê·œí™” í›„ ì¤‘ë³µ ì´ë¦„ ì²˜ë¦¬**")
        by_normalized = defaultdict(list)
        for apt in self.apartments:
            by_normalized[apt['normalized_name']].append(apt)
        duplicates = sum(1 for apts in by_normalized.values() if len(apts) >= 2)
        print(f"   - ì •ê·œí™” í›„ ì¤‘ë³µ: {duplicates:,}ê°œ")
        print(f"   - ì œì•ˆ: ì¤‘ë³µ ì´ë¦„ì€ kapt_codeë¡œ êµ¬ë¶„, region_id ì¶”ê°€ ê²€ì¦")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    csv_path = "/home/rivermoon/Documents/Github-Techeer/techeer-team-b-2026/db_backup/apartments.csv"
    
    analyzer = ApartmentAnalyzer(csv_path)
    analyzer.load_data()
    
    # ë¶„ì„ ì‹¤í–‰
    analyzer.analyze_rental_distribution()
    high_risk = analyzer.analyze_same_region_similar_names(similarity_threshold=0.85)
    analyzer.analyze_danji_cha_patterns()
    analyzer.analyze_brand_distribution()
    analyzer.analyze_name_complexity()
    analyzer.find_potential_duplicates()
    analyzer.generate_recommendations()
    
    print(f"\n{'='*80}")
    print(f"âœ… ë¶„ì„ ì™„ë£Œ!")
    print(f"{'='*80}\n")


if __name__ == "__main__":
    main()
