"""
AI ê´€ë ¨ API ì—”ë“œí¬ì¸íŠ¸

AI ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” APIì…ë‹ˆë‹¤.
"""
import logging
import sys
import time
from fastapi import APIRouter, Depends, HTTPException, status, Query
from sqlalchemy.ext.asyncio import AsyncSession

from app.api.v1.deps import get_db, get_current_user
from app.models.account import Account
from app.crud.my_property import my_property as my_property_crud
from app.crud.state import state as state_crud
from app.services.ai_service import ai_service
from datetime import datetime
from sqlalchemy.orm import selectinload
from sqlalchemy import select
from app.models.apartment import Apartment
from app.core.exceptions import (
    NotFoundException,
    ExternalAPIException
)
from app.utils.cache import (
    get_from_cache,
    set_to_cache,
    get_my_property_compliment_cache_key,
    get_apartment_summary_cache_key
)
from app.schemas.ai import AISearchRequest, AISearchResponse, AISearchCriteria
from app.services.apartment import apartment_service

# ë¡œê±° ì„¤ì • (Docker ë¡œê·¸ì— ì¶œë ¥ë˜ë„ë¡)
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
if not logger.handlers:
    handler = logging.StreamHandler(sys.stdout)
    handler.setLevel(logging.INFO)
    formatter = logging.Formatter(
        '%(asctime)s | %(levelname)s | %(name)s | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    logger.propagate = True  # ë£¨íŠ¸ ë¡œê±°ë¡œë„ ì „íŒŒ

router = APIRouter()


@router.post(
    "/summary/my-property",
    response_model=dict,
    status_code=status.HTTP_200_OK,
    tags=["ğŸ¤– AI (ì¸ê³µì§€ëŠ¥)"],
    summary="ë‚´ ì§‘ ì¹­ì°¬ê¸€ ìƒì„±",
    description="""
    AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‚´ ì§‘ì— ëŒ€í•œ ì¹­ì°¬ê¸€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    ### ê¸°ëŠ¥ ì„¤ëª…
    - Gemini AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‚´ ì§‘ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë”°ëœ»í•˜ê³  ê¸ì •ì ì¸ ì¹­ì°¬ê¸€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    - ìƒì„±ëœ ì¹­ì°¬ê¸€ì€ ìºì‹œë˜ì–´ ë™ì¼í•œ ë‚´ì§‘ì— ëŒ€í•œ ì¬ìš”ì²­ ì‹œ ë¹ ë¥´ê²Œ ë°˜í™˜ë©ë‹ˆë‹¤.
    - ì¹­ì°¬ê¸€ì€ 200ì ì´ë‚´ë¡œ ìƒì„±ë©ë‹ˆë‹¤.
    
    ### ìš”ì²­ ì •ë³´
    - `property_id`: ì¹­ì°¬ê¸€ì„ ìƒì„±í•  ë‚´ ì§‘ ID (query parameter)
    
    ### ì‘ë‹µ ì •ë³´
    - `compliment`: AIê°€ ìƒì„±í•œ ì¹­ì°¬ê¸€
    - `generated_at`: ìƒì„± ì¼ì‹œ
    
    ### ì œí•œì‚¬í•­
    - GEMINI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    - ë‚´ ì§‘ ì •ë³´ê°€ ì¶©ë¶„í•´ì•¼ ì¢‹ì€ ì¹­ì°¬ê¸€ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """,
    responses={
        200: {
            "description": "ì¹­ì°¬ê¸€ ìƒì„± ì„±ê³µ",
            "content": {
                "application/json": {
                    "example": {
                        "success": True,
                        "data": {
                            "property_id": 1,
                            "compliment": "ì´ ì§‘ì€ ì •ë§ ë©‹ì§„ ê³³ì´ë„¤ìš”! ê°•ë‚¨êµ¬ì˜ ì¤‘ì‹¬ë¶€ì— ìœ„ì¹˜í•œ ë˜ë¯¸ì•ˆ ê°•ë‚¨íŒŒí¬ëŠ” ìµœê³ ì˜ ì…ì§€ë¥¼ ìë‘í•©ë‹ˆë‹¤. 84.5ã¡ì˜ ë„‰ë„‰í•œ ì „ìš©ë©´ì ì€ ê°€ì¡±ì´ í•¨ê»˜ ìƒí™œí•˜ê¸°ì— ì¶©ë¶„í•œ ê³µê°„ì„ ì œê³µí•©ë‹ˆë‹¤. í˜„ì¬ ì‹œì„¸ 85,000ë§Œì›ì€ ì´ ì§€ì—­ì˜ ê°€ì¹˜ë¥¼ ì˜ ë°˜ì˜í•˜ê³  ìˆìœ¼ë©°, ì•ìœ¼ë¡œë„ ì§€ì†ì ì¸ ê°€ì¹˜ ìƒìŠ¹ì´ ê¸°ëŒ€ë˜ëŠ” ê³³ì…ë‹ˆë‹¤. ì •ë§ ë¶€ëŸ¬ìš´ ì§‘ì´ì—ìš”!",
                            "generated_at": "2026-01-14T15:30:00Z"
                        }
                    }
                }
            }
        },
        404: {
            "description": "ë‚´ ì§‘ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ"
        },
        503: {
            "description": "AI ì„œë¹„ìŠ¤ ì‚¬ìš© ë¶ˆê°€ (GEMINI_API_KEY ë¯¸ì„¤ì • ë˜ëŠ” API ì˜¤ë¥˜)"
        },
        401: {
            "description": "ì¸ì¦ í•„ìš”"
        }
    }
)
async def generate_property_compliment(
    property_id: int = Query(..., description="ì¹­ì°¬ê¸€ì„ ìƒì„±í•  ë‚´ ì§‘ ID", gt=0),
    current_user: Account = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    ë‚´ ì§‘ ì¹­ì°¬ê¸€ ìƒì„±
    
    AIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‚´ ì§‘ì— ëŒ€í•œ ì¹­ì°¬ê¸€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    ìƒì„±ëœ ì¹­ì°¬ê¸€ì€ ìºì‹œë˜ì–´ ì¬ì‚¬ìš©ë©ë‹ˆë‹¤.
    """
    # AI ì„œë¹„ìŠ¤ê°€ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸
    if ai_service is None:
        raise ExternalAPIException("AI ì„œë¹„ìŠ¤ê°€ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. GEMINI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    
    # 1. ë‚´ ì§‘ ì¡°íšŒ
    property_obj = await my_property_crud.get_by_account_and_id(
        db,
        account_id=current_user.account_id,
        property_id=property_id
    )
    
    if not property_obj:
        raise NotFoundException("ë‚´ ì§‘")
    
    # 2. ìºì‹œì—ì„œ ì¡°íšŒ ì‹œë„
    cache_key = get_my_property_compliment_cache_key(property_id)
    cached_compliment = await get_from_cache(cache_key)
    
    if cached_compliment is not None:
        # ìºì‹œ íˆíŠ¸: ìºì‹œëœ ì¹­ì°¬ê¸€ ë°˜í™˜
        return {
            "success": True,
            "data": {
                "property_id": property_id,
                "compliment": cached_compliment.get("compliment"),
                "generated_at": cached_compliment.get("generated_at")
            }
        }
    
    # 3. ì•„íŒŒíŠ¸ ë° ì§€ì—­ ì •ë³´ ì¡°íšŒ
    apartment = property_obj.apartment  # Apartment ê´€ê³„ ë¡œë“œë¨
    
    # State ê´€ê³„ ì •ë³´ í¬í•¨ (region_idë¡œ ì§ì ‘ ì¡°íšŒí•˜ì—¬ lazy loading ë°©ì§€)
    region = None
    if apartment and apartment.region_id:
        region = await state_crud.get(db, id=apartment.region_id)
    
    # ì•„íŒŒíŠ¸ ìƒì„¸ ì •ë³´ ì¡°íšŒ
    apart_detail = apartment.apart_detail if apartment else None
    
    # 4. AIì— ì „ë‹¬í•  ë°ì´í„° êµ¬ì„±
    property_data = {
        "nickname": property_obj.nickname,
        "apt_name": apartment.apt_name if apartment else None,
        "kapt_code": apartment.kapt_code if apartment else None,
        "region_name": region.region_name if region else None,
        "city_name": region.city_name if region else None,
        "exclusive_area": float(property_obj.exclusive_area) if property_obj.exclusive_area else None,
        "current_market_price": property_obj.current_market_price,
        "memo": property_obj.memo,
        # êµìœ¡ ì‹œì„¤ ë° êµí†µ ì •ë³´ ì¶”ê°€
        "education_facility": apart_detail.educationFacility if apart_detail else None,
        "subway_line": apart_detail.subway_line if apart_detail else None,
        "subway_station": apart_detail.subway_station if apart_detail else None,
        "subway_time": apart_detail.subway_time if apart_detail else None,
    }
    
    # 5. AI ì¹­ì°¬ê¸€ ìƒì„±
    try:
        compliment = await ai_service.generate_property_compliment(property_data)
    except Exception as e:
        raise ExternalAPIException(f"AI ì¹­ì°¬ê¸€ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    # 6. ìƒì„± ì¼ì‹œ
    generated_at = datetime.utcnow().isoformat() + "Z"
    
    # 7. ìºì‹œì— ì €ì¥ (TTL: 24ì‹œê°„ - ì¹­ì°¬ê¸€ì€ ìì£¼ ë³€ê²½ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ê¸´ TTL)
    await set_to_cache(
        cache_key,
        {
            "compliment": compliment,
            "generated_at": generated_at
        },
        ttl=86400  # 24ì‹œê°„
    )
    
    return {
        "success": True,
        "data": {
            "property_id": property_id,
            "compliment": compliment,
            "generated_at": generated_at
        }
    }


@router.post(
    "/summary/apartment",
    response_model=dict,
    status_code=status.HTTP_200_OK,
    tags=["ğŸ¤– AI (ì¸ê³µì§€ëŠ¥)"],
    summary="ì•„íŒŒíŠ¸ ì •ë³´ AI ìš”ì•½ ìƒì„±",
    description="""
    AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì•„íŒŒíŠ¸ì— ëŒ€í•œ ê°ê´€ì ì´ê³  ìœ ìš©í•œ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    ### ê¸°ëŠ¥ ì„¤ëª…
    - Gemini AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì•„íŒŒíŠ¸ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.
    - ìƒì„±ëœ ìš”ì•½ì€ ìºì‹œë˜ì–´ ë™ì¼í•œ ì•„íŒŒíŠ¸ì— ëŒ€í•œ ì¬ìš”ì²­ ì‹œ ë¹ ë¥´ê²Œ ë°˜í™˜ë©ë‹ˆë‹¤.
    - ìš”ì•½ì€ 300ì ì´ë‚´ë¡œ ìƒì„±ë©ë‹ˆë‹¤.
    
    ### ìš”ì²­ ì •ë³´
    - `apt_id`: ìš”ì•½ì„ ìƒì„±í•  ì•„íŒŒíŠ¸ ID (query parameter)
    
    ### ì‘ë‹µ ì •ë³´
    - `summary`: AIê°€ ìƒì„±í•œ ìš”ì•½
    - `apt_id`: ì•„íŒŒíŠ¸ ID
    - `generated_at`: ìƒì„± ì¼ì‹œ
    
    ### ì œí•œì‚¬í•­
    - GEMINI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    - ì•„íŒŒíŠ¸ ì •ë³´ê°€ ì¶©ë¶„í•´ì•¼ ì¢‹ì€ ìš”ì•½ì„ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """,
    responses={
        200: {
            "description": "ìš”ì•½ ìƒì„± ì„±ê³µ",
            "content": {
                "application/json": {
                    "example": {
                        "success": True,
                        "data": {
                            "apt_id": 1,
                            "summary": "ì´ ì•„íŒŒíŠ¸ëŠ” ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬ì— ìœ„ì¹˜í•œ ëŒ€ê·œëª¨ ì•„íŒŒíŠ¸ ë‹¨ì§€ì…ë‹ˆë‹¤. ì´ 500ì„¸ëŒ€ ê·œëª¨ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ì§€í•˜ì²  2í˜¸ì„  ê°•ë‚¨ì—­ê³¼ ë„ë³´ 5ë¶„ ê±°ë¦¬ì— ìœ„ì¹˜í•˜ì—¬ êµí†µ ì ‘ê·¼ì„±ì´ ìš°ìˆ˜í•©ë‹ˆë‹¤. ì¸ê·¼ì— ì´ˆë“±í•™êµì™€ ì¤‘í•™êµê°€ ìˆì–´ êµìœ¡ í™˜ê²½ì´ ì–‘í˜¸í•˜ë©°, ì´ ì£¼ì°¨ëŒ€ìˆ˜ 300ëŒ€ë¡œ ì£¼ì°¨ ì‹œì„¤ë„ ì¶©ë¶„í•©ë‹ˆë‹¤.",
                            "generated_at": "2026-01-14T15:30:00Z"
                        }
                    }
                }
            }
        },
        404: {
            "description": "ì•„íŒŒíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ"
        },
        503: {
            "description": "AI ì„œë¹„ìŠ¤ ì‚¬ìš© ë¶ˆê°€ (GEMINI_API_KEY ë¯¸ì„¤ì • ë˜ëŠ” API ì˜¤ë¥˜)"
        }
    }
)
async def generate_apartment_summary(
    apt_id: int = Query(..., description="ìš”ì•½ì„ ìƒì„±í•  ì•„íŒŒíŠ¸ ID", gt=0),
    db: AsyncSession = Depends(get_db)
):
    """
    ì•„íŒŒíŠ¸ ì •ë³´ AI ìš”ì•½ ìƒì„±
    
    AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì•„íŒŒíŠ¸ì— ëŒ€í•œ ê°ê´€ì ì´ê³  ìœ ìš©í•œ ìš”ì•½ì„ ìƒì„±í•©ë‹ˆë‹¤.
    ìƒì„±ëœ ìš”ì•½ì€ ìºì‹œë˜ì–´ ì¬ì‚¬ìš©ë©ë‹ˆë‹¤.
    """
    # AI ì„œë¹„ìŠ¤ê°€ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸
    if ai_service is None:
        raise ExternalAPIException("AI ì„œë¹„ìŠ¤ê°€ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. GEMINI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    
    # 1. ìºì‹œì—ì„œ ì¡°íšŒ ì‹œë„
    cache_key = get_apartment_summary_cache_key(apt_id)
    cached_summary = await get_from_cache(cache_key)
    
    if cached_summary is not None:
        # ìºì‹œ íˆíŠ¸: ìºì‹œëœ ìš”ì•½ ë°˜í™˜
        return {
            "success": True,
            "data": {
                "apt_id": apt_id,
                "summary": cached_summary.get("summary"),
                "generated_at": cached_summary.get("generated_at")
            }
        }
    
    # 2. ì•„íŒŒíŠ¸ ì •ë³´ ì¡°íšŒ (eager loadingìœ¼ë¡œ ê´€ê³„ ì •ë³´ í¬í•¨)
    result = await db.execute(
        select(Apartment)
        .where(
            Apartment.apt_id == apt_id,
            Apartment.is_deleted == False
        )
        .options(
            selectinload(Apartment.region),  # State ê´€ê³„ ë¡œë“œ
            selectinload(Apartment.apart_detail)  # ApartDetail ê´€ê³„ ë¡œë“œ (1ëŒ€1)
        )
    )
    apartment = result.scalar_one_or_none()
    
    if not apartment:
        raise NotFoundException("ì•„íŒŒíŠ¸")
    
    # 3. ì§€ì—­ ì •ë³´ ë° ìƒì„¸ ì •ë³´ ì¶”ì¶œ
    region = apartment.region if apartment else None
    apart_detail = apartment.apart_detail if apartment else None
    
    # 4. AIì— ì „ë‹¬í•  ë°ì´í„° êµ¬ì„±
    apartment_data = {
        "apt_name": apartment.apt_name if apartment else None,
        "kapt_code": apartment.kapt_code if apartment else None,
        "region_name": region.region_name if region else None,
        "city_name": region.city_name if region else None,
        "road_address": apart_detail.road_address if apart_detail else None,
        "jibun_address": apart_detail.jibun_address if apart_detail else None,
        "total_household_cnt": apart_detail.total_household_cnt if apart_detail else None,
        "total_building_cnt": apart_detail.total_building_cnt if apart_detail else None,
        "highest_floor": apart_detail.highest_floor if apart_detail else None,
        "use_approval_date": apart_detail.use_approval_date.isoformat() if apart_detail and apart_detail.use_approval_date else None,
        "total_parking_cnt": apart_detail.total_parking_cnt if apart_detail else None,
        "builder_name": apart_detail.builder_name if apart_detail else None,
        "code_heat_nm": apart_detail.code_heat_nm if apart_detail else None,
        "education_facility": apart_detail.educationFacility if apart_detail else None,
        "subway_line": apart_detail.subway_line if apart_detail else None,
        "subway_station": apart_detail.subway_station if apart_detail else None,
        "subway_time": apart_detail.subway_time if apart_detail else None,
    }
    
    # 5. AI ìš”ì•½ ìƒì„±
    try:
        summary = await ai_service.generate_apartment_summary(apartment_data)
    except Exception as e:
        raise ExternalAPIException(f"AI ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    # 6. ìƒì„± ì¼ì‹œ
    generated_at = datetime.utcnow().isoformat() + "Z"
    
    # 7. ìºì‹œì— ì €ì¥ (TTL: 24ì‹œê°„ - ìš”ì•½ì€ ìì£¼ ë³€ê²½ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ê¸´ TTL)
    await set_to_cache(
        cache_key,
        {
            "summary": summary,
            "generated_at": generated_at
        },
        ttl=86400  # 24ì‹œê°„
    )
    
    return {
        "success": True,
        "data": {
            "apt_id": apt_id,
            "summary": summary,
            "generated_at": generated_at
        }
    }


@router.post(
    "/search",
    response_model=AISearchResponse,
    status_code=status.HTTP_200_OK,
    tags=["ğŸ¤– AI (ì¸ê³µì§€ëŠ¥)"],
    summary="AI ìì—°ì–´ ì•„íŒŒíŠ¸ ê²€ìƒ‰",
    description="""
    AIì—ê²Œ ìì—°ì–´ë¡œ ì›í•˜ëŠ” ì§‘ì— ëŒ€í•œ ì„¤ëª…ì„ í•˜ë©´ AIê°€ íŒŒì‹±í•´ì„œ ê´€ë ¨ëœ ì•„íŒŒíŠ¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    ### ê¸°ëŠ¥ ì„¤ëª…
    - ì‚¬ìš©ìê°€ ìì—°ì–´ë¡œ ì›í•˜ëŠ” ì§‘ì˜ ì¡°ê±´ì„ ì…ë ¥í•©ë‹ˆë‹¤ (ì˜ˆ: "ê°•ë‚¨êµ¬ì— ìˆëŠ” 30í‰ëŒ€ ì•„íŒŒíŠ¸, ì§€í•˜ì² ì—­ì—ì„œ 10ë¶„ ì´ë‚´, ì´ˆë“±í•™êµ ê·¼ì²˜")
    - AIê°€ ìì—°ì–´ë¥¼ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ê²€ìƒ‰ ì¡°ê±´ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤
    - ë³€í™˜ëœ ì¡°ê±´ìœ¼ë¡œ ì•„íŒŒíŠ¸ë¥¼ ê²€ìƒ‰í•˜ì—¬ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤
    
    ### ì§€ì›í•˜ëŠ” ê²€ìƒ‰ ì¡°ê±´
    - ìœ„ì¹˜: ì§€ì—­ëª… (ì˜ˆ: "ê°•ë‚¨êµ¬", "ì„œìš¸ì‹œ ê°•ë‚¨êµ¬")
    - í‰ìˆ˜: ì „ìš©ë©´ì  (ì˜ˆ: "30í‰ëŒ€", "20í‰~30í‰")
    - ê°€ê²©: ë§¤ë§¤ê°€ê²© (ì˜ˆ: "5ì–µ", "3ì–µ~5ì–µ")
    - ì§€í•˜ì²  ê±°ë¦¬: ì§€í•˜ì² ì—­ê¹Œì§€ ë„ë³´ ì‹œê°„ (ì˜ˆ: "10ë¶„ ì´ë‚´", "ì§€í•˜ì²  ê·¼ì²˜")
    - êµìœ¡ì‹œì„¤: êµìœ¡ì‹œì„¤ ìœ ë¬´ (ì˜ˆ: "ì´ˆë“±í•™êµ ê·¼ì²˜", "í•™êµ ê·¼ì²˜")
    
    ### ìš”ì²­ ì •ë³´
    - `query`: ìì—°ì–´ ê²€ìƒ‰ ì¿¼ë¦¬ (5ì ì´ìƒ, 500ì ì´í•˜)
    
    ### ì‘ë‹µ ì •ë³´
    - `criteria`: AIê°€ íŒŒì‹±í•œ ê²€ìƒ‰ ì¡°ê±´
    - `apartments`: ê²€ìƒ‰ ê²°ê³¼ ì•„íŒŒíŠ¸ ëª©ë¡
    - `count`: ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜
    - `total`: ì „ì²´ ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜
    
    ### ì œí•œì‚¬í•­
    - GEMINI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    - ìì—°ì–´ íŒŒì‹±ì˜ ì •í™•ë„ëŠ” ì…ë ¥ëœ ì„¤ëª…ì˜ ëª…í™•ë„ì— ë”°ë¼ ë‹¬ë¼ì§‘ë‹ˆë‹¤.
    """,
    responses={
        200: {
            "description": "ê²€ìƒ‰ ì„±ê³µ",
            "content": {
                "application/json": {
                    "example": {
                        "success": True,
                        "data": {
                            "criteria": {
                                "location": "ê°•ë‚¨êµ¬",
                                "min_area": 84.0,
                                "max_area": 114.0,
                                "subway_max_distance_minutes": 10,
                                "has_education_facility": True,
                                "raw_query": "ê°•ë‚¨êµ¬ì— ìˆëŠ” 30í‰ëŒ€ ì•„íŒŒíŠ¸, ì§€í•˜ì² ì—­ì—ì„œ 10ë¶„ ì´ë‚´, ì´ˆë“±í•™êµ ê·¼ì²˜",
                                "parsed_confidence": 0.9
                            },
                            "apartments": [
                                {
                                    "apt_id": 1,
                                    "apt_name": "ë˜ë¯¸ì•ˆ ê°•ë‚¨íŒŒí¬",
                                    "address": "ì„œìš¸íŠ¹ë³„ì‹œ ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œ 123",
                                    "location": {"lat": 37.5665, "lng": 126.9780},
                                    "exclusive_area": 84.5,
                                    "average_price": 85000,
                                    "subway_station": "ê°•ë‚¨ì—­",
                                    "subway_line": "2í˜¸ì„ ",
                                    "subway_time": "5~10ë¶„ì´ë‚´",
                                    "education_facility": "ì´ˆë“±í•™êµ(ê°•ë‚¨ì´ˆë“±í•™êµ)"
                                }
                            ],
                            "count": 1,
                            "total": 1
                        }
                    }
                }
            }
        },
        400: {
            "description": "ì˜ëª»ëœ ìš”ì²­ (ì¿¼ë¦¬ ê¸¸ì´ ë¶€ì¡± ë“±)"
        },
        503: {
            "description": "AI ì„œë¹„ìŠ¤ ì‚¬ìš© ë¶ˆê°€ (GEMINI_API_KEY ë¯¸ì„¤ì • ë˜ëŠ” API ì˜¤ë¥˜)"
        }
    }
)
async def ai_search_apartments(
    request: AISearchRequest,
    db: AsyncSession = Depends(get_db)
):
    """
    AI ìì—°ì–´ ì•„íŒŒíŠ¸ ê²€ìƒ‰
    
    ì‚¬ìš©ìê°€ ìì—°ì–´ë¡œ ì›í•˜ëŠ” ì§‘ì— ëŒ€í•œ ì„¤ëª…ì„ ì…ë ¥í•˜ë©´
    AIê°€ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ê²€ìƒ‰ ì¡°ê±´ìœ¼ë¡œ ë³€í™˜í•˜ê³ ,
    í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ì•„íŒŒíŠ¸ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # AI ì„œë¹„ìŠ¤ê°€ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸
    if ai_service is None:
        raise ExternalAPIException("AI ì„œë¹„ìŠ¤ê°€ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. GEMINI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    
    # ì „ì²´ ì‹œì‘ ì‹œê°„
    total_start_time = time.time()
    logger.info(f"[AI_SEARCH] ========== ê²€ìƒ‰ ì‹œì‘ ==========")
    logger.info(f"[AI_SEARCH] ì¿¼ë¦¬: {request.query}")
    logger.info(f"[AI_SEARCH] ì‹œì‘ ì‹œê°„: {datetime.now().isoformat()}")
    
    # 1. AIë¡œ ìì—°ì–´ íŒŒì‹±
    parse_start_time = time.time()
    try:
        logger.info(f"[AI_SEARCH] [1ë‹¨ê³„] AI íŒŒì‹± ì‹œì‘ - ì‹œê°„: {datetime.now().isoformat()}")
        parsed_criteria = await ai_service.parse_search_query(request.query)
        parse_end_time = time.time()
        parse_duration = parse_end_time - parse_start_time
        logger.info(f"[AI_SEARCH] [1ë‹¨ê³„] AI íŒŒì‹± ì™„ë£Œ - ì†Œìš”ì‹œê°„: {parse_duration:.3f}ì´ˆ, ì‹œê°„: {datetime.now().isoformat()}")
        
        # ê²€ìƒ‰ì–´ í•´ì„ ë¶ˆê°€ ì²´í¬
        is_invalid = parsed_criteria.get("is_invalid", False)
        confidence = parsed_criteria.get("parsed_confidence", 0.0)
        
        if is_invalid or confidence < 0.3:
            logger.info(f"[AI_SEARCH] ê²€ìƒ‰ì–´ í•´ì„ ë¶ˆê°€ - is_invalid: {is_invalid}, confidence: {confidence}")
            return {
                "success": False,
                "data": {
                    "criteria": parsed_criteria,
                    "apartments": [],
                    "count": 0,
                    "total": 0,
                    "error_message": "ê²€ìƒ‰ì–´ë¥¼ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì•„íŒŒíŠ¸ ê´€ë ¨ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
                }
            }
        
        logger.info(f"[AI_SEARCH] íŒŒì‹±ëœ ì¡°ê±´ ìƒì„¸:")
        logger.info(f"[AI_SEARCH]   - location: {parsed_criteria.get('location')}")
        logger.info(f"[AI_SEARCH]   - region_id: {parsed_criteria.get('region_id')}")
        logger.info(f"[AI_SEARCH]   - apartment_name: {parsed_criteria.get('apartment_name')}")
        logger.info(f"[AI_SEARCH]   - min_area: {parsed_criteria.get('min_area')}, max_area: {parsed_criteria.get('max_area')}")
        logger.info(f"[AI_SEARCH]   - min_price: {parsed_criteria.get('min_price')}, max_price: {parsed_criteria.get('max_price')}")
        
        # ì „ì„¸/ì›”ì„¸ ì¡°ê±´ í™•ì¸
        min_deposit = parsed_criteria.get("min_deposit")
        max_deposit = parsed_criteria.get("max_deposit")
        min_monthly_rent = parsed_criteria.get("min_monthly_rent")
        max_monthly_rent = parsed_criteria.get("max_monthly_rent")
        
        if min_deposit or max_deposit:
            logger.info(f"[AI_SEARCH]   - ì „ì„¸ ì¡°ê±´ ë°œê²¬: min_deposit={min_deposit}ë§Œì›, max_deposit={max_deposit}ë§Œì›")
        if min_monthly_rent or max_monthly_rent:
            logger.info(f"[AI_SEARCH]   - ì›”ì„¸ ì¡°ê±´ ë°œê²¬: min_monthly_rent={min_monthly_rent}ë§Œì›, max_monthly_rent={max_monthly_rent}ë§Œì›")
    except Exception as e:
        parse_end_time = time.time()
        parse_duration = parse_end_time - parse_start_time
        logger.error(f"[AI_SEARCH] [1ë‹¨ê³„] AI íŒŒì‹± ì‹¤íŒ¨ - ì†Œìš”ì‹œê°„: {parse_duration:.3f}ì´ˆ, ì˜¤ë¥˜: {str(e)}, ì‹œê°„: {datetime.now().isoformat()}", exc_info=True)
        raise ExternalAPIException(f"AI ìì—°ì–´ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
    
    # 2. ì§€ì—­ëª…ì´ ìˆìœ¼ë©´ region_id ì¡°íšŒ
    region_lookup_start_time = time.time()
    logger.info(f"[AI_SEARCH] [2ë‹¨ê³„] ì§€ì—­ ID ì¡°íšŒ ì‹œì‘ - ì‹œê°„: {datetime.now().isoformat()}")
    region_id = parsed_criteria.get("region_id")
    region_lookup_duration = 0.0  # ì´ˆê¸°í™”
    if not region_id and parsed_criteria.get("location"):
        location_name = parsed_criteria.get("location")
        logger.info(f"[AI_SEARCH] ì§€ì—­ëª…ìœ¼ë¡œ region_id ì¡°íšŒ ì‹œë„ - location: {location_name}")
        
        # ì§€ì—­ëª…ìœ¼ë¡œ region_id ì°¾ê¸°
        # ì§€ì› í˜•ì‹:
        # - "ê²½ê¸°ë„ íŒŒì£¼ì‹œ ì•¼ë‹¹ë™" (3ë‹¨ê³„: ì‹œë„ ì‹œêµ°êµ¬ ë™)
        # - "íŒŒì£¼ì‹œ ì•¼ë‹¹ë™" (2ë‹¨ê³„: ì‹œêµ°êµ¬ ë™)
        # - "ê²½ê¸°ë„ íŒŒì£¼ì‹œ" (2ë‹¨ê³„: ì‹œë„ ì‹œêµ°êµ¬)
        # - "ì•¼ë‹¹ë™" (1ë‹¨ê³„: ë™)
        # - "íŒŒì£¼ì‹œ" (1ë‹¨ê³„: ì‹œêµ°êµ¬)
        try:
            from sqlalchemy import or_, and_
            from app.models.state import State
            
            # ì§€ì—­ëª… íŒŒì‹±
            parts = location_name.strip().split()
            
            # city_name ì •ê·œí™” ë§¤í•‘
            city_mapping = {
                "ì„œìš¸": "ì„œìš¸íŠ¹ë³„ì‹œ", "ë¶€ì‚°": "ë¶€ì‚°ê´‘ì—­ì‹œ", "ëŒ€êµ¬": "ëŒ€êµ¬ê´‘ì—­ì‹œ",
                "ì¸ì²œ": "ì¸ì²œê´‘ì—­ì‹œ", "ê´‘ì£¼": "ê´‘ì£¼ê´‘ì—­ì‹œ", "ëŒ€ì „": "ëŒ€ì „ê´‘ì—­ì‹œ",
                "ìš¸ì‚°": "ìš¸ì‚°ê´‘ì—­ì‹œ", "ì„¸ì¢…": "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ", "ê²½ê¸°": "ê²½ê¸°ë„",
                "ê°•ì›": "ê°•ì›íŠ¹ë³„ìì¹˜ë„", "ì¶©ë¶": "ì¶©ì²­ë¶ë„", "ì¶©ë‚¨": "ì¶©ì²­ë‚¨ë„",
                "ì „ë¶": "ì „ë¶íŠ¹ë³„ìì¹˜ë„", "ì „ë‚¨": "ì „ë¼ë‚¨ë„", "ê²½ë¶": "ê²½ìƒë¶ë„",
                "ê²½ë‚¨": "ê²½ìƒë‚¨ë„", "ì œì£¼": "ì œì£¼íŠ¹ë³„ìì¹˜ë„"
            }
            
            # ë™ ë ˆë²¨ íŒë‹¨ í—¬í¼ í•¨ìˆ˜
            def is_dong_level(name: str) -> bool:
                return name.endswith(("ë™", "ë¦¬", "ê°€"))
            
            # ì‹œë„ëª… ì •ê·œí™” í—¬í¼ í•¨ìˆ˜
            def normalize_city(name: str) -> str:
                city_part = name.replace("ì‹œ", "íŠ¹ë³„ì‹œ").replace("ë„", "")
                result = city_mapping.get(city_part, city_part)
                if not result.endswith(("ì‹œ", "ë„", "íŠ¹ë³„ì‹œ", "ê´‘ì—­ì‹œ", "íŠ¹ë³„ìì¹˜ì‹œ", "íŠ¹ë³„ìì¹˜ë„")):
                    result = city_mapping.get(city_part, f"{city_part}ì‹œ")
                return result
            
            # ===== ìµœì í™”: ë‹¨ì¼ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰ (region_idë§Œ SELECT) =====
            if len(parts) >= 3:
                # 3ë‹¨ê³„: "ê²½ê¸°ë„ íŒŒì£¼ì‹œ ì•¼ë‹¹ë™"
                city_name = normalize_city(parts[0])
                dong_part = parts[2]
                
                result = await db.execute(
                    select(State.region_id)
                    .where(
                        State.is_deleted == False,
                        State.city_name == city_name,
                        State.region_name == dong_part,
                        ~State.region_code.like("_____00000")  # ë™ ë ˆë²¨
                    )
                    .limit(1)
                )
                row = result.scalar_one_or_none()
                if row:
                    region_id = row
                    parsed_criteria["region_id"] = region_id
                    logger.info(f"[AI_SEARCH] ì§€ì—­ ID ì¡°íšŒ ì„±ê³µ - region_id: {region_id}")
                    
            elif len(parts) == 2:
                first_part, second_part = parts[0], parts[1]
                
                if is_dong_level(second_part):
                    # "íŒŒì£¼ì‹œ ì•¼ë‹¹ë™" (ì‹œêµ°êµ¬ + ë™)
                    result = await db.execute(
                        select(State.region_id)
                        .where(
                            State.is_deleted == False,
                            State.region_name == second_part,
                            ~State.region_code.like("_____00000")
                        )
                        .limit(1)
                    )
                    row = result.scalar_one_or_none()
                    if row:
                        region_id = row
                        parsed_criteria["region_id"] = region_id
                        logger.info(f"[AI_SEARCH] ì§€ì—­ ID ì¡°íšŒ ì„±ê³µ - region_id: {region_id}")
                else:
                    # "ê²½ê¸°ë„ íŒŒì£¼ì‹œ" (ì‹œë„ + ì‹œêµ°êµ¬)
                    city_name = normalize_city(first_part)
                    
                    result = await db.execute(
                        select(State.region_id)
                        .where(
                            State.is_deleted == False,
                            State.city_name == city_name,
                            State.region_name == second_part,
                            State.region_code.like("_____00000")
                        )
                        .limit(1)
                    )
                    row = result.scalar_one_or_none()
                    if row:
                        region_id = row
                        parsed_criteria["region_id"] = region_id
                        logger.info(f"[AI_SEARCH] ì§€ì—­ ID ì¡°íšŒ ì„±ê³µ - region_id: {region_id}")
            else:
                # 1ë‹¨ê³„: "ì•¼ë‹¹ë™" ë˜ëŠ” "íŒŒì£¼ì‹œ"
                region_part = parts[0]
                
                if is_dong_level(region_part):
                    result = await db.execute(
                        select(State.region_id)
                        .where(
                            State.is_deleted == False,
                            State.region_name == region_part,
                            ~State.region_code.like("_____00000")
                        )
                        .limit(1)
                    )
                else:
                    result = await db.execute(
                        select(State.region_id)
                        .where(
                            State.is_deleted == False,
                            State.region_name == region_part,
                            State.region_code.like("_____00000")
                        )
                        .limit(1)
                    )
                
                row = result.scalar_one_or_none()
                if row:
                    region_id = row
                    parsed_criteria["region_id"] = region_id
                    logger.info(f"[AI_SEARCH] ì§€ì—­ ID ì¡°íšŒ ì„±ê³µ - region_id: {region_id}")
            
            if not region_id:
                logger.warning(f"[AI_SEARCH] ì§€ì—­ ID ì¡°íšŒ ì‹¤íŒ¨ - location: {location_name}")
        except Exception as e:
            logger.warning(f"[AI_SEARCH] ì§€ì—­ëª… ë§¤ì¹­ ì‹¤íŒ¨ - location: {location_name}, ì˜¤ë¥˜: {str(e)}")
    
    region_lookup_end_time = time.time()
    region_lookup_duration = region_lookup_end_time - region_lookup_start_time
    logger.info(f"[AI_SEARCH] [2ë‹¨ê³„] ì§€ì—­ ID ì¡°íšŒ ì™„ë£Œ - ì†Œìš”ì‹œê°„: {region_lookup_duration:.3f}ì´ˆ, region_id: {region_id}, ì‹œê°„: {datetime.now().isoformat()}")
    
    # 3. ìƒì„¸ ê²€ìƒ‰ ì‹¤í–‰
    search_start_time = time.time()
    logger.info(f"[AI_SEARCH] [3ë‹¨ê³„] ìƒì„¸ ê²€ìƒ‰ ì‹œì‘ - ì‹œê°„: {datetime.now().isoformat()}")
    try:
        # ì§€ì—­ ì¡°ê±´ì´ ì—†ìœ¼ë©´ limitì„ ëŠ˜ë ¤ì„œ ë” ë§ì€ ê²°ê³¼ ë°˜í™˜
        search_limit = 50 if region_id else 200
        
        # ì „ì„¸/ì›”ì„¸ ì¡°ê±´ ë¡œê¹…
        min_deposit = parsed_criteria.get("min_deposit")
        max_deposit = parsed_criteria.get("max_deposit")
        min_monthly_rent = parsed_criteria.get("min_monthly_rent")
        max_monthly_rent = parsed_criteria.get("max_monthly_rent")
        
        logger.info(f"[AI_SEARCH] ê²€ìƒ‰ íŒŒë¼ë¯¸í„°:")
        logger.info(f"[AI_SEARCH]   - region_id: {region_id}")
        logger.info(f"[AI_SEARCH]   - min_area: {parsed_criteria.get('min_area')}, max_area: {parsed_criteria.get('max_area')}")
        logger.info(f"[AI_SEARCH]   - min_price: {parsed_criteria.get('min_price')}, max_price: {parsed_criteria.get('max_price')}")
        logger.info(f"[AI_SEARCH]   - min_deposit: {min_deposit}ë§Œì›, max_deposit: {max_deposit}ë§Œì›")
        logger.info(f"[AI_SEARCH]   - min_monthly_rent: {min_monthly_rent}ë§Œì›, max_monthly_rent: {max_monthly_rent}ë§Œì›")
        logger.info(f"[AI_SEARCH]   - search_limit: {search_limit}")
        
        apartments = await apartment_service.detailed_search(
            db,
            region_id=region_id,
            min_area=parsed_criteria.get("min_area"),
            max_area=parsed_criteria.get("max_area"),
            min_price=parsed_criteria.get("min_price"),
            max_price=parsed_criteria.get("max_price"),
            min_deposit=min_deposit,
            max_deposit=max_deposit,
            min_monthly_rent=min_monthly_rent,
            max_monthly_rent=max_monthly_rent,
            subway_max_distance_minutes=parsed_criteria.get("subway_max_distance_minutes"),
            subway_line=parsed_criteria.get("subway_line"),
            subway_station=parsed_criteria.get("subway_station"),
            has_education_facility=parsed_criteria.get("has_education_facility"),
            min_build_year=parsed_criteria.get("min_build_year"),
            max_build_year=parsed_criteria.get("max_build_year"),
            build_year_range=parsed_criteria.get("build_year_range"),
            min_floor=parsed_criteria.get("min_floor"),
            max_floor=parsed_criteria.get("max_floor"),
            floor_type=parsed_criteria.get("floor_type"),
            min_parking_cnt=parsed_criteria.get("min_parking_cnt"),
            has_parking=parsed_criteria.get("has_parking"),
            builder_name=parsed_criteria.get("builder_name"),
            developer_name=parsed_criteria.get("developer_name"),
            heating_type=parsed_criteria.get("heating_type"),
            manage_type=parsed_criteria.get("manage_type"),
            hallway_type=parsed_criteria.get("hallway_type"),
            recent_transaction_months=parsed_criteria.get("recent_transaction_months"),
            apartment_name=parsed_criteria.get("apartment_name"),
            limit=search_limit,
            skip=0
        )
        
        search_end_time = time.time()
        search_duration = search_end_time - search_start_time
        logger.info(f"[AI_SEARCH] [3ë‹¨ê³„] ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì™„ë£Œ - ì†Œìš”ì‹œê°„: {search_duration:.3f}ì´ˆ, ê²°ê³¼ ê°œìˆ˜: {len(apartments)}, ì‹œê°„: {datetime.now().isoformat()}")
        
        # ì „ì„¸ ì¡°ê±´ì´ ìˆëŠ”ë° ê²°ê³¼ê°€ ë§¤ë§¤ ê°€ê²©ë§Œ ìˆëŠ” ê²½ìš° ë¡œê¹…
        if (min_deposit is not None or max_deposit is not None) and apartments:
            deposit_count = sum(1 for apt in apartments if apt.get("average_deposit") is not None)
            logger.info(f"[AI_SEARCH] ì „ì„¸ ì¡°ê±´ í•„í„°ë§ ê²°ê³¼ - ì „ì„¸ ë°ì´í„° ìˆëŠ” ì•„íŒŒíŠ¸: {deposit_count}/{len(apartments)}")
            if deposit_count == 0:
                logger.warning(f"[AI_SEARCH] âš ï¸ ì „ì„¸ ì¡°ê±´ì´ ìˆì§€ë§Œ ì „ì„¸ ë°ì´í„°ê°€ ìˆëŠ” ì•„íŒŒíŠ¸ê°€ ì—†ìŒ!")
                # ìƒ˜í”Œ ê²°ê³¼ ë¡œê¹…
                if len(apartments) > 0:
                    sample = apartments[0]
                    logger.warning(f"[AI_SEARCH] ìƒ˜í”Œ ê²°ê³¼ - apt_id: {sample.get('apt_id')}, apt_name: {sample.get('apt_name')}, average_price: {sample.get('average_price')}, average_deposit: {sample.get('average_deposit')}")
            else:
                # ì „ì„¸ ê°€ê²© ë²”ìœ„ í™•ì¸
                deposit_prices = [apt.get("average_deposit") for apt in apartments if apt.get("average_deposit") is not None]
                if deposit_prices:
                    min_deposit_result = min(deposit_prices)
                    max_deposit_result = max(deposit_prices)
                    logger.info(f"[AI_SEARCH] ì „ì„¸ ê°€ê²© ë²”ìœ„ - ìµœì†Œ: {min_deposit_result:.1f}ë§Œì›, ìµœëŒ€: {max_deposit_result:.1f}ë§Œì›, ì¡°ê±´: min_deposit={min_deposit}, max_deposit={max_deposit}")
        
    except Exception as e:
        search_end_time = time.time()
        search_duration = search_end_time - search_start_time
        logger.error(f"[AI_SEARCH] [3ë‹¨ê³„] ê²€ìƒ‰ ì„œë¹„ìŠ¤ ì‹¤íŒ¨ - ì†Œìš”ì‹œê°„: {search_duration:.3f}ì´ˆ, ì˜¤ë¥˜: {str(e)}, ì‹œê°„: {datetime.now().isoformat()}", exc_info=True)
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ì•„íŒŒíŠ¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )
    
    # 4. ì‘ë‹µ êµ¬ì„±
    total_end_time = time.time()
    total_duration = total_end_time - total_start_time
    logger.info(f"[AI_SEARCH] [4ë‹¨ê³„] ì‘ë‹µ êµ¬ì„± ì™„ë£Œ - ì‹œê°„: {datetime.now().isoformat()}")
    logger.info(f"[AI_SEARCH] ========== ì „ì²´ ê²€ìƒ‰ ì™„ë£Œ ==========")
    logger.info(f"[AI_SEARCH] ì´ ì†Œìš”ì‹œê°„: {total_duration:.3f}ì´ˆ")
    logger.info(f"[AI_SEARCH]   - íŒŒì‹±: {parse_duration:.3f}ì´ˆ")
    logger.info(f"[AI_SEARCH]   - ì§€ì—­ ì¡°íšŒ: {region_lookup_duration:.3f}ì´ˆ")
    logger.info(f"[AI_SEARCH]   - ê²€ìƒ‰: {search_duration:.3f}ì´ˆ")
    logger.info(f"[AI_SEARCH] ìµœì¢… ê²°ê³¼: {len(apartments)}ê°œ")
    logger.info(f"[AI_SEARCH] ==================================")
    
    return {
        "success": True,
        "data": {
            "criteria": parsed_criteria,
            "apartments": apartments,
            "count": len(apartments),
            "total": len(apartments)
        }
    }
