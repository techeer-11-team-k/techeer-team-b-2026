"""
ë°ì´í„° ìˆ˜ì§‘ ì„œë¹„ìŠ¤

êµ­í† êµí†µë¶€ APIì—ì„œ ì§€ì—­ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
"""
import logging
import asyncio
import sys
import csv
from pathlib import Path
from typing import List, Dict, Any, Optional
from urllib.parse import quote
import httpx
from datetime import datetime

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select

# ëª¨ë“  ëª¨ë¸ì„ importí•˜ì—¬ SQLAlchemy ê´€ê³„ ì„¤ì •ì´ ì œëŒ€ë¡œ ì‘ë™í•˜ë„ë¡ í•¨
from app.models import (  # noqa: F401
    Account,
    State,
    Apartment,
    ApartDetail,
    Sale,
    Rent,
    HouseScore,
    FavoriteLocation,
    FavoriteApartment,
    MyProperty,
)

from app.core.config import settings
from app.crud.state import state as state_crud
from app.crud.apartment import apartment as apartment_crud
from app.crud.apart_detail import apart_detail as apart_detail_crud
from app.crud.house_score import house_score as house_score_crud
from app.schemas.state import StateCreate, StateCollectionResponse
from app.schemas.apartment import ApartmentCreate, ApartmentCollectionResponse
from app.schemas.apart_detail import ApartDetailCreate, ApartDetailCollectionResponse
from app.schemas.house_score import HouseScoreCreate, HouseScoreCollectionResponse

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# í•¸ë“¤ëŸ¬ê°€ ì—†ìœ¼ë©´ ì¶”ê°€
if not logger.handlers:
    handler = logging.StreamHandler(sys.stdout)
    handler.setLevel(logging.INFO)
    formatter = logging.Formatter(
        '%(asctime)s | %(levelname)s | %(name)s | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    logger.propagate = False  # ë¶€ëª¨ ë¡œê±°ë¡œ ì „íŒŒí•˜ì§€ ì•ŠìŒ

# êµ­í† ë¶€ í‘œì¤€ì§€ì—­ì½”ë“œ API ì—”ë“œí¬ì¸íŠ¸
MOLIT_REGION_API_URL = "https://apis.data.go.kr/1741000/StanReginCd/getStanReginCdList"

# êµ­í† ë¶€ ì•„íŒŒíŠ¸ ëª©ë¡ API ì—”ë“œí¬ì¸íŠ¸
MOLIT_APARTMENT_LIST_API_URL = "https://apis.data.go.kr/1613000/AptListService3/getTotalAptList3"

# êµ­í† ë¶€ ì•„íŒŒíŠ¸ ê¸°ë³¸ì •ë³´ API ì—”ë“œí¬ì¸íŠ¸
MOLIT_APARTMENT_BASIC_API_URL = "https://apis.data.go.kr/1613000/AptBasisInfoServiceV4/getAphusBassInfoV4"

# êµ­í† ë¶€ ì•„íŒŒíŠ¸ ìƒì„¸ì •ë³´ API ì—”ë“œí¬ì¸íŠ¸
MOLIT_APARTMENT_DETAIL_API_URL = "https://apis.data.go.kr/1613000/AptBasisInfoServiceV4/getAphusDtlInfoV4"

# í•œêµ­ë¶€ë™ì‚°ì› API ì—”ë“œí¬ì¸íŠ¸
REB_DATA_URL = "https://www.reb.or.kr/r-one/openapi/SttsApiTblData.do"

# ì‹œë„ ëª©ë¡ (17ê°œ)
CITY_NAMES = [
    "ê°•ì›íŠ¹ë³„ìì¹˜ë„",
    "ê²½ê¸°ë„",
    "ê²½ìƒë‚¨ë„",
    "ê²½ìƒë¶ë„",
    "ê´‘ì£¼ê´‘ì—­ì‹œ",
    "ëŒ€êµ¬ê´‘ì—­ì‹œ",
    "ëŒ€ì „ê´‘ì—­ì‹œ",
    "ë¶€ì‚°ê´‘ì—­ì‹œ",
    "ì„œìš¸íŠ¹ë³„ì‹œ",
    "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ",
    "ìš¸ì‚°ê´‘ì—­ì‹œ",
    "ì¸ì²œê´‘ì—­ì‹œ",
    "ì „ë¼ë‚¨ë„",
    "ì „ë¶íŠ¹ë³„ìì¹˜ë„",
    "ì œì£¼íŠ¹ë³„ìì¹˜ë„",
    "ì¶©ì²­ë‚¨ë„",
    "ì¶©ì²­ë¶ë„"
]


class DataCollectionService:
    """
    ë°ì´í„° ìˆ˜ì§‘ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
    
    êµ­í† êµí†µë¶€ APIì—ì„œ ì§€ì—­ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    
    # CSV íŒŒì¼ ê²½ë¡œ ìºì‹œ (í•œ ë²ˆë§Œ í™•ì¸)
    _csv_path_cache: Optional[Path] = None
    _csv_path_checked: bool = False
    
    def __init__(self):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        if not settings.MOLIT_API_KEY:
            raise ValueError("MOLIT_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        self.api_key = settings.MOLIT_API_KEY
    
    async def fetch_with_retry(self, url: str, params: Dict[str, Any], retries: int = 3) -> Dict[str, Any]:
        """
        API í˜¸ì¶œ ì¬ì‹œë„ ë¡œì§ (ì§€ìˆ˜ ë°±ì˜¤í”„)
        """
        for attempt in range(retries):
            try:
                async with httpx.AsyncClient(timeout=10.0) as client:
                    response = await client.get(url, params=params)
                    response.raise_for_status()
                    return response.json()
            except httpx.TimeoutException:
                if attempt == retries - 1:
                    logger.warning(f"â° [Timeout] API í˜¸ì¶œ ì‹œê°„ ì´ˆê³¼ ({url}) - {retries}íšŒ ì‹œë„ ì‹¤íŒ¨")
                    raise
                await asyncio.sleep(0.5 * (2 ** attempt))
            except Exception as e:
                if attempt == retries - 1:
                    logger.warning(f"âŒ [API Error] {e} ({url})")
                    raise
                await asyncio.sleep(0.5 * (2 ** attempt))
        return {}
    
    async def fetch_region_data(
        self,
        city_name: str,
        page_no: int = 1,
        num_of_rows: int = 1000
    ) -> Dict[str, Any]:
        """
        êµ­í† ë¶€ APIì—ì„œ ì§€ì—­ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        
        Args:
            city_name: ì‹œë„ëª… (ì˜ˆ: ì„œìš¸íŠ¹ë³„ì‹œ)
            page_no: í˜ì´ì§€ ë²ˆí˜¸ (ê¸°ë³¸ê°’: 1)
            num_of_rows: í•œ í˜ì´ì§€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 1000)
        
        Returns:
            API ì‘ë‹µ ë°ì´í„° (dict)
        
        Raises:
            httpx.HTTPError: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        # URL ì¸ì½”ë”©
        encoded_city_name = quote(city_name)
        
        # API ìš”ì²­ íŒŒë¼ë¯¸í„°
        # locatadd_nm: ì£¼ì†Œëª…ìœ¼ë¡œ í•„í„°ë§ (ì‹œë„ëª…ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  ì£¼ì†Œ)
        params = {
            "serviceKey": self.api_key,
            "pageNo": str(page_no),
            "numOfRows": str(num_of_rows),
            "type": "json",
            "locatadd_nm": city_name  # ì˜ˆ: "ì„œìš¸íŠ¹ë³„ì‹œ"ë¡œ ê²€ìƒ‰í•˜ë©´ "ì„œìš¸íŠ¹ë³„ì‹œ"ë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  ì£¼ì†Œ ë°˜í™˜
        }
        
        logger.info(f"ğŸ“¡ API í˜¸ì¶œ: {city_name} (í˜ì´ì§€ {page_no}, ìš”ì²­: {num_of_rows}ê°œ)")
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.get(MOLIT_REGION_API_URL, params=params)
            response.raise_for_status()
            data = response.json()
            
            # API ì‘ë‹µ êµ¬ì¡° í™•ì¸ìš© ë¡œê¹… (ì²« í˜ì´ì§€ë§Œ)
            if page_no == 1:
                logger.debug(f"   ğŸ” API ì‘ë‹µ êµ¬ì¡° í™•ì¸: {list(data.keys()) if isinstance(data, dict) else 'ë¦¬ìŠ¤íŠ¸'}")
            
            return data
    
    def parse_region_data(
        self,
        api_response: Dict[str, Any],
        city_name: str
    ) -> tuple[List[Dict[str, str]], int, int]:
        """
        API ì‘ë‹µ ë°ì´í„° íŒŒì‹± (ëª¨ë“  ë ˆë²¨ ìˆ˜ì§‘)
        
        ì‹¤ì œ API ì‘ë‹µ êµ¬ì¡°:
        {
          "StanReginCd": [
            {
              "head": [
                {"totalCount": 493},
                {"numOfRows": "10", "pageNo": "1", "type": "JSON"},
                {"RESULT": {"resultCode": "INFO-0", "resultMsg": "NOMAL SERVICE"}}
              ]
            },
            {
              "row": [
                {
                  "region_cd": "1171000000",
                  "sido_cd": "11",
                  "sgg_cd": "710",
                  "umd_cd": "000",
                  "locatadd_nm": "ì„œìš¸íŠ¹ë³„ì‹œ ì†¡íŒŒêµ¬",
                  "locallow_nm": "ì†¡íŒŒêµ¬",
                  ...
                }
              ]
            }
          ]
        }
        
        Args:
            api_response: API ì‘ë‹µ ë°ì´í„°
            city_name: ì‹œë„ëª… (íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬ë°›ì€ ê°’)
        
        Returns:
            (íŒŒì‹±ëœ ì§€ì—­ ë°ì´í„° ëª©ë¡, ì´ ê°œìˆ˜, ì›ë³¸ ë°ì´í„° ìˆ˜)
        """
        regions = []
        total_count = 0
        original_count = 0
        
        try:
            # StanReginCd ë°°ì—´ì—ì„œ ë°ì´í„° ì¶”ì¶œ
            stan_regin_cd = api_response.get("StanReginCd", [])
            
            if not stan_regin_cd or len(stan_regin_cd) < 2:
                logger.warning("âš ï¸ API ì‘ë‹µ êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤")
                return [], 0, 0
            
            # headì—ì„œ totalCount ì¶”ì¶œ
            head_data = stan_regin_cd[0].get("head", [])
            for head_item in head_data:
                if isinstance(head_item, dict) and "totalCount" in head_item:
                    total_count = int(head_item["totalCount"])
                    break
            
            # rowì—ì„œ ì‹¤ì œ ë°ì´í„° ì¶”ì¶œ
            row_data = stan_regin_cd[1].get("row", [])
            
            # rowê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
            if not isinstance(row_data, list):
                row_data = [row_data] if row_data else []
            
            # ì›ë³¸ ë°ì´í„° ìˆ˜ ì €ì¥ (í•„í„°ë§ ì „)
            original_count = len(row_data)
            
            for item in row_data:
                # í•„ìˆ˜ í•„ë“œ ì¶”ì¶œ
                region_cd = str(item.get("region_cd", "")).strip()
                locatadd_nm = str(item.get("locatadd_nm", "")).strip()  # ì „ì²´ ì£¼ì†Œëª… (ì˜ˆ: "ì„œìš¸íŠ¹ë³„ì‹œ ì†¡íŒŒêµ¬")
                locallow_nm = str(item.get("locallow_nm", "")).strip()  # ì‹œêµ°êµ¬ëª… (ì˜ˆ: "ì†¡íŒŒêµ¬")
                umd_cd = str(item.get("umd_cd", "")).strip()  # ìë©´ë™ ì½”ë“œ
                sgg_cd = str(item.get("sgg_cd", "")).strip()  # ì‹œêµ°êµ¬ ì½”ë“œ
                ri_cd = str(item.get("ri_cd", "")).strip()  # ë¦¬ ì½”ë“œ
                
                # region_cdê°€ 10ìë¦¬ê°€ ì•„ë‹ˆë©´ ê±´ë„ˆë›°ê¸°
                if len(region_cd) != 10:
                    continue
                
                # ëª¨ë“  ë ˆë²¨ ìˆ˜ì§‘ (ë‚˜ì¤‘ì— ìµœí•˜ìœ„ ë ˆë²¨ë§Œ í•„í„°ë§)
                # ì‹œë„ëª… ì¶”ì¶œ (locatadd_nmì—ì„œ ì¶”ì¶œí•˜ê±°ë‚˜ íŒŒë¼ë¯¸í„° ì‚¬ìš©)
                parsed_city = self._extract_city_name_from_address(locatadd_nm) or city_name
                
                # ì‹œêµ°êµ¬ëª…ì´ ì—†ìœ¼ë©´ locatadd_nmì—ì„œ ì¶”ì¶œ ì‹œë„
                if not locallow_nm:
                    # "ì„œìš¸íŠ¹ë³„ì‹œ ì†¡íŒŒêµ¬" -> "ì†¡íŒŒêµ¬"
                    parts = locatadd_nm.split()
                    if len(parts) >= 2:
                        locallow_nm = parts[-1]
                    else:
                        locallow_nm = locatadd_nm
                
                regions.append({
                    "region_code": region_cd,
                    "region_name": locallow_nm,
                    "city_name": parsed_city
                })
            
            logger.info(f"âœ… íŒŒì‹± ì™„ë£Œ: ì›ë³¸ {original_count}ê°œ â†’ ìˆ˜ì§‘ {len(regions)}ê°œ ì§€ì—­ (ëª¨ë“  ë ˆë²¨ ì €ì¥, ì „ì²´ {total_count}ê°œ ì¤‘)")
            return regions, total_count, original_count
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨: {e}")
            logger.debug(f"API ì‘ë‹µ: {api_response}")
            import traceback
            logger.debug(traceback.format_exc())
            return [], 0, 0
    
    
    def _extract_city_name_from_address(self, locatadd_nm: str) -> str:
        """
        ì£¼ì†Œëª…ì—ì„œ ì‹œë„ëª… ì¶”ì¶œ
        
        Args:
            locatadd_nm: ì „ì²´ ì£¼ì†Œëª… (ì˜ˆ: "ì„œìš¸íŠ¹ë³„ì‹œ ì†¡íŒŒêµ¬")
        
        Returns:
            ì‹œë„ëª… (ì˜ˆ: "ì„œìš¸íŠ¹ë³„ì‹œ")
        """
        if not locatadd_nm:
            return ""
        
        # ì£¼ì†Œëª…ì—ì„œ ì‹œë„ëª… ì¶”ì¶œ
        for city in CITY_NAMES:
            if locatadd_nm.startswith(city):
                return city
        
        return ""
    
    def _extract_city_name_from_code(self, region_code: str) -> str:
        """
        ì§€ì—­ì½”ë“œì—ì„œ ì‹œë„ëª… ì¶”ì¶œ
        
        Args:
            region_code: ì§€ì—­ì½”ë“œ (10ìë¦¬, ì²« 2ìë¦¬ê°€ ì‹œë„ì½”ë“œ)
        
        Returns:
            ì‹œë„ëª…
        """
        if len(region_code) < 2:
            return ""
        
        sido_code = region_code[:2]
        # ì‹œë„ì½”ë“œ ë§¤í•‘
        sido_map = {
            "11": "ì„œìš¸íŠ¹ë³„ì‹œ",
            "26": "ë¶€ì‚°ê´‘ì—­ì‹œ",
            "27": "ëŒ€êµ¬ê´‘ì—­ì‹œ",
            "28": "ì¸ì²œê´‘ì—­ì‹œ",
            "29": "ê´‘ì£¼ê´‘ì—­ì‹œ",
            "30": "ëŒ€ì „ê´‘ì—­ì‹œ",
            "31": "ìš¸ì‚°ê´‘ì—­ì‹œ",
            "36": "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ",
            "41": "ê²½ê¸°ë„",
            "42": "ê°•ì›íŠ¹ë³„ìì¹˜ë„",
            "43": "ì¶©ì²­ë¶ë„",
            "44": "ì¶©ì²­ë‚¨ë„",
            "45": "ì „ë¶íŠ¹ë³„ìì¹˜ë„",
            "46": "ì „ë¼ë‚¨ë„",
            "47": "ê²½ìƒë¶ë„",
            "48": "ê²½ìƒë‚¨ë„",
            "50": "ì œì£¼íŠ¹ë³„ìì¹˜ë„"
        }
        return sido_map.get(sido_code, "")
    
    async def collect_all_regions(
        self,
        db: AsyncSession
    ) -> StateCollectionResponse:
        """
        ëª¨ë“  ì‹œë„ì˜ ì§€ì—­ ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥
        
        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        
        Returns:
            ìˆ˜ì§‘ ê²°ê³¼
        """
        total_fetched = 0
        total_saved = 0
        skipped = 0
        errors = []
        
        logger.info("=" * 60)
        logger.info("ğŸš€ ì§€ì—­ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        logger.info(f"ğŸ“‹ ëŒ€ìƒ ì‹œë„: {len(CITY_NAMES)}ê°œ")
        logger.info(f"ğŸ“‹ ì‹œë„ ëª©ë¡: {', '.join(CITY_NAMES)}")
        logger.info("=" * 60)
        
        for idx, city_name in enumerate(CITY_NAMES, 1):
            logger.info(f"\n{'='*60}")
            logger.info(f"[{idx}/{len(CITY_NAMES)}] {city_name} ì²˜ë¦¬ ì‹œì‘ (í˜„ì¬ê¹Œì§€ ì „ì²´ ìˆ˜ì§‘: {total_fetched}ê°œ)")
            logger.info(f"{'='*60}")
            
            try:
                # API í˜¸ì¶œ
                page_no = 1
                has_more = True
                city_fetched = 0
                city_saved = 0
                city_skipped = 0
                city_total_original = 0  # í•´ë‹¹ ì‹œë„ì˜ ì „ì²´ ì›ë³¸ ë°ì´í„° ìˆ˜ (ëˆ„ì )
                num_of_rows = 700  # í˜ì´ì§€ë‹¹ ìš”ì²­í•  ë ˆì½”ë“œ ìˆ˜
                
                logger.info(f"   ğŸ” {city_name} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (í˜ì´ì§€ë‹¹ {num_of_rows}ê°œ ìš”ì²­, ëª¨ë“  ë ˆë²¨ ì €ì¥)")
                
                while has_more:
                    # API ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                    api_response = await self.fetch_region_data(
                        city_name=city_name,
                        page_no=page_no,
                        num_of_rows=num_of_rows
                    )
                    
                    # ë°ì´í„° íŒŒì‹± (ëª¨ë“  ë ˆë²¨ ìˆ˜ì§‘)
                    regions, _, original_count = self.parse_region_data(api_response, city_name)
                    
                    # ì›ë³¸ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ (APIì—ì„œ ë°ì´í„°ë¥¼ ë” ì´ìƒ ë°˜í™˜í•˜ì§€ ì•ŠìŒ)
                    if original_count == 0:
                        logger.info(f"   â„¹ï¸  í˜ì´ì§€ {page_no}: ì›ë³¸ ë°ì´í„° ì—†ìŒ (ì¢…ë£Œ)")
                        has_more = False
                        break
                    
                    city_total_original += original_count
                    city_fetched += len(regions)
                    total_fetched += len(regions)
                    
                    logger.info(f"   ğŸ“„ í˜ì´ì§€ {page_no}: ì›ë³¸ {original_count}ê°œ â†’ ìˆ˜ì§‘ {len(regions)}ê°œ ì§€ì—­ (ëª¨ë“  ë ˆë²¨, ëˆ„ì : {city_fetched}ê°œ)")
                    
                    # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (ì¤‘ë³µë§Œ ì œì™¸)
                    for region_idx, region_data in enumerate(regions, 1):
                        try:
                            region_code = region_data.get('region_code', 'Unknown')
                            region_name = region_data.get('region_name', 'Unknown')
                            region_city = region_data.get('city_name', city_name)
                            
                            # ìƒì„¸ ë¡œê·¸: ì–´ëŠ ë„ì˜ ì–´ëŠ ì§€ì—­ì„ ì²˜ë¦¬í•˜ëŠ”ì§€
                            logger.info(f"   ğŸ’¾ [{city_name}] {region_city} {region_name} (ì½”ë“œ: {region_code}) ì €ì¥ ì‹œë„... ({region_idx}/{len(regions)}ë²ˆì§¸)")
                            
                            state_create = StateCreate(**region_data)
                            db_obj, is_created = await state_crud.create_or_skip(
                                db,
                                obj_in=state_create
                            )
                            
                            if is_created:
                                city_saved += 1
                                total_saved += 1
                                logger.info(f"      âœ… ì €ì¥ ì™„ë£Œ: {region_city} {region_name} (ì „ì²´ ì €ì¥: {total_saved}ê°œ)")
                            else:
                                city_skipped += 1
                                skipped += 1
                                logger.info(f"      â­ï¸  ê±´ë„ˆëœ€ (ì´ë¯¸ ì¡´ì¬): {region_city} {region_name} (ì „ì²´ ê±´ë„ˆëœ€: {skipped}ê°œ)")
                                
                        except Exception as e:
                            error_msg = f"{city_name} - {region_data.get('region_name', 'Unknown')}: {str(e)}"
                            errors.append(error_msg)
                            logger.warning(f"      âš ï¸ ì €ì¥ ì‹¤íŒ¨: {error_msg}")
                    
                    # ë‹¤ìŒ í˜ì´ì§€ í™•ì¸
                    if original_count < num_of_rows:
                        logger.info(f"   âœ… ë§ˆì§€ë§‰ í˜ì´ì§€ë¡œ íŒë‹¨ (ì›ë³¸ {original_count}ê°œ < ìš”ì²­ {num_of_rows}ê°œ)")
                        has_more = False
                    else:
                        logger.info(f"   â­ï¸  ë‹¤ìŒ í˜ì´ì§€ë¡œ... (ì›ë³¸ {original_count}ê°œ, ë‹¤ìŒ í˜ì´ì§€: {page_no + 1})")
                        page_no += 1
                    
                    # API í˜¸ì¶œ ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ë”œë ˆì´
                    await asyncio.sleep(0.2)
                
                logger.info(f"âœ… {city_name} ì™„ë£Œ: ì´ {page_no}í˜ì´ì§€ ì²˜ë¦¬, ì›ë³¸ {city_total_original}ê°œ â†’ ìˆ˜ì§‘ {city_fetched}ê°œ, ì €ì¥ {city_saved}ê°œ, ê±´ë„ˆëœ€ {city_skipped}ê°œ")
                logger.info(f"   ğŸ“Š í˜„ì¬ê¹Œì§€ ì „ì²´ í†µê³„: ìˆ˜ì§‘ {total_fetched}ê°œ, ì €ì¥ {total_saved}ê°œ, ê±´ë„ˆëœ€ {skipped}ê°œ")
                logger.info(f"   â¡ï¸  ë‹¤ìŒ ì‹œë„ë¡œ ì§„í–‰í•©ë‹ˆë‹¤...")
                
            except Exception as e:
                error_msg = f"{city_name} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
                errors.append(error_msg)
                logger.error(f"âŒ {error_msg}")
                logger.error(f"   âš ï¸ {city_name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ, ë‹¤ìŒ ì‹œë„ë¡œ ì§„í–‰í•©ë‹ˆë‹¤...")
                import traceback
                logger.error(traceback.format_exc())
                # ì˜ˆì™¸ê°€ ë°œìƒí•´ë„ ë‹¤ìŒ ì‹œë„ë¡œ ê³„ì† ì§„í–‰
                continue
        
        logger.info("=" * 60)
        logger.info("ğŸ‰ ì§€ì—­ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
        logger.info(f"ğŸ“Š ìµœì¢… í†µê³„:")
        logger.info(f"   - ì²˜ë¦¬í•œ ì‹œë„: {len(CITY_NAMES)}ê°œ")
        logger.info(f"   - ê°€ì ¸ì˜´: {total_fetched}ê°œ")
        logger.info(f"   - ì €ì¥: {total_saved}ê°œ")
        logger.info(f"   - ê±´ë„ˆëœ€: {skipped}ê°œ")
        if errors:
            logger.warning(f"âš ï¸ ì˜¤ë¥˜ {len(errors)}ê°œ ë°œìƒ:")
            for error in errors[:10]:  # ìµœëŒ€ 10ê°œë§Œ ì¶œë ¥
                logger.warning(f"   - {error}")
            if len(errors) > 10:
                logger.warning(f"   ... ì™¸ {len(errors) - 10}ê°œ ì˜¤ë¥˜")
        logger.info("=" * 60)
        
        return StateCollectionResponse(
            success=len(errors) == 0,
            total_fetched=total_fetched,
            total_saved=total_saved,
            skipped=skipped,
            errors=errors,
            message=f"ìˆ˜ì§‘ ì™„ë£Œ: {total_saved}ê°œ ì €ì¥, {skipped}ê°œ ê±´ë„ˆëœ€"
        )


    async def fetch_apartment_data(
        self,
        page_no: int = 1,
        num_of_rows: int = 1000
    ) -> Dict[str, Any]:
        """
        êµ­í† ë¶€ APIì—ì„œ ì•„íŒŒíŠ¸ ëª©ë¡ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        
        Args:
            page_no: í˜ì´ì§€ ë²ˆí˜¸ (ê¸°ë³¸ê°’: 1)
            num_of_rows: í•œ í˜ì´ì§€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 1000)
        
        Returns:
            API ì‘ë‹µ ë°ì´í„° (dict)
        
        Raises:
            httpx.HTTPError: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        # API ìš”ì²­ íŒŒë¼ë¯¸í„°
        params = {
            "serviceKey": self.api_key,
            "pageNo": str(page_no),
            "numOfRows": str(num_of_rows)
        }
        
        logger.info(f"   ğŸ“¡ API í˜¸ì¶œ: í˜ì´ì§€ {page_no}, {num_of_rows}ê°œ ìš”ì²­")
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.get(MOLIT_APARTMENT_LIST_API_URL, params=params)
            response.raise_for_status()
            data = response.json()
            
            # ì²« í˜ì´ì§€ì¼ ë•Œë§Œ ë””ë²„ê·¸ ë¡œê·¸ ì¶œë ¥
            if page_no == 1:
                logger.debug(f"   ğŸ” API ì‘ë‹µ êµ¬ì¡°: {data}")
            
            return data
    
    def parse_apartment_data(
        self,
        api_response: Dict[str, Any]
    ) -> tuple[List[Dict[str, Any]], int, int]:
        """
        ì•„íŒŒíŠ¸ ëª©ë¡ API ì‘ë‹µ íŒŒì‹±
        
        Args:
            api_response: API ì‘ë‹µ ë°ì´í„°
        
        Returns:
            (íŒŒì‹±ëœ ì•„íŒŒíŠ¸ ëª©ë¡, ì „ì²´ ê°œìˆ˜, ì›ë³¸ ê°œìˆ˜)
        """
        try:
            # ì‘ë‹µ êµ¬ì¡°: response.body.items
            body = api_response.get("response", {}).get("body", {})
            items = body.get("items", [])
            total_count = int(body.get("totalCount", 0))
            
            # itemsê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš° (ë‹¨ì¼ ê°ì²´)
            if not isinstance(items, list):
                items = [items] if items else []
            
            original_count = len(items)
            apartments = []
            
            for item in items:
                if not item:
                    continue
                
                # API ì‘ë‹µ í•„ë“œ ë§¤í•‘
                kapt_code = item.get("kaptCode", "").strip()
                kapt_name = item.get("kaptName", "").strip()
                bjd_code = item.get("bjdCode", "").strip()
                
                # í•„ìˆ˜ í•„ë“œ ê²€ì¦
                if not kapt_code or not kapt_name or not bjd_code:
                    continue
                
                apartments.append({
                    "kapt_code": kapt_code,
                    "apt_name": kapt_name,
                    "bjd_code": bjd_code,  # ë²•ì •ë™ ì½”ë“œ (region_codeë¡œ ë§¤ì¹­)
                    "as1": item.get("as1"),  # ì‹œë„
                    "as2": item.get("as2"),  # ì‹œêµ°êµ¬
                    "as3": item.get("as3"),  # ìë©´ë™
                    "as4": item.get("as4")   # ë¦¬
                })
            
            logger.info(f"âœ… íŒŒì‹± ì™„ë£Œ: ì›ë³¸ {original_count}ê°œ â†’ ìˆ˜ì§‘ {len(apartments)}ê°œ ì•„íŒŒíŠ¸ (ì „ì²´ {total_count}ê°œ ì¤‘)")
            
            return apartments, total_count, original_count
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return [], 0, 0
    
    async def collect_all_apartments(
        self,
        db: AsyncSession
    ) -> ApartmentCollectionResponse:
        """
        ëª¨ë“  ì•„íŒŒíŠ¸ ëª©ë¡ ìˆ˜ì§‘
        
        êµ­í† ë¶€ ì•„íŒŒíŠ¸ ëª©ë¡ APIì—ì„œ ëª¨ë“  ì•„íŒŒíŠ¸ë¥¼ ê°€ì ¸ì™€ì„œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤.
        
        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        
        Returns:
            ApartmentCollectionResponse: ìˆ˜ì§‘ ê²°ê³¼ í†µê³„
        """
        total_fetched = 0
        total_saved = 0
        skipped = 0
        errors = []
        
        try:
            logger.info("=" * 80)
            logger.info("ğŸ¢ ì•„íŒŒíŠ¸ ëª©ë¡ ìˆ˜ì§‘ ì‹œì‘")
            logger.info("=" * 80)
            
            page_no = 1
            has_more = True
            num_of_rows = 1000  # í˜ì´ì§€ë‹¹ ìš”ì²­í•  ë ˆì½”ë“œ ìˆ˜
            
            logger.info(f"ğŸ” ì•„íŒŒíŠ¸ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (í˜ì´ì§€ë‹¹ {num_of_rows}ê°œ ìš”ì²­)")
            
            while has_more:
                # API ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                api_response = await self.fetch_apartment_data(
                    page_no=page_no,
                    num_of_rows=num_of_rows
                )
                
                # ë°ì´í„° íŒŒì‹±
                apartments, total_count, original_count = self.parse_apartment_data(api_response)
                
                # ì›ë³¸ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
                if original_count == 0:
                    logger.info(f"   â„¹ï¸  í˜ì´ì§€ {page_no}: ì›ë³¸ ë°ì´í„° ì—†ìŒ (ì¢…ë£Œ)")
                    has_more = False
                    break
                
                total_fetched += len(apartments)
                
                logger.info(f"   ğŸ“„ í˜ì´ì§€ {page_no}: ì›ë³¸ {original_count}ê°œ â†’ ìˆ˜ì§‘ {len(apartments)}ê°œ ì•„íŒŒíŠ¸ (ëˆ„ì : {total_fetched}ê°œ)")
                
                # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                for apt_idx, apt_data in enumerate(apartments, 1):
                    try:
                        kapt_code = apt_data.get('kapt_code', 'Unknown')
                        apt_name = apt_data.get('apt_name', 'Unknown')
                        bjd_code = apt_data.get('bjd_code', '')
                        
                        # bjdCodeë¥¼ region_codeë¡œ ì‚¬ìš©í•˜ì—¬ region_id ì°¾ê¸°
                        region = await state_crud.get_by_region_code(db, region_code=bjd_code)
                        
                        if not region:
                            error_msg = f"ì•„íŒŒíŠ¸ '{apt_name}' (ì½”ë“œ: {kapt_code}): ë²•ì •ë™ ì½”ë“œ '{bjd_code}'ì— í•´ë‹¹í•˜ëŠ” ì§€ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                            errors.append(error_msg)
                            logger.warning(f"      âš ï¸ {error_msg}")
                            continue
                        
                        # ìƒì„¸ ë¡œê·¸
                        logger.info(f"   ğŸ’¾ [{region.city_name} {region.region_name}] {apt_name} (ë‹¨ì§€ì½”ë“œ: {kapt_code}) ì €ì¥ ì‹œë„... ({apt_idx}/{len(apartments)}ë²ˆì§¸)")
                        
                        apartment_create = ApartmentCreate(
                            region_id=region.region_id,
                            apt_name=apt_name,
                            kapt_code=kapt_code,
                            is_available=None  # ê¸°ë³¸ê°’
                        )
                        
                        db_obj, is_created = await apartment_crud.create_or_skip(
                            db,
                            obj_in=apartment_create
                        )
                        
                        if is_created:
                            total_saved += 1
                            logger.info(f"      âœ… ì €ì¥ ì™„ë£Œ: {apt_name} (ì „ì²´ ì €ì¥: {total_saved}ê°œ)")
                        else:
                            skipped += 1
                            logger.info(f"      â­ï¸  ê±´ë„ˆëœ€ (ì´ë¯¸ ì¡´ì¬): {apt_name} (ì „ì²´ ê±´ë„ˆëœ€: {skipped}ê°œ)")
                            
                    except Exception as e:
                        error_msg = f"ì•„íŒŒíŠ¸ '{apt_data.get('apt_name', 'Unknown')}': {str(e)}"
                        errors.append(error_msg)
                        logger.warning(f"      âš ï¸ ì €ì¥ ì‹¤íŒ¨: {error_msg}")
                
                # ë‹¤ìŒ í˜ì´ì§€ í™•ì¸
                if original_count < num_of_rows:
                    logger.info(f"   âœ… ë§ˆì§€ë§‰ í˜ì´ì§€ë¡œ íŒë‹¨ (ì›ë³¸ {original_count}ê°œ < ìš”ì²­ {num_of_rows}ê°œ)")
                    has_more = False
                else:
                    logger.info(f"   â­ï¸  ë‹¤ìŒ í˜ì´ì§€ë¡œ... (ì›ë³¸ {original_count}ê°œ, ë‹¤ìŒ í˜ì´ì§€: {page_no + 1})")
                    page_no += 1
                
                # API í˜¸ì¶œ ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ë”œë ˆì´
                await asyncio.sleep(0.2)
            
            logger.info("=" * 80)
            logger.info(f"âœ… ì•„íŒŒíŠ¸ ëª©ë¡ ìˆ˜ì§‘ ì™„ë£Œ")
            logger.info(f"   - ì´ {page_no}í˜ì´ì§€ ì²˜ë¦¬")
            logger.info(f"   - ìˆ˜ì§‘: {total_fetched}ê°œ")
            logger.info(f"   - ì €ì¥: {total_saved}ê°œ")
            logger.info(f"   - ê±´ë„ˆëœ€: {skipped}ê°œ")
            if errors:
                logger.info(f"   - ì˜¤ë¥˜: {len(errors)}ê°œ")
            logger.info("=" * 80)
            
            return ApartmentCollectionResponse(
                success=True,
                total_fetched=total_fetched,
                total_saved=total_saved,
                skipped=skipped,
                errors=errors,
                message=f"ìˆ˜ì§‘ ì™„ë£Œ: {total_saved}ê°œ ì €ì¥, {skipped}ê°œ ê±´ë„ˆëœ€"
            )
            
        except Exception as e:
            logger.error(f"âŒ ì•„íŒŒíŠ¸ ëª©ë¡ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}", exc_info=True)
            return ApartmentCollectionResponse(
                success=False,
                total_fetched=total_fetched,
                total_saved=total_saved,
                skipped=skipped,
                errors=errors + [str(e)],
                message=f"ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}"
            )

    async def fetch_apartment_basic_info(self, kapt_code: str) -> Dict[str, Any]:
        """
        êµ­í† ë¶€ APIì—ì„œ ì•„íŒŒíŠ¸ ê¸°ë³¸ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        
        Args:
            kapt_code: êµ­í† ë¶€ ë‹¨ì§€ì½”ë“œ
        
        Returns:
            API ì‘ë‹µ ë°ì´í„° (dict)
        
        Raises:
            httpx.HTTPError: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        params = {
            "serviceKey": self.api_key,
            "kaptCode": kapt_code
        }
        
        logger.debug(f"ê¸°ë³¸ì •ë³´ API í˜¸ì¶œ: {kapt_code}")
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.get(MOLIT_APARTMENT_BASIC_API_URL, params=params)
            response.raise_for_status()
            data = response.json()
            return data
    
    async def fetch_apartment_detail_info(self, kapt_code: str) -> Dict[str, Any]:
        """
        êµ­í† ë¶€ APIì—ì„œ ì•„íŒŒíŠ¸ ìƒì„¸ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        
        Args:
            kapt_code: êµ­í† ë¶€ ë‹¨ì§€ì½”ë“œ
        
        Returns:
            API ì‘ë‹µ ë°ì´í„° (dict)
        
        Raises:
            httpx.HTTPError: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        params = {
            "serviceKey": self.api_key,
            "kaptCode": kapt_code
        }
        
        logger.debug(f"ìƒì„¸ì •ë³´ API í˜¸ì¶œ: {kapt_code}")
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.get(MOLIT_APARTMENT_DETAIL_API_URL, params=params)
            response.raise_for_status()
            data = response.json()
            return data
    
    def parse_date(self, date_str: Optional[str]) -> Optional[str]:
        """
        ë‚ ì§œ ë¬¸ìì—´ íŒŒì‹± (YYYYMMDD -> YYYY-MM-DD)
        
        Args:
            date_str: YYYYMMDD í˜•ì‹ì˜ ë‚ ì§œ ë¬¸ìì—´
        
        Returns:
            YYYY-MM-DD í˜•ì‹ì˜ ë‚ ì§œ ë¬¸ìì—´ ë˜ëŠ” None
        """
        if not date_str or len(date_str) != 8:
            return None
        try:
            return f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
        except Exception:
            return None
    
    def parse_int(self, value: Any) -> Optional[int]:
        """
        ì •ìˆ˜ë¡œ ë³€í™˜ (ì‹¤íŒ¨ ì‹œ None ë°˜í™˜)
        
        Args:
            value: ë³€í™˜í•  ê°’
        
        Returns:
            ì •ìˆ˜ ë˜ëŠ” None
        """
        if value is None or value == "":
            return None
        try:
            if isinstance(value, str):
                # ë¹ˆ ë¬¸ìì—´ì´ë‚˜ ê³µë°± ì œê±°
                value = value.strip()
                if not value:
                    return None
            return int(value)
        except (ValueError, TypeError):
            return None
    
    def parse_float(self, value: Any) -> Optional[float]:
        """ë¬¸ìì—´/ìˆ«ìë¥¼ floatë¡œ ë³€í™˜"""
        if value is None or value == "": return None
        try:
            if isinstance(value, str):
                value = value.strip()
                if not value: return None
            return float(value)
        except (ValueError, TypeError): return None
    
    def parse_apartment_details(
        self,
        basic_info: Dict[str, Any],
        detail_info: Dict[str, Any],
        apt_id: int
    ) -> Optional[ApartDetailCreate]:
        """
        ë‘ API ì‘ë‹µì„ ì¡°í•©í•˜ì—¬ ApartDetailCreate ê°ì²´ ìƒì„±
        
        Args:
            basic_info: ê¸°ë³¸ì •ë³´ API ì‘ë‹µ
            detail_info: ìƒì„¸ì •ë³´ API ì‘ë‹µ
            apt_id: ì•„íŒŒíŠ¸ ID
        
        Returns:
            ApartDetailCreate ê°ì²´ ë˜ëŠ” None
        """
        try:
            logger.debug(f"íŒŒì‹± ì‹œì‘: apt_id={apt_id}")
            
            # ê¸°ë³¸ì •ë³´ íŒŒì‹±
            basic_item = basic_info.get("response", {}).get("body", {}).get("item", {})
            if not basic_item:
                logger.debug(f"ê¸°ë³¸ì •ë³´ API ì‘ë‹µì— itemì´ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # ìƒì„¸ì •ë³´ íŒŒì‹±
            detail_item = detail_info.get("response", {}).get("body", {}).get("item", {})
            if not detail_item:
                logger.debug(f"ìƒì„¸ì •ë³´ API ì‘ë‹µì— itemì´ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # í•„ìˆ˜ í•„ë“œ ê²€ì¦: ë„ë¡œëª… ì£¼ì†Œ ë˜ëŠ” ì§€ë²ˆ ì£¼ì†Œ
            doro_juso = basic_item.get("doroJuso", "").strip() if basic_item.get("doroJuso") else ""
            kapt_addr = basic_item.get("kaptAddr", "").strip() if basic_item.get("kaptAddr") else ""
            
            if not doro_juso and not kapt_addr:
                logger.debug("ë„ë¡œëª… ì£¼ì†Œì™€ ì§€ë²ˆ ì£¼ì†Œê°€ ëª¨ë‘ ì—†ìŠµë‹ˆë‹¤.")
                return None
            
            # ë„ë¡œëª… ì£¼ì†Œê°€ ì—†ìœ¼ë©´ ì§€ë²ˆ ì£¼ì†Œ ì‚¬ìš©
            if not doro_juso:
                doro_juso = kapt_addr
            # ì§€ë²ˆ ì£¼ì†Œê°€ ì—†ìœ¼ë©´ ë„ë¡œëª… ì£¼ì†Œ ì‚¬ìš©
            if not kapt_addr:
                kapt_addr = doro_juso
            
            # ìš°í¸ë²ˆí˜¸ ì²˜ë¦¬ (5ìë¦¬ë¡œ ì œí•œ)
            zipcode = basic_item.get("zipcode", "").strip() if basic_item.get("zipcode") else None
            if zipcode and len(zipcode) > 5:
                zipcode = zipcode[:5]
            
            # ë‚ ì§œ íŒŒì‹±
            use_approval_date_str = self.parse_date(basic_item.get("kaptUsedate"))
            use_approval_date = None
            if use_approval_date_str:
                try:
                    from datetime import datetime
                    use_approval_date = datetime.strptime(use_approval_date_str, "%Y-%m-%d").date()
                except Exception:
                    pass
            
            # ì´ ì„¸ëŒ€ ìˆ˜ (í•„ìˆ˜)
            kaptda_cnt_raw = basic_item.get("kaptdaCnt")
            total_household_cnt = self.parse_int(kaptda_cnt_raw)
            
            if total_household_cnt is None:
                logger.debug(f"ì´ ì„¸ëŒ€ ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤. (ì›ë³¸ ê°’: {kaptda_cnt_raw})")
                return None
            
            # ê´€ë¦¬ ë°©ì‹: ìƒì„¸ì •ë³´ì˜ codeMgr ìš°ì„ , ì—†ìœ¼ë©´ ê¸°ë³¸ì •ë³´ì˜ codeMgrNm
            manage_type = detail_item.get("codeMgr", "").strip()
            if not manage_type:
                manage_type = basic_item.get("codeMgrNm", "").strip()
            if not manage_type:
                manage_type = None
            
            # ì§€í•˜ì²  ì •ë³´: ìƒì„¸ì •ë³´ ìš°ì„ 
            subway_line = detail_item.get("subwayLine", "").strip() if detail_item.get("subwayLine") else None
            subway_station = detail_item.get("subwayStation", "").strip() if detail_item.get("subwayStation") else None
            subway_time = detail_item.get("kaptdWtimesub", "").strip() if detail_item.get("kaptdWtimesub") else None
            
            # êµìœ¡ ì‹œì„¤ (200ì ì œí•œ)
            education_facility = detail_item.get("educationFacility", "").strip() if detail_item.get("educationFacility") else None
            if education_facility and len(education_facility) > 200:
                education_facility = education_facility[:200]
                logger.debug(f"educationFacilityê°€ 200ìë¥¼ ì´ˆê³¼í•˜ì—¬ ì˜ë¦¼: {len(detail_item.get('educationFacility', ''))}ì -> 200ì")
            
            # ApartDetailCreate ê°ì²´ ìƒì„±
            try:
                detail_create = ApartDetailCreate(
                    apt_id=apt_id,
                    road_address=doro_juso,
                    jibun_address=kapt_addr,
                    zip_code=zipcode,
                    code_sale_nm=basic_item.get("codeSaleNm", "").strip() if basic_item.get("codeSaleNm") else None,
                    code_heat_nm=basic_item.get("codeHeatNm", "").strip() if basic_item.get("codeHeatNm") else None,
                    total_household_cnt=total_household_cnt,
                    total_building_cnt=self.parse_int(basic_item.get("kaptDongCnt")),
                    highest_floor=self.parse_int(basic_item.get("kaptTopFloor")),
                    use_approval_date=use_approval_date,
                    total_parking_cnt=self.parse_int(detail_item.get("kaptdPcntu")),
                    builder_name=basic_item.get("kaptBcompany", "").strip() if basic_item.get("kaptBcompany") else None,
                    developer_name=basic_item.get("kaptAcompany", "").strip() if basic_item.get("kaptAcompany") else None,
                    manage_type=manage_type,
                    hallway_type=basic_item.get("codeHallNm", "").strip() if basic_item.get("codeHallNm") else None,
                    subway_time=subway_time,
                    subway_line=subway_line,
                    subway_station=subway_station,
                    educationFacility=education_facility,
                    geometry=None  # APIì—ì„œ ì œê³µë˜ì§€ ì•ŠìŒ
                )
                logger.debug(f"ApartDetailCreate ê°ì²´ ìƒì„± ì™„ë£Œ")
                return detail_create
            except Exception as create_error:
                logger.error(f"ApartDetailCreate ê°ì²´ ìƒì„± ì‹¤íŒ¨: {str(create_error)}")
                import traceback
                logger.debug(f"ìƒì„¸ ìŠ¤íƒ: {traceback.format_exc()}")
                return None
            
        except Exception as e:
            logger.error(f"íŒŒì‹± ì˜¤ë¥˜: {e}")
            import traceback
            logger.debug(f"ìƒì„¸ ìŠ¤íƒ: {traceback.format_exc()}")
            return None
    
    async def collect_apartment_details(
        self,
        db: AsyncSession,
        limit: Optional[int] = None
    ) -> ApartDetailCollectionResponse:
        """
        ëª¨ë“  ì•„íŒŒíŠ¸ì˜ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
        
        ë°ì´í„°ë² ì´ìŠ¤ì— ìˆëŠ” ëª¨ë“  ì•„íŒŒíŠ¸ì— ëŒ€í•´ ìƒì„¸ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
        100ê°œì”© ì²˜ë¦¬ í›„ ì»¤ë°‹í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.
        
        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            limit: ì²˜ë¦¬í•  ì•„íŒŒíŠ¸ ìˆ˜ ì œí•œ (Noneì´ë©´ ì „ì²´)
        
        Returns:
            ApartDetailCollectionResponse: ìˆ˜ì§‘ ê²°ê³¼ í†µê³„
        """
        total_processed = 0
        total_saved = 0
        skipped = 0
        errors = []
        
        try:
            # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ëª¨ë“  ì•„íŒŒíŠ¸ ì¡°íšŒ
            from sqlalchemy import select
            from app.models.apartment import Apartment
            query = select(Apartment).where(Apartment.is_deleted == False)
            if limit:
                query = query.limit(limit)
            
            result = await db.execute(query)
            apartments = list(result.scalars().all())
            
            if not apartments:
                logger.warning("âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ì— ì•„íŒŒíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return ApartDetailCollectionResponse(
                    success=True,
                    total_processed=0,
                    total_saved=0,
                    skipped=0,
                    errors=[],
                    message="ìˆ˜ì§‘í•  ì•„íŒŒíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."
                )
            
            # ì‹œì‘ ë©”ì‹œì§€ ì¶œë ¥ (ì•„íŒŒíŠ¸ ê°œìˆ˜ í™•ì¸ í›„)
            total_count_msg = f"{len(apartments)}ê°œ" if not limit else f"{limit}ê°œ (ì œí•œ)"
            logger.info(f"ğŸ¢ ì•„íŒŒíŠ¸ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘: {total_count_msg}")
            
            # ì£¼ê¸°ì  ì»¤ë°‹ì„ ìœ„í•œ ì¹´ìš´í„°
            commit_interval = 10
            last_commit_count = 0
            
            for idx, apartment in enumerate(apartments, 1):
                # ê° ì•„íŒŒíŠ¸ë§ˆë‹¤ savepointë¥¼ ì‚¬ìš©í•˜ì—¬ ë…ë¦½ì ì¸ íŠ¸ëœì­ì…˜ìœ¼ë¡œ ì²˜ë¦¬
                savepoint = await db.begin_nested()
                try:
                    # 1ë‹¨ê³„: ì•„íŒŒíŠ¸ ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
                    kapt_code = apartment.kapt_code
                    apt_name = apartment.apt_name
                    apt_id = apartment.apt_id
                    
                    # 2ë‹¨ê³„: ì¤‘ë³µ í™•ì¸ (1ëŒ€1 ê´€ê³„ ë³´ì¥)
                    try:
                        existing_detail = await apart_detail_crud.get_by_apt_id(db, apt_id=apt_id)
                        if existing_detail:
                            skipped += 1
                            total_processed += 1
                            await savepoint.commit()
                            continue
                    except Exception as check_error:
                        error_msg = f"ì¤‘ë³µ í™•ì¸ ì‹¤íŒ¨: {str(check_error)}"
                        errors.append(f"ì•„íŒŒíŠ¸ '{apt_name}' (ID: {apt_id}): {error_msg}")
                        total_processed += 1
                        logger.error(f"[{idx}/{len(apartments)}] {apt_name} | âŒ ì‹¤íŒ¨: {error_msg}")
                        import traceback
                        logger.debug(f"ìƒì„¸ ìŠ¤íƒ: {traceback.format_exc()}")
                        await savepoint.rollback()
                        continue
                    
                    # 3ë‹¨ê³„: ê¸°ë³¸ì •ë³´ API í˜¸ì¶œ
                    try:
                        basic_info = await self.fetch_apartment_basic_info(kapt_code)
                        await asyncio.sleep(0.2)  # API í˜¸ì¶œ ì œí•œ ë°©ì§€
                        
                        # API ì‘ë‹µ êµ¬ì¡° í™•ì¸
                        if not isinstance(basic_info, dict):
                            error_msg = f"ê¸°ë³¸ì •ë³´ API ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜"
                            errors.append(f"ì•„íŒŒíŠ¸ '{apt_name}' (ì½”ë“œ: {kapt_code}): {error_msg}")
                            total_processed += 1
                            logger.error(f"[{idx}/{len(apartments)}] {apt_name} | âŒ ì‹¤íŒ¨: {error_msg}")
                            await savepoint.rollback()
                            continue
                        
                        response = basic_info.get("response", {})
                        if not response:
                            error_msg = f"ê¸°ë³¸ì •ë³´ API ì‘ë‹µ êµ¬ì¡° ì˜¤ë¥˜"
                            errors.append(f"ì•„íŒŒíŠ¸ '{apt_name}' (ì½”ë“œ: {kapt_code}): {error_msg}")
                            total_processed += 1
                            logger.error(f"[{idx}/{len(apartments)}] {apt_name} | âŒ ì‹¤íŒ¨: {error_msg}")
                            await savepoint.rollback()
                            continue
                        
                        header = response.get("header", {})
                        body = response.get("body", {})
                        basic_result_code = header.get("resultCode", "")
                        basic_result_msg = header.get("resultMsg", "")
                        
                        if basic_result_code != "00":
                            error_msg = f"ê¸°ë³¸ì •ë³´ API ì˜¤ë¥˜: {basic_result_msg}"
                            errors.append(f"ì•„íŒŒíŠ¸ '{apt_name}' (ì½”ë“œ: {kapt_code}): {error_msg}")
                            total_processed += 1
                            logger.error(f"[{idx}/{len(apartments)}] {apt_name} | âŒ ì‹¤íŒ¨: {error_msg}")
                            await savepoint.rollback()
                            continue
                        
                        basic_item = body.get("item", {})
                        if not basic_item:
                            error_msg = f"ê¸°ë³¸ì •ë³´ API ì‘ë‹µì— ë°ì´í„° ì—†ìŒ"
                            errors.append(f"ì•„íŒŒíŠ¸ '{apt_name}' (ì½”ë“œ: {kapt_code}): {error_msg}")
                            total_processed += 1
                            logger.error(f"[{idx}/{len(apartments)}] {apt_name} | âŒ ì‹¤íŒ¨: {error_msg}")
                            await savepoint.rollback()
                            continue
                        
                    except httpx.HTTPError as http_error:
                        error_msg = f"ê¸°ë³¸ì •ë³´ API HTTP ì˜¤ë¥˜: {str(http_error)}"
                        errors.append(f"ì•„íŒŒíŠ¸ '{apt_name}' (ì½”ë“œ: {kapt_code}): {error_msg}")
                        total_processed += 1
                        logger.error(f"[{idx}/{len(apartments)}] {apt_name} | âŒ ì‹¤íŒ¨: {error_msg}")
                        import traceback
                        logger.debug(f"ìƒì„¸ ìŠ¤íƒ: {traceback.format_exc()}")
                        await savepoint.rollback()
                        continue
                    except Exception as e:
                        error_msg = f"ê¸°ë³¸ì •ë³´ API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}"
                        errors.append(f"ì•„íŒŒíŠ¸ '{apt_name}' (ì½”ë“œ: {kapt_code}): {error_msg}")
                        total_processed += 1
                        logger.error(f"[{idx}/{len(apartments)}] {apt_name} | âŒ ì‹¤íŒ¨: {error_msg}")
                        import traceback
                        logger.debug(f"ìƒì„¸ ìŠ¤íƒ: {traceback.format_exc()}")
                        await savepoint.rollback()
                        continue
                    
                    # 4ë‹¨ê³„: ìƒì„¸ì •ë³´ API í˜¸ì¶œ
                    try:
                        detail_info = await self.fetch_apartment_detail_info(kapt_code)
                        await asyncio.sleep(0.2)  # API í˜¸ì¶œ ì œí•œ ë°©ì§€
                        
                        # API ì‘ë‹µ êµ¬ì¡° í™•ì¸
                        if not isinstance(detail_info, dict):
                            error_msg = f"ìƒì„¸ì •ë³´ API ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜"
                            errors.append(f"ì•„íŒŒíŠ¸ '{apt_name}' (ì½”ë“œ: {kapt_code}): {error_msg}")
                            total_processed += 1
                            logger.error(f"[{idx}/{len(apartments)}] {apt_name} | âŒ ì‹¤íŒ¨: {error_msg}")
                            await savepoint.rollback()
                            continue
                        
                        response = detail_info.get("response", {})
                        if not response:
                            error_msg = f"ìƒì„¸ì •ë³´ API ì‘ë‹µ êµ¬ì¡° ì˜¤ë¥˜"
                            errors.append(f"ì•„íŒŒíŠ¸ '{apt_name}' (ì½”ë“œ: {kapt_code}): {error_msg}")
                            total_processed += 1
                            logger.error(f"[{idx}/{len(apartments)}] {apt_name} | âŒ ì‹¤íŒ¨: {error_msg}")
                            await savepoint.rollback()
                            continue
                        
                        header = response.get("header", {})
                        body = response.get("body", {})
                        detail_result_code = header.get("resultCode", "")
                        detail_result_msg = header.get("resultMsg", "")
                        
                        if detail_result_code != "00":
                            error_msg = f"ìƒì„¸ì •ë³´ API ì˜¤ë¥˜: {detail_result_msg}"
                            errors.append(f"ì•„íŒŒíŠ¸ '{apt_name}' (ì½”ë“œ: {kapt_code}): {error_msg}")
                            total_processed += 1
                            logger.error(f"[{idx}/{len(apartments)}] {apt_name} | âŒ ì‹¤íŒ¨: {error_msg}")
                            await savepoint.rollback()
                            continue
                        
                        detail_item = body.get("item", {})
                        if not detail_item:
                            error_msg = f"ìƒì„¸ì •ë³´ API ì‘ë‹µì— ë°ì´í„° ì—†ìŒ"
                            errors.append(f"ì•„íŒŒíŠ¸ '{apt_name}' (ì½”ë“œ: {kapt_code}): {error_msg}")
                            total_processed += 1
                            logger.error(f"[{idx}/{len(apartments)}] {apt_name} | âŒ ì‹¤íŒ¨: {error_msg}")
                            await savepoint.rollback()
                            continue
                        
                    except httpx.HTTPError as http_error:
                        error_msg = f"ìƒì„¸ì •ë³´ API HTTP ì˜¤ë¥˜: {str(http_error)}"
                        errors.append(f"ì•„íŒŒíŠ¸ '{apt_name}' (ì½”ë“œ: {kapt_code}): {error_msg}")
                        total_processed += 1
                        logger.error(f"[{idx}/{len(apartments)}] {apt_name} | âŒ ì‹¤íŒ¨: {error_msg}")
                        import traceback
                        logger.debug(f"ìƒì„¸ ìŠ¤íƒ: {traceback.format_exc()}")
                        await savepoint.rollback()
                        continue
                    except Exception as e:
                        error_msg = f"ìƒì„¸ì •ë³´ API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}"
                        errors.append(f"ì•„íŒŒíŠ¸ '{apt_name}' (ì½”ë“œ: {kapt_code}): {error_msg}")
                        total_processed += 1
                        logger.error(f"[{idx}/{len(apartments)}] {apt_name} | âŒ ì‹¤íŒ¨: {error_msg}")
                        import traceback
                        logger.debug(f"ìƒì„¸ ìŠ¤íƒ: {traceback.format_exc()}")
                        await savepoint.rollback()
                        continue
                    
                    # 5ë‹¨ê³„: ë°ì´í„° íŒŒì‹± ë° ì¡°í•©
                    try:
                        detail_create = self.parse_apartment_details(
                            basic_info,
                            detail_info,
                            apt_id
                        )
                        
                        if not detail_create:
                            error_msg = f"ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨"
                            errors.append(f"ì•„íŒŒíŠ¸ '{apt_name}' (ì½”ë“œ: {kapt_code}): {error_msg}")
                            total_processed += 1
                            logger.error(f"[{idx}/{len(apartments)}] {apt_name} | âŒ ì‹¤íŒ¨: {error_msg}")
                            await savepoint.rollback()
                            continue
                        
                    except Exception as parse_error:
                        error_msg = f"íŒŒì‹± ì¤‘ ì˜ˆì™¸ ë°œìƒ: {str(parse_error)}"
                        errors.append(f"ì•„íŒŒíŠ¸ '{apt_name}' (ì½”ë“œ: {kapt_code}): {error_msg}")
                        total_processed += 1
                        logger.error(f"[{idx}/{len(apartments)}] {apt_name} | âŒ ì‹¤íŒ¨: {error_msg}")
                        import traceback
                        logger.debug(f"ìƒì„¸ ìŠ¤íƒ: {traceback.format_exc()}")
                        await savepoint.rollback()
                        continue
                    
                    # 6ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (1ëŒ€1 ê´€ê³„ ë³´ì¥)
                    try:
                        db_obj, is_created = await apart_detail_crud.create_or_skip(
                            db,
                            obj_in=detail_create
                        )
                        
                        if is_created:
                            total_saved += 1
                            await savepoint.commit()  # savepoint ì»¤ë°‹ (ì¤‘ì²© íŠ¸ëœì­ì…˜)
                            
                            # ê° ì•„íŒŒíŠ¸ ì €ì¥ ì‹œ ë¡œê·¸ ì¶œë ¥
                            logger.info(f"[{idx}/{len(apartments)}] {apt_name} | âœ… ì €ì¥ ì™„ë£Œ | í˜„ì¬ê¹Œì§€ ì €ì¥: {total_saved}ê°œ")
                            
                            # ì£¼ê¸°ì  ì»¤ë°‹: 10ê°œë§ˆë‹¤ ìµœìƒìœ„ íŠ¸ëœì­ì…˜ ì»¤ë°‹
                            pending_commit_count = total_saved - last_commit_count
                            if pending_commit_count >= commit_interval:
                                try:
                                    await db.commit()  # ìµœìƒìœ„ íŠ¸ëœì­ì…˜ ì»¤ë°‹ (ì‹¤ì œ DB ë°˜ì˜)
                                    last_commit_count = total_saved
                                    logger.info(f"ğŸ’¾ ì»¤ë°‹ ì™„ë£Œ: {total_saved}ê°œ ì €ì¥ë¨")
                                except Exception as commit_error:
                                    error_msg = f"ì»¤ë°‹ ì‹¤íŒ¨: {str(commit_error)}"
                                    errors.append(f"ì£¼ê¸°ì  ì»¤ë°‹ ì‹¤íŒ¨ (ì €ì¥ëœ {last_commit_count}ê°œëŠ” ìœ ì§€ë¨): {str(commit_error)}")
                                    try:
                                        await db.rollback()
                                    except Exception:
                                        pass
                                    logger.error(f"[{idx}/{len(apartments)}] {apt_name} | âŒ ì»¤ë°‹ ì‹¤íŒ¨: {error_msg}")
                        else:
                            skipped += 1
                            await savepoint.commit()  # savepoint ì»¤ë°‹ (ì¤‘ì²© íŠ¸ëœì­ì…˜)
                        
                        total_processed += 1
                        
                    except Exception as save_error:
                        error_msg = f"ì €ì¥ ì‹¤íŒ¨: {str(save_error)}"
                        errors.append(f"ì•„íŒŒíŠ¸ '{apt_name}' (ì½”ë“œ: {kapt_code}): {error_msg}")
                        total_processed += 1
                        logger.error(f"[{idx}/{len(apartments)}] {apt_name} | âŒ ì‹¤íŒ¨: {error_msg}")
                        import traceback
                        logger.debug(f"ìƒì„¸ ìŠ¤íƒ: {traceback.format_exc()}")
                        await savepoint.rollback()
                    
                except Exception as e:
                    # savepoint ë¡¤ë°±
                    try:
                        await savepoint.rollback()
                    except Exception:
                        pass
                    
                    error_msg = f"ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
                    errors.append(f"ì•„íŒŒíŠ¸ '{apt_name}' (ID: {apt_id}, ì½”ë“œ: {kapt_code}): {error_msg}")
                    total_processed += 1
                    logger.error(f"[{idx}/{len(apartments)}] {apt_name} | âŒ ì‹¤íŒ¨: {error_msg}")
                    import traceback
                    logger.debug(f"ìƒì„¸ ìŠ¤íƒ: {traceback.format_exc()}")
            
            # ë§ˆì§€ë§‰ ë‚¨ì€ ë°ì´í„° ì»¤ë°‹ (ë°˜ë“œì‹œ ì‹¤í–‰ë˜ì–´ì•¼ í•¨)
            remaining_count = total_saved - last_commit_count
            if remaining_count > 0:
                try:
                    await db.commit()  # ìµœìƒìœ„ íŠ¸ëœì­ì…˜ ì»¤ë°‹ (ì‹¤ì œ DB ë°˜ì˜)
                    last_commit_count = total_saved
                    logger.info(f"ğŸ’¾ ìµœì¢… ì»¤ë°‹ ì™„ë£Œ: ì´ {total_saved}ê°œ ì €ì¥ë¨")
                except Exception as commit_error:
                    logger.error(f"âŒ ìµœì¢… ì»¤ë°‹ ì‹¤íŒ¨: {remaining_count}ê°œ ë°ì´í„° ì†ì‹¤ ê°€ëŠ¥ - {str(commit_error)}")
                    try:
                        await db.rollback()
                    except Exception:
                        pass
                    errors.append(f"ìµœì¢… ì»¤ë°‹ ì‹¤íŒ¨ ({remaining_count}ê°œ ë°ì´í„° ì†ì‹¤): {str(commit_error)}")
            
            logger.info(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ: ì²˜ë¦¬ {total_processed}ê°œ | ì €ì¥ {total_saved}ê°œ | ê±´ë„ˆëœ€ {skipped}ê°œ")
            if errors:
                logger.warning(f"âš ï¸ ì˜¤ë¥˜ {len(errors)}ê°œ ë°œìƒ")
                for error in errors[:10]:
                    logger.warning(f"   - {error}")
                if len(errors) > 10:
                    logger.warning(f"   ... ì™¸ {len(errors) - 10}ê°œ ì˜¤ë¥˜")
            
            # ìµœì¢… ì»¤ë°‹ ì‹¤íŒ¨ê°€ ìˆì—ˆìœ¼ë©´ success=Falseë¡œ ë°˜í™˜
            final_success = len([e for e in errors if "ìµœì¢… ì»¤ë°‹ ì‹¤íŒ¨" in e]) == 0
            
            return ApartDetailCollectionResponse(
                success=final_success,
                total_processed=total_processed,
                total_saved=total_saved,
                skipped=skipped,
                errors=errors,
                message=f"ìˆ˜ì§‘ ì™„ë£Œ: {total_saved}ê°œ ì €ì¥, {skipped}ê°œ ê±´ë„ˆëœ€" if final_success else f"ìˆ˜ì§‘ ì™„ë£Œ (ì¼ë¶€ ì˜¤ë¥˜): {total_saved}ê°œ ì €ì¥, {skipped}ê°œ ê±´ë„ˆëœ€"
            )
            
        except Exception as e:
            logger.error(f"âŒ ì•„íŒŒíŠ¸ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}", exc_info=True)
            # ì˜ˆì™¸ ë°œìƒ ì‹œ ë‚¨ì€ ë°ì´í„° ì»¤ë°‹ ì‹œë„
            try:
                remaining_count = total_saved - last_commit_count
                if remaining_count > 0:
                    logger.warning(f"   âš ï¸ ì˜ˆì™¸ ë°œìƒ ì „ ë‚¨ì€ {remaining_count}ê°œ ë°ì´í„° ì»¤ë°‹ ì‹œë„...")
                    try:
                        await db.commit()
                        logger.info(f"   âœ… ì˜ˆì™¸ ë°œìƒ ì „ ë°ì´í„° ì»¤ë°‹ ì™„ë£Œ")
                    except Exception as commit_error:
                        logger.error(f"   âŒ ì˜ˆì™¸ ë°œìƒ ì „ ë°ì´í„° ì»¤ë°‹ ì‹¤íŒ¨: {str(commit_error)}")
                        await db.rollback()
            except Exception:
                pass  # ì´ë¯¸ ì˜ˆì™¸ê°€ ë°œìƒí•œ ìƒíƒœì´ë¯€ë¡œ ë¬´ì‹œ
            
            return ApartDetailCollectionResponse(
                success=False,
                total_processed=total_processed,
                total_saved=total_saved,
                skipped=skipped,
                errors=errors + [str(e)],
                message=f"ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}"
            )
    
    def _get_area_code_from_csv(self, region_code_prefix: str) -> Optional[int]:
        """
        CSV íŒŒì¼ì—ì„œ region_code ì• 5ìë¦¬ë¡œ area_code(CLS_ID)ë¥¼ ì°¾ì•„ ë°˜í™˜
        
        Args:
            region_code_prefix: region_code ì• 5ìë¦¬
        
        Returns:
            area_code (int) ë˜ëŠ” None
        """
        try:
            # CSV íŒŒì¼ ê²½ë¡œ ìºì‹± (í•œ ë²ˆë§Œ í™•ì¸)
            if not DataCollectionService._csv_path_checked:
                current_file = Path(__file__).resolve()
                current_file_str = str(current_file)
                
                if current_file_str.startswith('/app'):
                    # Docker ì»¨í…Œì´ë„ˆ ë‚´ë¶€
                    csv_path = Path('/app/legion_code.csv')
                else:
                    # ë¡œì»¬ ì‹¤í–‰: backend/app/services/data_collection.py -> í”„ë¡œì íŠ¸ ë£¨íŠ¸
                    csv_path = current_file.parent.parent.parent.parent / 'legion_code.csv'
                
                if not csv_path.exists():
                    logger.error(f"âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")
                    logger.error(f"   í˜„ì¬ íŒŒì¼ ê²½ë¡œ: {current_file_str}")
                    DataCollectionService._csv_path_checked = True
                    DataCollectionService._csv_path_cache = None
                    return None
                
                DataCollectionService._csv_path_cache = csv_path
                DataCollectionService._csv_path_checked = True
            
            # ìºì‹œëœ ê²½ë¡œê°€ ì—†ìœ¼ë©´ (íŒŒì¼ì´ ì—†ëŠ” ê²½ìš°)
            if DataCollectionService._csv_path_cache is None:
                return None
            
            csv_path = DataCollectionService._csv_path_cache
            
            region_code_prefix = str(region_code_prefix)
            if len(region_code_prefix) < 5:
                region_code_prefix = region_code_prefix[:5].ljust(5, '0')
            
            # CSV íŒŒì¼ ì½ê¸°
            with open(csv_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                rows = list(reader)
            
            # 1. 5ìë¦¬ ì¼ì¹˜ ê²€ìƒ‰
            for row in rows:
                region_code = str(row.get('region_code', '')).strip()
                if region_code.startswith(region_code_prefix):
                    return int(row.get('area_code', 0))
            
            # 2. ì• 2ìë¦¬ ì¼ì¹˜ ê²€ìƒ‰ (fallback)
            prefix_2 = region_code_prefix[:2]
            for row in rows:
                region_code = str(row.get('region_code', '')).strip()
                if region_code.startswith(prefix_2):
                    return int(row.get('area_code', 0))
            
            return None
        except Exception as e:
            logger.error(f"âŒ CSV íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
            return None
    
    async def collect_house_scores(
        self,
        db: AsyncSession
    ) -> HouseScoreCollectionResponse:
        """
        ë¶€ë™ì‚° ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘
        
        STATES í…Œì´ë¸”ì˜ region_codeë¥¼ ì‚¬ìš©í•˜ì—¬ í•œêµ­ë¶€ë™ì‚°ì› APIì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ
        HOUSE_SCORES í…Œì´ë¸”ì— ì €ì¥í•©ë‹ˆë‹¤.
        """
        total_fetched = 0
        total_saved = 0
        skipped = 0
        errors = []
        
        # ì—ëŸ¬ ì œí•œ ì„¤ì •
        MAX_CONSECUTIVE_ERRORS = 10  # ì—°ì† ì—ëŸ¬ ìµœëŒ€ íšŸìˆ˜
        MAX_ERROR_RATIO = 0.5  # ì „ì²´ ì—ëŸ¬ ë¹„ìœ¨ ìµœëŒ€ê°’ (50%)
        MIN_PROCESSED_FOR_RATIO_CHECK = 10  # ì—ëŸ¬ ë¹„ìœ¨ ì²´í¬ë¥¼ ìœ„í•œ ìµœì†Œ ì²˜ë¦¬ íšŸìˆ˜
        consecutive_errors = 0  # ì—°ì† ì—ëŸ¬ ì¹´ìš´í„°
        total_processed = 0  # ì²˜ë¦¬í•œ ì§€ì—­ ìˆ˜
        
        try:
            # REB_API_KEY í™•ì¸
            if not settings.REB_API_KEY:
                raise ValueError("REB_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
            
            logger.info("=" * 60)
            logger.info("ğŸ  ë¶€ë™ì‚° ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
            logger.info("=" * 60)
            
            # STATES í…Œì´ë¸”ì—ì„œ ëª¨ë“  region_code ì¡°íšŒ
            from app.models.state import State
            result = await db.execute(
                select(State.region_id, State.region_code)
                .where(State.is_deleted == False)
            )
            states = result.fetchall()
            
            if not states:
                logger.warning("âš ï¸ STATES í…Œì´ë¸”ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return HouseScoreCollectionResponse(
                    success=False,
                    total_fetched=0,
                    total_saved=0,
                    skipped=0,
                    errors=["STATES í…Œì´ë¸”ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."],
                    message="STATES í…Œì´ë¸”ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
                )
            
            logger.info(f"ğŸ“Š ì´ {len(states)}ê°œì˜ ì§€ì—­ ì½”ë“œ ë°œê²¬")
            
            # ê¸°ë³¸ API íŒŒë¼ë¯¸í„°
            STATBL_ID = "A_2024_00045"
            DTACYCLE_CD = "MM"
            
            # ì§„í–‰ ìƒí™© ì¶œë ¥ ê°„ê²© ì„¤ì •
            PROGRESS_INTERVAL = 50  # 50ê°œ ì§€ì—­ë§ˆë‹¤ ì§„í–‰ ìƒí™© ì¶œë ¥
            region_count = 0  # ì²˜ë¦¬í•œ ì§€ì—­ ìˆ˜ ì¹´ìš´í„°
            
            for state in states:
                region_count += 1
                # ì—ëŸ¬ ì œí•œ ì²´í¬ (ì‹¤ì œ API í˜¸ì¶œ ì—ëŸ¬ë§Œ ì¹´ìš´íŠ¸)
                if consecutive_errors >= MAX_CONSECUTIVE_ERRORS:
                    error_msg = f"âŒ ì—°ì† API í˜¸ì¶œ ì—ëŸ¬ {consecutive_errors}íšŒ ë°œìƒ. ìˆ˜ì§‘ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤."
                    logger.error(error_msg)
                    errors.append(error_msg)
                    break
                
                # ì „ì²´ ì—ëŸ¬ ë¹„ìœ¨ ì²´í¬ (ìµœì†Œ ì²˜ë¦¬ íšŸìˆ˜ ì´ìƒì¼ ë•Œë§Œ ì²´í¬)
                if total_processed >= MIN_PROCESSED_FOR_RATIO_CHECK and len(errors) > 0:
                    error_ratio = len(errors) / total_processed
                    if error_ratio >= MAX_ERROR_RATIO:
                        error_msg = f"âŒ ì „ì²´ API í˜¸ì¶œ ì—ëŸ¬ ë¹„ìœ¨ {error_ratio:.1%} ({len(errors)}/{total_processed})ê°€ ë„ˆë¬´ ë†’ìŠµë‹ˆë‹¤. ìˆ˜ì§‘ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤."
                        logger.error(error_msg)
                        errors.append(error_msg)
                        break
                
                region_id, region_code = state
                region_code_str = str(region_code)
                
                # region_code ê¸¸ì´ í™•ì¸ (ì—ëŸ¬ê°€ ì•„ë‹Œ ê±´ë„ˆë›°ê¸°)
                if len(region_code_str) < 5:
                    logger.debug(f"   â­ï¸ {region_code_str}: region_code ê¸¸ì´ê°€ 5ìë¦¬ ë¯¸ë§Œ - ê±´ë„ˆëœ€")
                    continue
                
                # region_code ì• 5ìë¦¬ ì¶”ì¶œ
                region_code_prefix = region_code_str[:5]
                
                # CSVì—ì„œ area_code ì°¾ê¸° (ì—ëŸ¬ê°€ ì•„ë‹Œ ê±´ë„ˆë›°ê¸°)
                area_code = self._get_area_code_from_csv(region_code_prefix)
                if not area_code:
                    logger.debug(f"   â­ï¸ {region_code_str}: area_codeë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ - ê±´ë„ˆëœ€")
                    continue
                
                # API í˜¸ì¶œ ì‹œì‘ - total_processed ì¹´ìš´íŠ¸ëŠ” ì‹¤ì œ API í˜¸ì¶œ ì‹œë„ ì‹œì—ë§Œ ì¦ê°€
                total_processed += 1
                
                # API í˜¸ì¶œ íŒŒë¼ë¯¸í„° (í˜ì´ì§€ë„¤ì´ì…˜: ìµœëŒ€ 1000ê°œì”©)
                p_size = 1000  # API ìµœëŒ€ í˜ì´ì§€ í¬ê¸°
                first_params = {
                    "KEY": settings.REB_API_KEY,
                    "Type": "json",
                    "pIndex": 1,
                    "pSize": p_size,
                    "STATBL_ID": STATBL_ID,
                    "DTACYCLE_CD": DTACYCLE_CD,
                    "CLS_ID": str(area_code)
                }
                
                try:
                    first_response = await self.fetch_with_retry(REB_DATA_URL, first_params)
                    
                    # API ì‘ë‹µ êµ¬ì¡° í™•ì¸ (ë””ë²„ê¹…ìš©)
                    if not first_response or not isinstance(first_response, dict):
                        consecutive_errors += 1
                        error_msg = f"{region_code_str}: API ì‘ë‹µì´ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤ (ì‘ë‹µ íƒ€ì…: {type(first_response)}) [area_code: {area_code}]"
                        errors.append(error_msg)
                        logger.warning(f"   âš ï¸ {error_msg} (ì—°ì† ì—ëŸ¬: {consecutive_errors}/{MAX_CONSECUTIVE_ERRORS})")
                        continue
                    
                    # API ì‘ë‹µ êµ¬ì¡°: {"SttsApiTblData": [{"head": [...]}, {"row": [...]}]}
                    stts_data = first_response.get("SttsApiTblData", [])
                    if not isinstance(stts_data, list) or len(stts_data) < 2:
                        consecutive_errors += 1
                        error_msg = f"{region_code_str}: API ì‘ë‹µ êµ¬ì¡°ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤ [area_code: {area_code}]"
                        errors.append(error_msg)
                        logger.warning(f"   âš ï¸ {error_msg} (ì—°ì† ì—ëŸ¬: {consecutive_errors}/{MAX_CONSECUTIVE_ERRORS})")
                        continue
                    
                    # RESULT ì •ë³´ ë° ì „ì²´ ê°œìˆ˜ ì¶”ì¶œ (head ë°ì´í„°ì—ì„œ)
                    head_data = stts_data[0].get("head", [])
                    result_data = {}
                    total_count = 0
                    
                    for item in head_data:
                        if isinstance(item, dict):
                            # RESULT ì •ë³´ ì¶”ì¶œ
                            if "RESULT" in item:
                                result_data = item["RESULT"]
                            # ì „ì²´ ê°œìˆ˜ ì¶”ì¶œ (list_total_count ë˜ëŠ” totalCount)
                            if "list_total_count" in item:
                                total_count = int(item["list_total_count"])
                            elif "totalCount" in item:
                                total_count = int(item["totalCount"])
                    
                    response_code = result_data.get("CODE", "UNKNOWN")
                    response_message = result_data.get("MESSAGE", "")
                    
                    # ì‘ë‹µì´ ì„±ê³µì¸ì§€ í™•ì¸
                    if response_code != "INFO-000":
                        consecutive_errors += 1
                        error_msg = f"{region_code_str}: API ì‘ë‹µ ì˜¤ë¥˜ [CODE: {response_code}]"
                        if response_message:
                            error_msg += f" - {response_message}"
                        error_msg += f" [area_code: {area_code}]"
                        
                        errors.append(error_msg)
                        logger.warning(f"   âš ï¸ {error_msg} (ì—°ì† ì—ëŸ¬: {consecutive_errors}/{MAX_CONSECUTIVE_ERRORS})")
                        continue
                    
                    # ì„±ê³µ ì‹œ ì—°ì† ì—ëŸ¬ ì¹´ìš´í„° ë¦¬ì…‹
                    consecutive_errors = 0
                    
                    # ì²« ë²ˆì§¸ í˜ì´ì§€ ë°ì´í„° ìˆ˜ì§‘
                    all_items = []
                    
                    # ì²« ë²ˆì§¸ í˜ì´ì§€ ROW ë°ì´í„° ì¶”ì¶œ
                    row_data = stts_data[1].get("row", [])
                    if not isinstance(row_data, list):
                        row_data = [row_data] if row_data else []
                    all_items.extend(row_data)
                    
                    # ì „ì²´ ê°œìˆ˜ê°€ í˜ì´ì§€ í¬ê¸°ë³´ë‹¤ í¬ë©´ ì¶”ê°€ í˜ì´ì§€ ì²˜ë¦¬
                    if total_count > p_size:
                        total_pages = (total_count // p_size) + (1 if total_count % p_size > 0 else 0)
                        logger.info(f"   ğŸ“„ {region_code_str}: ì´ {total_count}ê°œ ë°ì´í„°, {total_pages}í˜ì´ì§€ ìˆ˜ì§‘ ì‹œì‘")
                        
                        # ì¶”ê°€ í˜ì´ì§€ ìˆ˜ì§‘
                        for page_index in range(2, total_pages + 1):
                            try:
                                page_params = {
                                    "KEY": settings.REB_API_KEY,
                                    "Type": "json",
                                    "pIndex": page_index,
                                    "pSize": p_size,
                                    "STATBL_ID": STATBL_ID,
                                    "DTACYCLE_CD": DTACYCLE_CD,
                                    "CLS_ID": str(area_code)
                                }
                                
                                page_response = await self.fetch_with_retry(REB_DATA_URL, page_params)
                                
                                if not page_response or not isinstance(page_response, dict):
                                    logger.warning(f"   âš ï¸ {region_code_str}: í˜ì´ì§€ {page_index} ì‘ë‹µ ì˜¤ë¥˜ - ê±´ë„ˆëœ€")
                                    continue
                                
                                page_stts_data = page_response.get("SttsApiTblData", [])
                                if not isinstance(page_stts_data, list) or len(page_stts_data) < 2:
                                    logger.warning(f"   âš ï¸ {region_code_str}: í˜ì´ì§€ {page_index} êµ¬ì¡° ì˜¤ë¥˜ - ê±´ë„ˆëœ€")
                                    continue
                                
                                # í˜ì´ì§€ ì‘ë‹µ ì„±ê³µ í™•ì¸
                                page_head_data = page_stts_data[0].get("head", [])
                                page_result_data = {}
                                for item in page_head_data:
                                    if isinstance(item, dict) and "RESULT" in item:
                                        page_result_data = item["RESULT"]
                                        break
                                
                                page_response_code = page_result_data.get("CODE", "UNKNOWN")
                                if page_response_code != "INFO-000":
                                    logger.warning(f"   âš ï¸ {region_code_str}: í˜ì´ì§€ {page_index} API ì˜¤ë¥˜ [CODE: {page_response_code}] - ê±´ë„ˆëœ€")
                                    continue
                                
                                # í˜ì´ì§€ ë°ì´í„° ì¶”ê°€
                                page_row_data = page_stts_data[1].get("row", [])
                                if not isinstance(page_row_data, list):
                                    page_row_data = [page_row_data] if page_row_data else []
                                all_items.extend(page_row_data)
                                
                                # API í˜¸ì¶œ ì œí•œ ë°©ì§€
                                await asyncio.sleep(0.1)
                                
                            except Exception as e:
                                logger.warning(f"   âš ï¸ {region_code_str}: í˜ì´ì§€ {page_index} ì²˜ë¦¬ ì˜¤ë¥˜ - {str(e)} - ê±´ë„ˆëœ€")
                                continue
                    
                    logger.info(f"   ğŸ“Š {region_code_str}: {len(all_items)}ê°œ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")
                    
                    # API ì‘ë‹µ ë°ì´í„° ë¶„ì„: ì›”ë³„ ë¶„í¬ í™•ì¸
                    months_found = []
                    for item in all_items:
                        wrttime = item.get("WRTTIME_IDTFR_ID", "")
                        if wrttime and len(wrttime) >= 6:
                            base_ym = wrttime[:6]
                            if base_ym not in months_found:
                                months_found.append(base_ym)
                    
                    months_found_sorted = sorted(months_found)
                    
                    # í™€ìˆ˜/ì§ìˆ˜ ë‹¬ ë¶„ì„
                    odd_months = []
                    even_months = []
                    for month_str in months_found_sorted:
                        if len(month_str) >= 6:
                            month_num = int(month_str[4:6])
                            if month_num % 2 == 1:
                                odd_months.append(month_str)
                            else:
                                even_months.append(month_str)
                    
                    # ì›”ë³„ ë¶„ì„ ë¡œê¹…
                    logger.info(f"   ğŸ“… {region_code_str}: ì›”ë³„ ë¶„ì„ - ì´ {len(months_found_sorted)}ê°œ ì›” ë°œê²¬")
                    logger.info(f"      í™€ìˆ˜ ë‹¬: {len(odd_months)}ê°œ ({', '.join(odd_months[:10])}{'...' if len(odd_months) > 10 else ''})")
                    logger.info(f"      ì§ìˆ˜ ë‹¬: {len(even_months)}ê°œ ({', '.join(even_months[:10])}{'...' if len(even_months) > 10 else ''})")
                    
                    if len(months_found_sorted) > 0:
                        logger.info(f"      ì›” ë²”ìœ„: {months_found_sorted[0]} ~ {months_found_sorted[-1]}")
                    
                    total_fetched += len(all_items)
                    
                    # ì €ì¥ ì „ ì¹´ìš´íŠ¸ ì €ì¥
                    saved_before = total_saved
                    skipped_before = skipped
                    
                    # base_ymìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ì €ì¥ (ì „ì›” ë°ì´í„° ê³„ì‚°ì„ ìœ„í•´)
                    # WRTTIME_IDTFR_IDì˜ ì• 6ìë¦¬ê°€ base_ymì´ë¯€ë¡œ ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
                    def get_base_ym_for_sort(item):
                        wrttime = item.get("WRTTIME_IDTFR_ID", "")
                        return wrttime[:6] if len(wrttime) >= 6 else wrttime
                    
                    all_items_sorted = sorted(all_items, key=get_base_ym_for_sort)
                    
                    # ì²˜ë¦¬ ì „ ì›”ë³„ í†µê³„
                    months_before_processing = set()
                    for item in all_items_sorted:
                        wrttime = item.get("WRTTIME_IDTFR_ID", "")
                        if wrttime and len(wrttime) >= 6:
                            base_ym = wrttime[:6]
                            months_before_processing.add(base_ym)
                    
                    logger.info(f"   ğŸ” {region_code_str}: ì²˜ë¦¬ ì „ ì›” ê°œìˆ˜ - {len(months_before_processing)}ê°œ, ì´ í•­ëª© ìˆ˜: {len(all_items_sorted)}ê°œ")
                    
                    # ê° í•­ëª© ì²˜ë¦¬
                    processed_months = set()
                    skipped_months = set()
                    saved_items_by_month = {}  # ì›”ë³„ ì €ì¥ëœ í•­ëª© ì¶”ì 
                    skipped_items_by_month = {}  # ì›”ë³„ ê±´ë„ˆë›´ í•­ëª© ì¶”ì 
                    index_type_counts = {}  # index_typeë³„ ê°œìˆ˜ ì¶”ì 
                    total_items_processed = 0  # ì‹¤ì œ ì²˜ë¦¬ëœ í•­ëª© ìˆ˜
                    items_by_month_type = {}  # ì›”ë³„ index_typeë³„ í•­ëª© ìˆ˜
                    for item in all_items_sorted:
                        try:
                            # í•„ë“œ ë§¤í•‘
                            itm_nm = item.get("ITM_NM", "").strip()
                            wrttime_idtfr_id = item.get("WRTTIME_IDTFR_ID", "").strip()
                            dta_val = item.get("DTA_VAL")
                            statbl_id = item.get("STATBL_ID", STATBL_ID).strip()
                            
                            # í•„ìˆ˜ í•„ë“œ í™•ì¸
                            if not itm_nm or not wrttime_idtfr_id or dta_val is None:
                                skipped_months.add(wrttime_idtfr_id[:6] if len(wrttime_idtfr_id) >= 6 else "UNKNOWN")
                                continue
                            
                            # base_ym í˜•ì‹ ë³€í™˜ (YYYYMM)
                            base_ym = wrttime_idtfr_id[:6] if len(wrttime_idtfr_id) >= 6 else wrttime_idtfr_id
                            
                            # index_value ë³€í™˜
                            index_value = self.parse_float(dta_val)
                            if index_value is None:
                                skipped_months.add(base_ym)
                                continue
                            
                            processed_months.add(base_ym)
                            total_items_processed += 1
                            
                            # index_type ë³€í™˜ (ITM_NM -> APT/HOUSE/ALL)
                            index_type = "APT"  # ê¸°ë³¸ê°’
                            if "ë‹¨ë…" in itm_nm or "ì£¼íƒ" in itm_nm:
                                index_type = "HOUSE"
                            elif "ì „ì²´" in itm_nm or "ALL" in itm_nm.upper():
                                index_type = "ALL"
                            
                            # ì›”ë³„ index_typeë³„ í•­ëª© ìˆ˜ ì¶”ì 
                            month_type_key = f"{base_ym}_{index_type}"
                            if month_type_key not in items_by_month_type:
                                items_by_month_type[month_type_key] = 0
                            items_by_month_type[month_type_key] += 1
                            
                            # index_typeë³„ ê°œìˆ˜ ì¶”ì 
                            key = f"{base_ym}_{index_type}"
                            if key not in index_type_counts:
                                index_type_counts[key] = 0
                            index_type_counts[key] += 1
                            
                            # ì „ì›” ë°ì´í„° ì¡°íšŒí•˜ì—¬ ë³€ë™ë¥  ê³„ì‚°
                            prev_score = await house_score_crud.get_previous_month(
                                db,
                                region_id=region_id,
                                base_ym=base_ym,
                                index_type=index_type
                            )
                            
                            index_change_rate = None
                            if prev_score and prev_score.index_value:
                                # Decimal íƒ€ì…ì„ floatë¡œ ë³€í™˜
                                prev_value = float(prev_score.index_value)
                                index_change_rate = index_value - prev_value
                            
                            # HouseScoreCreate ìƒì„±
                            house_score_create = HouseScoreCreate(
                                region_id=region_id,
                                base_ym=base_ym,
                                index_value=index_value,
                                index_change_rate=index_change_rate,
                                index_type=index_type,
                                data_source=statbl_id
                            )
                            
                            # ì €ì¥ ë˜ëŠ” ê±´ë„ˆë›°ê¸°
                            _, is_created = await house_score_crud.create_or_skip(
                                db,
                                obj_in=house_score_create
                            )
                            
                            if is_created:
                                total_saved += 1
                                if base_ym not in saved_items_by_month:
                                    saved_items_by_month[base_ym] = []
                                saved_items_by_month[base_ym].append(index_type)
                            else:
                                skipped += 1
                                if base_ym not in skipped_items_by_month:
                                    skipped_items_by_month[base_ym] = []
                                skipped_items_by_month[base_ym].append(index_type)
                        
                        except Exception as e:
                            logger.warning(f"   âš ï¸ {region_code_str}: í•­ëª© ì²˜ë¦¬ ì˜¤ë¥˜ - {e}")
                            continue
                    
                    # ì²˜ë¦¬ í›„ í†µê³„ ì¶œë ¥
                    logger.info(f"   ğŸ“Š {region_code_str}: ì‹¤ì œ ì²˜ë¦¬ëœ í•­ëª© ìˆ˜ - {total_items_processed}ê°œ")
                    
                    # ì›”ë³„ index_typeë³„ í†µê³„
                    odd_month_items = sum(1 for key in items_by_month_type.keys() if len(key) >= 6 and int(key[4:6]) % 2 == 1)
                    even_month_items = sum(1 for key in items_by_month_type.keys() if len(key) >= 6 and int(key[4:6]) % 2 == 0)
                    logger.info(f"   ğŸ“ˆ {region_code_str}: ì²˜ë¦¬ëœ í•­ëª© (ì›”+íƒ€ì… ì¡°í•©) - í™€ìˆ˜ ë‹¬: {odd_month_items}ê°œ, ì§ìˆ˜ ë‹¬: {even_month_items}ê°œ")
                    
                    # ì €ì¥ ê²°ê³¼ ì¶œë ¥
                    region_saved = total_saved - saved_before
                    region_skipped = skipped - skipped_before
                    logger.info(f"   ğŸ’¾ {region_code_str}: ì €ì¥ ì™„ë£Œ (ì €ì¥: {region_saved}, ê±´ë„ˆëœ€: {region_skipped})")
                    
                    # ì²˜ë¦¬ í›„ ì›”ë³„ í†µê³„
                    processed_months_sorted = sorted(processed_months)
                    skipped_months_sorted = sorted(skipped_months)
                    
                    processed_odd = [m for m in processed_months_sorted if len(m) >= 6 and int(m[4:6]) % 2 == 1]
                    processed_even = [m for m in processed_months_sorted if len(m) >= 6 and int(m[4:6]) % 2 == 0]
                    
                    logger.info(f"   âœ… {region_code_str}: ì²˜ë¦¬ëœ ì›” - {len(processed_months_sorted)}ê°œ (í™€ìˆ˜: {len(processed_odd)}, ì§ìˆ˜: {len(processed_even)})")
                    if len(processed_months_sorted) > 0:
                        logger.info(f"      ì²˜ë¦¬ëœ ì›” ëª©ë¡: {', '.join(processed_months_sorted[:15])}{'...' if len(processed_months_sorted) > 15 else ''}")
                    
                    if len(skipped_months_sorted) > 0:
                        logger.info(f"   âš ï¸ {region_code_str}: í•„í„°ë§ëœ ì›” - {len(skipped_months_sorted)}ê°œ")
                    
                    # ì €ì¥/ê±´ë„ˆë›´ í•­ëª© ìƒì„¸ ë¶„ì„
                    saved_months_odd = [m for m in saved_items_by_month.keys() if len(m) >= 6 and int(m[4:6]) % 2 == 1]
                    saved_months_even = [m for m in saved_items_by_month.keys() if len(m) >= 6 and int(m[4:6]) % 2 == 0]
                    
                    logger.info(f"   ğŸ’¾ {region_code_str}: ì €ì¥ëœ ì›” - {len(saved_items_by_month)}ê°œ (í™€ìˆ˜: {len(saved_months_odd)}, ì§ìˆ˜: {len(saved_months_even)})")
                    
                    # index_typeë³„ í†µê³„
                    apt_count = sum(1 for types in saved_items_by_month.values() for t in types if t == "APT")
                    house_count = sum(1 for types in saved_items_by_month.values() for t in types if t == "HOUSE")
                    all_count = sum(1 for types in saved_items_by_month.values() for t in types if t == "ALL")
                    logger.info(f"   ğŸ“Š {region_code_str}: ì €ì¥ëœ index_type - APT: {apt_count}, HOUSE: {house_count}, ALL: {all_count}")
                    
                    # ê±´ë„ˆë›´ í•­ëª© ë¶„ì„ (ì¤‘ë³µ ì²´í¬ë¡œ ì¸í•œ ê±´ë„ˆë›°ê¸°)
                    if len(skipped_items_by_month) > 0:
                        skipped_months_odd = [m for m in skipped_items_by_month.keys() if len(m) >= 6 and int(m[4:6]) % 2 == 1]
                        skipped_months_even = [m for m in skipped_items_by_month.keys() if len(m) >= 6 and int(m[4:6]) % 2 == 0]
                        logger.info(f"   â­ï¸ {region_code_str}: ê±´ë„ˆë›´ ì›” - {len(skipped_items_by_month)}ê°œ (í™€ìˆ˜: {len(skipped_months_odd)}, ì§ìˆ˜: {len(skipped_months_even)})")
                        
                        # ê±´ë„ˆë›´ í•­ëª© ìƒ˜í”Œ (ì²˜ìŒ 5ê°œ)
                        skipped_samples = list(skipped_items_by_month.items())[:5]
                        for month, types in skipped_samples:
                            logger.info(f"      ê±´ë„ˆë›´ ì˜ˆì‹œ: {month} - {', '.join(types)}")
                    
                    # ì§„í–‰ ìƒí™© ì¶œë ¥ (ì¼ì • ê°„ê²©ë§ˆë‹¤ ë˜ëŠ” ë§ˆì§€ë§‰ ì§€ì—­)
                    if region_count % PROGRESS_INTERVAL == 0 or region_count == len(states):
                        progress_pct = (region_count / len(states)) * 100
                        logger.info(f"   ğŸ“ˆ ì§„í–‰ ìƒí™©: {region_count}/{len(states)} ì§€ì—­ ì²˜ë¦¬ ({progress_pct:.1f}%) | ì €ì¥: {total_saved}, ê±´ë„ˆëœ€: {skipped}, ìˆ˜ì§‘: {total_fetched}")
                    
                    # ì§€ì—­ ê°„ ë”œë ˆì´ (API í˜¸ì¶œ ì œí•œ ë°©ì§€)
                    await asyncio.sleep(0.1)
                
                except Exception as e:
                    consecutive_errors += 1
                    error_msg = f"{region_code_str}: API í˜¸ì¶œ ì˜¤ë¥˜ - {str(e)}"
                    errors.append(error_msg)
                    logger.warning(f"   âš ï¸ {error_msg} (ì—°ì† ì—ëŸ¬: {consecutive_errors}/{MAX_CONSECUTIVE_ERRORS})")
                    
                    # ì—ëŸ¬ ì œí•œ ì²´í¬
                    if consecutive_errors >= MAX_CONSECUTIVE_ERRORS:
                        logger.error(f"âŒ ì—°ì† ì—ëŸ¬ {consecutive_errors}íšŒ ë°œìƒ. ìˆ˜ì§‘ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
                        break
                    continue
            
            logger.info("=" * 60)
            logger.info(f"ğŸ‰ ë¶€ë™ì‚° ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ (ì €ì¥: {total_saved}, ê±´ë„ˆëœ€: {skipped})")
            logger.info("=" * 60)
            
            return HouseScoreCollectionResponse(
                success=True,
                total_fetched=total_fetched,
                total_saved=total_saved,
                skipped=skipped,
                errors=errors[:100],
                message=f"ë¶€ë™ì‚° ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ: {total_saved}ê°œ ì €ì¥, {skipped}ê°œ ê±´ë„ˆëœ€"
            )
        
        except ValueError as e:
            logger.error(f"âŒ ì„¤ì • ì˜¤ë¥˜: {e}")
            return HouseScoreCollectionResponse(
                success=False,
                total_fetched=total_fetched,
                total_saved=total_saved,
                skipped=skipped,
                errors=[str(e)],
                message=f"ì„¤ì • ì˜¤ë¥˜: {str(e)}"
            )
        except Exception as e:
            logger.error(f"âŒ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            return HouseScoreCollectionResponse(
                success=False,
                total_fetched=total_fetched,
                total_saved=total_saved,
                skipped=skipped,
                errors=[str(e)],
                message=f"ì˜¤ë¥˜: {str(e)}"
            )

# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
data_collection_service = DataCollectionService()
