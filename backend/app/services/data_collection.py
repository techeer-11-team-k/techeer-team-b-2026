"""
ë°ì´í„° ìˆ˜ì§‘ ì„œë¹„ìŠ¤

êµ­í† êµí†µë¶€ APIì—ì„œ ì§€ì—­ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
"""
import logging
import asyncio
import sys
import csv
import re
import calendar
import xml.etree.ElementTree as ET
from difflib import SequenceMatcher
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from urllib.parse import quote
import httpx
from datetime import datetime, date

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func, and_, text
from sqlalchemy.orm import joinedload
from sqlalchemy.exc import OperationalError, TimeoutError
from asyncpg.exceptions import TooManyConnectionsError, ConnectionDoesNotExistError
from app.db.session import AsyncSessionLocal

# ëª¨ë“  ëª¨ë¸ì„ importí•˜ì—¬ SQLAlchemy ê´€ê³„ ì„¤ì •ì´ ì œëŒ€ë¡œ ì‘ë™í•˜ë„ë¡ í•¨
from app.models import (  # noqa: F401
    Account,
    State,
    Apartment,
    ApartDetail,
    Sale,
    Rent,
    HouseScore,
    FavoriteLocation,
    FavoriteApartment,
    MyProperty,
)

from app.core.config import settings
from app.crud.state import state as state_crud
from app.crud.apartment import apartment as apartment_crud
from app.crud.apart_detail import apart_detail as apart_detail_crud
from app.crud.house_score import house_score as house_score_crud
from app.crud.rent import rent as rent_crud
from app.schemas.state import StateCreate, StateCollectionResponse
from app.schemas.apartment import ApartmentCreate, ApartmentCollectionResponse
from app.schemas.apart_detail import ApartDetailCreate, ApartDetailCollectionResponse
from app.schemas.house_score import HouseScoreCreate, HouseScoreCollectionResponse
from app.schemas.rent import RentCreate, RentCollectionResponse

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# í•¸ë“¤ëŸ¬ê°€ ì—†ìœ¼ë©´ ì¶”ê°€
if not logger.handlers:
    handler = logging.StreamHandler(sys.stdout)
    handler.setLevel(logging.INFO)
    formatter = logging.Formatter(
        '%(asctime)s | %(levelname)s | %(name)s | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    logger.propagate = False  # ë¶€ëª¨ ë¡œê±°ë¡œ ì „íŒŒí•˜ì§€ ì•ŠìŒ

# êµ­í† ë¶€ í‘œì¤€ì§€ì—­ì½”ë“œ API ì—”ë“œí¬ì¸íŠ¸
MOLIT_REGION_API_URL = "https://apis.data.go.kr/1741000/StanReginCd/getStanReginCdList"

# êµ­í† ë¶€ ì•„íŒŒíŠ¸ ëª©ë¡ API ì—”ë“œí¬ì¸íŠ¸
MOLIT_APARTMENT_LIST_API_URL = "https://apis.data.go.kr/1613000/AptListService3/getTotalAptList3"

# êµ­í† ë¶€ ì•„íŒŒíŠ¸ ê¸°ë³¸ì •ë³´ API ì—”ë“œí¬ì¸íŠ¸
MOLIT_APARTMENT_BASIC_API_URL = "https://apis.data.go.kr/1613000/AptBasisInfoServiceV4/getAphusBassInfoV4"

# êµ­í† ë¶€ ì•„íŒŒíŠ¸ ìƒì„¸ì •ë³´ API ì—”ë“œí¬ì¸íŠ¸
MOLIT_APARTMENT_DETAIL_API_URL = "https://apis.data.go.kr/1613000/AptBasisInfoServiceV4/getAphusDtlInfoV4"

# í•œêµ­ë¶€ë™ì‚°ì› API ì—”ë“œí¬ì¸íŠ¸
REB_DATA_URL = "https://www.reb.or.kr/r-one/openapi/SttsApiTblData.do"

# êµ­í† ë¶€ ì•„íŒŒíŠ¸ ë§¤ë§¤ ì‹¤ê±°ë˜ê°€ API ì—”ë“œí¬ì¸íŠ¸ (JSON)
MOLIT_SALE_API_URL = "https://apis.data.go.kr/1613000/RTMSDataSvcAptTrade/getRTMSDataSvcAptTrade"

# êµ­í† ë¶€ ì•„íŒŒíŠ¸ ì „ì›”ì„¸ ì‹¤ê±°ë˜ê°€ API ì—”ë“œí¬ì¸íŠ¸ (JSON)
MOLIT_RENT_API_URL = "https://apis.data.go.kr/1613000/RTMSDataSvcAptRent/getRTMSDataSvcAptRent"

# ì‹œë„ ëª©ë¡ (17ê°œ)
CITY_NAMES = [
    "ê°•ì›íŠ¹ë³„ìì¹˜ë„",
    "ê²½ê¸°ë„",
    "ê²½ìƒë‚¨ë„",
    "ê²½ìƒë¶ë„",
    "ê´‘ì£¼ê´‘ì—­ì‹œ",
    "ëŒ€êµ¬ê´‘ì—­ì‹œ",
    "ëŒ€ì „ê´‘ì—­ì‹œ",
    "ë¶€ì‚°ê´‘ì—­ì‹œ",
    "ì„œìš¸íŠ¹ë³„ì‹œ",
    "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ",
    "ìš¸ì‚°ê´‘ì—­ì‹œ",
    "ì¸ì²œê´‘ì—­ì‹œ",
    "ì „ë¼ë‚¨ë„",
    "ì „ë¶íŠ¹ë³„ìì¹˜ë„",
    "ì œì£¼íŠ¹ë³„ìì¹˜ë„",
    "ì¶©ì²­ë‚¨ë„",
    "ì¶©ì²­ë¶ë„"
]


class DataCollectionService:
    """
    ë°ì´í„° ìˆ˜ì§‘ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
    
    êµ­í† êµí†µë¶€ APIì—ì„œ ì§€ì—­ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    
    # CSV íŒŒì¼ ê²½ë¡œ ìºì‹œ (í•œ ë²ˆë§Œ í™•ì¸)
    _csv_path_cache: Optional[Path] = None
    _csv_path_checked: bool = False
    
    # HTTP í´ë¼ì´ì–¸íŠ¸ í’€ (ì¬ì‚¬ìš©ìœ¼ë¡œ ì†ë„ í–¥ìƒ)
    _http_client: Optional[httpx.AsyncClient] = None
    
    def __init__(self):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        if not settings.MOLIT_API_KEY:
            raise ValueError("MOLIT_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        self.api_key = settings.MOLIT_API_KEY
    
    def _get_http_client(self) -> httpx.AsyncClient:
        """HTTP í´ë¼ì´ì–¸íŠ¸ í’€ ë°˜í™˜ (ì¬ì‚¬ìš©ìœ¼ë¡œ ì†ë„ í–¥ìƒ)"""
        if self._http_client is None:
            # ì—°ê²° í’€ ì„¤ì •ìœ¼ë¡œ ì¬ì‚¬ìš© ìµœì í™”
            limits = httpx.Limits(max_keepalive_connections=50, max_connections=100)
            try:
                self._http_client = httpx.AsyncClient(
                    timeout=httpx.Timeout(15.0, connect=5.0),  # íƒ€ì„ì•„ì›ƒ ìµœì í™” (30ì´ˆ -> 15ì´ˆ)
                    limits=limits,
                    http2=False  # HTTP/2ëŠ” ì¼ë¶€ ì„œë²„ì—ì„œ ë¬¸ì œ ë°œìƒ ê°€ëŠ¥í•˜ë¯€ë¡œ ë¹„í™œì„±í™”
                )
            except Exception as e:
                # HTTP/2 ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ HTTP/1.1ë¡œ í´ë°±
                logger.warning(f"HTTP/2 ì´ˆê¸°í™” ì‹¤íŒ¨, HTTP/1.1ë¡œ í´ë°±: {e}")
                self._http_client = httpx.AsyncClient(
                    timeout=httpx.Timeout(15.0, connect=5.0),
                    limits=limits
                )
        return self._http_client
    
    async def _close_http_client(self):
        """HTTP í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ"""
        if self._http_client:
            await self._http_client.aclose()
            self._http_client = None
    
    async def fetch_with_retry(self, url: str, params: Dict[str, Any], retries: int = 3) -> Dict[str, Any]:
        """
        API í˜¸ì¶œ ì¬ì‹œë„ ë¡œì§ (ì§€ìˆ˜ ë°±ì˜¤í”„)
        """
        for attempt in range(retries):
            try:
                async with httpx.AsyncClient(timeout=10.0) as client:
                    response = await client.get(url, params=params)
                    response.raise_for_status()
                    return response.json()
            except httpx.TimeoutException:
                if attempt == retries - 1:
                    logger.warning(f"â° [Timeout] API í˜¸ì¶œ ì‹œê°„ ì´ˆê³¼ ({url}) - {retries}íšŒ ì‹œë„ ì‹¤íŒ¨")
                    raise
                await asyncio.sleep(0.5 * (2 ** attempt))
            except Exception as e:
                if attempt == retries - 1:
                    logger.warning(f"âŒ [API Error] {e} ({url})")
                    raise
                await asyncio.sleep(0.5 * (2 ** attempt))
        return {}
    
    async def fetch_region_data(
        self,
        city_name: str,
        page_no: int = 1,
        num_of_rows: int = 1000
    ) -> Dict[str, Any]:
        """
        êµ­í† ë¶€ APIì—ì„œ ì§€ì—­ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        
        Args:
            city_name: ì‹œë„ëª… (ì˜ˆ: ì„œìš¸íŠ¹ë³„ì‹œ)
            page_no: í˜ì´ì§€ ë²ˆí˜¸ (ê¸°ë³¸ê°’: 1)
            num_of_rows: í•œ í˜ì´ì§€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 1000)
        
        Returns:
            API ì‘ë‹µ ë°ì´í„° (dict)
        
        Raises:
            httpx.HTTPError: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        # URL ì¸ì½”ë”©
        encoded_city_name = quote(city_name)
        
        # API ìš”ì²­ íŒŒë¼ë¯¸í„°
        # locatadd_nm: ì£¼ì†Œëª…ìœ¼ë¡œ í•„í„°ë§ (ì‹œë„ëª…ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  ì£¼ì†Œ)
        params = {
            "serviceKey": self.api_key,
            "pageNo": str(page_no),
            "numOfRows": str(num_of_rows),
            "type": "json",
            "locatadd_nm": city_name  # ì˜ˆ: "ì„œìš¸íŠ¹ë³„ì‹œ"ë¡œ ê²€ìƒ‰í•˜ë©´ "ì„œìš¸íŠ¹ë³„ì‹œ"ë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  ì£¼ì†Œ ë°˜í™˜
        }
        
        logger.info(f"ğŸ“¡ API í˜¸ì¶œ: {city_name} (í˜ì´ì§€ {page_no}, ìš”ì²­: {num_of_rows}ê°œ)")
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.get(MOLIT_REGION_API_URL, params=params)
            response.raise_for_status()
            data = response.json()
            
            # API ì‘ë‹µ êµ¬ì¡° í™•ì¸ìš© ë¡œê¹… (ì²« í˜ì´ì§€ë§Œ)
            if page_no == 1:
                logger.debug(f"   ğŸ” API ì‘ë‹µ êµ¬ì¡° í™•ì¸: {list(data.keys()) if isinstance(data, dict) else 'ë¦¬ìŠ¤íŠ¸'}")
            
            return data
    
    def parse_region_data(
        self,
        api_response: Dict[str, Any],
        city_name: str
    ) -> tuple[List[Dict[str, str]], int, int]:
        """
        API ì‘ë‹µ ë°ì´í„° íŒŒì‹± (ëª¨ë“  ë ˆë²¨ ìˆ˜ì§‘)
        
        ì‹¤ì œ API ì‘ë‹µ êµ¬ì¡°:
        {
          "StanReginCd": [
            {
              "head": [
                {"totalCount": 493},
                {"numOfRows": "10", "pageNo": "1", "type": "JSON"},
                {"RESULT": {"resultCode": "INFO-0", "resultMsg": "NOMAL SERVICE"}}
              ]
            },
            {
              "row": [
                {
                  "region_cd": "1171000000",
                  "sido_cd": "11",
                  "sgg_cd": "710",
                  "umd_cd": "000",
                  "locatadd_nm": "ì„œìš¸íŠ¹ë³„ì‹œ ì†¡íŒŒêµ¬",
                  "locallow_nm": "ì†¡íŒŒêµ¬",
                  ...
                }
              ]
            }
          ]
        }
        
        Args:
            api_response: API ì‘ë‹µ ë°ì´í„°
            city_name: ì‹œë„ëª… (íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬ë°›ì€ ê°’)
        
        Returns:
            (íŒŒì‹±ëœ ì§€ì—­ ë°ì´í„° ëª©ë¡, ì´ ê°œìˆ˜, ì›ë³¸ ë°ì´í„° ìˆ˜)
        """
        regions = []
        total_count = 0
        original_count = 0
        
        try:
            # StanReginCd ë°°ì—´ì—ì„œ ë°ì´í„° ì¶”ì¶œ
            stan_regin_cd = api_response.get("StanReginCd", [])
            
            if not stan_regin_cd or len(stan_regin_cd) < 2:
                logger.warning("âš ï¸ API ì‘ë‹µ êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤")
                return [], 0, 0
            
            # headì—ì„œ totalCount ì¶”ì¶œ
            head_data = stan_regin_cd[0].get("head", [])
            for head_item in head_data:
                if isinstance(head_item, dict) and "totalCount" in head_item:
                    total_count = int(head_item["totalCount"])
                    break
            
            # rowì—ì„œ ì‹¤ì œ ë°ì´í„° ì¶”ì¶œ
            row_data = stan_regin_cd[1].get("row", [])
            
            # rowê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
            if not isinstance(row_data, list):
                row_data = [row_data] if row_data else []
            
            # ì›ë³¸ ë°ì´í„° ìˆ˜ ì €ì¥ (í•„í„°ë§ ì „)
            original_count = len(row_data)
            
            for item in row_data:
                # í•„ìˆ˜ í•„ë“œ ì¶”ì¶œ
                region_cd = str(item.get("region_cd", "")).strip()
                locatadd_nm = str(item.get("locatadd_nm", "")).strip()  # ì „ì²´ ì£¼ì†Œëª… (ì˜ˆ: "ì„œìš¸íŠ¹ë³„ì‹œ ì†¡íŒŒêµ¬")
                locallow_nm = str(item.get("locallow_nm", "")).strip()  # ì‹œêµ°êµ¬ëª… (ì˜ˆ: "ì†¡íŒŒêµ¬")
                umd_cd = str(item.get("umd_cd", "")).strip()  # ìë©´ë™ ì½”ë“œ
                sgg_cd = str(item.get("sgg_cd", "")).strip()  # ì‹œêµ°êµ¬ ì½”ë“œ
                ri_cd = str(item.get("ri_cd", "")).strip()  # ë¦¬ ì½”ë“œ
                
                # region_cdê°€ 10ìë¦¬ê°€ ì•„ë‹ˆë©´ ê±´ë„ˆë›°ê¸°
                if len(region_cd) != 10:
                    continue
                
                # ëª¨ë“  ë ˆë²¨ ìˆ˜ì§‘ (ë‚˜ì¤‘ì— ìµœí•˜ìœ„ ë ˆë²¨ë§Œ í•„í„°ë§)
                # ì‹œë„ëª… ì¶”ì¶œ (locatadd_nmì—ì„œ ì¶”ì¶œí•˜ê±°ë‚˜ íŒŒë¼ë¯¸í„° ì‚¬ìš©)
                parsed_city = self._extract_city_name_from_address(locatadd_nm) or city_name
                
                # ì‹œêµ°êµ¬ëª…ì´ ì—†ìœ¼ë©´ locatadd_nmì—ì„œ ì¶”ì¶œ ì‹œë„
                if not locallow_nm:
                    # "ì„œìš¸íŠ¹ë³„ì‹œ ì†¡íŒŒêµ¬" -> "ì†¡íŒŒêµ¬"
                    parts = locatadd_nm.split()
                    if len(parts) >= 2:
                        locallow_nm = parts[-1]
                    else:
                        locallow_nm = locatadd_nm
                
                regions.append({
                    "region_code": region_cd,
                    "region_name": locallow_nm,
                    "city_name": parsed_city
                })
            
            logger.info(f"âœ… íŒŒì‹± ì™„ë£Œ: ì›ë³¸ {original_count}ê°œ â†’ ìˆ˜ì§‘ {len(regions)}ê°œ ì§€ì—­ (ëª¨ë“  ë ˆë²¨ ì €ì¥, ì „ì²´ {total_count}ê°œ ì¤‘)")
            return regions, total_count, original_count
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨: {e}")
            logger.debug(f"API ì‘ë‹µ: {api_response}")
            import traceback
            logger.debug(traceback.format_exc())
            return [], 0, 0
    
    
    def _extract_city_name_from_address(self, locatadd_nm: str) -> str:
        """
        ì£¼ì†Œëª…ì—ì„œ ì‹œë„ëª… ì¶”ì¶œ
        
        Args:
            locatadd_nm: ì „ì²´ ì£¼ì†Œëª… (ì˜ˆ: "ì„œìš¸íŠ¹ë³„ì‹œ ì†¡íŒŒêµ¬")
        
        Returns:
            ì‹œë„ëª… (ì˜ˆ: "ì„œìš¸íŠ¹ë³„ì‹œ")
        """
        if not locatadd_nm:
            return ""
        
        # ì£¼ì†Œëª…ì—ì„œ ì‹œë„ëª… ì¶”ì¶œ
        for city in CITY_NAMES:
            if locatadd_nm.startswith(city):
                return city
        
        return ""
    
    def _extract_city_name_from_code(self, region_code: str) -> str:
        """
        ì§€ì—­ì½”ë“œì—ì„œ ì‹œë„ëª… ì¶”ì¶œ
        
        Args:
            region_code: ì§€ì—­ì½”ë“œ (10ìë¦¬, ì²« 2ìë¦¬ê°€ ì‹œë„ì½”ë“œ)
        
        Returns:
            ì‹œë„ëª…
        """
        if len(region_code) < 2:
            return ""
        
        sido_code = region_code[:2]
        # ì‹œë„ì½”ë“œ ë§¤í•‘
        sido_map = {
            "11": "ì„œìš¸íŠ¹ë³„ì‹œ",
            "26": "ë¶€ì‚°ê´‘ì—­ì‹œ",
            "27": "ëŒ€êµ¬ê´‘ì—­ì‹œ",
            "28": "ì¸ì²œê´‘ì—­ì‹œ",
            "29": "ê´‘ì£¼ê´‘ì—­ì‹œ",
            "30": "ëŒ€ì „ê´‘ì—­ì‹œ",
            "31": "ìš¸ì‚°ê´‘ì—­ì‹œ",
            "36": "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ",
            "41": "ê²½ê¸°ë„",
            "42": "ê°•ì›íŠ¹ë³„ìì¹˜ë„",
            "43": "ì¶©ì²­ë¶ë„",
            "44": "ì¶©ì²­ë‚¨ë„",
            "45": "ì „ë¶íŠ¹ë³„ìì¹˜ë„",
            "46": "ì „ë¼ë‚¨ë„",
            "47": "ê²½ìƒë¶ë„",
            "48": "ê²½ìƒë‚¨ë„",
            "50": "ì œì£¼íŠ¹ë³„ìì¹˜ë„"
        }
        return sido_map.get(sido_code, "")
    
    async def collect_all_regions(
        self,
        db: AsyncSession
    ) -> StateCollectionResponse:
        """
        ëª¨ë“  ì‹œë„ì˜ ì§€ì—­ ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥
        
        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        
        Returns:
            ìˆ˜ì§‘ ê²°ê³¼
        """
        total_fetched = 0
        total_saved = 0
        skipped = 0
        errors = []
        
        logger.info("=" * 60)
        logger.info("ğŸš€ ì§€ì—­ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        logger.info(f"ğŸ“‹ ëŒ€ìƒ ì‹œë„: {len(CITY_NAMES)}ê°œ")
        logger.info(f"ğŸ“‹ ì‹œë„ ëª©ë¡: {', '.join(CITY_NAMES)}")
        logger.info("=" * 60)
        
        for idx, city_name in enumerate(CITY_NAMES, 1):
            logger.info(f"\n{'='*60}")
            logger.info(f"[{idx}/{len(CITY_NAMES)}] {city_name} ì²˜ë¦¬ ì‹œì‘ (í˜„ì¬ê¹Œì§€ ì „ì²´ ìˆ˜ì§‘: {total_fetched}ê°œ)")
            logger.info(f"{'='*60}")
            
            try:
                # API í˜¸ì¶œ
                page_no = 1
                has_more = True
                city_fetched = 0
                city_saved = 0
                city_skipped = 0
                city_total_original = 0  # í•´ë‹¹ ì‹œë„ì˜ ì „ì²´ ì›ë³¸ ë°ì´í„° ìˆ˜ (ëˆ„ì )
                num_of_rows = 700  # í˜ì´ì§€ë‹¹ ìš”ì²­í•  ë ˆì½”ë“œ ìˆ˜
                
                logger.info(f"   ğŸ” {city_name} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (í˜ì´ì§€ë‹¹ {num_of_rows}ê°œ ìš”ì²­, ëª¨ë“  ë ˆë²¨ ì €ì¥)")
                
                while has_more:
                    # API ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                    api_response = await self.fetch_region_data(
                        city_name=city_name,
                        page_no=page_no,
                        num_of_rows=num_of_rows
                    )
                    
                    # ë°ì´í„° íŒŒì‹± (ëª¨ë“  ë ˆë²¨ ìˆ˜ì§‘)
                    regions, _, original_count = self.parse_region_data(api_response, city_name)
                    
                    # ì›ë³¸ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ (APIì—ì„œ ë°ì´í„°ë¥¼ ë” ì´ìƒ ë°˜í™˜í•˜ì§€ ì•ŠìŒ)
                    if original_count == 0:
                        logger.info(f"   â„¹ï¸  í˜ì´ì§€ {page_no}: ì›ë³¸ ë°ì´í„° ì—†ìŒ (ì¢…ë£Œ)")
                        has_more = False
                        break
                    
                    city_total_original += original_count
                    city_fetched += len(regions)
                    total_fetched += len(regions)
                    
                    logger.info(f"   ğŸ“„ í˜ì´ì§€ {page_no}: ì›ë³¸ {original_count}ê°œ â†’ ìˆ˜ì§‘ {len(regions)}ê°œ ì§€ì—­ (ëª¨ë“  ë ˆë²¨, ëˆ„ì : {city_fetched}ê°œ)")
                    
                    # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (ì¤‘ë³µë§Œ ì œì™¸)
                    for region_idx, region_data in enumerate(regions, 1):
                        try:
                            region_code = region_data.get('region_code', 'Unknown')
                            region_name = region_data.get('region_name', 'Unknown')
                            region_city = region_data.get('city_name', city_name)
                            
                            # ìƒì„¸ ë¡œê·¸: ì–´ëŠ ë„ì˜ ì–´ëŠ ì§€ì—­ì„ ì²˜ë¦¬í•˜ëŠ”ì§€
                            logger.info(f"   ğŸ’¾ [{city_name}] {region_city} {region_name} (ì½”ë“œ: {region_code}) ì €ì¥ ì‹œë„... ({region_idx}/{len(regions)}ë²ˆì§¸)")
                            
                            state_create = StateCreate(**region_data)
                            db_obj, is_created = await state_crud.create_or_skip(
                                db,
                                obj_in=state_create
                            )
                            
                            if is_created:
                                city_saved += 1
                                total_saved += 1
                                logger.info(f"      âœ… ì €ì¥ ì™„ë£Œ: {region_city} {region_name} (ì „ì²´ ì €ì¥: {total_saved}ê°œ)")
                            else:
                                city_skipped += 1
                                skipped += 1
                                logger.info(f"      â­ï¸  ê±´ë„ˆëœ€ (ì´ë¯¸ ì¡´ì¬): {region_city} {region_name} (ì „ì²´ ê±´ë„ˆëœ€: {skipped}ê°œ)")
                                
                        except Exception as e:
                            error_msg = f"{city_name} - {region_data.get('region_name', 'Unknown')}: {str(e)}"
                            errors.append(error_msg)
                            logger.warning(f"      âš ï¸ ì €ì¥ ì‹¤íŒ¨: {error_msg}")
                    
                    # ë‹¤ìŒ í˜ì´ì§€ í™•ì¸
                    if original_count < num_of_rows:
                        logger.info(f"   âœ… ë§ˆì§€ë§‰ í˜ì´ì§€ë¡œ íŒë‹¨ (ì›ë³¸ {original_count}ê°œ < ìš”ì²­ {num_of_rows}ê°œ)")
                        has_more = False
                    else:
                        logger.info(f"   â­ï¸  ë‹¤ìŒ í˜ì´ì§€ë¡œ... (ì›ë³¸ {original_count}ê°œ, ë‹¤ìŒ í˜ì´ì§€: {page_no + 1})")
                        page_no += 1
                    
                    # API í˜¸ì¶œ ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ë”œë ˆì´
                    await asyncio.sleep(0.2)
                
                logger.info(f"âœ… {city_name} ì™„ë£Œ: ì´ {page_no}í˜ì´ì§€ ì²˜ë¦¬, ì›ë³¸ {city_total_original}ê°œ â†’ ìˆ˜ì§‘ {city_fetched}ê°œ, ì €ì¥ {city_saved}ê°œ, ê±´ë„ˆëœ€ {city_skipped}ê°œ")
                logger.info(f"   ğŸ“Š í˜„ì¬ê¹Œì§€ ì „ì²´ í†µê³„: ìˆ˜ì§‘ {total_fetched}ê°œ, ì €ì¥ {total_saved}ê°œ, ê±´ë„ˆëœ€ {skipped}ê°œ")
                logger.info(f"   â¡ï¸  ë‹¤ìŒ ì‹œë„ë¡œ ì§„í–‰í•©ë‹ˆë‹¤...")
                
            except Exception as e:
                error_msg = f"{city_name} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
                errors.append(error_msg)
                logger.error(f"âŒ {error_msg}")
                logger.error(f"   âš ï¸ {city_name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ, ë‹¤ìŒ ì‹œë„ë¡œ ì§„í–‰í•©ë‹ˆë‹¤...")
                import traceback
                logger.error(traceback.format_exc())
                # ì˜ˆì™¸ê°€ ë°œìƒí•´ë„ ë‹¤ìŒ ì‹œë„ë¡œ ê³„ì† ì§„í–‰
                continue
        
        logger.info("=" * 60)
        logger.info("ğŸ‰ ì§€ì—­ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
        logger.info(f"ğŸ“Š ìµœì¢… í†µê³„:")
        logger.info(f"   - ì²˜ë¦¬í•œ ì‹œë„: {len(CITY_NAMES)}ê°œ")
        logger.info(f"   - ê°€ì ¸ì˜´: {total_fetched}ê°œ")
        logger.info(f"   - ì €ì¥: {total_saved}ê°œ")
        logger.info(f"   - ê±´ë„ˆëœ€: {skipped}ê°œ")
        if errors:
            logger.warning(f"âš ï¸ ì˜¤ë¥˜ {len(errors)}ê°œ ë°œìƒ:")
            for error in errors[:10]:  # ìµœëŒ€ 10ê°œë§Œ ì¶œë ¥
                logger.warning(f"   - {error}")
            if len(errors) > 10:
                logger.warning(f"   ... ì™¸ {len(errors) - 10}ê°œ ì˜¤ë¥˜")
        logger.info("=" * 60)
        
        return StateCollectionResponse(
            success=len(errors) == 0,
            total_fetched=total_fetched,
            total_saved=total_saved,
            skipped=skipped,
            errors=errors,
            message=f"ìˆ˜ì§‘ ì™„ë£Œ: {total_saved}ê°œ ì €ì¥, {skipped}ê°œ ê±´ë„ˆëœ€"
        )


    async def fetch_apartment_data(
        self,
        page_no: int = 1,
        num_of_rows: int = 1000
    ) -> Dict[str, Any]:
        """
        êµ­í† ë¶€ APIì—ì„œ ì•„íŒŒíŠ¸ ëª©ë¡ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        
        Args:
            page_no: í˜ì´ì§€ ë²ˆí˜¸ (ê¸°ë³¸ê°’: 1)
            num_of_rows: í•œ í˜ì´ì§€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 1000)
        
        Returns:
            API ì‘ë‹µ ë°ì´í„° (dict)
        
        Raises:
            httpx.HTTPError: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        # API ìš”ì²­ íŒŒë¼ë¯¸í„°
        params = {
            "serviceKey": self.api_key,
            "pageNo": str(page_no),
            "numOfRows": str(num_of_rows)
        }
        
        logger.info(f"   ğŸ“¡ API í˜¸ì¶œ: í˜ì´ì§€ {page_no}, {num_of_rows}ê°œ ìš”ì²­")
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.get(MOLIT_APARTMENT_LIST_API_URL, params=params)
            response.raise_for_status()
            data = response.json()
            
            # ì²« í˜ì´ì§€ì¼ ë•Œë§Œ ë””ë²„ê·¸ ë¡œê·¸ ì¶œë ¥
            if page_no == 1:
                logger.debug(f"   ğŸ” API ì‘ë‹µ êµ¬ì¡°: {data}")
            
            return data
    
    def parse_apartment_data(
        self,
        api_response: Dict[str, Any]
    ) -> tuple[List[Dict[str, Any]], int, int]:
        """
        ì•„íŒŒíŠ¸ ëª©ë¡ API ì‘ë‹µ íŒŒì‹±
        
        Args:
            api_response: API ì‘ë‹µ ë°ì´í„°
        
        Returns:
            (íŒŒì‹±ëœ ì•„íŒŒíŠ¸ ëª©ë¡, ì „ì²´ ê°œìˆ˜, ì›ë³¸ ê°œìˆ˜)
        """
        try:
            # ì‘ë‹µ êµ¬ì¡°: response.body.items
            body = api_response.get("response", {}).get("body", {})
            items = body.get("items", [])
            total_count = int(body.get("totalCount", 0))
            
            # itemsê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš° (ë‹¨ì¼ ê°ì²´)
            if not isinstance(items, list):
                items = [items] if items else []
            
            original_count = len(items)
            apartments = []
            
            for item in items:
                if not item:
                    continue
                
                # API ì‘ë‹µ í•„ë“œ ë§¤í•‘
                kapt_code = item.get("kaptCode", "").strip()
                kapt_name = item.get("kaptName", "").strip()
                bjd_code = item.get("bjdCode", "").strip()
                
                # í•„ìˆ˜ í•„ë“œ ê²€ì¦
                if not kapt_code or not kapt_name or not bjd_code:
                    continue
                
                apartments.append({
                    "kapt_code": kapt_code,
                    "apt_name": kapt_name,
                    "bjd_code": bjd_code,  # ë²•ì •ë™ ì½”ë“œ (region_codeë¡œ ë§¤ì¹­)
                    "as1": item.get("as1"),  # ì‹œë„
                    "as2": item.get("as2"),  # ì‹œêµ°êµ¬
                    "as3": item.get("as3"),  # ìë©´ë™
                    "as4": item.get("as4")   # ë¦¬
                })
            
            logger.info(f"âœ… íŒŒì‹± ì™„ë£Œ: ì›ë³¸ {original_count}ê°œ â†’ ìˆ˜ì§‘ {len(apartments)}ê°œ ì•„íŒŒíŠ¸ (ì „ì²´ {total_count}ê°œ ì¤‘)")
            
            return apartments, total_count, original_count
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return [], 0, 0
    
    async def collect_all_apartments(
        self,
        db: AsyncSession
    ) -> ApartmentCollectionResponse:
        """
        ëª¨ë“  ì•„íŒŒíŠ¸ ëª©ë¡ ìˆ˜ì§‘
        
        êµ­í† ë¶€ ì•„íŒŒíŠ¸ ëª©ë¡ APIì—ì„œ ëª¨ë“  ì•„íŒŒíŠ¸ë¥¼ ê°€ì ¸ì™€ì„œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤.
        
        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        
        Returns:
            ApartmentCollectionResponse: ìˆ˜ì§‘ ê²°ê³¼ í†µê³„
        """
        total_fetched = 0
        total_saved = 0
        skipped = 0
        errors = []
        
        try:
            logger.info("=" * 80)
            logger.info("ğŸ¢ ì•„íŒŒíŠ¸ ëª©ë¡ ìˆ˜ì§‘ ì‹œì‘")
            logger.info("=" * 80)
            
            page_no = 1
            has_more = True
            num_of_rows = 1000  # í˜ì´ì§€ë‹¹ ìš”ì²­í•  ë ˆì½”ë“œ ìˆ˜
            
            logger.info(f"ğŸ” ì•„íŒŒíŠ¸ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (í˜ì´ì§€ë‹¹ {num_of_rows}ê°œ ìš”ì²­)")
            
            while has_more:
                # API ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                api_response = await self.fetch_apartment_data(
                    page_no=page_no,
                    num_of_rows=num_of_rows
                )
                
                # ë°ì´í„° íŒŒì‹±
                apartments, total_count, original_count = self.parse_apartment_data(api_response)
                
                # ì›ë³¸ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
                if original_count == 0:
                    logger.info(f"   â„¹ï¸  í˜ì´ì§€ {page_no}: ì›ë³¸ ë°ì´í„° ì—†ìŒ (ì¢…ë£Œ)")
                    has_more = False
                    break
                
                total_fetched += len(apartments)
                
                logger.info(f"   ğŸ“„ í˜ì´ì§€ {page_no}: ì›ë³¸ {original_count}ê°œ â†’ ìˆ˜ì§‘ {len(apartments)}ê°œ ì•„íŒŒíŠ¸ (ëˆ„ì : {total_fetched}ê°œ)")
                
                # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                for apt_idx, apt_data in enumerate(apartments, 1):
                    try:
                        kapt_code = apt_data.get('kapt_code', 'Unknown')
                        apt_name = apt_data.get('apt_name', 'Unknown')
                        bjd_code = apt_data.get('bjd_code', '')
                        
                        # bjdCodeë¥¼ region_codeë¡œ ì‚¬ìš©í•˜ì—¬ region_id ì°¾ê¸°
                        region = await state_crud.get_by_region_code(db, region_code=bjd_code)
                        
                        if not region:
                            error_msg = f"ì•„íŒŒíŠ¸ '{apt_name}' (ì½”ë“œ: {kapt_code}): ë²•ì •ë™ ì½”ë“œ '{bjd_code}'ì— í•´ë‹¹í•˜ëŠ” ì§€ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                            errors.append(error_msg)
                            logger.warning(f"      âš ï¸ {error_msg}")
                            continue
                        
                        # ìƒì„¸ ë¡œê·¸
                        logger.info(f"   ğŸ’¾ [{region.city_name} {region.region_name}] {apt_name} (ë‹¨ì§€ì½”ë“œ: {kapt_code}) ì €ì¥ ì‹œë„... ({apt_idx}/{len(apartments)}ë²ˆì§¸)")
                        
                        apartment_create = ApartmentCreate(
                            region_id=region.region_id,
                            apt_name=apt_name,
                            kapt_code=kapt_code,
                            is_available=None  # ê¸°ë³¸ê°’
                        )
                        
                        db_obj, is_created = await apartment_crud.create_or_skip(
                            db,
                            obj_in=apartment_create
                        )
                        
                        if is_created:
                            total_saved += 1
                            logger.info(f"      âœ… ì €ì¥ ì™„ë£Œ: {apt_name} (ì „ì²´ ì €ì¥: {total_saved}ê°œ)")
                        else:
                            skipped += 1
                            logger.info(f"      â­ï¸  ê±´ë„ˆëœ€ (ì´ë¯¸ ì¡´ì¬): {apt_name} (ì „ì²´ ê±´ë„ˆëœ€: {skipped}ê°œ)")
                            
                    except Exception as e:
                        error_msg = f"ì•„íŒŒíŠ¸ '{apt_data.get('apt_name', 'Unknown')}': {str(e)}"
                        errors.append(error_msg)
                        logger.warning(f"      âš ï¸ ì €ì¥ ì‹¤íŒ¨: {error_msg}")
                
                # ë‹¤ìŒ í˜ì´ì§€ í™•ì¸
                if original_count < num_of_rows:
                    logger.info(f"   âœ… ë§ˆì§€ë§‰ í˜ì´ì§€ë¡œ íŒë‹¨ (ì›ë³¸ {original_count}ê°œ < ìš”ì²­ {num_of_rows}ê°œ)")
                    has_more = False
                else:
                    logger.info(f"   â­ï¸  ë‹¤ìŒ í˜ì´ì§€ë¡œ... (ì›ë³¸ {original_count}ê°œ, ë‹¤ìŒ í˜ì´ì§€: {page_no + 1})")
                    page_no += 1
                
                # API í˜¸ì¶œ ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ë”œë ˆì´
                await asyncio.sleep(0.2)
            
            logger.info("=" * 80)
            logger.info(f"âœ… ì•„íŒŒíŠ¸ ëª©ë¡ ìˆ˜ì§‘ ì™„ë£Œ")
            logger.info(f"   - ì´ {page_no}í˜ì´ì§€ ì²˜ë¦¬")
            logger.info(f"   - ìˆ˜ì§‘: {total_fetched}ê°œ")
            logger.info(f"   - ì €ì¥: {total_saved}ê°œ")
            logger.info(f"   - ê±´ë„ˆëœ€: {skipped}ê°œ")
            if errors:
                logger.info(f"   - ì˜¤ë¥˜: {len(errors)}ê°œ")
            logger.info("=" * 80)
            
            return ApartmentCollectionResponse(
                success=True,
                total_fetched=total_fetched,
                total_saved=total_saved,
                skipped=skipped,
                errors=errors,
                message=f"ìˆ˜ì§‘ ì™„ë£Œ: {total_saved}ê°œ ì €ì¥, {skipped}ê°œ ê±´ë„ˆëœ€"
            )
            
        except Exception as e:
            logger.error(f"âŒ ì•„íŒŒíŠ¸ ëª©ë¡ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}", exc_info=True)
            return ApartmentCollectionResponse(
                success=False,
                total_fetched=total_fetched,
                total_saved=total_saved,
                skipped=skipped,
                errors=errors + [str(e)],
                message=f"ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}"
            )

    async def fetch_apartment_basic_info(self, kapt_code: str, retries: int = 3) -> Dict[str, Any]:
        """
        êµ­í† ë¶€ APIì—ì„œ ì•„íŒŒíŠ¸ ê¸°ë³¸ì •ë³´ ê°€ì ¸ì˜¤ê¸° (Rate Limit ì²˜ë¦¬ í¬í•¨)
        
        HTTP í´ë¼ì´ì–¸íŠ¸ í’€ì„ ì¬ì‚¬ìš©í•˜ê³ , 429 ì—ëŸ¬ ì‹œ ì¬ì‹œë„ ë° ë”œë ˆì´ ì²˜ë¦¬
        
        Args:
            kapt_code: êµ­í† ë¶€ ë‹¨ì§€ì½”ë“œ
            retries: ì¬ì‹œë„ íšŸìˆ˜
        
        Returns:
            API ì‘ë‹µ ë°ì´í„° (dict)
        
        Raises:
            httpx.HTTPError: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        params = {
            "serviceKey": self.api_key,
            "kaptCode": kapt_code
        }
        
        client = self._get_http_client()
        
        for attempt in range(retries):
            try:
                response = await client.get(MOLIT_APARTMENT_BASIC_API_URL, params=params)
                
                # 429 ì—ëŸ¬ ì²˜ë¦¬ (Rate Limit)
                if response.status_code == 429:
                    wait_time = (attempt + 1) * 2  # ì§€ìˆ˜ ë°±ì˜¤í”„: 2ì´ˆ, 4ì´ˆ, 6ì´ˆ
                    logger.warning(f"âš ï¸ Rate Limit (429) ë°œìƒ, {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                    await asyncio.sleep(wait_time)
                    continue
                
                response.raise_for_status()
                logger.info(f"âœ… ì™¸ë¶€ API í˜¸ì¶œ ì„±ê³µ: ê¸°ë³¸ì •ë³´ API (kapt_code: {kapt_code})")
                data = response.json()
                return data
                
            except httpx.HTTPStatusError as e:
                if e.response.status_code == 429 and attempt < retries - 1:
                    wait_time = (attempt + 1) * 2
                    logger.warning(f"âš ï¸ Rate Limit (429) ë°œìƒ, {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                    await asyncio.sleep(wait_time)
                    continue
                raise
        
        raise httpx.HTTPStatusError("Rate Limit ì´ˆê³¼", request=None, response=None)
    
    async def fetch_apartment_detail_info(self, kapt_code: str, retries: int = 3) -> Dict[str, Any]:
        """
        êµ­í† ë¶€ APIì—ì„œ ì•„íŒŒíŠ¸ ìƒì„¸ì •ë³´ ê°€ì ¸ì˜¤ê¸° (Rate Limit ì²˜ë¦¬ í¬í•¨)
        
        HTTP í´ë¼ì´ì–¸íŠ¸ í’€ì„ ì¬ì‚¬ìš©í•˜ê³ , 429 ì—ëŸ¬ ì‹œ ì¬ì‹œë„ ë° ë”œë ˆì´ ì²˜ë¦¬
        
        Args:
            kapt_code: êµ­í† ë¶€ ë‹¨ì§€ì½”ë“œ
            retries: ì¬ì‹œë„ íšŸìˆ˜
        
        Returns:
            API ì‘ë‹µ ë°ì´í„° (dict)
        
        Raises:
            httpx.HTTPError: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        params = {
            "serviceKey": self.api_key,
            "kaptCode": kapt_code
        }
        
        client = self._get_http_client()
        
        for attempt in range(retries):
            try:
                response = await client.get(MOLIT_APARTMENT_DETAIL_API_URL, params=params)
                
                # 429 ì—ëŸ¬ ì²˜ë¦¬ (Rate Limit)
                if response.status_code == 429:
                    wait_time = (attempt + 1) * 2  # ì§€ìˆ˜ ë°±ì˜¤í”„: 2ì´ˆ, 4ì´ˆ, 6ì´ˆ
                    logger.warning(f"âš ï¸ Rate Limit (429) ë°œìƒ, {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                    await asyncio.sleep(wait_time)
                    continue
                
                response.raise_for_status()
                logger.info(f"âœ… ì™¸ë¶€ API í˜¸ì¶œ ì„±ê³µ: ìƒì„¸ì •ë³´ API (kapt_code: {kapt_code})")
                data = response.json()
                return data
                
            except httpx.HTTPStatusError as e:
                if e.response.status_code == 429 and attempt < retries - 1:
                    wait_time = (attempt + 1) * 2
                    logger.warning(f"âš ï¸ Rate Limit (429) ë°œìƒ, {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                    await asyncio.sleep(wait_time)
                    continue
                raise
        
        raise httpx.HTTPStatusError("Rate Limit ì´ˆê³¼", request=None, response=None)
    
    def parse_date(self, date_str: Optional[str]) -> Optional[str]:
        """
        ë‚ ì§œ ë¬¸ìì—´ íŒŒì‹± (YYYYMMDD -> YYYY-MM-DD)
        
        Args:
            date_str: YYYYMMDD í˜•ì‹ì˜ ë‚ ì§œ ë¬¸ìì—´
        
        Returns:
            YYYY-MM-DD í˜•ì‹ì˜ ë‚ ì§œ ë¬¸ìì—´ ë˜ëŠ” None
        """
        if not date_str or len(date_str) != 8:
            return None
        try:
            return f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
        except Exception:
            return None
    
    def parse_int(self, value: Any) -> Optional[int]:
        """
        ì •ìˆ˜ë¡œ ë³€í™˜ (ì‹¤íŒ¨ ì‹œ None ë°˜í™˜)
        
        Args:
            value: ë³€í™˜í•  ê°’
        
        Returns:
            ì •ìˆ˜ ë˜ëŠ” None
        """
        if value is None or value == "":
            return None
        try:
            if isinstance(value, str):
                # ë¹ˆ ë¬¸ìì—´ì´ë‚˜ ê³µë°± ì œê±°
                value = value.strip()
                if not value:
                    return None
            return int(value)
        except (ValueError, TypeError):
            return None
    
    def parse_float(self, value: Any) -> Optional[float]:
        """ë¬¸ìì—´/ìˆ«ìë¥¼ floatë¡œ ë³€í™˜"""
        if value is None or value == "": return None
        try:
            if isinstance(value, str):
                value = value.strip()
                if not value: return None
            return float(value)
        except (ValueError, TypeError): return None
    
    def parse_apartment_details(
        self,
        basic_info: Dict[str, Any],
        detail_info: Dict[str, Any],
        apt_id: int
    ) -> Optional[ApartDetailCreate]:
        """
        ë‘ API ì‘ë‹µì„ ì¡°í•©í•˜ì—¬ ApartDetailCreate ê°ì²´ ìƒì„±
        
        Args:
            basic_info: ê¸°ë³¸ì •ë³´ API ì‘ë‹µ
            detail_info: ìƒì„¸ì •ë³´ API ì‘ë‹µ
            apt_id: ì•„íŒŒíŠ¸ ID
        
        Returns:
            ApartDetailCreate ê°ì²´ ë˜ëŠ” None
        """
        try:
            logger.debug(f"íŒŒì‹± ì‹œì‘: apt_id={apt_id}")
            
            # ê¸°ë³¸ì •ë³´ íŒŒì‹±
            basic_item = basic_info.get("response", {}).get("body", {}).get("item", {})
            if not basic_item:
                logger.warning(f"âš ï¸ íŒŒì‹± ì‹¤íŒ¨: ê¸°ë³¸ì •ë³´ API ì‘ë‹µì— itemì´ ì—†ìŠµë‹ˆë‹¤. (apt_id: {apt_id})")
                logger.debug(f"ê¸°ë³¸ì •ë³´ ì‘ë‹µ êµ¬ì¡°: {basic_info}")
                return None
            
            # ìƒì„¸ì •ë³´ íŒŒì‹±
            detail_item = detail_info.get("response", {}).get("body", {}).get("item", {})
            if not detail_item:
                logger.warning(f"âš ï¸ íŒŒì‹± ì‹¤íŒ¨: ìƒì„¸ì •ë³´ API ì‘ë‹µì— itemì´ ì—†ìŠµë‹ˆë‹¤. (apt_id: {apt_id})")
                logger.debug(f"ìƒì„¸ì •ë³´ ì‘ë‹µ êµ¬ì¡°: {detail_info}")
                return None
            
            # í•„ìˆ˜ í•„ë“œ ê²€ì¦: ë„ë¡œëª… ì£¼ì†Œ ë˜ëŠ” ì§€ë²ˆ ì£¼ì†Œ
            doro_juso = basic_item.get("doroJuso", "").strip() if basic_item.get("doroJuso") else ""
            kapt_addr = basic_item.get("kaptAddr", "").strip() if basic_item.get("kaptAddr") else ""
            
            if not doro_juso and not kapt_addr:
                logger.warning(f"âš ï¸ íŒŒì‹± ì‹¤íŒ¨: ë„ë¡œëª… ì£¼ì†Œì™€ ì§€ë²ˆ ì£¼ì†Œê°€ ëª¨ë‘ ì—†ìŠµë‹ˆë‹¤. (apt_id: {apt_id})")
                return None
            
            # ë„ë¡œëª… ì£¼ì†Œê°€ ì—†ìœ¼ë©´ ì§€ë²ˆ ì£¼ì†Œ ì‚¬ìš©
            if not doro_juso:
                doro_juso = kapt_addr
            # ì§€ë²ˆ ì£¼ì†Œê°€ ì—†ìœ¼ë©´ ë„ë¡œëª… ì£¼ì†Œ ì‚¬ìš©
            if not kapt_addr:
                kapt_addr = doro_juso
            
            # ìš°í¸ë²ˆí˜¸ ì²˜ë¦¬ (5ìë¦¬ë¡œ ì œí•œ)
            zipcode = basic_item.get("zipcode", "").strip() if basic_item.get("zipcode") else None
            if zipcode and len(zipcode) > 5:
                zipcode = zipcode[:5]
            
            # ë‚ ì§œ íŒŒì‹±
            use_approval_date_str = self.parse_date(basic_item.get("kaptUsedate"))
            use_approval_date = None
            if use_approval_date_str:
                try:
                    from datetime import datetime
                    use_approval_date = datetime.strptime(use_approval_date_str, "%Y-%m-%d").date()
                except Exception:
                    pass
            
            # ì´ ì„¸ëŒ€ ìˆ˜ (í•„ìˆ˜)
            kaptda_cnt_raw = basic_item.get("kaptdaCnt")
            total_household_cnt = self.parse_int(kaptda_cnt_raw)
            
            if total_household_cnt is None:
                logger.debug(f"ì´ ì„¸ëŒ€ ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤. (ì›ë³¸ ê°’: {kaptda_cnt_raw})")
                return None
            
            # ê´€ë¦¬ ë°©ì‹: ìƒì„¸ì •ë³´ì˜ codeMgr ìš°ì„ , ì—†ìœ¼ë©´ ê¸°ë³¸ì •ë³´ì˜ codeMgrNm
            manage_type = detail_item.get("codeMgr", "").strip()
            if not manage_type:
                manage_type = basic_item.get("codeMgrNm", "").strip()
            if not manage_type:
                manage_type = None
            
            # ì§€í•˜ì²  ì •ë³´: ìƒì„¸ì •ë³´ ìš°ì„  (100ì ì œí•œ)
            subway_line = detail_item.get("subwayLine", "").strip() if detail_item.get("subwayLine") else None
            subway_station = detail_item.get("subwayStation", "").strip() if detail_item.get("subwayStation") else None
            subway_time = detail_item.get("kaptdWtimesub", "").strip() if detail_item.get("kaptdWtimesub") else None
            
            # 100ì ì´ˆê³¼ ì‹œ ìë¥´ê¸° (ìŠ¤í‚¤ë§ˆ ì œí•œì— ë§ì¶¤)
            if subway_line and len(subway_line) > 100:
                subway_line = subway_line[:100]
                logger.debug(f"subway_lineì´ 100ìë¥¼ ì´ˆê³¼í•˜ì—¬ ì˜ë¦¼: {len(detail_item.get('subwayLine', ''))}ì -> 100ì")
            if subway_station and len(subway_station) > 100:
                subway_station = subway_station[:100]
                logger.debug(f"subway_stationì´ 100ìë¥¼ ì´ˆê³¼í•˜ì—¬ ì˜ë¦¼: {len(detail_item.get('subwayStation', ''))}ì -> 100ì")
            if subway_time and len(subway_time) > 100:
                subway_time = subway_time[:100]
                logger.debug(f"subway_timeì´ 100ìë¥¼ ì´ˆê³¼í•˜ì—¬ ì˜ë¦¼: {len(detail_item.get('kaptdWtimesub', ''))}ì -> 100ì")
            
            # êµìœ¡ ì‹œì„¤ (200ì ì œí•œ)
            education_facility = detail_item.get("educationFacility", "").strip() if detail_item.get("educationFacility") else None
            if education_facility and len(education_facility) > 200:
                education_facility = education_facility[:200]
                logger.debug(f"educationFacilityê°€ 200ìë¥¼ ì´ˆê³¼í•˜ì—¬ ì˜ë¦¼: {len(detail_item.get('educationFacility', ''))}ì -> 200ì")
            
            # ApartDetailCreate ê°ì²´ ìƒì„±
            try:
                detail_create = ApartDetailCreate(
                    apt_id=apt_id,
                    road_address=doro_juso,
                    jibun_address=kapt_addr,
                    zip_code=zipcode,
                    code_sale_nm=basic_item.get("codeSaleNm", "").strip() if basic_item.get("codeSaleNm") else None,
                    code_heat_nm=basic_item.get("codeHeatNm", "").strip() if basic_item.get("codeHeatNm") else None,
                    total_household_cnt=total_household_cnt,
                    total_building_cnt=self.parse_int(basic_item.get("kaptDongCnt")),
                    highest_floor=self.parse_int(basic_item.get("kaptTopFloor")),
                    use_approval_date=use_approval_date,
                    total_parking_cnt=self.parse_int(detail_item.get("kaptdPcntu")),
                    builder_name=basic_item.get("kaptBcompany", "").strip() if basic_item.get("kaptBcompany") else None,
                    developer_name=basic_item.get("kaptAcompany", "").strip() if basic_item.get("kaptAcompany") else None,
                    manage_type=manage_type,
                    hallway_type=basic_item.get("codeHallNm", "").strip() if basic_item.get("codeHallNm") else None,
                    subway_time=subway_time,
                    subway_line=subway_line,
                    subway_station=subway_station,
                    educationFacility=education_facility,
                    geometry=None  # APIì—ì„œ ì œê³µë˜ì§€ ì•ŠìŒ
                )
                logger.debug(f"ApartDetailCreate ê°ì²´ ìƒì„± ì™„ë£Œ")
                return detail_create
            except Exception as create_error:
                logger.error(f"ApartDetailCreate ê°ì²´ ìƒì„± ì‹¤íŒ¨: {str(create_error)}")
                import traceback
                logger.debug(f"ìƒì„¸ ìŠ¤íƒ: {traceback.format_exc()}")
                return None
            
        except Exception as e:
            logger.error(f"íŒŒì‹± ì˜¤ë¥˜: {e}")
            import traceback
            logger.debug(f"ìƒì„¸ ìŠ¤íƒ: {traceback.format_exc()}")
            return None
    
    async def _process_single_apartment(
        self,
        apt: Apartment,
        semaphore: asyncio.Semaphore
    ) -> Dict[str, Any]:
        """
        ë‹¨ì¼ ì•„íŒŒíŠ¸ì˜ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ë° ì €ì¥ (ìµœì í™” ë²„ì „)
        
        ì‚¬ì „ ì¤‘ë³µ ì²´í¬ë¥¼ ê±°ì³¤ìœ¼ë¯€ë¡œ ë°”ë¡œ API í˜¸ì¶œí•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
        ê° ì‘ì—…ì´ ë…ë¦½ì ì¸ ì„¸ì…˜ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        
        Args:
            apt: ì•„íŒŒíŠ¸ ê°ì²´
            semaphore: ë™ì‹œì„± ì œì–´ìš© ì„¸ë§ˆí¬ì–´
        
        Returns:
            {
                "success": bool,
                "apt_name": str,
                "saved": bool,  # ì €ì¥ ì„±ê³µ ì—¬ë¶€
                "skipped": bool,  # ê±´ë„ˆëœ€ ì—¬ë¶€
                "error": str ë˜ëŠ” None
            }
        """
        async with semaphore:
            # ë…ë¦½ì ì¸ ì„¸ì…˜ ì‚¬ìš©
            async with AsyncSessionLocal() as local_db:
                try:
                    # ì‚¬ì „ ì¤‘ë³µ ì²´í¬ë¥¼ ê±°ì³¤ì§€ë§Œ, ë™ì‹œì„± ë¬¸ì œë¥¼ ëŒ€ë¹„í•´ í•œ ë²ˆ ë” ì²´í¬
                    exists_stmt = select(ApartDetail).where(
                        and_(
                            ApartDetail.apt_id == apt.apt_id,
                            ApartDetail.is_deleted == False
                        )
                    )
                    exists_result = await local_db.execute(exists_stmt)
                    existing_detail = exists_result.scalars().first()
                    
                    if existing_detail:
                        return {
                            "success": True,
                            "apt_name": apt.apt_name,
                            "saved": False,
                            "skipped": True,
                            "error": None
                        }
                    
                    # ê¸°ë³¸ì •ë³´ì™€ ìƒì„¸ì •ë³´ API í˜¸ì¶œ (Rate Limit ë°©ì§€ë¥¼ ìœ„í•´ ìˆœì°¨ ì²˜ë¦¬)
                    logger.info(f"ğŸŒ ì™¸ë¶€ API í˜¸ì¶œ ì‹œì‘: {apt.apt_name} (kapt_code: {apt.kapt_code})")
                    # 429 ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ ìˆœì°¨ì ìœ¼ë¡œ í˜¸ì¶œ (ê° í˜¸ì¶œ ì‚¬ì´ì— ì‘ì€ ë”œë ˆì´)
                    basic_info = await self.fetch_apartment_basic_info(apt.kapt_code)
                    await asyncio.sleep(0.1)  # API í˜¸ì¶œ ê°„ ì‘ì€ ë”œë ˆì´
                    detail_info = await self.fetch_apartment_detail_info(apt.kapt_code)
                    
                    # ì˜ˆì™¸ ì²˜ë¦¬
                    if isinstance(basic_info, Exception):
                        error_msg = f"ê¸°ë³¸ì •ë³´ API ì˜¤ë¥˜: {str(basic_info)}"
                        logger.debug(f"âŒ {apt.apt_name}: {error_msg}")
                        return {
                            "success": False,
                            "apt_name": apt.apt_name,
                            "saved": False,
                            "skipped": False,
                            "error": error_msg
                        }
                    
                    if isinstance(detail_info, Exception):
                        error_msg = f"ìƒì„¸ì •ë³´ API ì˜¤ë¥˜: {str(detail_info)}"
                        logger.debug(f"âŒ {apt.apt_name}: {error_msg}")
                        return {
                            "success": False,
                            "apt_name": apt.apt_name,
                            "saved": False,
                            "skipped": False,
                            "error": error_msg
                        }
                    
                    # ì‘ë‹µ ê²€ì¦
                    basic_result_code = basic_info.get("response", {}).get("header", {}).get("resultCode", "")
                    detail_result_code = detail_info.get("response", {}).get("header", {}).get("resultCode", "")
                    
                    if basic_result_code != "00":
                        basic_msg = basic_info.get("response", {}).get("header", {}).get("resultMsg", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
                        return {
                            "success": False,
                            "apt_name": apt.apt_name,
                            "saved": False,
                            "skipped": False,
                            "error": f"ê¸°ë³¸ì •ë³´ API ì˜¤ë¥˜: {basic_msg}"
                        }
                    
                    if detail_result_code != "00":
                        detail_msg = detail_info.get("response", {}).get("header", {}).get("resultMsg", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
                        return {
                            "success": False,
                            "apt_name": apt.apt_name,
                            "saved": False,
                            "skipped": False,
                            "error": f"ìƒì„¸ì •ë³´ API ì˜¤ë¥˜: {detail_msg}"
                        }
                    
                    # 3. ë°ì´í„° íŒŒì‹±
                    logger.info(f"ğŸ” íŒŒì‹± ì‹œì‘: {apt.apt_name} (apt_id: {apt.apt_id}, kapt_code: {apt.kapt_code})")
                    detail_create = self.parse_apartment_details(basic_info, detail_info, apt.apt_id)
                    
                    if not detail_create:
                        logger.warning(f"âš ï¸ íŒŒì‹± ì‹¤íŒ¨: {apt.apt_name} (kapt_code: {apt.kapt_code}) - í•„ìˆ˜ í•„ë“œ ëˆ„ë½")
                        return {
                            "success": False,
                            "apt_name": apt.apt_name,
                            "saved": False,
                            "skipped": False,
                            "error": "íŒŒì‹± ì‹¤íŒ¨: í•„ìˆ˜ í•„ë“œ ëˆ„ë½"
                        }
                    
                    logger.info(f"âœ… íŒŒì‹± ì„±ê³µ: {apt.apt_name} (apt_id: {apt.apt_id})")
                    
                    # 4. ì €ì¥ (ë§¤ë§¤/ì „ì›”ì„¸ì™€ ë™ì¼í•œ ë°©ì‹)
                    logger.info(f"ğŸ’¾ ì €ì¥ ì‹œë„: {apt.apt_name} (apt_id: {apt.apt_id})")
                    try:
                        # apt_detail_idë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì œê±°í•˜ì—¬ ìë™ ìƒì„±ë˜ë„ë¡ í•¨
                        detail_dict = detail_create.model_dump()
                        # apt_detail_idê°€ ìˆìœ¼ë©´ ì œê±° (ìë™ ìƒì„±ë˜ì–´ì•¼ í•¨)
                        if 'apt_detail_id' in detail_dict:
                            logger.warning(f"âš ï¸ apt_detail_idê°€ ìŠ¤í‚¤ë§ˆì— í¬í•¨ë˜ì–´ ìˆìŒ: {detail_dict.get('apt_detail_id')} - ì œê±°í•¨")
                            detail_dict.pop('apt_detail_id')
                        
                        # SQLAlchemyê°€ ìë™ìœ¼ë¡œ ì‹œí€€ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë„ë¡ í•¨
                        db_obj = ApartDetail(**detail_dict)
                        # apt_detail_idë¥¼ ëª…ì‹œì ìœ¼ë¡œ Noneìœ¼ë¡œ ì„¤ì • (ì‹œí€€ìŠ¤ ì‚¬ìš© ê°•ì œ)
                        db_obj.apt_detail_id = None
                        local_db.add(db_obj)
                        await local_db.commit()
                        await local_db.refresh(db_obj)  # ìƒì„±ëœ apt_detail_id ê°€ì ¸ì˜¤ê¸°
                        logger.info(f"âœ… ì €ì¥ ì„±ê³µ: {apt.apt_name} (apt_id: {apt.apt_id}, apt_detail_id: {db_obj.apt_detail_id}, kapt_code: {apt.kapt_code})")
                        
                        return {
                            "success": True,
                            "apt_name": apt.apt_name,
                            "saved": True,
                            "skipped": False,
                            "error": None
                        }
                    except Exception as save_error:
                        await local_db.rollback()
                        logger.error(f"âŒ ì €ì¥ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {apt.apt_name} (apt_id: {apt.apt_id}) - {save_error}")
                        raise save_error
                    
                except Exception as e:
                    await local_db.rollback()
                    # ì¤‘ë³µ í‚¤ ì—ëŸ¬ ì²˜ë¦¬
                    from sqlalchemy.exc import IntegrityError
                    if isinstance(e, IntegrityError):
                        error_str = str(e).lower()
                        # apt_id ì¤‘ë³µ (unique constraint) ë˜ëŠ” apt_detail_id ì¤‘ë³µ (primary key)
                        if 'duplicate key' in error_str or 'unique constraint' in error_str:
                            # ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ ë‹¤ì‹œ í™•ì¸
                            verify_stmt = select(ApartDetail).where(
                                and_(
                                    ApartDetail.apt_id == apt.apt_id,
                                    ApartDetail.is_deleted == False
                                )
                            )
                            verify_result = await local_db.execute(verify_stmt)
                            existing = verify_result.scalars().first()
                            
                            if existing:
                                logger.info(f"â­ï¸ ì¤‘ë³µìœ¼ë¡œ ê±´ë„ˆëœ€: {apt.apt_name} (apt_id: {apt.apt_id}, apt_detail_id: {existing.apt_detail_id}) - ì´ë¯¸ ì¡´ì¬í•¨")
                            else:
                                # apt_detail_id ì¤‘ë³µ ì—ëŸ¬ì¸ ê²½ìš° ì‹œí€€ìŠ¤ ë¬¸ì œë¡œ íŒë‹¨
                                if 'apt_detail_id' in str(e) or 'apart_details_pkey' in str(e):
                                    logger.error(
                                        f"âŒ ì‹œí€€ìŠ¤ ë™ê¸°í™” ë¬¸ì œ ê°ì§€: {apt.apt_name} (apt_id: {apt.apt_id}). "
                                        f"apart_details í…Œì´ë¸”ì˜ apt_detail_id ì‹œí€€ìŠ¤ê°€ ì‹¤ì œ ë°ì´í„°ì™€ ë™ê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                                        f"ë‹¤ìŒ SQLì„ ì‹¤í–‰í•˜ì„¸ìš”: "
                                        f"SELECT setval('apart_details_apt_detail_id_seq', COALESCE((SELECT MAX(apt_detail_id) FROM apart_details), 0) + 1, false);"
                                    )
                                else:
                                    logger.warning(
                                        f"âš ï¸ ì¤‘ë³µ ì—ëŸ¬ ë°œìƒí–ˆì§€ë§Œ ì‹¤ì œë¡œëŠ” ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {apt.apt_name} (apt_id: {apt.apt_id}). "
                                        f"ì—ëŸ¬: {str(e)}"
                                    )
                            
                            return {
                                "success": True,
                                "apt_name": apt.apt_name,
                                "saved": False,
                                "skipped": True,
                                "error": None
                            }
                    
                    logger.error(f"âŒ ì•„íŒŒíŠ¸ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨ ({apt.apt_name}): {e}", exc_info=True)
                    return {
                        "success": False,
                        "apt_name": apt.apt_name,
                        "saved": False,
                        "skipped": False,
                        "error": str(e)
                    }
    
    async def collect_apartment_details(
        self,
        db: AsyncSession,
        limit: Optional[int] = None
    ) -> ApartDetailCollectionResponse:
        """
        ëª¨ë“  ì•„íŒŒíŠ¸ì˜ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ (ì´ˆê³ ì† ìµœì í™” ë²„ì „)
        
        ìµœì í™” ë°©ì•ˆ:
        1. ì‚¬ì „ ì¤‘ë³µ ì²´í¬ë¡œ ë¶ˆí•„ìš”í•œ API í˜¸ì¶œ ì œê±° (ê°€ì¥ ì¤‘ìš”!)
        2. HTTP í´ë¼ì´ì–¸íŠ¸ í’€ ì¬ì‚¬ìš©
        3. ë³‘ë ¬ ì²˜ë¦¬ ì¦ê°€
        4. íƒ€ì„ì•„ì›ƒ ìµœì í™”
        
        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ (ì•„íŒŒíŠ¸ ëª©ë¡ ì¡°íšŒìš©)
            limit: ì²˜ë¦¬í•  ì•„íŒŒíŠ¸ ìˆ˜ ì œí•œ (Noneì´ë©´ ì „ì²´)
        
        Returns:
            ApartDetailCollectionResponse: ìˆ˜ì§‘ ê²°ê³¼ í†µê³„
        """
        total_processed = 0
        total_saved = 0
        skipped = 0
        errors = []
        # ë³‘ë ¬ ì²˜ë¦¬ (API Rate Limit ê³ ë ¤í•˜ì—¬ ì¡°ì •)
        # ê° ì•„íŒŒíŠ¸ë§ˆë‹¤ 2ê°œ API í˜¸ì¶œ(ê¸°ë³¸ì •ë³´+ìƒì„¸ì •ë³´)ì´ ë³‘ë ¬ë¡œ ë°œìƒí•˜ë¯€ë¡œ ì‹¤ì œ ë™ì‹œ ìš”ì²­ì€ 2ë°°
        CONCURRENT_LIMIT = 5  # 429 ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ 5ê°œë¡œ ì œí•œ (ì‹¤ì œ ë™ì‹œ ìš”ì²­: ìµœëŒ€ 10ê°œ)
        semaphore = asyncio.Semaphore(CONCURRENT_LIMIT)
        BATCH_SIZE = 16  # ë°°ì¹˜ í¬ê¸° ê°ì†Œ (100 -> 50 -> 40)
        
        try:
            logger.info("ğŸš€ [ì´ˆê³ ì† ëª¨ë“œ] ì•„íŒŒíŠ¸ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘")
            logger.info(f"   ì„¤ì •: ë³‘ë ¬ {CONCURRENT_LIMIT}ê°œ, ë°°ì¹˜ {BATCH_SIZE}ê°œ")
            logger.info("   ìµœì í™”: ì‚¬ì „ ì¤‘ë³µ ì²´í¬ + HTTP í’€ ì¬ì‚¬ìš© + Rate Limit ì²˜ë¦¬")
            loop_limit = limit if limit else 1000000
            
            while total_processed < loop_limit:
                fetch_limit = min(BATCH_SIZE, loop_limit - total_processed)
                if fetch_limit <= 0: break
                
                # ì•„íŒŒíŠ¸ ëª©ë¡ ì¡°íšŒ (ë©”ì¸ ì„¸ì…˜ ì‚¬ìš©)
                targets = await apartment_crud.get_multi_missing_details(db, limit=fetch_limit)
                
                if not targets:
                    logger.info("âœ¨ ë” ì´ìƒ ìˆ˜ì§‘í•  ì•„íŒŒíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    break
                
                logger.info(f"   ğŸ” 1ì°¨ í•„í„°ë§: get_multi_missing_details ë°˜í™˜ {len(targets)}ê°œ")
                
                # ğŸš€ ìµœì í™” 1: ì‚¬ì „ ì¤‘ë³µ ì²´í¬ë¡œ ë¶ˆí•„ìš”í•œ API í˜¸ì¶œ ì œê±°
                apt_ids = [apt.apt_id for apt in targets]
                check_stmt = select(ApartDetail.apt_id).where(
                    and_(
                        ApartDetail.apt_id.in_(apt_ids),
                        ApartDetail.is_deleted == False
                    )
                )
                check_result = await db.execute(check_stmt)
                existing_apt_ids = set(check_result.scalars().all())
                
                # ì¤‘ë³µì´ ì•„ë‹Œ ì•„íŒŒíŠ¸ë§Œ í•„í„°ë§
                targets_to_process = [apt for apt in targets if apt.apt_id not in existing_apt_ids]
                pre_skipped = len(existing_apt_ids)
                skipped += pre_skipped
                
                # ğŸš¨ ì¤‘ìš”: 1ì°¨ í•„í„°ë§ ê²°ê³¼ì™€ 2ì°¨ ì²´í¬ ê²°ê³¼ê°€ ë‹¤ë¥´ë©´ ê²½ê³ 
                if pre_skipped > 0:
                    logger.warning(
                        f"   âš ï¸  ì¤‘ë³µ ë°œê²¬: 1ì°¨ í•„í„°ë§ì—ì„œ {len(targets)}ê°œ ë°˜í™˜í–ˆì§€ë§Œ, "
                        f"2ì°¨ ì²´í¬ì—ì„œ {pre_skipped}ê°œê°€ ì´ë¯¸ ì¡´ì¬í•¨. "
                        f"get_multi_missing_details ì¿¼ë¦¬ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
                    )
                
                if not targets_to_process:
                    logger.info(f"   â­ï¸  ë°°ì¹˜ ì „ì²´ ê±´ë„ˆëœ€ ({pre_skipped}ê°œ ì´ë¯¸ ì¡´ì¬) - API í˜¸ì¶œ ì—†ìŒ âœ…")
                    total_processed += len(targets)
                    continue
                
                logger.info(
                    f"   ğŸ“Š ë°°ì¹˜: ì „ì²´ {len(targets)}ê°œ ì¤‘ {pre_skipped}ê°œ ê±´ë„ˆëœ€, "
                    f"{len(targets_to_process)}ê°œ ì²˜ë¦¬ (ì˜ˆìƒ API í˜¸ì¶œ: {len(targets_to_process) * 2}íšŒ)"
                )
                
                # ë³‘ë ¬ë¡œ ì²˜ë¦¬ (ê° ì‘ì—…ì´ ë…ë¦½ì ì¸ ì„¸ì…˜ ì‚¬ìš©)
                # Rate Limitì„ ê³ ë ¤í•˜ì—¬ ì‘ì€ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
                batch_tasks = []
                for i in range(0, len(targets_to_process), CONCURRENT_LIMIT):
                    batch = targets_to_process[i:i + CONCURRENT_LIMIT]
                    tasks = [self._process_single_apartment(apt, semaphore) for apt in batch]
                    batch_tasks.append(tasks)
                
                # ê° ë°°ì¹˜ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬ (Rate Limit ë°©ì§€)
                all_results = []
                for batch_idx, tasks in enumerate(batch_tasks):
                    results = await asyncio.gather(*tasks, return_exceptions=True)
                    all_results.extend(results)
                    
                    # ë°°ì¹˜ ê°„ ë”œë ˆì´ (Rate Limit ë°©ì§€) - 429 ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ ì¦ê°€
                    if batch_idx < len(batch_tasks) - 1:  # ë§ˆì§€ë§‰ ë°°ì¹˜ê°€ ì•„ë‹ˆë©´
                        delay_time = 0.1  # 2ì´ˆ ë”œë ˆì´ë¡œ ì¦ê°€
                        logger.info(f"   â¸ï¸  ë°°ì¹˜ ê°„ {delay_time}ì´ˆ ëŒ€ê¸° ì¤‘... (Rate Limit ë°©ì§€)")
                        await asyncio.sleep(delay_time)
                
                results = all_results
                
                # ê²°ê³¼ ì§‘ê³„
                batch_saved = 0
                batch_skipped = 0
                batch_errors = 0
                error_samples = []  # ì—ëŸ¬ ìƒ˜í”Œ (ì²˜ìŒ 5ê°œë§Œ)
                
                for res in results:
                    if isinstance(res, Exception):
                        batch_errors += 1
                        error_msg = f"ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸: {str(res)}"
                        errors.append(error_msg)
                        if len(error_samples) < 5:
                            error_samples.append(error_msg)
                        continue
                    
                    if res.get("success"):
                        if res.get("saved"):
                            batch_saved += 1
                            total_saved += 1
                        elif res.get("skipped"):
                            batch_skipped += 1
                            skipped += 1
                    else:
                        batch_errors += 1
                        error_msg = f"{res.get('apt_name', 'Unknown')}: {res.get('error', 'Unknown error')}"
                        errors.append(error_msg)
                        if len(error_samples) < 5:
                            error_samples.append(error_msg)
                
                # ì—ëŸ¬ê°€ ìˆìœ¼ë©´ ìƒ˜í”Œ ì¶œë ¥
                if batch_errors > 0 and error_samples:
                    logger.warning(f"   âš ï¸ ì—ëŸ¬ ìƒ˜í”Œ (ì´ {batch_errors}ê°œ ì¤‘): {error_samples[:3]}")
                
                total_processed += len(targets)
                
                # ë¡œê·¸ ì¶œë ¥
                if batch_saved > 0 or batch_skipped > 0 or batch_errors > 0:
                    logger.info(
                        f"   ğŸ’¾ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: ì €ì¥ {batch_saved}ê°œ, "
                        f"ê±´ë„ˆëœ€ {batch_skipped}ê°œ, ì‹¤íŒ¨ {batch_errors}ê°œ "
                        f"(ì‚¬ì „ ê±´ë„ˆëœ€ {pre_skipped}ê°œ í¬í•¨, ëˆ„ì : ì €ì¥ {total_saved}ê°œ, ê±´ë„ˆëœ€ {skipped}ê°œ)"
                    )

            # HTTP í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ
            await self._close_http_client()
            
            logger.info("=" * 60)
            logger.info(f"ğŸ‰ ìˆ˜ì§‘ ì™„ë£Œ (ì´ {total_saved}ê°œ ì €ì¥, {skipped}ê°œ ê±´ë„ˆëœ€, {len(errors)}ê°œ ì˜¤ë¥˜)")
            return ApartDetailCollectionResponse(
                success=True,
                total_processed=total_processed,
                total_saved=total_saved,
                skipped=skipped,
                errors=errors[:100],
                message=f"ì´ˆê³ ì† ìˆ˜ì§‘ ì™„ë£Œ: {total_saved}ê°œ ì €ì¥ë¨"
            )

        except Exception as e:
            await self._close_http_client()
            logger.error(f"âŒ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            return ApartDetailCollectionResponse(success=False, total_processed=total_processed, errors=[str(e)], message=f"ì˜¤ë¥˜: {str(e)}")

    # =========================================================================
    # ì „ì›”ì„¸ ì‹¤ê±°ë˜ê°€ ìˆ˜ì§‘ ë©”ì„œë“œ
    # =========================================================================
    
    async def fetch_rent_data(
        self,
        lawd_cd: str,
        deal_ymd: str
    ) -> str:
        """
        êµ­í† êµí†µë¶€ APIì—ì„œ ì•„íŒŒíŠ¸ ì „ì›”ì„¸ ì‹¤ê±°ë˜ê°€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        
        Args:
            lawd_cd: ì§€ì—­ì½”ë“œ (ë²•ì •ë™ì½”ë“œ ì• 5ìë¦¬)
            deal_ymd: ê³„ì•½ë…„ì›” (YYYYMM)
        
        Returns:
            XML ì‘ë‹µ ë¬¸ìì—´
        
        Raises:
            httpx.HTTPError: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        
        Note:
            - API ì¸ì¦í‚¤ëŠ” ì„œë²„ì˜ MOLIT_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
            - êµ­í† ë¶€ ì „ì›”ì„¸ APIëŠ” XML í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•©ë‹ˆë‹¤.
            - JSON ë³€í™˜ì€ parse_rent_xml_to_json() ë©”ì„œë“œì—ì„œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        """
        
        params = {
            "serviceKey": self.api_key,
            "LAWD_CD": lawd_cd,
            "DEAL_YMD": deal_ymd
        }
        
        logger.info(f"ğŸ“¡ ì „ì›”ì„¸ API í˜¸ì¶œ: ì§€ì—­ì½”ë“œ={lawd_cd}, ê³„ì•½ë…„ì›”={deal_ymd}")
        
        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.get(MOLIT_RENT_API_URL, params=params)
            response.raise_for_status()
            
            # ì‘ë‹µì´ XMLì´ë¯€ë¡œ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜
            return response.text
    
    def parse_rent_xml_to_json(
        self,
        xml_data: str
    ) -> tuple[List[Dict[str, Any]], str, str]:
        """
        êµ­í† ë¶€ ì „ì›”ì„¸ API XML ì‘ë‹µì„ JSONìœ¼ë¡œ ë³€í™˜
        
        Args:
            xml_data: XML ì‘ë‹µ ë¬¸ìì—´
        
        Returns:
            (ê±°ë˜ ë°ì´í„° ë¦¬ìŠ¤íŠ¸, ê²°ê³¼ì½”ë“œ, ê²°ê³¼ë©”ì‹œì§€)
        
        Note:
            - xmltodict ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ XML â†’ dict ë³€í™˜
            - API ì‘ë‹µì˜ ë¹ˆ ê°’(" ")ì€ Noneìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        """
        try:
            # XML â†’ dict ë³€í™˜
            data = xmltodict.parse(xml_data)
            
            # ì‘ë‹µ êµ¬ì¡° ì¶”ì¶œ
            response = data.get("response", {})
            header = response.get("header", {})
            body = response.get("body", {})
            
            result_code = header.get("resultCode", "")
            result_msg = header.get("resultMsg", "")
            
            # ê²°ê³¼ ì½”ë“œ í™•ì¸ (000 ë˜ëŠ” 00ì´ ì„±ê³µ)
            if result_code not in ["000", "00"]:
                logger.warning(f"âš ï¸ API ì‘ë‹µ ì˜¤ë¥˜: {result_code} - {result_msg}")
                return [], result_code, result_msg
            
            # items ì¶”ì¶œ
            items = body.get("items", {})
            if not items:
                logger.info("   â„¹ï¸ ì¡°íšŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return [], result_code, result_msg
            
            item_list = items.get("item", [])
            
            # ë‹¨ì¼ ì•„ì´í…œì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            if isinstance(item_list, dict):
                item_list = [item_list]
            
            # ë¹ˆ ê°’(" ") â†’ None ë³€í™˜
            cleaned_items = []
            for item in item_list:
                cleaned_item = {}
                for key, value in item.items():
                    if isinstance(value, str) and value.strip() == "":
                        cleaned_item[key] = None
                    else:
                        cleaned_item[key] = value
                cleaned_items.append(cleaned_item)
            
            logger.info(f"âœ… XML â†’ JSON ë³€í™˜ ì™„ë£Œ: {len(cleaned_items)}ê°œ ê±°ë˜ ë°ì´í„°")
            
            return cleaned_items, result_code, result_msg
            
        except Exception as e:
            logger.error(f"âŒ XML íŒŒì‹± ì‹¤íŒ¨: {e}")
            return [], "PARSE_ERROR", str(e)
    
    def parse_rent_item_from_xml(
        self,
        item: ET.Element,
        apt_id: int,
        apt_name: str = ""
    ) -> Optional[RentCreate]:
        """
        ì „ì›”ì„¸ ê±°ë˜ ë°ì´í„° íŒŒì‹± (XML Element)
        
        API ì‘ë‹µì˜ ë‹¨ì¼ XML ì•„ì´í…œì„ RentCreate ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            item: API ì‘ë‹µ ì•„ì´í…œ (XML Element)
            apt_id: ë§¤ì¹­ëœ ì•„íŒŒíŠ¸ ID
        
        Returns:
            RentCreate ìŠ¤í‚¤ë§ˆ ë˜ëŠ” None (íŒŒì‹± ì‹¤íŒ¨ ì‹œ)
        
        Note:
            - ë³´ì¦ê¸ˆê³¼ ì›”ì„¸ì˜ ì‰¼í‘œ(,)ë¥¼ ì œê±°í•˜ê³  ì •ìˆ˜ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
            - ê±°ë˜ì¼ì€ dealYear, dealMonth, dealDayë¥¼ ì¡°í•©í•˜ì—¬ ìƒì„±í•©ë‹ˆë‹¤.
            - ê³„ì•½ìœ í˜•ì€ "ê°±ì‹ "ì´ë©´ True, ê·¸ ì™¸ì—ëŠ” False ë˜ëŠ” Noneì…ë‹ˆë‹¤.
            - monthlyRentê°€ 0ì´ë©´ ì „ì„¸, 0ì´ ì•„ë‹ˆë©´ ì›”ì„¸ì…ë‹ˆë‹¤.
        """
        try:
            # ê±°ë˜ì¼ íŒŒì‹± (í•„ìˆ˜)
            deal_year_elem = item.find("dealYear")
            deal_month_elem = item.find("dealMonth")
            deal_day_elem = item.find("dealDay")
            
            deal_year = deal_year_elem.text.strip() if deal_year_elem is not None and deal_year_elem.text else None
            deal_month = deal_month_elem.text.strip() if deal_month_elem is not None and deal_month_elem.text else None
            deal_day = deal_day_elem.text.strip() if deal_day_elem is not None and deal_day_elem.text else None
            
            if not deal_year or not deal_month or not deal_day:
                apt_nm_elem = item.find("aptNm")
                apt_nm = apt_nm_elem.text if apt_nm_elem is not None and apt_nm_elem.text else "Unknown"
                logger.warning(f"   âš ï¸ ê±°ë˜ì¼ ì •ë³´ ëˆ„ë½: {apt_nm}")
                return None
            
            try:
                deal_date_obj = date(
                    int(deal_year),
                    int(deal_month),
                    int(deal_day)
                )
            except (ValueError, TypeError) as e:
                logger.warning(f"   âš ï¸ ê±°ë˜ì¼ ë³€í™˜ ì‹¤íŒ¨: {deal_year}-{deal_month}-{deal_day}, ì˜¤ë¥˜: {e}")
                return None
            
            # ì „ìš©ë©´ì  íŒŒì‹± (í•„ìˆ˜)
            exclu_use_ar_elem = item.find("excluUseAr")
            exclu_use_ar = exclu_use_ar_elem.text.strip() if exclu_use_ar_elem is not None and exclu_use_ar_elem.text else None
            
            if not exclu_use_ar:
                apt_nm_elem = item.find("aptNm")
                apt_nm = apt_nm_elem.text if apt_nm_elem is not None and apt_nm_elem.text else "Unknown"
                logger.warning(f"   âš ï¸ ì „ìš©ë©´ì  ì •ë³´ ëˆ„ë½: {apt_nm}")
                return None
            
            try:
                exclusive_area = float(exclu_use_ar)
            except (ValueError, TypeError):
                logger.warning(f"   âš ï¸ ì „ìš©ë©´ì  ë³€í™˜ ì‹¤íŒ¨: {exclu_use_ar}")
                return None
            
            # ì¸µ íŒŒì‹± (í•„ìˆ˜)
            floor_elem = item.find("floor")
            floor_str = floor_elem.text.strip() if floor_elem is not None and floor_elem.text else None
            
            if not floor_str:
                apt_nm_elem = item.find("aptNm")
                apt_nm = apt_nm_elem.text if apt_nm_elem is not None and apt_nm_elem.text else "Unknown"
                logger.warning(f"   âš ï¸ ì¸µ ì •ë³´ ëˆ„ë½: {apt_nm}")
                return None
            
            try:
                floor = int(floor_str)
            except (ValueError, TypeError):
                logger.warning(f"   âš ï¸ ì¸µ ë³€í™˜ ì‹¤íŒ¨: {floor_str}")
                return None
            
            # ë³´ì¦ê¸ˆ íŒŒì‹± (ì‰¼í‘œ ì œê±°)
            deposit_elem = item.find("deposit")
            deposit_str = deposit_elem.text.strip() if deposit_elem is not None and deposit_elem.text else None
            deposit_price = None
            if deposit_str:
                try:
                    deposit_price = int(deposit_str.replace(",", ""))
                except (ValueError, TypeError, AttributeError):
                    pass
            
            # ì›”ì„¸ íŒŒì‹±
            monthly_rent_elem = item.find("monthlyRent")
            monthly_rent_str = monthly_rent_elem.text.strip() if monthly_rent_elem is not None and monthly_rent_elem.text else None
            monthly_rent = None
            if monthly_rent_str:
                try:
                    monthly_rent = int(monthly_rent_str.replace(",", ""))
                except (ValueError, TypeError, AttributeError):
                    pass
            
            # ì „ì„¸/ì›”ì„¸ êµ¬ë¶„: monthlyRentê°€ 0ì´ë©´ ì „ì„¸, 0ì´ ì•„ë‹ˆë©´ ì›”ì„¸
            # ì „ì„¸ì¸ ê²½ìš°: deposit_priceê°€ ì „ì„¸ê°€, monthly_rentëŠ” None
            # ì›”ì„¸ì¸ ê²½ìš°: deposit_priceê°€ ë³´ì¦ê¸ˆ, monthly_rentê°€ ì›”ì„¸ê°€
            if monthly_rent == 0:
                # ì „ì„¸
                monthly_rent = None
            # ì›”ì„¸ì¸ ê²½ìš°ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
            
            # ê³„ì•½ìœ í˜• íŒŒì‹± (ê°±ì‹ =True, ì‹ ê·œ/None=False)
            contract_type_elem = item.find("contractType")
            contract_type_str = contract_type_elem.text.strip() if contract_type_elem is not None and contract_type_elem.text else None
            contract_type = None
            if contract_type_str:
                contract_type = contract_type_str.strip() == "ê°±ì‹ "
            
            # apt_seq ì¶”ì¶œ
            apt_seq_elem = item.find("aptSeq")
            apt_seq = apt_seq_elem.text.strip() if apt_seq_elem is not None and apt_seq_elem.text else None
            if apt_seq and len(apt_seq) > 10:
                apt_seq = apt_seq[:10]  # DB ì»¬ëŸ¼ ì œí•œì— ë§ê²Œ ìë¥´ê¸°
            
            # ê±´ì¶•ë…„ë„
            build_year_elem = item.find("buildYear")
            build_year = build_year_elem.text.strip() if build_year_elem is not None and build_year_elem.text else None
            
            return RentCreate(
                apt_id=apt_id,
                build_year=build_year,
                contract_type=contract_type,
                deposit_price=deposit_price,
                monthly_rent=monthly_rent,
                exclusive_area=exclusive_area,
                floor=floor,
                apt_seq=apt_seq,
                deal_date=deal_date_obj,
                contract_date=None,  # APIì—ì„œ ë³„ë„ ì œê³µí•˜ì§€ ì•ŠìŒ
                remarks=apt_name  # ì•„íŒŒíŠ¸ ì´ë¦„ ì €ì¥
            )
            
        except Exception as e:
            logger.error(f"   âŒ ê±°ë˜ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨: {e}")
            import traceback
            logger.debug(f"   ìƒì„¸: {traceback.format_exc()}")
            return None
    
    def parse_rent_item(
        self,
        item: Dict[str, Any],
        apt_id: int
    ) -> Optional[RentCreate]:
        """
        ì „ì›”ì„¸ ê±°ë˜ ë°ì´í„° íŒŒì‹± (Dict - ë ˆê±°ì‹œ)
        
        API ì‘ë‹µì˜ ë‹¨ì¼ ì•„ì´í…œì„ RentCreate ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            item: API ì‘ë‹µ ì•„ì´í…œ (dict)
            apt_id: ë§¤ì¹­ëœ ì•„íŒŒíŠ¸ ID
        
        Returns:
            RentCreate ìŠ¤í‚¤ë§ˆ ë˜ëŠ” None (íŒŒì‹± ì‹¤íŒ¨ ì‹œ)
        
        Note:
            - ë³´ì¦ê¸ˆê³¼ ì›”ì„¸ì˜ ì‰¼í‘œ(,)ë¥¼ ì œê±°í•˜ê³  ì •ìˆ˜ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
            - ê±°ë˜ì¼ì€ dealYear, dealMonth, dealDayë¥¼ ì¡°í•©í•˜ì—¬ ìƒì„±í•©ë‹ˆë‹¤.
            - ê³„ì•½ìœ í˜•ì€ "ê°±ì‹ "ì´ë©´ True, ê·¸ ì™¸ì—ëŠ” False ë˜ëŠ” Noneì…ë‹ˆë‹¤.
        """
        try:
            # ê±°ë˜ì¼ íŒŒì‹± (í•„ìˆ˜)
            deal_year = item.get("dealYear")
            deal_month = item.get("dealMonth")
            deal_day = item.get("dealDay")
            
            if not deal_year or not deal_month or not deal_day:
                logger.warning(f"   âš ï¸ ê±°ë˜ì¼ ì •ë³´ ëˆ„ë½: {item.get('aptNm', 'Unknown')}")
                return None
            
            try:
                deal_date_obj = date(
                    int(deal_year),
                    int(deal_month),
                    int(deal_day)
                )
            except (ValueError, TypeError) as e:
                logger.warning(f"   âš ï¸ ê±°ë˜ì¼ ë³€í™˜ ì‹¤íŒ¨: {deal_year}-{deal_month}-{deal_day}, ì˜¤ë¥˜: {e}")
                return None
            
            # ì „ìš©ë©´ì  íŒŒì‹± (í•„ìˆ˜)
            exclu_use_ar = item.get("excluUseAr")
            if not exclu_use_ar:
                logger.warning(f"   âš ï¸ ì „ìš©ë©´ì  ì •ë³´ ëˆ„ë½: {item.get('aptNm', 'Unknown')}")
                return None
            
            try:
                exclusive_area = float(exclu_use_ar)
            except (ValueError, TypeError):
                logger.warning(f"   âš ï¸ ì „ìš©ë©´ì  ë³€í™˜ ì‹¤íŒ¨: {exclu_use_ar}")
                return None
            
            # ì¸µ íŒŒì‹± (í•„ìˆ˜)
            floor_str = item.get("floor")
            if not floor_str:
                logger.warning(f"   âš ï¸ ì¸µ ì •ë³´ ëˆ„ë½: {item.get('aptNm', 'Unknown')}")
                return None
            
            try:
                floor = int(floor_str)
            except (ValueError, TypeError):
                logger.warning(f"   âš ï¸ ì¸µ ë³€í™˜ ì‹¤íŒ¨: {floor_str}")
                return None
            
            # ë³´ì¦ê¸ˆ íŒŒì‹± (ì‰¼í‘œ ì œê±°)
            deposit_str = item.get("deposit")
            deposit_price = None
            if deposit_str:
                try:
                    deposit_price = int(deposit_str.replace(",", ""))
                except (ValueError, TypeError, AttributeError):
                    pass
            
            # ì›”ì„¸ íŒŒì‹±
            monthly_rent_str = item.get("monthlyRent")
            monthly_rent = None
            if monthly_rent_str:
                try:
                    monthly_rent = int(monthly_rent_str.replace(",", ""))
                except (ValueError, TypeError, AttributeError):
                    pass
            
            # ê³„ì•½ìœ í˜• íŒŒì‹± (ê°±ì‹ =True, ì‹ ê·œ/None=False)
            contract_type_str = item.get("contractType")
            contract_type = None
            if contract_type_str:
                contract_type = contract_type_str.strip() == "ê°±ì‹ "
            
            # apt_seq ì¶”ì¶œ
            apt_seq = item.get("aptSeq")
            if apt_seq and len(apt_seq) > 10:
                apt_seq = apt_seq[:10]  # DB ì»¬ëŸ¼ ì œí•œì— ë§ê²Œ ìë¥´ê¸°
            
            # ê±´ì¶•ë…„ë„
            build_year = item.get("buildYear")
            
            return RentCreate(
                apt_id=apt_id,
                build_year=build_year,
                contract_type=contract_type,
                deposit_price=deposit_price,
                monthly_rent=monthly_rent,
                exclusive_area=exclusive_area,
                floor=floor,
                apt_seq=apt_seq,
                deal_date=deal_date_obj,
                contract_date=None  # APIì—ì„œ ë³„ë„ ì œê³µí•˜ì§€ ì•ŠìŒ
            )
            
        except Exception as e:
            logger.error(f"   âŒ ê±°ë˜ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨: {e}")
            import traceback
            logger.debug(f"   ìƒì„¸: {traceback.format_exc()}")
            return None
    
    async def find_apartment_by_name_and_region(
        self,
        db: AsyncSession,
        apt_name: str,
        sgg_cd: str
    ) -> Optional[Apartment]:
        """
        ì•„íŒŒíŠ¸ ì´ë¦„ê³¼ ì‹œêµ°êµ¬ ì½”ë“œë¡œ ì•„íŒŒíŠ¸ ê²€ìƒ‰
        
        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            apt_name: ì•„íŒŒíŠ¸ ì´ë¦„
            sgg_cd: ì‹œêµ°êµ¬ ì½”ë“œ (5ìë¦¬)
        
        Returns:
            Apartment ê°ì²´ ë˜ëŠ” None
        
        Note:
            - ë¨¼ì € ì‹œêµ°êµ¬ ì½”ë“œë¡œ ì‹œì‘í•˜ëŠ” region_codeë¥¼ ê°€ì§„ ì§€ì—­ì„ ì°¾ìŠµë‹ˆë‹¤.
            - í•´ë‹¹ ì§€ì—­ì— ì†í•œ ì•„íŒŒíŠ¸ ì¤‘ ì´ë¦„ì´ ì¼ì¹˜í•˜ëŠ” ê²ƒì„ ì°¾ìŠµë‹ˆë‹¤.
            - ì´ë¦„ì´ ì •í™•íˆ ì¼ì¹˜í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ LIKE ê²€ìƒ‰ë„ ì‹œë„í•©ë‹ˆë‹¤.
        """
        from app.models.state import State
        
        try:
            # 1ë‹¨ê³„: ì‹œêµ°êµ¬ ì½”ë“œë¡œ ì‹œì‘í•˜ëŠ” regionì„ ê°€ì§„ ì•„íŒŒíŠ¸ ì°¾ê¸° (ì •í™•í•œ ì´ë¦„ ë§¤ì¹­)
            result = await db.execute(
                select(Apartment)
                .join(State, Apartment.region_id == State.region_id)
                .where(
                    State.region_code.like(f"{sgg_cd}%"),
                    Apartment.apt_name == apt_name,
                    Apartment.is_deleted == False
                )
                .limit(1)
            )
            apartment = result.scalar_one_or_none()
            
            if apartment:
                return apartment
            
            # 2ë‹¨ê³„: ì´ë¦„ ë¶€ë¶„ ë§¤ì¹­ ì‹œë„ (ì˜ˆ: "ì•„íŒŒíŠ¸" ì ‘ë¯¸ì‚¬ ì œê±° ë“±)
            # "â—‹â—‹ì•„íŒŒíŠ¸" â†’ "â—‹â—‹" ë˜ëŠ” "â—‹â—‹" â†’ "â—‹â—‹ì•„íŒŒíŠ¸"
            search_names = [apt_name]
            if apt_name.endswith("ì•„íŒŒíŠ¸"):
                search_names.append(apt_name[:-3])  # "ì•„íŒŒíŠ¸" ì œê±°
            else:
                search_names.append(apt_name + "ì•„íŒŒíŠ¸")  # "ì•„íŒŒíŠ¸" ì¶”ê°€
            
            for name in search_names:
                result = await db.execute(
                    select(Apartment)
                    .join(State, Apartment.region_id == State.region_id)
                    .where(
                        State.region_code.like(f"{sgg_cd}%"),
                        Apartment.apt_name.like(f"%{name}%"),
                        Apartment.is_deleted == False
                    )
                    .limit(1)
                )
                apartment = result.scalar_one_or_none()
                if apartment:
                    return apartment
            
            return None
            
        except Exception as e:
            logger.error(f"   âŒ ì•„íŒŒíŠ¸ ê²€ìƒ‰ ì‹¤íŒ¨ ({apt_name}): {e}")
            return None
    
    async def collect_rent_transactions(
        self,
        db: AsyncSession,
        lawd_cd: str,
        deal_ymd: str
    ) -> RentCollectionResponse:
        """
        ì „ì›”ì„¸ ì‹¤ê±°ë˜ê°€ ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥
        
        êµ­í† êµí†µë¶€ APIì—ì„œ ì „ì›”ì„¸ ì‹¤ê±°ë˜ê°€ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ DBì— ì €ì¥í•©ë‹ˆë‹¤.
        
        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            lawd_cd: ì§€ì—­ì½”ë“œ (ë²•ì •ë™ì½”ë“œ ì• 5ìë¦¬)
            deal_ymd: ê³„ì•½ë…„ì›” (YYYYMM)
        
        Returns:
            RentCollectionResponse: ìˆ˜ì§‘ ê²°ê³¼ í†µê³„
        
        Note:
            - API ì¸ì¦í‚¤ëŠ” ì„œë²„ì˜ MOLIT_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
            - XML ì‘ë‹µì„ JSONìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
            - ì•„íŒŒíŠ¸ ì´ë¦„ê³¼ ì§€ì—­ì½”ë“œë¡œ apartments í…Œì´ë¸”ì—ì„œ apt_idë¥¼ ì°¾ìŠµë‹ˆë‹¤.
            - ì¤‘ë³µ ê±°ë˜ ë°ì´í„°ëŠ” ê±´ë„ˆëœë‹ˆë‹¤.
        """
        total_fetched = 0
        total_saved = 0
        skipped = 0
        errors = []
        
        try:
            logger.info("=" * 80)
            logger.info(f"ğŸ  ì „ì›”ì„¸ ì‹¤ê±°ë˜ê°€ ìˆ˜ì§‘ ì‹œì‘")
            logger.info(f"   ğŸ“ ì§€ì—­ì½”ë“œ: {lawd_cd}")
            logger.info(f"   ğŸ“… ê³„ì•½ë…„ì›”: {deal_ymd}")
            logger.info("=" * 80)
            
            # 1ë‹¨ê³„: API í˜¸ì¶œí•˜ì—¬ XML ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (MOLIT_API_KEY ì‚¬ìš©)
            try:
                xml_data = await self.fetch_rent_data(lawd_cd, deal_ymd)
            except httpx.HTTPError as e:
                error_msg = f"API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}"
                logger.error(f"âŒ {error_msg}")
                return RentCollectionResponse(
                    success=False,
                    total_fetched=0,
                    total_saved=0,
                    skipped=0,
                    errors=[error_msg],
                    message=error_msg,
                    lawd_cd=lawd_cd,
                    deal_ymd=deal_ymd
                )
            
            # 2ë‹¨ê³„: XML â†’ JSON ë³€í™˜
            items, result_code, result_msg = self.parse_rent_xml_to_json(xml_data)
            
            if result_code not in ["000", "00"]:
                error_msg = f"API ì‘ë‹µ ì˜¤ë¥˜: {result_code} - {result_msg}"
                logger.error(f"âŒ {error_msg}")
                return RentCollectionResponse(
                    success=False,
                    total_fetched=0,
                    total_saved=0,
                    skipped=0,
                    errors=[error_msg],
                    message=error_msg,
                    lawd_cd=lawd_cd,
                    deal_ymd=deal_ymd
                )
            
            total_fetched = len(items)
            logger.info(f"ğŸ“Š ìˆ˜ì§‘ëœ ê±°ë˜ ë°ì´í„°: {total_fetched}ê°œ")
            
            if total_fetched == 0:
                return RentCollectionResponse(
                    success=True,
                    total_fetched=0,
                    total_saved=0,
                    skipped=0,
                    errors=[],
                    message="ì¡°íšŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.",
                    lawd_cd=lawd_cd,
                    deal_ymd=deal_ymd
                )
            
            # 3ë‹¨ê³„: ê° ê±°ë˜ ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ì—¬ DBì— ì €ì¥
            apt_cache = {}  # ì•„íŒŒíŠ¸ ì´ë¦„ â†’ apt_id ìºì‹œ (ë°˜ë³µ ê²€ìƒ‰ ë°©ì§€)
            
            for idx, item in enumerate(items, 1):
                apt_name = item.get("aptNm", "Unknown")
                sgg_cd = item.get("sggCd", lawd_cd)  # ì‹œêµ°êµ¬ ì½”ë“œ (ì—†ìœ¼ë©´ lawd_cd ì‚¬ìš©)
                
                try:
                    # 3-1: ì•„íŒŒíŠ¸ ID ì°¾ê¸° (ìºì‹œ í™œìš©)
                    cache_key = f"{sgg_cd}:{apt_name}"
                    
                    if cache_key in apt_cache:
                        apt_id = apt_cache[cache_key]
                    else:
                        apartment = await self.find_apartment_by_name_and_region(
                            db, apt_name, sgg_cd
                        )
                        
                        if not apartment:
                            error_msg = f"ì•„íŒŒíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {apt_name} (ì§€ì—­: {sgg_cd})"
                            errors.append(error_msg)
                            logger.warning(f"   âš ï¸ [{idx}/{total_fetched}] {error_msg}")
                            continue
                        
                        apt_id = apartment.apt_id
                        apt_cache[cache_key] = apt_id
                    
                    # 3-2: ê±°ë˜ ë°ì´í„° íŒŒì‹±
                    rent_create = self.parse_rent_item(item, apt_id)
                    
                    if not rent_create:
                        error_msg = f"ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨: {apt_name}"
                        errors.append(error_msg)
                        logger.warning(f"   âš ï¸ [{idx}/{total_fetched}] {error_msg}")
                        continue
                    
                    # 3-3: DBì— ì €ì¥ (ì¤‘ë³µ ì²´í¬)
                    db_obj, is_created = await rent_crud.create_or_skip(
                        db,
                        obj_in=rent_create
                    )
                    
                    if is_created:
                        total_saved += 1
                        if total_saved % 10 == 0 or total_saved == 1:
                            logger.info(f"   ğŸ’¾ [{idx}/{total_fetched}] {apt_name} ì €ì¥ ì™„ë£Œ (í˜„ì¬ê¹Œì§€: {total_saved}ê°œ)")
                    else:
                        skipped += 1
                        logger.debug(f"   â­ï¸ [{idx}/{total_fetched}] {apt_name} ê±´ë„ˆëœ€ (ì¤‘ë³µ)")
                    
                except Exception as e:
                    # savepoint ë¡¤ë°±
                    try:
                        await savepoint.rollback()
                    except Exception:
                        pass
                    
                    error_msg = f"ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
                    errors.append(f"ì•„íŒŒíŠ¸ '{apt_name}' (ID: {apt_id}, ì½”ë“œ: {kapt_code}): {error_msg}")
                    total_processed += 1
                    logger.error(f"[{idx}/{len(apartments)}] {apt_name} | âŒ ì‹¤íŒ¨: {error_msg}")
                    import traceback
                    logger.debug(f"ìƒì„¸ ìŠ¤íƒ: {traceback.format_exc()}")
            
            # ë§ˆì§€ë§‰ ë‚¨ì€ ë°ì´í„° ì»¤ë°‹ (ë°˜ë“œì‹œ ì‹¤í–‰ë˜ì–´ì•¼ í•¨)
            remaining_count = total_saved - last_commit_count
            if remaining_count > 0:
                try:
                    await db.commit()  # ìµœìƒìœ„ íŠ¸ëœì­ì…˜ ì»¤ë°‹ (ì‹¤ì œ DB ë°˜ì˜)
                    last_commit_count = total_saved
                    logger.info(f"ğŸ’¾ ìµœì¢… ì»¤ë°‹ ì™„ë£Œ: ì´ {total_saved}ê°œ ì €ì¥ë¨")
                except Exception as commit_error:
                    logger.error(f"âŒ ìµœì¢… ì»¤ë°‹ ì‹¤íŒ¨: {remaining_count}ê°œ ë°ì´í„° ì†ì‹¤ ê°€ëŠ¥ - {str(commit_error)}")
                    try:
                        await db.rollback()
                    except Exception:
                        pass
                    errors.append(f"ìµœì¢… ì»¤ë°‹ ì‹¤íŒ¨ ({remaining_count}ê°œ ë°ì´í„° ì†ì‹¤): {str(commit_error)}")
            
            logger.info(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ: ì²˜ë¦¬ {total_processed}ê°œ | ì €ì¥ {total_saved}ê°œ | ê±´ë„ˆëœ€ {skipped}ê°œ")
            if errors:
                logger.warning(f"âš ï¸ ì˜¤ë¥˜ {len(errors)}ê°œ ë°œìƒ")
                for error in errors[:10]:
                    logger.warning(f"   - {error}")
                if len(errors) > 10:
                    logger.warning(f"   ... ì™¸ {len(errors) - 10}ê°œ ì˜¤ë¥˜")
            
            # ìµœì¢… ì»¤ë°‹ ì‹¤íŒ¨ê°€ ìˆì—ˆìœ¼ë©´ success=Falseë¡œ ë°˜í™˜
            final_success = len([e for e in errors if "ìµœì¢… ì»¤ë°‹ ì‹¤íŒ¨" in e]) == 0
            
            return ApartDetailCollectionResponse(
                success=final_success,
                total_processed=total_processed,
                total_saved=total_saved,
                skipped=skipped,
                errors=errors,
                message=f"ìˆ˜ì§‘ ì™„ë£Œ: {total_saved}ê°œ ì €ì¥, {skipped}ê°œ ê±´ë„ˆëœ€" if final_success else f"ìˆ˜ì§‘ ì™„ë£Œ (ì¼ë¶€ ì˜¤ë¥˜): {total_saved}ê°œ ì €ì¥, {skipped}ê°œ ê±´ë„ˆëœ€"
            )
            
        except Exception as e:
            logger.error(f"âŒ ì•„íŒŒíŠ¸ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}", exc_info=True)
            # ì˜ˆì™¸ ë°œìƒ ì‹œ ë‚¨ì€ ë°ì´í„° ì»¤ë°‹ ì‹œë„
            try:
                remaining_count = total_saved - last_commit_count
                if remaining_count > 0:
                    logger.warning(f"   âš ï¸ ì˜ˆì™¸ ë°œìƒ ì „ ë‚¨ì€ {remaining_count}ê°œ ë°ì´í„° ì»¤ë°‹ ì‹œë„...")
                    try:
                        await db.commit()
                        logger.info(f"   âœ… ì˜ˆì™¸ ë°œìƒ ì „ ë°ì´í„° ì»¤ë°‹ ì™„ë£Œ")
                    except Exception as commit_error:
                        logger.error(f"   âŒ ì˜ˆì™¸ ë°œìƒ ì „ ë°ì´í„° ì»¤ë°‹ ì‹¤íŒ¨: {str(commit_error)}")
                        await db.rollback()
            except Exception:
                pass  # ì´ë¯¸ ì˜ˆì™¸ê°€ ë°œìƒí•œ ìƒíƒœì´ë¯€ë¡œ ë¬´ì‹œ
            
            return ApartDetailCollectionResponse(
                success=False,
                total_processed=total_processed,
                total_saved=total_saved,
                skipped=skipped,
                errors=errors + [str(e)],
                message=f"ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}"
            )
    
    def _get_area_code_from_csv(self, region_code_prefix: str) -> Optional[int]:
        """
        CSV íŒŒì¼ì—ì„œ region_code ì• 5ìë¦¬ë¡œ area_code(CLS_ID)ë¥¼ ì°¾ì•„ ë°˜í™˜
        
        Args:
            region_code_prefix: region_code ì• 5ìë¦¬
        
        Returns:
            area_code (int) ë˜ëŠ” None
        """
        try:
            # CSV íŒŒì¼ ê²½ë¡œ ìºì‹± (í•œ ë²ˆë§Œ í™•ì¸)
            if not DataCollectionService._csv_path_checked:
                current_file = Path(__file__).resolve()
                current_file_str = str(current_file)
                
                if current_file_str.startswith('/app'):
                    # Docker ì»¨í…Œì´ë„ˆ ë‚´ë¶€
                    csv_path = Path('/app/legion_code.csv')
                else:
                    # ë¡œì»¬ ì‹¤í–‰: backend/app/services/data_collection.py -> í”„ë¡œì íŠ¸ ë£¨íŠ¸
                    csv_path = current_file.parent.parent.parent.parent / 'legion_code.csv'
                
                if not csv_path.exists():
                    logger.error(f"âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")
                    logger.error(f"   í˜„ì¬ íŒŒì¼ ê²½ë¡œ: {current_file_str}")
                    DataCollectionService._csv_path_checked = True
                    DataCollectionService._csv_path_cache = None
                    return None
                
                DataCollectionService._csv_path_cache = csv_path
                DataCollectionService._csv_path_checked = True
            
            # ìºì‹œëœ ê²½ë¡œê°€ ì—†ìœ¼ë©´ (íŒŒì¼ì´ ì—†ëŠ” ê²½ìš°)
            if DataCollectionService._csv_path_cache is None:
                return None
            
            csv_path = DataCollectionService._csv_path_cache
            
            region_code_prefix = str(region_code_prefix)
            if len(region_code_prefix) < 5:
                region_code_prefix = region_code_prefix[:5].ljust(5, '0')
            
            # CSV íŒŒì¼ ì½ê¸°
            with open(csv_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                rows = list(reader)
            
            # 1. 5ìë¦¬ ì¼ì¹˜ ê²€ìƒ‰
            for row in rows:
                region_code = str(row.get('region_code', '')).strip()
                if region_code.startswith(region_code_prefix):
                    return int(row.get('area_code', 0))
            
            # 2. ì• 2ìë¦¬ ì¼ì¹˜ ê²€ìƒ‰ (fallback)
            prefix_2 = region_code_prefix[:2]
            for row in rows:
                region_code = str(row.get('region_code', '')).strip()
                if region_code.startswith(prefix_2):
                    return int(row.get('area_code', 0))
            
            return None
        except Exception as e:
            logger.error(f"âŒ CSV íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
            return None
    
    async def collect_house_scores(
        self,
        db: AsyncSession
    ) -> HouseScoreCollectionResponse:
        """
        ë¶€ë™ì‚° ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘
        
        STATES í…Œì´ë¸”ì˜ region_codeë¥¼ ì‚¬ìš©í•˜ì—¬ í•œêµ­ë¶€ë™ì‚°ì› APIì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ
        HOUSE_SCORES í…Œì´ë¸”ì— ì €ì¥í•©ë‹ˆë‹¤.
        """
        total_fetched = 0
        total_saved = 0
        skipped = 0
        errors = []
        
        # ì—ëŸ¬ ì œí•œ ì„¤ì •
        MAX_CONSECUTIVE_ERRORS = 10  # ì—°ì† ì—ëŸ¬ ìµœëŒ€ íšŸìˆ˜
        MAX_ERROR_RATIO = 0.5  # ì „ì²´ ì—ëŸ¬ ë¹„ìœ¨ ìµœëŒ€ê°’ (50%)
        MIN_PROCESSED_FOR_RATIO_CHECK = 10  # ì—ëŸ¬ ë¹„ìœ¨ ì²´í¬ë¥¼ ìœ„í•œ ìµœì†Œ ì²˜ë¦¬ íšŸìˆ˜
        consecutive_errors = 0  # ì—°ì† ì—ëŸ¬ ì¹´ìš´í„°
        total_processed = 0  # ì²˜ë¦¬í•œ ì§€ì—­ ìˆ˜
        
        try:
            # REB_API_KEY í™•ì¸
            if not settings.REB_API_KEY:
                raise ValueError("REB_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
            
            logger.info("=" * 60)
            logger.info("ğŸ  ë¶€ë™ì‚° ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
            logger.info("=" * 60)
            
            # STATES í…Œì´ë¸”ì—ì„œ ëª¨ë“  region_code ì¡°íšŒ
            from app.models.state import State
            result = await db.execute(
                select(State.region_id, State.region_code)
                .where(State.is_deleted == False)
            )
            states = result.fetchall()
            
            if not states:
                logger.warning("âš ï¸ STATES í…Œì´ë¸”ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return HouseScoreCollectionResponse(
                    success=False,
                    total_fetched=0,
                    total_saved=0,
                    skipped=0,
                    errors=[],
                    message=f"ëª¨ë“  ì§€ì—­ ìˆ˜ì§‘ ì™„ë£Œ (ì‹œì‘ ì¸ë±ìŠ¤ {start_region_index} >= ì´ ì§€ì—­ ìˆ˜ {len(region_codes)})",
                    api_calls_used=0
                )
            
            # 2ë‹¨ê³„: ìˆ˜ì§‘í•  ë…„ì›” ëª©ë¡ ìƒì„±
            year_months = self.generate_year_months(start_year, start_month)
            
            # ì‹œì‘ ì¸ë±ìŠ¤ë¶€í„°ì˜ ì§€ì—­ì½”ë“œë§Œ ì‚¬ìš©
            remaining_region_codes = region_codes[start_region_index:]
            
            total_combinations = len(remaining_region_codes) * len(year_months)
            
            logger.info(f"ğŸ“ ìˆ˜ì§‘ ëŒ€ìƒ: {len(remaining_region_codes)}ê°œ ì§€ì—­ Ã— {len(year_months)}ê°œì›”")
            logger.info(f"ğŸ“… ìˆ˜ì§‘ ê¸°ê°„: {year_months[0]} ~ {year_months[-1]}")
            logger.info(f"ğŸ“Š ì´ ì˜ˆìƒ API í˜¸ì¶œ: {total_combinations}íšŒ")
            logger.info(f"ğŸš€ ì‹œì‘ ì§€ì—­ ì¸ë±ìŠ¤: {start_region_index} ({remaining_region_codes[0] if remaining_region_codes else 'N/A'})")
            logger.info("=" * 80)
            
            # 3ë‹¨ê³„: ê° ì§€ì—­ì½”ë“œ Ã— ë…„ì›” ì¡°í•©ì— ëŒ€í•´ ìˆ˜ì§‘
            current_idx = 0
            stopped_by_limit = False
            
            for region_offset, lawd_cd in enumerate(remaining_region_codes):
                actual_region_index = start_region_index + region_offset
                
                logger.info(f"\n{'='*60}")
                logger.info(f"ğŸ“ [ì§€ì—­ {actual_region_index + 1}/{len(region_codes)}] ì§€ì—­ì½”ë“œ: {lawd_cd}")
                logger.info(f"   API í˜¸ì¶œ: {api_calls_used}/{max_api_calls}")
                logger.info(f"{'='*60}")
                
                for ym_idx, deal_ymd in enumerate(year_months):
                    # API í˜¸ì¶œ ì œí•œ ì²´í¬
                    if api_calls_used >= max_api_calls:
                        logger.warning(f"âš ï¸ ì¼ì¼ API í˜¸ì¶œ ì œí•œ ë„ë‹¬! ({api_calls_used}/{max_api_calls})")
                        stopped_by_limit = True
                        next_region_index = actual_region_index  # í˜„ì¬ ì§€ì—­ë¶€í„° ì¬ì‹œì‘
                        break
                    
                    current_idx += 1
                    progress = (current_idx / total_combinations) * 100
                    
                    logger.info(f"   [{current_idx}/{total_combinations}] ({progress:.1f}%) {lawd_cd} - {deal_ymd}")
                    
                    try:
                        # API í˜¸ì¶œ
                        xml_data = await self.fetch_rent_data(lawd_cd, deal_ymd)
                        api_calls_used += 1
                        last_lawd_cd = lawd_cd
                        last_deal_ymd = deal_ymd
                        
                        # XML â†’ JSON ë³€í™˜
                        items, result_code, result_msg = self.parse_rent_xml_to_json(xml_data)
                        
                        if result_code not in ["000", "00"]:
                            error_msg = f"{lawd_cd}/{deal_ymd}: API ì˜¤ë¥˜ - {result_msg}"
                            all_errors.append(error_msg)
                            logger.warning(f"      âš ï¸ {error_msg}")
                            await asyncio.sleep(0.3)
                            continue
                        
                        if not items:
                            logger.debug(f"      â„¹ï¸ ë°ì´í„° ì—†ìŒ")
                            await asyncio.sleep(0.2)
                            continue
                        
                        total_fetched += len(items)
                        
                        # ì•„íŒŒíŠ¸ ìºì‹œ (ë°˜ë³µ ê²€ìƒ‰ ë°©ì§€)
                        apt_cache = {}
                        saved_count = 0
                        skipped_count = 0
                        
                        for item in items:
                            apt_name = item.get("aptNm", "Unknown")
                            sgg_cd = item.get("sggCd", lawd_cd)
                            
                            try:
                                # ì•„íŒŒíŠ¸ ID ì°¾ê¸°
                                cache_key = f"{sgg_cd}:{apt_name}"
                                
                                if cache_key in apt_cache:
                                    apt_id = apt_cache[cache_key]
                                elif cache_key not in apt_cache:
                                    apartment = await self.find_apartment_by_name_and_region(
                                        db, apt_name, sgg_cd
                                    )
                                    
                                    if not apartment:
                                        apt_cache[cache_key] = None
                                        continue
                                    
                                    apt_id = apartment.apt_id
                                    apt_cache[cache_key] = apt_id
                                
                                if apt_cache.get(cache_key) is None:
                                    continue
                                
                                # í˜ì´ì§€ ì‘ë‹µ ì„±ê³µ í™•ì¸
                                page_head_data = page_stts_data[0].get("head", [])
                                page_result_data = {}
                                for item in page_head_data:
                                    if isinstance(item, dict) and "RESULT" in item:
                                        page_result_data = item["RESULT"]
                                        break
                                
                                page_response_code = page_result_data.get("CODE", "UNKNOWN")
                                if page_response_code != "INFO-000":
                                    logger.warning(f"   âš ï¸ {region_code_str}: í˜ì´ì§€ {page_index} API ì˜¤ë¥˜ [CODE: {page_response_code}] - ê±´ë„ˆëœ€")
                                    continue
                                
                                # DB ì €ì¥
                                _, is_created = await rent_crud.create_or_skip(
                                    db,
                                    obj_in=rent_create
                                )
                                
                                if is_created:
                                    saved_count += 1
                                else:
                                    skipped_count += 1
                                    
                            except Exception as e:
                                pass  # ê°œë³„ ì˜¤ë¥˜ëŠ” ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
                        
                        total_saved += saved_count
                        total_skipped += skipped_count
                        
                        if saved_count > 0:
                            logger.info(f"      âœ… {len(items)}ê±´ ì¤‘ {saved_count}ê±´ ì €ì¥, {skipped_count}ê±´ ê±´ë„ˆëœ€")
                        
                    except httpx.HTTPError as e:
                        error_msg = f"{lawd_cd}/{deal_ymd}: HTTP ì˜¤ë¥˜ - {str(e)}"
                        all_errors.append(error_msg)
                        logger.warning(f"      âš ï¸ {error_msg}")
                    except Exception as e:
                        error_msg = f"{lawd_cd}/{deal_ymd}: ì˜¤ë¥˜ - {str(e)}"
                        all_errors.append(error_msg)
                        logger.warning(f"      âš ï¸ {error_msg}")
                    
                    # API í˜¸ì¶œ ì œí•œ ë°©ì§€ ë”œë ˆì´
                    await asyncio.sleep(0.3)
                
                # API ì œí•œìœ¼ë¡œ ì¤‘ë‹¨ëœ ê²½ìš°
                if stopped_by_limit:
                    break
            
            # ëª¨ë“  ì§€ì—­ ì™„ë£Œ ì²´í¬
            if not stopped_by_limit:
                next_region_index = None  # ëª¨ë‘ ì™„ë£Œ
            
            # ê²°ê³¼ ì¶œë ¥
            logger.info("\n" + "=" * 80)
            if stopped_by_limit:
                logger.info("â¸ï¸ ì „ì›”ì„¸ ì‹¤ê±°ë˜ê°€ ìˆ˜ì§‘ ì¼ì‹œ ì¤‘ë‹¨ (ì¼ì¼ API í˜¸ì¶œ ì œí•œ)")
                logger.info(f"   â¡ï¸ ë‹¤ìŒì— ì‹œì‘í•  ì§€ì—­ ì¸ë±ìŠ¤: {next_region_index}")
            else:
                logger.info("ğŸ‰ ì „ì›”ì„¸ ì‹¤ê±°ë˜ê°€ ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ!")
            logger.info(f"   ğŸ“Š ì´ ìˆ˜ì§‘: {total_fetched}ê±´")
            logger.info(f"   ğŸ’¾ ì €ì¥: {total_saved}ê±´")
            logger.info(f"   â­ï¸ ê±´ë„ˆëœ€: {total_skipped}ê±´")
            logger.info(f"   ğŸ”„ API í˜¸ì¶œ: {api_calls_used}íšŒ")
            logger.info(f"   âš ï¸ ì˜¤ë¥˜: {len(all_errors)}ê±´")
            logger.info("=" * 80)
            
            message = f"ìˆ˜ì§‘ ì™„ë£Œ: {total_saved}ê±´ ì €ì¥, {total_skipped}ê±´ ê±´ë„ˆëœ€"
            if stopped_by_limit:
                message = f"ì¼ì¼ ì œí•œìœ¼ë¡œ ì¤‘ë‹¨ (ë‹¤ìŒ ì‹œì‘: ì§€ì—­ ì¸ë±ìŠ¤ {next_region_index}): {total_saved}ê±´ ì €ì¥"
            
            return RentCollectionResponse(
                success=True,
                total_fetched=total_fetched,
                total_saved=total_saved,
                skipped=total_skipped,
                errors=all_errors[:100],  # ìµœëŒ€ 100ê°œë§Œ
                message=message,
                lawd_cd=last_lawd_cd,
                deal_ymd=last_deal_ymd,
                api_calls_used=api_calls_used,
                next_region_index=next_region_index
            )
            
        except Exception as e:
            logger.error(f"âŒ ì „ì²´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}", exc_info=True)
            return RentCollectionResponse(
                success=False,
                total_fetched=total_fetched,
                total_saved=total_saved,
                skipped=total_skipped,
                errors=all_errors + [str(e)],
                message=f"ì „ì²´ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}",
                api_calls_used=api_calls_used,
                next_region_index=start_region_index  # ì‹¤íŒ¨ ì‹œ í˜„ì¬ ìœ„ì¹˜ ë°˜í™˜
            )


    def _convert_sgg_code_to_db_format(self, sgg_cd: str) -> Optional[str]:
        """5ìë¦¬ ì‹œêµ°êµ¬ ì½”ë“œë¥¼ 10ìë¦¬ DB í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        if not sgg_cd or len(sgg_cd) != 5:
            return None
        return f"{sgg_cd}00000"
    
    def _normalize_dong_name(self, dong_name: str) -> str:
        """ë™ ì´ë¦„ ì •ê·œí™” (ìˆ«ì, ë™, ê°€ ì œê±°)"""
        if not dong_name:
            return ""
        # ìˆ«ì ì œê±° (ì˜ˆ: "ì‚¬ì§1ë™" â†’ "ì‚¬ì§ë™")
        normalized = re.sub(r'\d+', '', dong_name)
        # "ë™", "ê°€" ì œê±°
        normalized = normalized.replace("ë™", "").replace("ê°€", "").strip()
        return normalized
    
    # í•œêµ­ ëŒ€í‘œ ì•„íŒŒíŠ¸ ë¸Œëœë“œëª… ì‚¬ì „ (ì •ê·œí™”ëœ í˜•íƒœë¡œ ì €ì¥, ê¸´ ê²ƒ ìš°ì„ )
    APARTMENT_BRANDS = [
        # ë³µí•© ë¸Œëœë“œëª… (ë¨¼ì € ë§¤ì¹­)
        'ë¡¯ë°ìºìŠ¬íŒŒí¬íƒ€ìš´', 'ë¡¯ë°ìºìŠ¬ê³¨ë“œíƒ€ìš´', 'ë¡¯ë°ìºìŠ¬', 
        'í˜„ëŒ€íìŠ¤í…Œì´íŠ¸', 'íìŠ¤í…Œì´íŠ¸',
        'ì´í¸í•œì„¸ìƒ', 'eí¸í•œì„¸ìƒ', 'í¸í•œì„¸ìƒ',
        'í•œë¼ë¹„ë°œë””', 'ë¹„ë°œë””',
        'í˜¸ë°˜ì¨ë°‹', 'ì¨ë°‹',
        'ìš°ë¯¸ë¦°',
        'ë˜ë¯¸ì•ˆ', 'ë¼ë¯¸ì•ˆ',
        'í‘¸ë¥´ì§€ì˜¤',
        'ë”ìƒµ', 'theìƒµ',
        'ì•„ì´íŒŒí¬',
        'ìì´', 'xi',
        'ìœ„ë¸Œ',
        'skë·°', 'ì—ìŠ¤ì¼€ì´ë·°',
        'ê¿ˆì—ê·¸ë¦°', 'í¬ë ˆë‚˜',
        'ë² ìŠ¤íŠ¸ë¹Œ', 'ì–´ìš¸ë¦¼',
        'ë¡œì–„ë“€í¬',
        'ìŠ¤ìœ—ë‹·í™ˆ', 'ì˜ˆê°€',
        'ì„¼íŠ¸ë ˆë¹Œ',
        'ì•„í¬ë¡œ',
        'ì‚¬ë‘ìœ¼ë¡œ',
        'sí´ë˜ìŠ¤', 'ì¤‘í¥',
        'ìˆ˜ìì¸', 'ë‚˜ë¹Œë˜', 'ìŠ¤íƒ€í´ë˜ìŠ¤', 'ë…¸ë¹Œë¦¬í‹°', 'ìŠ¤ì¹´ì´ë·°',
        # ê±´ì„¤ì‚¬ ë¸Œëœë“œ
        'í˜„ëŒ€', 'ì‚¼ì„±', 'ëŒ€ë¦¼', 'ëŒ€ìš°', 'ë™ì•„', 'ê·¹ë™', 'ë²½ì‚°', 'ê¸ˆí˜¸', 'ë™ë¶€',
        'ì‹ ë™ì•„', 'ì‹ ì„±', 'ì£¼ê³µ', 'í•œì‹ ', 'íƒœì˜', 'ì§„í¥', 'ë™ì¼', 'ê±´ì˜',
        'ìš°ë°©', 'í•œì–‘', 'ì„±ì›', 'ê²½ë‚¨', 'ë™ë¬¸', 'í’ë¦¼', 'ì‹ ì•ˆ', 'ì„ ê²½',
        'íš¨ì„±', 'ì½”ì˜¤ë¡±', 'ëŒ€ë°©', 'ë™ì„±', 'ì¼ì‹ ', 'ì²­êµ¬', 'ì‚¼ìµ', 'ì§„ë¡œ',
        'ë¶€ì˜', 'ìŒìš©', 'ìºìŠ¬', 'ë¦°',
    ]
    
    # ë§ˆì„/ë‹¨ì§€ ì ‘ë¯¸ì‚¬ íŒ¨í„´
    VILLAGE_SUFFIXES = ['ë§ˆì„', 'ë‹¨ì§€', 'íƒ€ìš´', 'ë¹Œë¦¬ì§€', 'íŒŒí¬', 'ì‹œí‹°', 'íìŠ¤', 'ë·°']
    
    # ì˜ë¬¸ ë¸Œëœë“œëª… â†’ í•œê¸€ ë³€í™˜ ì‚¬ì „
    BRAND_ENG_TO_KOR = {
        'hillstate': 'íìŠ¤í…Œì´íŠ¸',
        'raemian': 'ë˜ë¯¸ì•ˆ',
        'xi': 'ìì´',
        'the#': 'ë”ìƒµ',
        'thesharp': 'ë”ìƒµ',
        'ipark': 'ì•„ì´íŒŒí¬',
        'prugio': 'í‘¸ë¥´ì§€ì˜¤',
        'skview': 'skë·°',
        'acro': 'ì•„í¬ë¡œ',
        'centreville': 'ì„¼íŠ¸ë ˆë¹Œ',
        'lottecatle': 'ë¡¯ë°ìºìŠ¬',
        'lottecastle': 'ë¡¯ë°ìºìŠ¬',
        'vivaldi': 'ë¹„ë°œë””',
        'weave': 'ìœ„ë¸Œ',
        'forena': 'í¬ë ˆë‚˜',
        'eí¸í•œì„¸ìƒ': 'ì´í¸í•œì„¸ìƒ',
        'summit': 'ì¨ë°‹',
        'bestville': 'ë² ìŠ¤íŠ¸ë¹Œ',
        'royalduke': 'ë¡œì–„ë“€í¬',
        'nobless': 'ë…¸ë¸”ë ˆìŠ¤',
        'parkview': 'íŒŒí¬ë·°',
        'lakeview': 'ë ˆì´í¬ë·°',
        'greenville': 'ê·¸ë¦°ë¹Œ',
        'skyview': 'ìŠ¤ì¹´ì´ë·°',
    }
    
    def _extract_danji_number(self, name: str) -> Optional[int]:
        """
        ë‹¨ì§€ ë²ˆí˜¸ ì¶”ì¶œ (ì˜ˆ: '4ë‹¨ì§€' â†’ 4, '9ë‹¨ì§€' â†’ 9, '101ë™' â†’ 101)
        
        ë‹¤ì–‘í•œ íŒ¨í„´ ì§€ì›:
        - "4ë‹¨ì§€", "9ë‹¨ì§€" â†’ 4, 9
        - "ì œ4ë‹¨ì§€", "ì œ9ë‹¨ì§€" â†’ 4, 9
        - "101ë™", "102ë™" â†’ 101, 102 (ì£¼ì˜: ì¸µìˆ˜ì™€ êµ¬ë¶„ í•„ìš”)
        - "1ì°¨", "2ì°¨" â†’ 1, 2
        - "â… ", "â…¡" â†’ 1, 2
        """
        if not name:
            return None
        
        # ì •ê·œí™” (ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ì œê±°)
        normalized = re.sub(r'\s+', '', name)
        
        # ë¡œë§ˆìˆ«ìë¥¼ ì•„ë¼ë¹„ì•„ ìˆ«ìë¡œ ë³€í™˜
        roman_map = {'â…°': '1', 'â…±': '2', 'â…²': '3', 'â…³': '4', 'â…´': '5', 
                     'â…µ': '6', 'â…¶': '7', 'â…·': '8', 'â…¸': '9', 'â…¹': '10',
                     'â… ': '1', 'â…¡': '2', 'â…¢': '3', 'â…£': '4', 'â…¤': '5',
                     'â…¥': '6', 'â…¦': '7', 'â…§': '8', 'â…¨': '9', 'â…©': '10'}
        for roman, arabic in roman_map.items():
            normalized = normalized.replace(roman, arabic)
        
        # ë‹¨ì§€ ë²ˆí˜¸ ì¶”ì¶œ íŒ¨í„´ë“¤ (ìš°ì„ ìˆœìœ„ìˆœ)
        patterns = [
            r'ì œ?(\d+)ë‹¨ì§€',      # "4ë‹¨ì§€", "ì œ4ë‹¨ì§€"
            r'(\d+)ì°¨',           # "1ì°¨", "2ì°¨" (ì°¨ìˆ˜)
            r'ì œ(\d+)ì°¨',         # "ì œ1ì°¨"
            r'(\d{3,})ë™',        # "101ë™", "102ë™" (3ìë¦¬ ì´ìƒ, ì¸µìˆ˜ êµ¬ë¶„)
        ]
        
        for pattern in patterns:
            match = re.search(pattern, normalized)
            if match:
                num = int(match.group(1))
                # ë™ ë²ˆí˜¸ëŠ” ë³´í†µ 100 ì´ìƒ (101ë™, 102ë™ ë“±)
                if 'ë™' in pattern and num < 100:
                    continue
                return num
        
        return None
    
    def _extract_cha_number(self, name: str) -> Optional[int]:
        """
        ì°¨ìˆ˜ ì¶”ì¶œ (ì˜ˆ: '1ì°¨' â†’ 1, 'â…¡' â†’ 2)
        
        ë‹¤ì–‘í•œ íŒ¨í„´ ì§€ì›:
        - "1ì°¨", "2ì°¨" â†’ 1, 2
        - "ì œ1ì°¨", "ì œ2ì°¨" â†’ 1, 2
        - "â… ", "â…¡" â†’ 1, 2 (ë¡œë§ˆìˆ«ì)
        - ëì— ë¶™ì€ ìˆ«ì (1~20 ì‚¬ì´ë§Œ ì°¨ìˆ˜ë¡œ ê°„ì£¼)
        """
        if not name:
            return None
        
        normalized = re.sub(r'\s+', '', name)
        
        # ë¡œë§ˆìˆ«ìë¥¼ ì•„ë¼ë¹„ì•„ ìˆ«ìë¡œ ë³€í™˜
        roman_map = {'â…°': '1', 'â…±': '2', 'â…²': '3', 'â…³': '4', 'â…´': '5', 
                     'â…µ': '6', 'â…¶': '7', 'â…·': '8', 'â…¸': '9', 'â…¹': '10',
                     'â… ': '1', 'â…¡': '2', 'â…¢': '3', 'â…£': '4', 'â…¤': '5',
                     'â…¥': '6', 'â…¦': '7', 'â…§': '8', 'â…¨': '9', 'â…©': '10',
                     'i': '1', 'ii': '2', 'iii': '3', 'iv': '4', 'v': '5',
                     'vi': '6', 'vii': '7', 'viii': '8', 'ix': '9', 'x': '10'}
        # ì†Œë¬¸ì ë¡œë§ˆìˆ«ìë„ ì²˜ë¦¬
        normalized_lower = normalized.lower()
        for roman, arabic in roman_map.items():
            normalized_lower = normalized_lower.replace(roman, arabic)
        
        # ì°¨ìˆ˜ ì¶”ì¶œ íŒ¨í„´ë“¤
        patterns = [
            (normalized, r'ì œ?(\d+)ì°¨'),      # "1ì°¨", "ì œ1ì°¨"
            (normalized_lower, r'(\d+)ì°¨'),   # ì†Œë¬¸ì ë¡œë§ˆìˆ«ì ë³€í™˜ í›„
        ]
        
        for text, pattern in patterns:
            match = re.search(pattern, text)
            if match:
                return int(match.group(1))
        
        # ëì— ë¶™ì€ ìˆ«ì (1~20 ì‚¬ì´ë§Œ ì°¨ìˆ˜ë¡œ ê°„ì£¼, ê·¸ ì´ìƒì€ ë™ ë²ˆí˜¸ì¼ ê°€ëŠ¥ì„±)
        match = re.search(r'(\d+)$', normalized)
        if match:
            num = int(match.group(1))
            if 1 <= num <= 20:
                return num
        
        return None
    
    def _extract_village_name(self, name: str) -> Optional[str]:
        """ë§ˆì„/ë‹¨ì§€ëª… ì¶”ì¶œ (ì˜ˆ: 'í•œë¹›ë§ˆì„4ë‹¨ì§€' â†’ 'í•œë¹›')"""
        if not name:
            return None
        
        normalized = re.sub(r'\s+', '', name).lower()
        
        # ë§ˆì„ëª… ì¶”ì¶œ íŒ¨í„´ë“¤
        for suffix in ['ë§ˆì„', 'ë‹¨ì§€']:
            pattern = rf'([ê°€-í£]+){suffix}'
            match = re.search(pattern, normalized)
            if match:
                village = match.group(1)
                # ìˆ«ì ì œê±° (ì˜ˆ: "í•œë¹›9" â†’ "í•œë¹›")
                village = re.sub(r'\d+', '', village)
                if len(village) >= 2:
                    return village
        
        return None
    
    def _extract_all_brands(self, name: str) -> List[str]:
        """ì•„íŒŒíŠ¸ ì´ë¦„ì—ì„œ ëª¨ë“  ë¸Œëœë“œëª… ì¶”ì¶œ (ë³µìˆ˜ ê°€ëŠ¥)"""
        if not name:
            return []
        
        normalized = re.sub(r'\s+', '', name).lower()
        
        # ë¡œë§ˆìˆ«ì ë³€í™˜
        roman_map = {'â…°': '1', 'â…±': '2', 'â…²': '3', 'â…³': '4', 'â…´': '5', 
                     'â…µ': '6', 'â…¶': '7', 'â…·': '8', 'â…¸': '9', 'â…¹': '10',
                     'â… ': '1', 'â…¡': '2', 'â…¢': '3', 'â…£': '4', 'â…¤': '5',
                     'â…¥': '6', 'â…¦': '7', 'â…§': '8', 'â…¨': '9', 'â…©': '10'}
        for roman, arabic in roman_map.items():
            normalized = normalized.replace(roman, arabic)
        
        # eí¸í•œì„¸ìƒ í†µì¼
        normalized = normalized.replace('eí¸í•œì„¸ìƒ', 'ì´í¸í•œì„¸ìƒ')
        
        found_brands = []
        for brand in self.APARTMENT_BRANDS:
            brand_lower = brand.lower()
            if brand_lower in normalized:
                found_brands.append(brand_lower)
        
        # ì¤‘ë³µ ì œê±° ë° ê¸´ ë¸Œëœë“œ ìš°ì„  (ì˜ˆ: 'ë¡¯ë°ìºìŠ¬íŒŒí¬íƒ€ìš´'ì´ ìˆìœ¼ë©´ 'ë¡¯ë°ìºìŠ¬' ì œê±°)
        final_brands = []
        for brand in found_brands:
            is_subset = False
            for other in found_brands:
                if brand != other and brand in other:
                    is_subset = True
                    break
            if not is_subset:
                final_brands.append(brand)
        
        return final_brands
    
    def _clean_apt_name(self, name: str) -> str:
        """
        ì•„íŒŒíŠ¸ ì´ë¦„ ì •ì œ (ê´„í˜¸ ë° ë¶€ê°€ ì •ë³´ ì œê±°, íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬)
        
        ì²˜ë¦¬ ë‚´ìš©:
        - ì…ì£¼ìëŒ€í‘œíšŒì˜, ê´€ë¦¬ì‚¬ë¬´ì†Œ ë“± ë¶€ê°€ ì •ë³´ ì œê±°
        - ê´„í˜¸ ë° ë‚´ìš© ì œê±°: (), [], {}
        - íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬: &, /, Â·, ~ ë“±
        """
        if not name:
            return ""
        
        # ì…ì£¼ìëŒ€í‘œíšŒì˜, ê´€ë¦¬ì‚¬ë¬´ì†Œ ë“± ë¶€ê°€ ì •ë³´ ì œê±°
        cleaned = re.sub(r'ì…ì£¼ìëŒ€í‘œíšŒì˜', '', name, flags=re.IGNORECASE)
        cleaned = re.sub(r'ê´€ë¦¬ì‚¬ë¬´ì†Œ', '', cleaned, flags=re.IGNORECASE)
        cleaned = re.sub(r'ì œ\d+ê´€ë¦¬ì‚¬ë¬´ì†Œ', '', cleaned)
        
        # ë‹¤ì–‘í•œ ê´„í˜¸ í˜•íƒœ ì œê±°: (), [], {}, ã€ˆã€‰, ã€Šã€‹
        cleaned = re.sub(r'[\(\[\{ã€ˆã€Š][^\)\]\}ã€‰ã€‹]*[\)\]\}ã€‰ã€‹]', '', cleaned)
        
        # & ê¸°í˜¸ë¥¼ ê³µë°±ìœ¼ë¡œ ë³€í™˜
        cleaned = cleaned.replace('&', ' ')
        
        # / ê¸°í˜¸ë¥¼ ê³µë°±ìœ¼ë¡œ ë³€í™˜ (ì˜ˆ: "íìŠ¤í…Œì´íŠ¸/íŒŒí¬" â†’ "íìŠ¤í…Œì´íŠ¸ íŒŒí¬")
        cleaned = cleaned.replace('/', ' ')
        
        # ì¤‘ê°„ì (Â·) ì œê±°
        cleaned = cleaned.replace('Â·', ' ')
        
        # ë¬¼ê²°í‘œ(~) ì œê±°
        cleaned = cleaned.replace('~', '')
        
        # ë™ ë²ˆí˜¸ ì œê±° (ì˜ˆ: "101ë™", "102ë™", "Aë™", "Bë™")
        cleaned = re.sub(r'\d{2,3}ë™\s*$', '', cleaned)
        cleaned = re.sub(r'[A-Za-z]ë™\s*$', '', cleaned)
        cleaned = re.sub(r'\d{2,3}ë™(?=\s|$)', '', cleaned)
        
        # êµ¬ì‹ ëª…ì¹­ ì œê±° (ëì— ë¶™ì€ ê²½ìš°ë§Œ)
        old_suffixes = ['ë§¨ì…˜', 'ë¹Œë¼', 'ì•„íŒŒíŠ¸', 'APT', 'apt', 'ì£¼íƒ', 'ì—°ë¦½', 'íƒ€ìš´í•˜ìš°ìŠ¤']
        for suffix in old_suffixes:
            if cleaned.lower().endswith(suffix.lower()):
                cleaned = cleaned[:-len(suffix)]
                break
        
        # ì—°ì†ëœ ê³µë°± ì œê±°
        cleaned = re.sub(r'\s+', ' ', cleaned)
        
        return cleaned.strip()
    
    def _normalize_apt_name(self, name: str) -> str:
        """
        ì•„íŒŒíŠ¸ ì´ë¦„ ì •ê·œí™” (ëŒ€í•œë¯¼êµ­ ì•„íŒŒíŠ¸ íŠ¹ì„± ê³ ë ¤, ì˜ë¬¸â†”í•œê¸€ ë¸Œëœë“œëª… í†µì¼)
        
        ì •ê·œí™” ê·œì¹™:
        - ê³µë°± ì œê±°
        - ì˜ë¬¸ ì†Œë¬¸ì ë³€í™˜
        - ë¡œë§ˆìˆ«ì â†’ ì•„ë¼ë¹„ì•„ ìˆ«ì
        - ì˜ë¬¸ ë¸Œëœë“œëª… â†’ í•œê¸€ í†µì¼
        - ì¼ë°˜ì ì¸ ì˜¤íƒ€ íŒ¨í„´ ì •ê·œí™”
        - íŠ¹ìˆ˜ë¬¸ì ì œê±°
        """
        if not name:
            return ""
        
        # ê³µë°± ì œê±°
        normalized = re.sub(r'\s+', '', name)
        
        # ì˜ë¬¸ ëŒ€ì†Œë¬¸ì í†µì¼ (ì†Œë¬¸ìë¡œ ë³€í™˜)
        normalized = normalized.lower()
        
        # ë¡œë§ˆìˆ«ìë¥¼ ì•„ë¼ë¹„ì•„ ìˆ«ìë¡œ ë³€í™˜
        roman_map = {'â…°': '1', 'â…±': '2', 'â…²': '3', 'â…³': '4', 'â…´': '5', 
                     'â…µ': '6', 'â…¶': '7', 'â…·': '8', 'â…¸': '9', 'â…¹': '10',
                     'â… ': '1', 'â…¡': '2', 'â…¢': '3', 'â…£': '4', 'â…¤': '5',
                     'â…¥': '6', 'â…¦': '7', 'â…§': '8', 'â…¨': '9', 'â…©': '10'}
        for roman, arabic in roman_map.items():
            normalized = normalized.replace(roman, arabic)
        
        # ì˜ë¬¸ ë¸Œëœë“œëª… â†’ í•œê¸€ë¡œ í†µì¼ (ê¸´ ê²ƒë¶€í„° ë¨¼ì € ì¹˜í™˜)
        sorted_brands = sorted(self.BRAND_ENG_TO_KOR.items(), key=lambda x: len(x[0]), reverse=True)
        for eng, kor in sorted_brands:
            normalized = normalized.replace(eng, kor)
        
        # ì¼ë°˜ì ì¸ ì˜¤íƒ€ íŒ¨í„´ ì •ê·œí™” (í•œê¸€)
        typo_map = {
            'íìŠ¤í…Œì‡': 'íìŠ¤í…Œì´íŠ¸',
            'í…Œì‡': 'í…Œì´íŠ¸',
            'ì¼€ìŠ¬': 'ìºìŠ¬',
            'ì¨ë°‹': 'ì„œë°‹',
            'ì¨ë¯¸íŠ¸': 'ì„œë°‹',
            'ë ˆë¯¸ì•ˆ': 'ë˜ë¯¸ì•ˆ',  # ì‹¤ì œë¡œëŠ” ë˜ë¯¸ì•ˆì´ ë§ì§€ë§Œ, ë ˆë¯¸ì•ˆìœ¼ë¡œ ì“°ëŠ” ê²½ìš°ê°€ ë§ìŒ
            'í‘¸ë¥´ì§€ì˜¤': 'í‘¸ë¥´ì§€ì˜¤',  # ì‹¤ì œ ë¸Œëœë“œëª…
            'í‘¸ë¥´ì§€ì›€': 'í‘¸ë¥´ì§€ì˜¤',
            'ìì´': 'ìì´',  # ì‹¤ì œ ë¸Œëœë“œëª…
            'ìŸˆì´': 'ìì´',
            'ì‰ë¥´ë¹Œ': 'ì…°ë¥´ë¹Œ',
            'ì‰ë¥´ë¹Œ': 'ì‰ë¥´ë¹Œ',
        }
        for typo, correct in typo_map.items():
            normalized = normalized.replace(typo, correct)
        
        # í•˜ì´í”ˆ/ëŒ€ì‹œ ì œê±°
        normalized = re.sub(r'[-â€“â€”]', '', normalized)
        
        # ì•„í¬ìŠ¤íŠ¸ë¡œí”¼ ì œê±°
        normalized = re.sub(r"[''`]", '', normalized)
        
        # íŠ¹ìˆ˜ë¬¸ì ì œê±° (í•œê¸€, ì˜ë¬¸, ìˆ«ìë§Œ ìœ ì§€)
        normalized = re.sub(r'[^\wê°€-í£]', '', normalized)
        
        return normalized
    
    def _normalize_apt_name_strict(self, name: str) -> str:
        """
        ì•„íŒŒíŠ¸ ì´ë¦„ ì—„ê²© ì •ê·œí™” (ì°¨ìˆ˜/ë‹¨ì§€ ë²ˆí˜¸ ì œê±°, ë‹¤ì–‘í•œ ì ‘ë¯¸ì‚¬ ì²˜ë¦¬)
        
        ì²˜ë¦¬ ë‚´ìš©:
        - ì°¨ìˆ˜/ë‹¨ì§€ ë²ˆí˜¸ ì œê±°
        - ë‹¤ì–‘í•œ ì•„íŒŒíŠ¸ ì ‘ë¯¸ì‚¬ ì œê±°: ì•„íŒŒíŠ¸, APT, ë¹Œë¼, ë¹Œ, íƒ€ìš´, í•˜ìš°ìŠ¤ ë“±
        """
        if not name:
            return ""
        
        normalized = self._normalize_apt_name(name)
        
        # ì°¨ìˆ˜/ë‹¨ì§€ í‘œê¸° ì œê±°
        normalized = re.sub(r'ì œ?\d+ì°¨', '', normalized)
        normalized = re.sub(r'ì œ?\d+ë‹¨ì§€', '', normalized)
        normalized = re.sub(r'\d{3,}ë™', '', normalized)  # 101ë™, 102ë™ ë“±
        
        # ëì— ë¶™ì€ ìˆ«ì ì œê±° (ì˜ˆ: "ì‚¼ì„±1" â†’ "ì‚¼ì„±", ë‹¨ 1~2ìë¦¬ë§Œ)
        normalized = re.sub(r'\d{1,2}$', '', normalized)
        
        # ë‹¤ì–‘í•œ ì•„íŒŒíŠ¸ ì ‘ë¯¸ì‚¬ ì œê±° (ëŒ€ì†Œë¬¸ì ë¬´ê´€)
        suffixes = [
            'apartment', 'apt', 'apts',
            'ì•„íŒŒíŠ¸', 'ì•„íŒŒì•„íŠ¸',  # ì˜¤íƒ€ í¬í•¨
            'ë¹Œë¼', 'ë¹Œ', 'ë¹Œë¦¬ì§€',
            'íƒ€ìš´', 'town',
            'í•˜ìš°ìŠ¤', 'house',
            'ë§¨ì…˜', 'mansion',
            'ìºìŠ¬', 'castle',
            'ë¹Œë”©', 'building',
            'ì˜¤í”¼ìŠ¤í…”', 'officetel',
        ]
        
        for suffix in suffixes:
            # ëì— ìˆëŠ” ê²½ìš°ë§Œ ì œê±°
            if normalized.endswith(suffix):
                normalized = normalized[:-len(suffix)]
        
        return normalized
    
    def _extract_brand_and_name(self, name: str) -> Tuple[Optional[str], str]:
        """ì•„íŒŒíŠ¸ ì´ë¦„ì—ì„œ ë¸Œëœë“œëª…ê³¼ ë‚˜ë¨¸ì§€ ë¶€ë¶„ ì¶”ì¶œ"""
        if not name:
            return None, ""
        
        normalized = self._normalize_apt_name(name)
        
        # ë¸Œëœë“œëª… ì°¾ê¸° (ê¸´ ê²ƒë¶€í„° ë§¤ì¹­)
        sorted_brands = sorted(self.APARTMENT_BRANDS, key=len, reverse=True)
        for brand in sorted_brands:
            brand_lower = brand.lower()
            if brand_lower in normalized:
                # ë¸Œëœë“œëª… ì œê±°í•œ ë‚˜ë¨¸ì§€ ë°˜í™˜
                remaining = normalized.replace(brand_lower, '', 1)
                return brand, remaining
        
        return None, normalized
    
    def _calculate_similarity(self, str1: str, str2: str) -> float:
        """ë‘ ë¬¸ìì—´ ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0)"""
        if not str1 or not str2:
            return 0.0
        return SequenceMatcher(None, str1, str2).ratio()
    
    def _extract_core_name(self, name: str) -> str:
        """í•µì‹¬ ì´ë¦„ ì¶”ì¶œ (ì§€ì—­ëª…, ë§ˆì„ëª… ë“± ì œê±°)"""
        if not name:
            return ""
        
        normalized = self._normalize_apt_name_strict(name)
        
        # ë§ˆì„/ë‹¨ì§€ ì ‘ë¯¸ì‚¬ì™€ ê·¸ ì•ì˜ ì§€ì—­ëª… ì œê±° ì‹œë„
        for suffix in self.VILLAGE_SUFFIXES:
            if suffix in normalized:
                # suffix ì´í›„ ë¶€ë¶„ë§Œ ì¶”ì¶œ (ë¸Œëœë“œëª…ì´ ë³´í†µ ë’¤ì— ì˜´)
                idx = normalized.find(suffix)
                after_suffix = normalized[idx + len(suffix):]
                if len(after_suffix) >= 2:
                    return after_suffix
        
        return normalized
    
    def _find_matching_regions(self, umd_nm: str, all_regions: Dict[int, Any]) -> set:
        """ë™ ì´ë¦„ìœ¼ë¡œ ë§¤ì¹­ë˜ëŠ” ì§€ì—­ ID ì°¾ê¸° (ë„ë„í•œ ë§¤ì¹­)"""
        matching_region_ids = set()
        normalized_umd = self._normalize_dong_name(umd_nm)
        
        for region_id, region in all_regions.items():
            normalized_region = self._normalize_dong_name(region.region_name)
            
            # ì •í™•í•œ ë§¤ì¹­
            if normalized_region == normalized_umd:
                matching_region_ids.add(region_id)
            # í¬í•¨ ê´€ê³„ í™•ì¸ (ì–‘ë°©í–¥)
            elif normalized_umd and normalized_region:
                if normalized_umd in normalized_region or normalized_region in normalized_umd:
                    matching_region_ids.add(region_id)
        
        return matching_region_ids
    
    def _match_apartment(
        self,
        apt_name_api: str,
        candidates: List[Apartment],
        sgg_cd: str,
        umd_nm: Optional[str] = None,
        jibun: Optional[str] = None,
        build_year: Optional[str] = None,
        apt_details: Optional[Dict[int, ApartDetail]] = None,
        normalized_cache: Optional[Dict[str, Any]] = None
    ) -> Optional[Apartment]:
        """
        ì•„íŒŒíŠ¸ ë§¤ì¹­ (í•œêµ­ ì•„íŒŒíŠ¸ íŠ¹ì„±ì— ìµœì í™”ëœ ê°•í™” ë²„ì „)

        ì§€ì—­ê³¼ ë²•ì •ë™ì´ ì¼ì¹˜í•œë‹¤ëŠ” ê°€ì • í•˜ì— ë‹¤ë‹¨ê³„ ë§¤ì¹­ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        í•µì‹¬ ë§¤ì¹­ ì „ëµ:
        1. ì •ê·œí™”ëœ ì´ë¦„ ì •í™• ë§¤ì¹­
        2. ë¸Œëœë“œëª… + ë‹¨ì§€ë²ˆí˜¸ ë³µí•© ë§¤ì¹­ (ê°€ì¥ ì¤‘ìš”!)
        3. ë¸Œëœë“œëª… + ë§ˆì„ëª… ë³µí•© ë§¤ì¹­
        4. ì§€ë²ˆ ê¸°ë°˜ ë§¤ì¹­ (NEW!)
        5. ê±´ì¶•ë…„ë„ ê¸°ë°˜ ë§¤ì¹­ (NEW!)
        6. ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­ (SequenceMatcher)
        7. í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤ì¹­

        ì˜ˆì‹œ:
        - "í•œë¹›ë§ˆì„4ë‹¨ì§€ë¡¯ë°ìºìŠ¬â…¡" â†” "ë¡¯ë°ìºìŠ¬ íŒŒí¬íƒ€ìš´ â…¡" (ë¸Œëœë“œ+ë‹¨ì§€ë²ˆí˜¸ ë¬´ì‹œ, ê°™ì€ ë™)
        - "í•œë¹›9ë‹¨ì§€ ë¡¯ë°ìºìŠ¬íŒŒí¬íƒ€ìš´" â†” "í•œë¹›ë§ˆì„9ë‹¨ì§€ë¡¯ë°ìºìŠ¬1ì°¨" (ë¸Œëœë“œ+ë‹¨ì§€ë²ˆí˜¸)

        Args:
            apt_name_api: APIì—ì„œ ë°›ì€ ì•„íŒŒíŠ¸ ì´ë¦„
            candidates: í›„ë³´ ì•„íŒŒíŠ¸ ë¦¬ìŠ¤íŠ¸
            sgg_cd: 5ìë¦¬ ì‹œêµ°êµ¬ ì½”ë“œ
            umd_nm: ë™ ì´ë¦„ (ì„ íƒ)
            jibun: API ì§€ë²ˆ (ì„ íƒ)
            build_year: API ê±´ì¶•ë…„ë„ (ì„ íƒ)
            apt_details: ì•„íŒŒíŠ¸ ìƒì„¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬ (ì„ íƒ)
            normalized_cache: ì •ê·œí™” ê²°ê³¼ ìºì‹œ (ì„±ëŠ¥ ìµœì í™”)

        Returns:
            ë§¤ì¹­ëœ Apartment ê°ì²´ ë˜ëŠ” None
        """
        if not apt_name_api or not candidates:
            return None
        
        # ì •ê·œí™” ê²°ê³¼ ìºì‹± (ì„±ëŠ¥ ìµœì í™”)
        if normalized_cache is None:
            normalized_cache = {}
        
        # API ì´ë¦„ ë¶„ì„ (ìºì‹±)
        cache_key_api = f"api:{apt_name_api}"
        if cache_key_api not in normalized_cache:
            cleaned_api = self._clean_apt_name(apt_name_api)
            normalized_api = self._normalize_apt_name(cleaned_api)
            normalized_strict_api = self._normalize_apt_name_strict(cleaned_api)
            brands_api = self._extract_all_brands(apt_name_api)
            danji_api = self._extract_danji_number(apt_name_api)
            cha_api = self._extract_cha_number(apt_name_api)
            village_api = self._extract_village_name(apt_name_api)
            core_api = self._extract_core_name(cleaned_api)
            normalized_cache[cache_key_api] = {
                'cleaned': cleaned_api,
                'normalized': normalized_api,
                'strict': normalized_strict_api,
                'brands': brands_api,
                'danji': danji_api,
                'cha': cha_api,
                'village': village_api,
                'core': core_api
            }
        api_cache = normalized_cache[cache_key_api]
        
        if not api_cache['cleaned'] or not api_cache['normalized']:
            return None
        
        # í›„ë³´ ì•„íŒŒíŠ¸ ì •ê·œí™” ë° ì ìˆ˜ ê³„ì‚°
        best_match = None
        best_score = 0.0
        
        for apt in candidates:
            cache_key_db = f"db:{apt.apt_name}"
            if cache_key_db not in normalized_cache:
                cleaned_db = self._clean_apt_name(apt.apt_name)
                normalized_db = self._normalize_apt_name(cleaned_db)
                normalized_strict_db = self._normalize_apt_name_strict(cleaned_db)
                brands_db = self._extract_all_brands(apt.apt_name)
                danji_db = self._extract_danji_number(apt.apt_name)
                cha_db = self._extract_cha_number(apt.apt_name)
                village_db = self._extract_village_name(apt.apt_name)
                core_db = self._extract_core_name(cleaned_db)
                normalized_cache[cache_key_db] = {
                    'cleaned': cleaned_db,
                    'normalized': normalized_db,
                    'strict': normalized_strict_db,
                    'brands': brands_db,
                    'danji': danji_db,
                    'cha': cha_db,
                    'village': village_db,
                    'core': core_db
                }
            db_cache = normalized_cache[cache_key_db]
            
            score = 0.0
            
            # === 1ë‹¨ê³„: ì •ê·œí™”ëœ ì´ë¦„ ì •í™• ë§¤ì¹­ (ìµœê³  ì ìˆ˜) ===
            if api_cache['normalized'] == db_cache['normalized']:
                return apt  # ì •í™• ë§¤ì¹­ì€ ë°”ë¡œ ë°˜í™˜
            
            # === 2ë‹¨ê³„: ì—„ê²© ì •ê·œí™” í›„ ì •í™• ë§¤ì¹­ ===
            if api_cache['strict'] == db_cache['strict']:
                return apt  # ì°¨ìˆ˜/ë‹¨ì§€ ì œê±° í›„ ì •í™• ë§¤ì¹­
            
            # === 3ë‹¨ê³„: ë¸Œëœë“œëª… + ë‹¨ì§€ë²ˆí˜¸ ë³µí•© ë§¤ì¹­ (í•µì‹¬!) ===
            # ê°™ì€ ë¸Œëœë“œê°€ ìˆëŠ”ì§€ í™•ì¸
            common_brands = set(api_cache['brands']) & set(db_cache['brands'])
            has_common_brand = len(common_brands) > 0
            
            # ë‹¨ì§€ë²ˆí˜¸ ì¼ì¹˜ í™•ì¸
            danji_match = (api_cache['danji'] is not None and 
                          db_cache['danji'] is not None and 
                          api_cache['danji'] == db_cache['danji'])
            
            # ë§ˆì„ëª… ì¼ì¹˜ í™•ì¸
            village_match = False
            if api_cache['village'] and db_cache['village']:
                v_api = api_cache['village'].lower()
                v_db = db_cache['village'].lower()
                village_match = (v_api == v_db or v_api in v_db or v_db in v_api)
            
            # ë¸Œëœë“œ + ë‹¨ì§€ë²ˆí˜¸ ì¼ì¹˜ â†’ ë§¤ìš° ë†’ì€ ì ìˆ˜ (ê±°ì˜ í™•ì‹¤íˆ ê°™ì€ ì•„íŒŒíŠ¸)
            if has_common_brand and danji_match:
                score = max(score, 0.95)
            
            # ë¸Œëœë“œ + ë§ˆì„ëª… ì¼ì¹˜ â†’ ë†’ì€ ì ìˆ˜
            if has_common_brand and village_match:
                score = max(score, 0.90)
            
            # ë‹¨ì§€ë²ˆí˜¸ + ë§ˆì„ëª… ì¼ì¹˜ â†’ ë†’ì€ ì ìˆ˜ (ë¸Œëœë“œ ì—†ì–´ë„)
            if danji_match and village_match:
                score = max(score, 0.88)
            
            # ë¸Œëœë“œë§Œ ì¼ì¹˜ (ê°™ì€ ë™ì— í•´ë‹¹ ë¸Œëœë“œ ì•„íŒŒíŠ¸ê°€ í•˜ë‚˜ë¿ì¼ ê°€ëŠ¥ì„±)
            if has_common_brand and len(candidates) <= 3:
                score = max(score, 0.75)
            elif has_common_brand:
                score = max(score, 0.60)
            
            # ë‹¨ì§€ë²ˆí˜¸ë§Œ ì¼ì¹˜ (ê°™ì€ ë™ì— í•´ë‹¹ ë‹¨ì§€ê°€ í•˜ë‚˜ë¿ì¼ ê°€ëŠ¥ì„±)
            if danji_match and len(candidates) <= 3:
                score = max(score, 0.70)
            
            # === 3.5ë‹¨ê³„: ì§€ë²ˆ ê¸°ë°˜ ë§¤ì¹­ (NEW!) ===
            jibun_match = False
            if jibun and apt_details and apt.apt_id in apt_details:
                detail = apt_details[apt.apt_id]
                if detail.jibun_address:
                    # ì§€ë²ˆ ì •ê·œí™” (ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ì œê±°)
                    norm_jibun_api = re.sub(r'[\s\-]+', '', jibun)
                    norm_jibun_db = re.sub(r'[\s\-]+', '', detail.jibun_address)
                    
                    # ì§€ë²ˆ ì£¼ì†Œì—ì„œ ë²ˆì§€ ë¶€ë¶„ë§Œ ì¶”ì¶œ (ì˜ˆ: "101-2", "101")
                    jibun_api_parts = norm_jibun_api.split(',')[0] if ',' in norm_jibun_api else norm_jibun_api
                    
                    # ì§€ë²ˆ í¬í•¨ í™•ì¸
                    if jibun_api_parts in norm_jibun_db or norm_jibun_api in norm_jibun_db:
                        jibun_match = True
                        # ì§€ë²ˆ ì¼ì¹˜ ì‹œ ì ìˆ˜ ëŒ€í­ ìƒìŠ¹ (ë§¤ìš° ì‹ ë¢°ë„ ë†’ìŒ)
                        if score >= 0.5:  # ì–´ëŠ ì •ë„ ì´ë¦„ë„ ìœ ì‚¬í•œ ê²½ìš°
                            score = max(score, 0.98)
                        else:  # ì´ë¦„ì€ ì•ˆ ë¹„ìŠ·í•˜ì§€ë§Œ ì§€ë²ˆì´ ê°™ì€ ê²½ìš°
                            score = max(score, 0.85)
            
            # === 3.6ë‹¨ê³„: ê±´ì¶•ë…„ë„ ê¸°ë°˜ ê²€ì¦ (NEW!) ===
            build_year_match = False
            if build_year and apt_details and apt.apt_id in apt_details:
                detail = apt_details[apt.apt_id]
                # use_approval_dateì—ì„œ ë…„ë„ ì¶”ì¶œ (YYYY-MM-DD í˜•ì‹)
                if detail.use_approval_date:
                    try:
                        approval_year = detail.use_approval_date.split('-')[0]
                        # ê±´ì¶•ë…„ë„ ì¼ì¹˜ í™•ì¸ (Â±1ë…„ í—ˆìš©)
                        if abs(int(build_year) - int(approval_year)) <= 1:
                            build_year_match = True
                            # ê±´ì¶•ë…„ë„ ì¼ì¹˜ ì‹œ ì ìˆ˜ ë³´ì • (ì‹ ë¢°ë„ ì¦ê°€)
                            if score >= 0.5:
                                score = max(score, score * 1.05)  # 5% ë³´ë„ˆìŠ¤
                    except (ValueError, AttributeError):
                        pass
            
            # ì§€ë²ˆ + ê±´ì¶•ë…„ë„ ëª¨ë‘ ì¼ì¹˜ ì‹œ ìµœê³  ì ìˆ˜
            if jibun_match and build_year_match:
                score = max(score, 0.99)
            
            # === 4ë‹¨ê³„: í¬í•¨ ê´€ê³„ í™•ì¸ (ì–‘ë°©í–¥) ===
            norm_api = api_cache['normalized']
            norm_db = db_cache['normalized']
            if len(norm_api) >= 4 and len(norm_db) >= 4:
                if norm_api in norm_db:
                    ratio = len(norm_api) / len(norm_db)
                    score = max(score, 0.70 + ratio * 0.2)
                elif norm_db in norm_api:
                    ratio = len(norm_db) / len(norm_api)
                    score = max(score, 0.70 + ratio * 0.2)
            
            # === 5ë‹¨ê³„: ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­ ===
            similarity = self._calculate_similarity(norm_api, norm_db)
            if similarity >= 0.85:
                score = max(score, similarity)
            elif similarity >= 0.70:
                score = max(score, similarity * 0.95)
            elif similarity >= 0.60:
                score = max(score, similarity * 0.90)
            
            # === 6ë‹¨ê³„: ì—„ê²© ì •ê·œí™” ìœ ì‚¬ë„ ===
            strict_similarity = self._calculate_similarity(
                api_cache['strict'], 
                db_cache['strict']
            )
            if strict_similarity >= 0.75:
                score = max(score, strict_similarity * 0.90)
            elif strict_similarity >= 0.60:
                score = max(score, strict_similarity * 0.85)
            
            # === 7ë‹¨ê³„: í•µì‹¬ ì´ë¦„ ë§¤ì¹­ ===
            if api_cache['core'] and db_cache['core']:
                core_similarity = self._calculate_similarity(
                    api_cache['core'], 
                    db_cache['core']
                )
                if core_similarity >= 0.80:
                    score = max(score, core_similarity * 0.85)
            
            # === 8ë‹¨ê³„: í•œê¸€ í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤ì¹­ ===
            api_keywords = set(re.findall(r'[ê°€-í£]{2,}', norm_api))
            db_keywords = set(re.findall(r'[ê°€-í£]{2,}', norm_db))
            
            if api_keywords and db_keywords:
                # ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­
                common_keywords = api_keywords & db_keywords
                
                # ë¶€ë¶„ í‚¤ì›Œë“œ ë§¤ì¹­ (í¬í•¨ ê´€ê³„)
                partial_matches = 0
                for api_kw in api_keywords:
                    for db_kw in db_keywords:
                        if api_kw != db_kw and len(api_kw) >= 2 and len(db_kw) >= 2:
                            if api_kw in db_kw or db_kw in api_kw:
                                partial_matches += 1
                                break
                
                total_matches = len(common_keywords) + partial_matches * 0.7
                total_keywords = max(len(api_keywords), len(db_keywords))
                
                if total_keywords > 0:
                    keyword_ratio = total_matches / total_keywords
                    if keyword_ratio >= 0.6:
                        score = max(score, 0.65 + keyword_ratio * 0.25)
                    elif keyword_ratio >= 0.4:
                        score = max(score, 0.55 + keyword_ratio * 0.20)
            
            # === 9ë‹¨ê³„: ë¸Œëœë“œ + ìœ ì‚¬ë„ ë³µí•© ì ìˆ˜ ===
            if has_common_brand and similarity >= 0.50:
                combined_score = 0.60 + similarity * 0.35
                score = max(score, combined_score)
            
            # === 10ë‹¨ê³„: í›„ë³´ê°€ ì ì„ ë•Œ ë” ê´€ëŒ€í•œ ë§¤ì¹­ ===
            # ì‹œêµ°êµ¬ ì½”ë“œì™€ ë™ìœ¼ë¡œ ì´ë¯¸ í•„í„°ë§ë˜ì—ˆìœ¼ë¯€ë¡œ ë§¤ìš° ê´€ëŒ€í•˜ê²Œ ë§¤ì¹­
            if len(candidates) == 1:
                # í›„ë³´ê°€ í•˜ë‚˜ë¿ì´ë©´ ê±°ì˜ ë¬´ì¡°ê±´ ë§¤ì¹­ (ê°™ì€ ë™ì— ì•„íŒŒíŠ¸ 1ê°œ)
                score = max(score, 0.50)
            elif len(candidates) <= 3:
                # í›„ë³´ê°€ 3ê°œ ì´í•˜ë©´ ë§¤ìš° ê´€ëŒ€í•˜ê²Œ
                if similarity >= 0.20 or strict_similarity >= 0.20 or has_common_brand:
                    score = max(score, 0.40)
            elif len(candidates) <= 5:
                # í›„ë³´ê°€ 5ê°œ ì´í•˜ë©´ ê´€ëŒ€í•˜ê²Œ
                if similarity >= 0.25 or strict_similarity >= 0.25 or has_common_brand:
                    score = max(score, 0.35)
            elif len(candidates) <= 10:
                # í›„ë³´ê°€ 10ê°œ ì´í•˜ë©´ ì•½ê°„ ê´€ëŒ€í•˜ê²Œ
                if similarity >= 0.30 or strict_similarity >= 0.30:
                    score = max(score, 0.32)
            
            # ìµœê³  ì ìˆ˜ ì—…ë°ì´íŠ¸
            if score > best_score:
                best_score = score
                best_match = apt
        
        # ì‹œêµ°êµ¬ ì½”ë“œì™€ ë™ìœ¼ë¡œ ì´ë¯¸ í•„í„°ë§ë˜ì—ˆìœ¼ë¯€ë¡œ ì„ê³„ê°’ ëŒ€í­ ë‚®ì¶¤
        # í›„ë³´ ìˆ˜ì— ë”°ë¼ ë™ì  ì„ê³„ê°’ ì ìš©
        threshold = 0.30  # ê¸°ë³¸ ì„ê³„ê°’
        if len(candidates) == 1:
            threshold = 0.05  # í›„ë³´ 1ê°œë©´ ê±°ì˜ ë¬´ì¡°ê±´ ë§¤ì¹­
        elif len(candidates) == 2:
            threshold = 0.10  # í›„ë³´ 2ê°œ
        elif len(candidates) <= 3:
            threshold = 0.15  # í›„ë³´ 3ê°œ ì´í•˜
        elif len(candidates) <= 5:
            threshold = 0.20  # í›„ë³´ 5ê°œ ì´í•˜
        elif len(candidates) <= 10:
            threshold = 0.25  # í›„ë³´ 10ê°œ ì´í•˜
        
        # ì§§ì€ ì´ë¦„ (2~3ê¸€ì)ì€ ì„ê³„ê°’ ì¶”ê°€ ë‚®ì¶¤
        cleaned_name = self._clean_apt_name(apt_name_api)
        if len(cleaned_name) <= 3:
            threshold = min(threshold, 0.10)
        elif len(cleaned_name) <= 4:
            threshold = min(threshold, 0.15)
        
        if best_score >= threshold:
            return best_match
        
        return None
    
    def _match_apartment_with_debug(
        self,
        apt_name_api: str,
        candidates: List[Apartment],
        sgg_cd: str,
        umd_nm: Optional[str] = None,
        jibun: Optional[str] = None,
        build_year: Optional[str] = None,
        apt_details: Optional[Dict[int, ApartDetail]] = None,
        normalized_cache: Optional[Dict[str, Any]] = None
    ) -> Tuple[Optional[Apartment], Dict[str, Any]]:
        """
        _match_apartmentì˜ ë””ë²„ê·¸ ë²„ì „ (ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ìƒì„¸ ì •ë³´ ë°˜í™˜)
        
        Returns:
            (ë§¤ì¹­ëœ Apartment ê°ì²´ ë˜ëŠ” None, ë””ë²„ê·¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬)
        """
        debug_info = {
            'debug_msg': '',
            'best_score': 0.0,
            'threshold': 0.0,
            'candidate_count': len(candidates),
            'has_apt_details': bool(apt_details and len(apt_details) > 0)
        }
        
        matched_apt = self._match_apartment(
            apt_name_api, candidates, sgg_cd, umd_nm,
            jibun, build_year, apt_details, normalized_cache
        )
        
        if matched_apt:
            debug_info['debug_msg'] = 'ë§¤ì¹­ ì„±ê³µ'
            return matched_apt, debug_info
        
        # ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
        if not apt_name_api or not candidates:
            debug_info['debug_msg'] = f'ì…ë ¥ ë¶€ì¡± (ì´ë¦„:{"ìˆìŒ" if apt_name_api else "ì—†ìŒ"}, í›„ë³´:{len(candidates) if candidates else 0})'
            return None, debug_info
        
        # í›„ë³´ë“¤ì˜ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ì—¬ ìµœê³  ì ìˆ˜ í™•ì¸
        if normalized_cache is None:
            normalized_cache = {}
        
        cache_key_api = f"api:{apt_name_api}"
        if cache_key_api not in normalized_cache:
            cleaned_api = self._clean_apt_name(apt_name_api)
            normalized_api = self._normalize_apt_name(cleaned_api)
            normalized_strict_api = self._normalize_apt_name_strict(cleaned_api)
            brands_api = self._extract_all_brands(apt_name_api)
            danji_api = self._extract_danji_number(apt_name_api)
            cha_api = self._extract_cha_number(apt_name_api)
            village_api = self._extract_village_name(apt_name_api)
            core_api = self._extract_core_name(cleaned_api)
            normalized_cache[cache_key_api] = {
                'cleaned': cleaned_api,
                'normalized': normalized_api,
                'strict': normalized_strict_api,
                'brands': brands_api,
                'danji': danji_api,
                'cha': cha_api,
                'village': village_api,
                'core': core_api
            }
        api_cache = normalized_cache[cache_key_api]
        
        best_score = 0.0
        threshold = 0.30
        if len(candidates) == 1:
            threshold = 0.05
        elif len(candidates) == 2:
            threshold = 0.10
        elif len(candidates) <= 3:
            threshold = 0.15
        elif len(candidates) <= 5:
            threshold = 0.20
        elif len(candidates) <= 10:
            threshold = 0.25
        
        # ì§§ì€ ì´ë¦„ (2~3ê¸€ì)ì€ ì„ê³„ê°’ ì¶”ê°€ ë‚®ì¶¤
        cleaned_name = self._clean_apt_name(apt_name_api)
        if len(cleaned_name) <= 3:
            threshold = min(threshold, 0.10)
        elif len(cleaned_name) <= 4:
            threshold = min(threshold, 0.15)
        
        # ëª¨ë“  í›„ë³´ì˜ ì ìˆ˜ ê³„ì‚° í›„ ìƒìœ„ 3ê°œ ì„ íƒ (ì ìˆ˜ìˆœ ì •ë ¬)
        all_scores = []
        for apt in candidates:
            cache_key_db = f"db:{apt.apt_name}"
            if cache_key_db not in normalized_cache:
                cleaned_db = self._clean_apt_name(apt.apt_name)
                normalized_db = self._normalize_apt_name(cleaned_db)
                normalized_cache[cache_key_db] = {
                    'cleaned': cleaned_db,
                    'normalized': normalized_db
                }
            db_cache = normalized_cache[cache_key_db]
            
            similarity = self._calculate_similarity(api_cache['normalized'], db_cache['normalized'])
            all_scores.append((apt.apt_name[:15], similarity))
            best_score = max(best_score, similarity)
        
        # ì ìˆ˜ìˆœ ì •ë ¬ í›„ ìƒìœ„ 3ê°œ ì„ íƒ
        all_scores.sort(key=lambda x: x[1], reverse=True)
        top_scores = all_scores[:3]
        
        debug_info['best_score'] = best_score
        debug_info['threshold'] = threshold
        top_scores_str = ', '.join([f"{name}:{score:.2f}" for name, score in top_scores])
        debug_info['debug_msg'] = f"ìµœê³ ì ìˆ˜:{best_score:.2f}(ì„ê³„ê°’:{threshold:.2f}) ìƒìœ„í›„ë³´:[{top_scores_str}]"
        
        return None, debug_info

    async def collect_sales_data(
        self,
        db: AsyncSession,
        start_ym: str,
        end_ym: str,
        max_items: Optional[int] = None,
        allow_duplicate: bool = False
    ) -> Any:
        """
        ì•„íŒŒíŠ¸ ë§¤ë§¤ ì‹¤ê±°ë˜ê°€ ë°ì´í„° ìˆ˜ì§‘ (ìƒˆë¡œìš´ JSON API ì‚¬ìš©)
        
        Args:
            start_ym: ì‹œì‘ ì—°ì›” (YYYYMM)
            end_ym: ì¢…ë£Œ ì—°ì›” (YYYYMM)
            max_items: ìµœëŒ€ ìˆ˜ì§‘ ê°œìˆ˜ ì œí•œ (ê¸°ë³¸ê°’: None, ì œí•œ ì—†ìŒ)
            allow_duplicate: ì¤‘ë³µ ì €ì¥ í—ˆìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: False, False=ê±´ë„ˆë›°ê¸°, True=ì—…ë°ì´íŠ¸)
        """
        from app.schemas.sale import SalesCollectionResponse, SaleCreate
        
        total_fetched = 0
        total_saved = 0
        skipped = 0
        errors = []
        failure_samples = []  # ì‹¤íŒ¨ ìƒ˜í”Œ ìˆ˜ì§‘
        
        logger.info(f"ğŸ’° ë§¤ë§¤ ìˆ˜ì§‘ ì‹œì‘: {start_ym} ~ {end_ym}")
        
        # 1. ê¸°ê°„ ìƒì„±
        def get_months(start, end):
            try:
                start_date = datetime.strptime(start, "%Y%m")
                end_date = datetime.strptime(end, "%Y%m")
            except ValueError:
                raise ValueError("ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. YYYYMM í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
            
            months = []
            curr = start_date
            while curr <= end_date:
                months.append(curr.strftime("%Y%m"))
                if curr.month == 12:
                    curr = curr.replace(year=curr.year + 1, month=1)
                else:
                    curr = curr.replace(month=curr.month + 1)
            return months
        
        try:
            target_months = get_months(start_ym, end_ym)
        except ValueError as e:
            return SalesCollectionResponse(success=False, message=str(e))
        
        # 2. ì§€ì—­ ì½”ë“œ ì¶”ì¶œ
        try:
            stmt = text("SELECT DISTINCT SUBSTR(region_code, 1, 5) FROM states WHERE length(region_code) >= 5")
            result = await db.execute(stmt)
            target_sgg_codes = [row[0] for row in result.fetchall() if row[0] and len(row[0]) == 5]
            logger.info(f"ğŸ“ {len(target_sgg_codes)}ê°œ ì§€ì—­ ì½”ë“œ ì¶”ì¶œ")
        except Exception as e:
            logger.error(f"âŒ ì§€ì—­ ì½”ë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return SalesCollectionResponse(success=False, message=f"DB ì˜¤ë¥˜: {e}")
        
        # 2.5. ì§€ì—­ë³„ ì•„íŒŒíŠ¸/ì§€ì—­ ì •ë³´ ì‚¬ì „ ë¡œë“œ (ì„±ëŠ¥ ìµœì í™”)
        apt_cache: Dict[str, List[Apartment]] = {}
        region_cache: Dict[str, Dict[int, State]] = {}
        detail_cache: Dict[str, Dict[int, ApartDetail]] = {}
        
        async def load_apts_and_regions(sgg_cd: str) -> tuple[List[Apartment], Dict[int, State], Dict[int, ApartDetail]]:
            """ì§€ì—­ë³„ ì•„íŒŒíŠ¸, ì§€ì—­ ì •ë³´, ì•„íŒŒíŠ¸ ìƒì„¸ ì •ë³´ ë¡œë“œ (ìºì‹±)"""
            if sgg_cd in apt_cache:
                return apt_cache[sgg_cd], region_cache[sgg_cd], detail_cache.get(sgg_cd, {})
            
            async with AsyncSessionLocal() as cache_db:
                # ì•„íŒŒíŠ¸ ë¡œë“œ
                stmt = select(Apartment).options(joinedload(Apartment.region)).join(State).where(
                    State.region_code.like(f"{sgg_cd}%")
                )
                apt_result = await cache_db.execute(stmt)
                local_apts = apt_result.scalars().all()
                
                # ë™ ì •ë³´ ìºì‹œ
                region_stmt = select(State).where(State.region_code.like(f"{sgg_cd}%"))
                region_result = await cache_db.execute(region_stmt)
                all_regions = {r.region_id: r for r in region_result.scalars().all()}
                
                # ì•„íŒŒíŠ¸ ìƒì„¸ ì •ë³´ ë¡œë“œ (ì§€ë²ˆ í¬í•¨)
                apt_ids = [apt.apt_id for apt in local_apts]
                if apt_ids:
                    detail_stmt = select(ApartDetail).where(ApartDetail.apt_id.in_(apt_ids))
                    detail_result = await cache_db.execute(detail_stmt)
                    apt_details = {d.apt_id: d for d in detail_result.scalars().all()}
                else:
                    apt_details = {}
                
                apt_cache[sgg_cd] = local_apts
                region_cache[sgg_cd] = all_regions
                detail_cache[sgg_cd] = apt_details
                
                return local_apts, all_regions, apt_details
        
        # 3. ë³‘ë ¬ ì²˜ë¦¬ (ì—°ê²° í’€ í¬ê¸°ì— ë§ì¶° 10ê°œë¡œ ì œí•œ, DB ì—°ê²° í’€ ê³ ë ¤)
        # DB ì—°ê²° í’€: pool_size=20, max_overflow=30 (ìµœëŒ€ 50ê°œ)
        # ì„¸ë§ˆí¬ì–´ë¥¼ 10ê°œë¡œ ì œí•œí•˜ì—¬ ì—°ê²° í’€ ì—¬ìœ  í™•ë³´
        semaphore = asyncio.Semaphore(10)
        
        def format_ym(ym: str) -> str:
            """ì—°ì›” í˜•ì‹ ë³€í™˜: YYYYMM -> YYYYë…„ MMì›”"""
            try:
                y = int(ym[:4])
                m = int(ym[4:])
                return f"{y}ë…„ {m}ì›”"
            except:
                return ym
        
        # ê³µìœ  HTTP í´ë¼ì´ì–¸íŠ¸ (ì—°ê²° ì¬ì‚¬ìš©ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ)
        http_client = httpx.AsyncClient(
            timeout=httpx.Timeout(60.0, connect=10.0),
            limits=httpx.Limits(max_connections=30, max_keepalive_connections=20)
        )
        
        async def process_sale_region(ym: str, sgg_cd: str, region_idx: int = 0, total_regions: int = 0):
            """ë§¤ë§¤ ë°ì´í„° ìˆ˜ì§‘ ì‘ì—…"""
            ym_formatted = format_ym(ym)
            region_progress_str = f"[{region_idx}/{total_regions}]" if total_regions > 0 else ""
            
            # ì§€ì—­ ìˆœíšŒ ì‹œì‘ ë¡œê·¸
            if total_regions > 0:
                logger.info(f"   ğŸ”„ {region_progress_str} {sgg_cd}/{ym} ({ym_formatted}) ì²˜ë¦¬ ì‹œì‘...")
            
            async with semaphore:
                async with AsyncSessionLocal() as local_db:
                    nonlocal total_fetched, total_saved, skipped, errors
                    
                    try:
                        # ê¸°ì¡´ ë°ì´í„° í™•ì¸
                        y = int(ym[:4])
                        m = int(ym[4:])
                        start_date = date(y, m, 1)
                        last_day = calendar.monthrange(y, m)[1]
                        end_date = date(y, m, last_day)
                        
                        check_stmt = select(func.count(Sale.trans_id)).join(Apartment).join(State).where(
                            and_(
                                State.region_code.like(f"{sgg_cd}%"),
                                Sale.contract_date >= start_date,
                                Sale.contract_date <= end_date
                            )
                        )
                        count_result = await local_db.execute(check_stmt)
                        existing_count = count_result.scalar() or 0
                        
                        if existing_count > 0 and not allow_duplicate:
                            skipped += existing_count
                            logger.info(f"â­ï¸ {sgg_cd}/{ym} ({ym_formatted}): ê±´ë„ˆëœ€ ({existing_count}ê±´ ì¡´ì¬)")
                            return
                        
                        # max_items ì œí•œ í™•ì¸
                        if max_items and total_saved >= max_items:
                            return
                        
                        # API í˜¸ì¶œ (XML) - ê³µìœ  í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©
                        params = {
                            "serviceKey": self.api_key,
                            "LAWD_CD": sgg_cd,
                            "DEAL_YMD": ym,
                            "numOfRows": 4000
                        }
                        
                        response = await http_client.get(MOLIT_SALE_API_URL, params=params)
                        response.raise_for_status()
                        xml_content = response.text
                        
                        # XML íŒŒì‹±
                        try:
                            root = ET.fromstring(xml_content)
                        except ET.ParseError as e:
                            errors.append(f"{sgg_cd}/{ym} ({ym_formatted}): XML íŒŒì‹± ì‹¤íŒ¨ - {str(e)}")
                            logger.error(f"âŒ {sgg_cd}/{ym} ({ym_formatted}): XML íŒŒì‹± ì‹¤íŒ¨ - {str(e)}")
                            return
                        
                        # ê²°ê³¼ ì½”ë“œ í™•ì¸
                        result_code_elem = root.find(".//resultCode")
                        result_msg_elem = root.find(".//resultMsg")
                        result_code = result_code_elem.text if result_code_elem is not None else ""
                        result_msg = result_msg_elem.text if result_msg_elem is not None else ""
                        
                        if result_code != "000":
                            errors.append(f"{sgg_cd}/{ym} ({ym_formatted}): {result_msg}")
                            logger.error(f"âŒ {sgg_cd}/{ym} ({ym_formatted}): {result_msg}")
                            return
                        
                        # items ì¶”ì¶œ
                        items = root.findall(".//item")
                        
                        if not items:
                            return
                        
                        total_fetched += len(items)
                        
                        # ì•„íŒŒíŠ¸ ë° ì§€ì—­ ì •ë³´ ë¡œë“œ (ìºì‹± í™œìš©)
                        local_apts, all_regions, apt_details = await load_apts_and_regions(sgg_cd)
                        
                        if not local_apts:
                            return
                        
                        sales_to_save = []
                        success_count = 0
                        skip_count = 0
                        error_count = 0
                        apt_name_log = ""
                        first_failure_details = None  # ì²« ë²ˆì§¸ ì‹¤íŒ¨ ìƒì„¸ ì •ë³´ ì €ì¥
                        normalized_cache: Dict[str, Any] = {}  # ì •ê·œí™” ê²°ê³¼ ìºì‹±
                        batch_size = 100  # ë°°ì¹˜ ì»¤ë°‹ í¬ê¸°
                        
                        for item in items:
                            # max_items ì œí•œ í™•ì¸
                            if max_items and total_saved >= max_items:
                                break
                            
                            try:
                                # XML Elementì—ì„œ í•„ë“œ ì¶”ì¶œ
                                apt_nm_elem = item.find("aptNm")
                                apt_nm = apt_nm_elem.text.strip() if apt_nm_elem is not None and apt_nm_elem.text else ""
                                
                                umd_nm_elem = item.find("umdNm")
                                umd_nm = umd_nm_elem.text.strip() if umd_nm_elem is not None and umd_nm_elem.text else ""
                                
                                sgg_cd_elem = item.find("sggCd")
                                sgg_cd_item = sgg_cd_elem.text.strip() if sgg_cd_elem is not None and sgg_cd_elem.text else sgg_cd
                                
                                # ì§€ë²ˆ ì¶”ì¶œ (ë§¤ì¹­ì— í™œìš©)
                                jibun_elem = item.find("jibun")
                                jibun = jibun_elem.text.strip() if jibun_elem is not None and jibun_elem.text else ""
                                
                                # ê±´ì¶•ë…„ë„ ì¶”ì¶œ (ë§¤ì¹­ì— í™œìš©)
                                build_year_elem = item.find("buildYear")
                                build_year_for_match = build_year_elem.text.strip() if build_year_elem is not None and build_year_elem.text else ""
                                
                                if not apt_nm:
                                    continue
                                
                                if not apt_name_log:
                                    apt_name_log = apt_nm
                                
                                # ë™ ê¸°ë°˜ í•„í„°ë§ (ê°œì„ ëœ ë²„ì „)
                                candidates = local_apts
                                sgg_code_matched = True
                                dong_matched = False
                                initial_candidate_count = len(local_apts)
                                
                                # ì‹œêµ°êµ¬ ì½”ë“œ ê¸°ë°˜ í•„í„°ë§ (ê°œì„ : 5ìë¦¬ â†’ 10ìë¦¬ ë³€í™˜)
                                if sgg_cd_item and str(sgg_cd_item).strip():
                                    sgg_cd_item_str = str(sgg_cd_item).strip()
                                    sgg_cd_str = str(sgg_cd).strip()
                                    
                                    # DB í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (5ìë¦¬ â†’ 10ìë¦¬)
                                    sgg_cd_db = self._convert_sgg_code_to_db_format(sgg_cd_item_str)
                                    
                                    if sgg_cd_db:
                                        # ì •í™•í•œ ë§¤ì¹­ ì‹œë„
                                        filtered = [
                                            apt for apt in local_apts
                                            if apt.region_id in all_regions
                                            and all_regions[apt.region_id].region_code == sgg_cd_db
                                        ]
                                        # ì •í™•í•œ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ì‹œì‘ ë¶€ë¶„ ë§¤ì¹­
                                        if not filtered:
                                            filtered = [
                                                apt for apt in local_apts
                                                if apt.region_id in all_regions
                                                and all_regions[apt.region_id].region_code.startswith(sgg_cd_item_str)
                                            ]
                                        if filtered:
                                            candidates = filtered
                                            sgg_code_matched = True
                                
                                # ë™ ê¸°ë°˜ í•„í„°ë§ (ê°œì„ : ë” ë„ë„í•œ ë§¤ì¹­)
                                if umd_nm and candidates:
                                    matching_region_ids = self._find_matching_regions(umd_nm, all_regions)
                                    
                                    if matching_region_ids:
                                        filtered = [
                                            apt for apt in candidates
                                            if apt.region_id in matching_region_ids
                                        ]
                                        if filtered:
                                            candidates = filtered
                                            dong_matched = True
                                    # í•„í„°ë§ ì‹¤íŒ¨í•´ë„ í›„ë³´ ìœ ì§€ (ë” ë„ë„í•˜ê²Œ)
                                
                                # í›„ë³´ê°€ ì—†ìœ¼ë©´ ì›ë˜ í›„ë³´ë¡œ ë³µì›
                                if not candidates:
                                    candidates = local_apts
                                    sgg_code_matched = True
                                    dong_matched = False
                                
                                filtered_candidate_count = len(candidates)
                                
                                # ì•„íŒŒíŠ¸ ë§¤ì¹­ (ì •ê·œí™” ìºì‹œ, ì§€ë²ˆ, ê±´ì¶•ë…„ë„, ìƒì„¸ì •ë³´ ì „ë‹¬)
                                matched_apt, match_debug_info = self._match_apartment_with_debug(
                                    apt_nm, candidates, sgg_cd, umd_nm, 
                                    jibun, build_year_for_match, apt_details, normalized_cache
                                )
                                
                                # í•„í„°ë§ëœ í›„ë³´ì—ì„œ ì‹¤íŒ¨ ì‹œ ì „ì²´ í›„ë³´ë¡œ ì¬ì‹œë„
                                if not matched_apt and len(candidates) < len(local_apts):
                                    logger.debug(f"   ğŸ”„ [ë§¤ë§¤] í•„í„°ë§ í›„ë³´({filtered_candidate_count}ê°œ)ì—ì„œ ì‹¤íŒ¨ â†’ ì „ì²´ í›„ë³´({initial_candidate_count}ê°œ)ë¡œ ì¬ì‹œë„: {apt_nm}")
                                    matched_apt, match_debug_info = self._match_apartment_with_debug(
                                        apt_nm, local_apts, sgg_cd, umd_nm, 
                                        jibun, build_year_for_match, apt_details, normalized_cache
                                    )
                                
                                if not matched_apt:
                                    error_count += 1
                                    # ìƒì„¸ ì‹¤íŒ¨ ë¡œê¹… (WARNING ë ˆë²¨ë¡œ ë³€ê²½í•˜ì—¬ í•­ìƒ ì¶œë ¥)
                                    debug_msg = ''
                                    if match_debug_info:
                                        debug_msg = match_debug_info.get('debug_msg', '')
                                    else:
                                        debug_msg = 'ë””ë²„ê·¸ì •ë³´ ì—†ìŒ'
                                    
                                    failure_detail = (
                                        f"ì•„íŒŒíŠ¸:{apt_nm} | ì§€ë²ˆ:{jibun or 'ì—†ìŒ'} | ê±´ì¶•ë…„ë„:{build_year_for_match or 'ì—†ìŒ'} | "
                                        f"ë™:{umd_nm or 'ì—†ìŒ'} | ì‹œêµ°êµ¬ì½”ë“œ:{sgg_cd_item or sgg_cd} | "
                                        f"í›„ë³´ìˆ˜:{filtered_candidate_count}(ì „ì²´:{initial_candidate_count}) | "
                                        f"ì‹œêµ°êµ¬ë§¤ì¹­:{sgg_code_matched} ë™ë§¤ì¹­:{dong_matched} | "
                                        f"ìƒì„¸ì •ë³´:{len(apt_details) if apt_details else 0}ê°œ | {debug_msg}"
                                    )
                                    
                                    # ì²« ë²ˆì§¸ ì‹¤íŒ¨ ìƒì„¸ ì •ë³´ ì €ì¥ (ë°˜ë“œì‹œ ì„¤ì •)
                                    if first_failure_details is None:
                                        first_failure_details = failure_detail
                                    
                                    # ìƒì„¸ ë¡œê·¸ ì¶œë ¥ (ì£¼ì„ ì²˜ë¦¬ - ì§€ì—­ ìˆœíšŒ í™•ì¸ì„ ìœ„í•´ ë¹„í™œì„±í™”)
                                    # logger.warning(
                                    #     f"   âŒ [ë§¤ë§¤] ë§¤ì¹­ ì‹¤íŒ¨: {failure_detail}"
                                    # )
                                    failure_samples.append({
                                        'type': 'ë§¤ë§¤',
                                        'apt_name': apt_nm,
                                        'jibun': jibun or '',
                                        'build_year': build_year_for_match or '',
                                        'umd_nm': umd_nm or '',
                                        'sgg_cd': sgg_cd,
                                        'ym': ym,
                                        'reason': f'ì´ë¦„ë§¤ì¹­ ì‹¤íŒ¨ (í›„ë³´:{filtered_candidate_count}, {debug_msg})'
                                    })
                                    continue
                                
                                # ê±°ë˜ ë°ì´í„° íŒŒì‹± (XML Elementì—ì„œ ì¶”ì¶œ)
                                deal_amount_elem = item.find("dealAmount")
                                deal_amount = deal_amount_elem.text.replace(",", "").strip() if deal_amount_elem is not None and deal_amount_elem.text else "0"
                                
                                build_year_elem = item.find("buildYear")
                                build_year = build_year_elem.text.strip() if build_year_elem is not None and build_year_elem.text else None
                                
                                deal_year_elem = item.find("dealYear")
                                deal_year = deal_year_elem.text.strip() if deal_year_elem is not None and deal_year_elem.text else None
                                
                                deal_month_elem = item.find("dealMonth")
                                deal_month = deal_month_elem.text.strip() if deal_month_elem is not None and deal_month_elem.text else None
                                
                                deal_day_elem = item.find("dealDay")
                                deal_day = deal_day_elem.text.strip() if deal_day_elem is not None and deal_day_elem.text else None
                                
                                exclu_use_ar_elem = item.find("excluUseAr")
                                exclu_use_ar = exclu_use_ar_elem.text.strip() if exclu_use_ar_elem is not None and exclu_use_ar_elem.text else None
                                
                                floor_elem = item.find("floor")
                                floor = floor_elem.text.strip() if floor_elem is not None and floor_elem.text else None
                                
                                contract_date = None
                                if deal_year and deal_month and deal_day:
                                    try:
                                        contract_date = date(int(deal_year), int(deal_month), int(deal_day))
                                    except:
                                        pass
                                
                                sale_create = SaleCreate(
                                    apt_id=matched_apt.apt_id,
                                    build_year=build_year,
                                    trans_type="ë§¤ë§¤",
                                    trans_price=int(deal_amount) if deal_amount else 0,
                                    exclusive_area=float(exclu_use_ar) if exclu_use_ar else 0.0,
                                    floor=int(floor) if floor else 0,
                                    contract_date=contract_date,
                                    is_canceled=False,
                                    remarks=matched_apt.apt_name
                                )
                                
                                # ì¤‘ë³µ ì²´í¬ ë° ì €ì¥
                                exists_stmt = select(Sale).where(
                                    and_(
                                        Sale.apt_id == sale_create.apt_id,
                                        Sale.contract_date == sale_create.contract_date,
                                        Sale.trans_price == sale_create.trans_price,
                                        Sale.floor == sale_create.floor,
                                        Sale.exclusive_area == sale_create.exclusive_area
                                    )
                                )
                                exists = await local_db.execute(exists_stmt)
                                existing_sale = exists.scalars().first()
                                
                                if existing_sale:
                                    if allow_duplicate:
                                        # ì—…ë°ì´íŠ¸
                                        existing_sale.build_year = build_year
                                        existing_sale.trans_price = sale_create.trans_price
                                        existing_sale.exclusive_area = sale_create.exclusive_area
                                        existing_sale.floor = sale_create.floor
                                        existing_sale.remarks = matched_apt.apt_name
                                        local_db.add(existing_sale)
                                        success_count += 1
                                        total_saved += 1
                                    else:
                                        skip_count += 1
                                    continue
                                
                                db_obj = Sale(**sale_create.model_dump())
                                local_db.add(db_obj)
                                sales_to_save.append(sale_create)
                                
                                # ì•„íŒŒíŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸
                                if matched_apt.is_available != "1":
                                    matched_apt.is_available = "1"
                                    local_db.add(matched_apt)
                                
                                # ë°°ì¹˜ ì»¤ë°‹ (ì„±ëŠ¥ ìµœì í™”)
                                if len(sales_to_save) >= batch_size:
                                    await local_db.commit()
                                    total_saved += len(sales_to_save)
                                    success_count += len(sales_to_save)
                                    sales_to_save = []
                            
                            except Exception as e:
                                error_count += 1
                                # ì˜ˆì™¸ ë°œìƒ ì‹œì—ë„ ì²« ë²ˆì§¸ ì‹¤íŒ¨ ìƒì„¸ ì •ë³´ ì €ì¥ ì‹œë„
                                if first_failure_details is None:
                                    try:
                                        # ì˜ˆì™¸ ë°œìƒí•œ í•­ëª©ì˜ ê¸°ë³¸ ì •ë³´ë¼ë„ ì €ì¥
                                        apt_nm_elem = item.find("aptNm") if 'item' in locals() else None
                                        apt_nm = apt_nm_elem.text.strip() if apt_nm_elem is not None and apt_nm_elem.text else "ì•Œìˆ˜ì—†ìŒ"
                                        first_failure_details = f"ì˜ˆì™¸ë°œìƒ: {str(e)[:100]} | ì•„íŒŒíŠ¸:{apt_nm}"
                                    except:
                                        first_failure_details = f"ì˜ˆì™¸ë°œìƒ: {str(e)[:100]}"
                                continue
                        
                        # ë‚¨ì€ ë°ì´í„° ì»¤ë°‹
                        if sales_to_save or (allow_duplicate and success_count > 0):
                            await local_db.commit()
                            if sales_to_save:
                                total_saved += len(sales_to_save)
                                success_count += len(sales_to_save)
                        
                        # ê°„ê²°í•œ ë¡œê·¸ (í•œ ì¤„) - ë§¤ì¹­ ì‹¤íŒ¨ê°€ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ ì‹¤íŒ¨ ìƒì„¸ ì •ë³´ í¬í•¨
                        if success_count > 0 or skip_count > 0 or error_count > 0:
                            if error_count > 0:
                                # ë§¤ì¹­ ì‹¤íŒ¨ê°€ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ ì‹¤íŒ¨ ìƒì„¸ ì •ë³´ í¬í•¨
                                if first_failure_details:
                                    logger.warning(
                                        f"{region_progress_str} {sgg_cd}/{ym} ({ym_formatted}): "
                                        f"âœ…{success_count} â­ï¸{skip_count} âŒ{error_count} ({apt_name_log}) | "
                                        f"ì²«ì‹¤íŒ¨: {first_failure_details}"
                                    )
                                else:
                                    # first_failure_detailsê°€ ì—†ìœ¼ë©´ (ì˜ˆì™¸ë¡œ ì¸í•œ ì‹¤íŒ¨ ë“±) ê¸°ë³¸ ì •ë³´ ì¶œë ¥
                                    logger.warning(
                                        f"{region_progress_str} {sgg_cd}/{ym} ({ym_formatted}): "
                                        f"âœ…{success_count} â­ï¸{skip_count} âŒ{error_count} ({apt_name_log}) | "
                                        f"âš ï¸ ìƒì„¸ì •ë³´ ì—†ìŒ (ì˜ˆì™¸ ë°œìƒ ê°€ëŠ¥)"
                                    )
                            else:
                                logger.info(
                                    f"{region_progress_str} {sgg_cd}/{ym} ({ym_formatted}): "
                                    f"âœ…{success_count} â­ï¸{skip_count} âŒ{error_count} "
                                    f"({apt_name_log})"
                                )
                        
                        skipped += skip_count
                        
                        # max_items ì œí•œ í™•ì¸
                        if max_items and total_saved >= max_items:
                            return
                        
                    except (OperationalError, TimeoutError, TooManyConnectionsError, ConnectionDoesNotExistError) as e:
                        # DB ì—°ê²° ê´€ë ¨ ì—ëŸ¬ ì²˜ë¦¬
                        error_msg = f"{sgg_cd}/{ym} ({ym_formatted}): DB ì—°ê²° ì˜¤ë¥˜ - {str(e)}"
                        errors.append(error_msg)
                        logger.error(f"âŒ {error_msg}")
                        try:
                            await local_db.rollback()
                        except:
                            pass
                        # ì—°ê²° í’€ ë¶€ì¡± ì‹œ ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„í•˜ì§€ ì•Šê³  ê±´ë„ˆëœ€
                        await asyncio.sleep(0.1)
                    except Exception as e:
                        error_msg = f"{sgg_cd}/{ym} ({ym_formatted}): {str(e)}"
                        errors.append(error_msg)
                        logger.error(f"âŒ {error_msg}")
                        try:
                            await local_db.rollback()
                        except:
                            pass
        
        # ë³‘ë ¬ ì‹¤í–‰
        total_regions = len(target_sgg_codes)
        
        # ì›”ë³„ ì§„í–‰ ìƒí™© ì¶”ì ì„ ìœ„í•œ ì¹´ìš´í„°
        region_progress = {"completed": 0, "total": total_regions}
        progress_lock = asyncio.Lock()
        
        async def process_sale_region_with_progress(ym: str, sgg_cd: str, region_idx: int):
            """ì§„í–‰ ìƒí™© ì¶”ì  ë˜í¼"""
            await process_sale_region(ym, sgg_cd, region_idx, total_regions)
            async with progress_lock:
                region_progress["completed"] += 1
        
        try:
            total_months = len(target_months)
            for month_idx, ym in enumerate(target_months, 1):
                if max_items and total_saved >= max_items:
                    break
                
                ym_display = format_ym(ym)
                logger.info(f"ğŸ“† [{month_idx}/{total_months}] {ym_display} ì‹œì‘: {total_regions}ê°œ ì§€ì—­ ìˆœíšŒ")
                
                # ì§„í–‰ ìƒí™© ì´ˆê¸°í™”
                region_progress["completed"] = 0
                
                tasks = [
                    process_sale_region_with_progress(ym, sgg_cd, idx) 
                    for idx, sgg_cd in enumerate(target_sgg_codes, 1)
                ]
                await asyncio.gather(*tasks, return_exceptions=True)
                
                logger.info(f"âœ… [{month_idx}/{total_months}] {ym_display} ì™„ë£Œ: {region_progress['completed']}/{region_progress['total']}ê°œ ì§€ì—­ ì²˜ë¦¬ë¨")
                
                if max_items and total_saved >= max_items:
                    break
        finally:
            # HTTP í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬
            await http_client.aclose()
        
        # ì‹¤íŒ¨ ìƒ˜í”Œ CSV íŒŒì¼ë¡œ ì €ì¥
        if failure_samples:
            try:
                csv_path = Path("db_backup/fail.csv")
                csv_path.parent.mkdir(parents=True, exist_ok=True)
                
                # íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ append, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
                file_exists = csv_path.exists()
                with open(csv_path, 'a', newline='', encoding='utf-8') as f:
                    writer = csv.DictWriter(f, fieldnames=['type', 'apt_name', 'jibun', 'build_year', 'umd_nm', 'sgg_cd', 'ym', 'reason'])
                    if not file_exists:
                        writer.writeheader()
                    writer.writerows(failure_samples)
                logger.info(f"ğŸ“Š ì‹¤íŒ¨ ìƒ˜í”Œ {len(failure_samples)}ê±´ ì €ì¥: {csv_path}")
            except Exception as e:
                logger.warning(f"âš ï¸ ì‹¤íŒ¨ ìƒ˜í”Œ ì €ì¥ ì‹¤íŒ¨: {e}")

        logger.info(f"âœ… ë§¤ë§¤ ìˆ˜ì§‘ ì™„ë£Œ: ì €ì¥ {total_saved}ê±´, ê±´ë„ˆëœ€ {skipped}ê±´, ì˜¤ë¥˜ {len(errors)}ê±´")
        
        return SalesCollectionResponse(
            success=True,
            total_fetched=total_fetched,
            total_saved=total_saved,
            skipped=skipped,
            errors=errors,
            message=f"ìˆ˜ì§‘ ì™„ë£Œ: {total_saved}ê±´ ì €ì¥"
        )

    async def collect_rent_data(
        self,
        db: AsyncSession,
        start_ym: str,
        end_ym: str,
        max_items: Optional[int] = None,
        allow_duplicate: bool = False
    ) -> RentCollectionResponse:
        """
        ì•„íŒŒíŠ¸ ì „ì›”ì„¸ ì‹¤ê±°ë˜ê°€ ë°ì´í„° ìˆ˜ì§‘ (ë§¤ë§¤ì™€ ë™ì¼í•œ ë°©ì‹)
        
        Args:
            start_ym: ì‹œì‘ ì—°ì›” (YYYYMM)
            end_ym: ì¢…ë£Œ ì—°ì›” (YYYYMM)
            max_items: ìµœëŒ€ ìˆ˜ì§‘ ê°œìˆ˜ ì œí•œ (ê¸°ë³¸ê°’: None, ì œí•œ ì—†ìŒ)
            allow_duplicate: ì¤‘ë³µ ì €ì¥ í—ˆìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: False, False=ê±´ë„ˆë›°ê¸°, True=ì—…ë°ì´íŠ¸)
        """
        total_fetched = 0
        total_saved = 0
        skipped = 0
        errors = []
        failure_samples = []  # ì‹¤íŒ¨ ìƒ˜í”Œ ìˆ˜ì§‘
        
        logger.info(f"ğŸ  ì „ì›”ì„¸ ìˆ˜ì§‘ ì‹œì‘: {start_ym} ~ {end_ym}")
        
        # 1. ê¸°ê°„ ìƒì„±
        def get_months(start, end):
            try:
                start_date = datetime.strptime(start, "%Y%m")
                end_date = datetime.strptime(end, "%Y%m")
            except ValueError:
                raise ValueError("ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. YYYYMM í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
            
            months = []
            curr = start_date
            while curr <= end_date:
                months.append(curr.strftime("%Y%m"))
                if curr.month == 12:
                    curr = curr.replace(year=curr.year + 1, month=1)
                else:
                    curr = curr.replace(month=curr.month + 1)
            return months
        
        try:
            target_months = get_months(start_ym, end_ym)
        except ValueError as e:
            return RentCollectionResponse(
                success=False,
                total_fetched=0,
                total_saved=0,
                skipped=0,
                errors=[str(e)],
                message=f"ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜: {str(e)}",
                lawd_cd=None,
                deal_ymd=None
            )
        
        # 2. ì§€ì—­ ì½”ë“œ ì¶”ì¶œ
        try:
            stmt = text("SELECT DISTINCT SUBSTR(region_code, 1, 5) FROM states WHERE length(region_code) >= 5")
            result = await db.execute(stmt)
            target_sgg_codes = [row[0] for row in result.fetchall() if row[0] and len(row[0]) == 5]
            logger.info(f"ğŸ“ {len(target_sgg_codes)}ê°œ ì§€ì—­ ì½”ë“œ ì¶”ì¶œ")
        except Exception as e:
            logger.error(f"âŒ ì§€ì—­ ì½”ë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return RentCollectionResponse(
                success=False,
                total_fetched=0,
                total_saved=0,
                skipped=0,
                errors=[f"DB ì˜¤ë¥˜: {e}"],
                message=f"DB ì˜¤ë¥˜: {e}",
                lawd_cd=None,
                deal_ymd=None
            )
        
        # 2.5. ì§€ì—­ë³„ ì•„íŒŒíŠ¸/ì§€ì—­ ì •ë³´ ì‚¬ì „ ë¡œë“œ (ì„±ëŠ¥ ìµœì í™”)
        apt_cache: Dict[str, List[Apartment]] = {}
        region_cache: Dict[str, Dict[int, State]] = {}
        detail_cache: Dict[str, Dict[int, ApartDetail]] = {}
        
        async def load_apts_and_regions(sgg_cd: str) -> tuple[List[Apartment], Dict[int, State], Dict[int, ApartDetail]]:
            """ì§€ì—­ë³„ ì•„íŒŒíŠ¸, ì§€ì—­ ì •ë³´, ì•„íŒŒíŠ¸ ìƒì„¸ ì •ë³´ ë¡œë“œ (ìºì‹±)"""
            if sgg_cd in apt_cache:
                return apt_cache[sgg_cd], region_cache[sgg_cd], detail_cache.get(sgg_cd, {})
            
            async with AsyncSessionLocal() as cache_db:
                # ì•„íŒŒíŠ¸ ë¡œë“œ
                stmt = select(Apartment).options(joinedload(Apartment.region)).join(State).where(
                    State.region_code.like(f"{sgg_cd}%")
                )
                apt_result = await cache_db.execute(stmt)
                local_apts = apt_result.scalars().all()
                
                # ë™ ì •ë³´ ìºì‹œ
                region_stmt = select(State).where(State.region_code.like(f"{sgg_cd}%"))
                region_result = await cache_db.execute(region_stmt)
                all_regions = {r.region_id: r for r in region_result.scalars().all()}
                
                # ì•„íŒŒíŠ¸ ìƒì„¸ ì •ë³´ ë¡œë“œ (ì§€ë²ˆ í¬í•¨)
                apt_ids = [apt.apt_id for apt in local_apts]
                if apt_ids:
                    detail_stmt = select(ApartDetail).where(ApartDetail.apt_id.in_(apt_ids))
                    detail_result = await cache_db.execute(detail_stmt)
                    apt_details = {d.apt_id: d for d in detail_result.scalars().all()}
                else:
                    apt_details = {}
                
                apt_cache[sgg_cd] = local_apts
                region_cache[sgg_cd] = all_regions
                detail_cache[sgg_cd] = apt_details
                
                return local_apts, all_regions, apt_details
        
        # 3. ë³‘ë ¬ ì²˜ë¦¬ (ì—°ê²° í’€ í¬ê¸°ì— ë§ì¶° 10ê°œë¡œ ì œí•œ, DB ì—°ê²° í’€ ê³ ë ¤)
        # DB ì—°ê²° í’€: pool_size=20, max_overflow=30 (ìµœëŒ€ 50ê°œ)
        # ì„¸ë§ˆí¬ì–´ë¥¼ 10ê°œë¡œ ì œí•œí•˜ì—¬ ì—°ê²° í’€ ì—¬ìœ  í™•ë³´
        semaphore = asyncio.Semaphore(10)
        
        def format_ym(ym: str) -> str:
            """ì—°ì›” í˜•ì‹ ë³€í™˜: YYYYMM -> YYYYë…„ MMì›”"""
            try:
                y = int(ym[:4])
                m = int(ym[4:])
                return f"{y}ë…„ {m}ì›”"
            except:
                return ym
        
        # ê³µìœ  HTTP í´ë¼ì´ì–¸íŠ¸ (ì—°ê²° ì¬ì‚¬ìš©ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ)
        http_client = httpx.AsyncClient(
            timeout=httpx.Timeout(60.0, connect=10.0),
            limits=httpx.Limits(max_connections=30, max_keepalive_connections=20)
        )
        
        async def process_rent_region(ym: str, sgg_cd: str, region_idx: int = 0, total_regions: int = 0):
            """ì „ì›”ì„¸ ë°ì´í„° ìˆ˜ì§‘ ì‘ì—…"""
            ym_formatted = format_ym(ym)
            region_progress_str = f"[{region_idx}/{total_regions}]" if total_regions > 0 else ""
            
            # ì§€ì—­ ìˆœíšŒ ì‹œì‘ ë¡œê·¸
            if total_regions > 0:
                logger.info(f"   ğŸ”„ {region_progress_str} {sgg_cd}/{ym} ({ym_formatted}) ì²˜ë¦¬ ì‹œì‘...")
            
            async with semaphore:
                async with AsyncSessionLocal() as local_db:
                    nonlocal total_fetched, total_saved, skipped, errors
                    
                    # max_items ì œí•œ í™•ì¸
                    if max_items and total_saved >= max_items:
                        return
                    
                    try:
                        # ê¸°ì¡´ ë°ì´í„° í™•ì¸
                        y = int(ym[:4])
                        m = int(ym[4:])
                        start_date = date(y, m, 1)
                        last_day = calendar.monthrange(y, m)[1]
                        end_date = date(y, m, last_day)
                        
                        check_stmt = select(func.count(Rent.trans_id)).join(Apartment).join(State).where(
                            and_(
                                State.region_code.like(f"{sgg_cd}%"),
                                Rent.deal_date >= start_date,
                                Rent.deal_date <= end_date
                            )
                        )
                        count_result = await local_db.execute(check_stmt)
                        existing_count = count_result.scalar() or 0
                        
                        if existing_count > 0 and not allow_duplicate:
                            skipped += existing_count
                            logger.info(f"â­ï¸ {sgg_cd}/{ym} ({ym_formatted}): ê±´ë„ˆëœ€ ({existing_count}ê±´ ì¡´ì¬)")
                            return
                        
                        # API í˜¸ì¶œ (XML) - ê³µìœ  í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©
                        params = {
                            "serviceKey": self.api_key,
                            "LAWD_CD": sgg_cd,
                            "DEAL_YMD": ym,
                            "numOfRows": 4000
                        }
                        
                        response = await http_client.get(MOLIT_RENT_API_URL, params=params)
                        response.raise_for_status()
                        xml_content = response.text
                        
                        # XML íŒŒì‹±
                        try:
                            root = ET.fromstring(xml_content)
                        except ET.ParseError as e:
                            errors.append(f"{sgg_cd}/{ym} ({ym_formatted}): XML íŒŒì‹± ì‹¤íŒ¨ - {str(e)}")
                            logger.error(f"âŒ {sgg_cd}/{ym} ({ym_formatted}): XML íŒŒì‹± ì‹¤íŒ¨ - {str(e)}")
                            return
                        
                        # ê²°ê³¼ ì½”ë“œ í™•ì¸
                        result_code_elem = root.find(".//resultCode")
                        result_msg_elem = root.find(".//resultMsg")
                        result_code = result_code_elem.text if result_code_elem is not None else ""
                        result_msg = result_msg_elem.text if result_msg_elem is not None else ""
                        
                        if result_code != "000":
                            errors.append(f"{sgg_cd}/{ym} ({ym_formatted}): {result_msg}")
                            logger.error(f"âŒ {sgg_cd}/{ym} ({ym_formatted}): {result_msg}")
                            return
                        
                        # items ì¶”ì¶œ
                        items = root.findall(".//item")
                        
                        if not items:
                            return
                        
                        total_fetched += len(items)
                        
                        # ì•„íŒŒíŠ¸ ë° ì§€ì—­ ì •ë³´ ë¡œë“œ (ìºì‹± í™œìš©)
                        local_apts, all_regions, apt_details = await load_apts_and_regions(sgg_cd)
                        
                        if not local_apts:
                            logger.warning(f"âš ï¸ {sgg_cd}/{ym} ({ym_formatted}): í•´ë‹¹ ì§€ì—­ì— ì•„íŒŒíŠ¸ê°€ ì—†ìŒ (ì‹œêµ°êµ¬ì½”ë“œ: {sgg_cd})")
                            return
                        
                        # apt_detailsê°€ ë¹„ì–´ìˆì„ ë•Œ ê²½ê³ 
                        if not apt_details:
                            logger.debug(f"   âš ï¸ {sgg_cd}/{ym}: ì•„íŒŒíŠ¸ ìƒì„¸ì •ë³´ê°€ ì—†ìŒ (ì§€ë²ˆ ë§¤ì¹­ ë¶ˆê°€, {len(local_apts)}ê°œ ì•„íŒŒíŠ¸)")
                        else:
                            logger.debug(f"   â„¹ï¸ {sgg_cd}/{ym}: ì•„íŒŒíŠ¸ {len(local_apts)}ê°œ, ìƒì„¸ì •ë³´ {len(apt_details)}ê°œ ë¡œë“œë¨")
                        
                        rents_to_save = []
                        success_count = 0
                        skip_count = 0
                        error_count = 0
                        jeonse_count = 0
                        wolse_count = 0
                        apt_name_log = ""
                        first_failure_details = None  # ì²« ë²ˆì§¸ ì‹¤íŒ¨ ìƒì„¸ ì •ë³´ ì €ì¥
                        normalized_cache: Dict[str, Any] = {}  # ì •ê·œí™” ê²°ê³¼ ìºì‹±
                        batch_size = 100  # ë°°ì¹˜ ì»¤ë°‹ í¬ê¸°
                        
                        for item in items:
                            # max_items ì œí•œ í™•ì¸
                            if max_items and total_saved >= max_items:
                                break
                            
                            try:
                                # XML Elementì—ì„œ í•„ë“œ ì¶”ì¶œ
                                apt_nm_elem = item.find("aptNm")
                                apt_nm = apt_nm_elem.text.strip() if apt_nm_elem is not None and apt_nm_elem.text else ""
                                
                                umd_nm_elem = item.find("umdNm")
                                umd_nm = umd_nm_elem.text.strip() if umd_nm_elem is not None and umd_nm_elem.text else ""
                                
                                sgg_cd_elem = item.find("sggCd")
                                sgg_cd_item = sgg_cd_elem.text.strip() if sgg_cd_elem is not None and sgg_cd_elem.text else sgg_cd
                                
                                # ì§€ë²ˆ ì¶”ì¶œ (ë§¤ì¹­ì— í™œìš©)
                                jibun_elem = item.find("jibun")
                                jibun = jibun_elem.text.strip() if jibun_elem is not None and jibun_elem.text else ""
                                
                                # ê±´ì¶•ë…„ë„ ì¶”ì¶œ (ë§¤ì¹­ì— í™œìš©)
                                build_year_elem = item.find("buildYear")
                                build_year_for_match = build_year_elem.text.strip() if build_year_elem is not None and build_year_elem.text else ""
                                
                                if not apt_nm:
                                    continue
                                
                                if not apt_name_log:
                                    apt_name_log = apt_nm
                                
                                # ë™ ê¸°ë°˜ í•„í„°ë§ (ê°œì„ ëœ ë²„ì „)
                                candidates = local_apts
                                sgg_code_matched = True
                                dong_matched = False
                                initial_candidate_count = len(local_apts)
                                
                                # ì‹œêµ°êµ¬ ì½”ë“œ ê¸°ë°˜ í•„í„°ë§ (ê°œì„ : 5ìë¦¬ â†’ 10ìë¦¬ ë³€í™˜)
                                if sgg_cd_item and str(sgg_cd_item).strip():
                                    sgg_cd_item_str = str(sgg_cd_item).strip()
                                    sgg_cd_str = str(sgg_cd).strip()
                                    
                                    # DB í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (5ìë¦¬ â†’ 10ìë¦¬)
                                    sgg_cd_db = self._convert_sgg_code_to_db_format(sgg_cd_item_str)
                                    
                                    if sgg_cd_db:
                                        # ì •í™•í•œ ë§¤ì¹­ ì‹œë„
                                        filtered = [
                                            apt for apt in local_apts
                                            if apt.region_id in all_regions
                                            and all_regions[apt.region_id].region_code == sgg_cd_db
                                        ]
                                        # ì •í™•í•œ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ì‹œì‘ ë¶€ë¶„ ë§¤ì¹­
                                        if not filtered:
                                            filtered = [
                                                apt for apt in local_apts
                                                if apt.region_id in all_regions
                                                and all_regions[apt.region_id].region_code.startswith(sgg_cd_item_str)
                                            ]
                                        if filtered:
                                            candidates = filtered
                                            sgg_code_matched = True
                                
                                # ë™ ê¸°ë°˜ í•„í„°ë§ (ê°œì„ : ë” ë„ë„í•œ ë§¤ì¹­)
                                if umd_nm and candidates:
                                    matching_region_ids = self._find_matching_regions(umd_nm, all_regions)
                                    
                                    if matching_region_ids:
                                        filtered = [
                                            apt for apt in candidates
                                            if apt.region_id in matching_region_ids
                                        ]
                                        if filtered:
                                            candidates = filtered
                                            dong_matched = True
                                    # í•„í„°ë§ ì‹¤íŒ¨í•´ë„ í›„ë³´ ìœ ì§€ (ë” ë„ë„í•˜ê²Œ)
                                
                                # í›„ë³´ê°€ ì—†ìœ¼ë©´ ì›ë˜ í›„ë³´ë¡œ ë³µì›
                                if not candidates:
                                    candidates = local_apts
                                    sgg_code_matched = True
                                    dong_matched = False
                                
                                filtered_candidate_count = len(candidates)
                                
                                # ì•„íŒŒíŠ¸ ë§¤ì¹­ (ì •ê·œí™” ìºì‹œ, ì§€ë²ˆ, ê±´ì¶•ë…„ë„, ìƒì„¸ì •ë³´ ì „ë‹¬)
                                matched_apt, match_debug_info = self._match_apartment_with_debug(
                                    apt_nm, candidates, sgg_cd, umd_nm, 
                                    jibun, build_year_for_match, apt_details, normalized_cache
                                )
                                
                                # í•„í„°ë§ëœ í›„ë³´ì—ì„œ ì‹¤íŒ¨ ì‹œ ì „ì²´ í›„ë³´ë¡œ ì¬ì‹œë„
                                if not matched_apt and len(candidates) < len(local_apts):
                                    logger.debug(f"   ğŸ”„ [ì „ì›”ì„¸] í•„í„°ë§ í›„ë³´({filtered_candidate_count}ê°œ)ì—ì„œ ì‹¤íŒ¨ â†’ ì „ì²´ í›„ë³´({initial_candidate_count}ê°œ)ë¡œ ì¬ì‹œë„: {apt_nm}")
                                    matched_apt, match_debug_info = self._match_apartment_with_debug(
                                        apt_nm, local_apts, sgg_cd, umd_nm, 
                                        jibun, build_year_for_match, apt_details, normalized_cache
                                    )
                                
                                if not matched_apt:
                                    error_count += 1
                                    # ìƒì„¸ ì‹¤íŒ¨ ë¡œê¹… (WARNING ë ˆë²¨ë¡œ ë³€ê²½í•˜ì—¬ í•­ìƒ ì¶œë ¥)
                                    debug_msg = ''
                                    if match_debug_info:
                                        debug_msg = match_debug_info.get('debug_msg', '')
                                    else:
                                        debug_msg = 'ë””ë²„ê·¸ì •ë³´ ì—†ìŒ'
                                    
                                    failure_detail = (
                                        f"ì•„íŒŒíŠ¸:{apt_nm} | ì§€ë²ˆ:{jibun or 'ì—†ìŒ'} | ê±´ì¶•ë…„ë„:{build_year_for_match or 'ì—†ìŒ'} | "
                                        f"ë™:{umd_nm or 'ì—†ìŒ'} | ì‹œêµ°êµ¬ì½”ë“œ:{sgg_cd_item or sgg_cd} | "
                                        f"í›„ë³´ìˆ˜:{filtered_candidate_count}(ì „ì²´:{initial_candidate_count}) | "
                                        f"ì‹œêµ°êµ¬ë§¤ì¹­:{sgg_code_matched} ë™ë§¤ì¹­:{dong_matched} | "
                                        f"ìƒì„¸ì •ë³´:{len(apt_details) if apt_details else 0}ê°œ | {debug_msg}"
                                    )
                                    
                                    # ì²« ë²ˆì§¸ ì‹¤íŒ¨ ìƒì„¸ ì •ë³´ ì €ì¥ (ë°˜ë“œì‹œ ì„¤ì •)
                                    if first_failure_details is None:
                                        first_failure_details = failure_detail
                                    
                                    # ìƒì„¸ ë¡œê·¸ ì¶œë ¥ (ì£¼ì„ ì²˜ë¦¬ - ì§€ì—­ ìˆœíšŒ í™•ì¸ì„ ìœ„í•´ ë¹„í™œì„±í™”)
                                    # logger.warning(
                                    #     f"   âŒ [ì „ì›”ì„¸] ë§¤ì¹­ ì‹¤íŒ¨: {failure_detail}"
                                    # )
                                    failure_samples.append({
                                        'type': 'ì „ì›”ì„¸',
                                        'apt_name': apt_nm,
                                        'jibun': jibun or '',
                                        'build_year': build_year_for_match or '',
                                        'umd_nm': umd_nm or '',
                                        'sgg_cd': sgg_cd,
                                        'ym': ym,
                                        'reason': f'ì´ë¦„ë§¤ì¹­ ì‹¤íŒ¨ (í›„ë³´:{filtered_candidate_count}, {debug_msg})'
                                    })
                                    continue
                                
                                # ê±°ë˜ ë°ì´í„° íŒŒì‹± (XML Elementì—ì„œ ì¶”ì¶œ) - ì¸ë¼ì¸ìœ¼ë¡œ ìµœì í™”
                                try:
                                    # ê±°ë˜ì¼ íŒŒì‹±
                                    deal_year_elem = item.find("dealYear")
                                    deal_month_elem = item.find("dealMonth")
                                    deal_day_elem = item.find("dealDay")
                                    
                                    deal_year = deal_year_elem.text.strip() if deal_year_elem is not None and deal_year_elem.text else None
                                    deal_month = deal_month_elem.text.strip() if deal_month_elem is not None and deal_month_elem.text else None
                                    deal_day = deal_day_elem.text.strip() if deal_day_elem is not None and deal_day_elem.text else None
                                    
                                    if not deal_year or not deal_month or not deal_day:
                                        error_count += 1
                                        continue
                                    
                                    deal_date_obj = date(int(deal_year), int(deal_month), int(deal_day))
                                    
                                    # ì „ìš©ë©´ì  íŒŒì‹±
                                    exclu_use_ar_elem = item.find("excluUseAr")
                                    exclu_use_ar = exclu_use_ar_elem.text.strip() if exclu_use_ar_elem is not None and exclu_use_ar_elem.text else None
                                    if not exclu_use_ar:
                                        error_count += 1
                                        continue
                                    exclusive_area = float(exclu_use_ar)
                                    
                                    # ì¸µ íŒŒì‹±
                                    floor_elem = item.find("floor")
                                    floor_str = floor_elem.text.strip() if floor_elem is not None and floor_elem.text else None
                                    if not floor_str:
                                        error_count += 1
                                        continue
                                    floor = int(floor_str)
                                    
                                    # ë³´ì¦ê¸ˆ íŒŒì‹±
                                    deposit_elem = item.find("deposit")
                                    deposit_str = deposit_elem.text.strip() if deposit_elem is not None and deposit_elem.text else None
                                    deposit_price = None
                                    if deposit_str:
                                        try:
                                            deposit_price = int(deposit_str.replace(",", ""))
                                        except:
                                            pass
                                    
                                    # ì›”ì„¸ íŒŒì‹±
                                    monthly_rent_elem = item.find("monthlyRent")
                                    monthly_rent_str = monthly_rent_elem.text.strip() if monthly_rent_elem is not None and monthly_rent_elem.text else None
                                    monthly_rent = None
                                    if monthly_rent_str:
                                        try:
                                            monthly_rent = int(monthly_rent_str.replace(",", ""))
                                            if monthly_rent == 0:
                                                monthly_rent = None  # ì „ì„¸ì¸ ê²½ìš°
                                        except:
                                            pass
                                    
                                    # ì „ì„¸/ì›”ì„¸ êµ¬ë¶„ ì¹´ìš´íŠ¸
                                    if monthly_rent and monthly_rent > 0:
                                        wolse_count += 1
                                    else:
                                        jeonse_count += 1
                                    
                                    # ì¤‘ë³µ ì²´í¬ (ì¸ë¼ì¸ìœ¼ë¡œ ìµœì í™” - ë§¤ë§¤ì™€ ë™ì¼í•œ ë°©ì‹)
                                    exists_stmt = select(Rent).where(
                                        and_(
                                            Rent.apt_id == matched_apt.apt_id,
                                            Rent.deal_date == deal_date_obj,
                                            Rent.floor == floor,
                                            Rent.exclusive_area == exclusive_area,
                                            Rent.deposit_price == deposit_price,
                                            Rent.monthly_rent == monthly_rent
                                        )
                                    )
                                    exists = await local_db.execute(exists_stmt)
                                    existing_rent = exists.scalars().first()
                                    
                                    if existing_rent:
                                        if allow_duplicate:
                                            # ì—…ë°ì´íŠ¸
                                            build_year_elem = item.find("buildYear")
                                            build_year = build_year_elem.text.strip() if build_year_elem is not None and build_year_elem.text else None
                                            contract_type_elem = item.find("contractType")
                                            contract_type_str = contract_type_elem.text.strip() if contract_type_elem is not None and contract_type_elem.text else None
                                            contract_type = contract_type_str == "ê°±ì‹ " if contract_type_str else None
                                            
                                            existing_rent.build_year = build_year
                                            existing_rent.deposit_price = deposit_price
                                            existing_rent.monthly_rent = monthly_rent
                                            existing_rent.contract_type = contract_type
                                            existing_rent.remarks = apt_nm
                                            local_db.add(existing_rent)
                                            success_count += 1
                                            total_saved += 1
                                        else:
                                            skip_count += 1
                                        continue
                                    
                                    # ìƒˆë¡œ ìƒì„±
                                    build_year_elem = item.find("buildYear")
                                    build_year = build_year_elem.text.strip() if build_year_elem is not None and build_year_elem.text else None
                                    contract_type_elem = item.find("contractType")
                                    contract_type_str = contract_type_elem.text.strip() if contract_type_elem is not None and contract_type_elem.text else None
                                    contract_type = contract_type_str == "ê°±ì‹ " if contract_type_str else None
                                    
                                    apt_seq_elem = item.find("aptSeq")
                                    apt_seq = apt_seq_elem.text.strip() if apt_seq_elem is not None and apt_seq_elem.text else None
                                    if apt_seq and len(apt_seq) > 10:
                                        apt_seq = apt_seq[:10]
                                    
                                    rent_create = RentCreate(
                                        apt_id=matched_apt.apt_id,
                                        build_year=build_year,
                                        contract_type=contract_type,
                                        deposit_price=deposit_price,
                                        monthly_rent=monthly_rent,
                                        exclusive_area=exclusive_area,
                                        floor=floor,
                                        apt_seq=apt_seq,
                                        deal_date=deal_date_obj,
                                        contract_date=None,
                                        remarks=apt_nm
                                    )
                                    
                                    db_obj = Rent(**rent_create.model_dump())
                                    local_db.add(db_obj)
                                    rents_to_save.append(rent_create)
                                    success_count += 1
                                    total_saved += 1
                                    
                                    # ë°°ì¹˜ ì»¤ë°‹ (ì„±ëŠ¥ ìµœì í™”)
                                    if len(rents_to_save) >= batch_size:
                                        await local_db.commit()
                                        rents_to_save = []
                                        
                                except Exception as e:
                                    error_count += 1
                                    continue
                                
                                # ì•„íŒŒíŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸
                                if matched_apt.is_available != "1":
                                    matched_apt.is_available = "1"
                                    local_db.add(matched_apt)
                                
                            except Exception as e:
                                error_count += 1
                                continue
                        
                        # ë‚¨ì€ ë°ì´í„° ì»¤ë°‹
                        if rents_to_save:
                            await local_db.commit()
                        
                        # ê°„ê²°í•œ ë¡œê·¸ (í•œ ì¤„) - ë§¤ì¹­ ì‹¤íŒ¨ê°€ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ ì‹¤íŒ¨ ìƒì„¸ ì •ë³´ í¬í•¨
                        if success_count > 0 or skip_count > 0 or error_count > 0:
                            if error_count > 0:
                                # ë§¤ì¹­ ì‹¤íŒ¨ê°€ ìˆìœ¼ë©´ ì²« ë²ˆì§¸ ì‹¤íŒ¨ ìƒì„¸ ì •ë³´ í¬í•¨
                                if first_failure_details:
                                    logger.warning(
                                        f"{region_progress_str} {sgg_cd}/{ym} ({ym_formatted}): "
                                        f"âœ…{success_count} â­ï¸{skip_count} âŒ{error_count} "
                                        f"(ì „ì„¸:{jeonse_count} ì›”ì„¸:{wolse_count}) ({apt_name_log}) | "
                                        f"ì²«ì‹¤íŒ¨: {first_failure_details}"
                                    )
                                else:
                                    # first_failure_detailsê°€ ì—†ìœ¼ë©´ (ì˜ˆì™¸ë¡œ ì¸í•œ ì‹¤íŒ¨ ë“±) ê¸°ë³¸ ì •ë³´ ì¶œë ¥
                                    logger.warning(
                                        f"{region_progress_str} {sgg_cd}/{ym} ({ym_formatted}): "
                                        f"âœ…{success_count} â­ï¸{skip_count} âŒ{error_count} "
                                        f"(ì „ì„¸:{jeonse_count} ì›”ì„¸:{wolse_count}) ({apt_name_log}) | "
                                        f"âš ï¸ ìƒì„¸ì •ë³´ ì—†ìŒ (ì˜ˆì™¸ ë°œìƒ ê°€ëŠ¥)"
                                    )
                            else:
                                logger.info(
                                    f"{region_progress_str} {sgg_cd}/{ym} ({ym_formatted}): "
                                    f"âœ…{success_count} â­ï¸{skip_count} âŒ{error_count} "
                                    f"(ì „ì„¸:{jeonse_count} ì›”ì„¸:{wolse_count}) ({apt_name_log})"
                                )
                        
                        skipped += skip_count
                        
                        # max_items ì œí•œ í™•ì¸
                        if max_items and total_saved >= max_items:
                            return
                        
                    except (OperationalError, TimeoutError, TooManyConnectionsError, ConnectionDoesNotExistError) as e:
                        # DB ì—°ê²° ê´€ë ¨ ì—ëŸ¬ ì²˜ë¦¬
                        error_msg = f"{sgg_cd}/{ym} ({ym_formatted}): DB ì—°ê²° ì˜¤ë¥˜ - {str(e)}"
                        errors.append(error_msg)
                        logger.error(f"âŒ {error_msg}")
                        try:
                            await local_db.rollback()
                        except:
                            pass
                        # ì—°ê²° í’€ ë¶€ì¡± ì‹œ ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„í•˜ì§€ ì•Šê³  ê±´ë„ˆëœ€
                        await asyncio.sleep(0.1)
                    except Exception as e:
                        error_msg = f"{sgg_cd}/{ym} ({ym_formatted}): {str(e)}"
                        errors.append(error_msg)
                        logger.error(f"âŒ {error_msg}")
                        try:
                            await local_db.rollback()
                        except:
                            pass
        
        # ë³‘ë ¬ ì‹¤í–‰
        total_regions = len(target_sgg_codes)
        
        # ì›”ë³„ ì§„í–‰ ìƒí™© ì¶”ì ì„ ìœ„í•œ ì¹´ìš´í„°
        region_progress = {"completed": 0, "total": total_regions}
        progress_lock = asyncio.Lock()
        
        async def process_rent_region_with_progress(ym: str, sgg_cd: str, region_idx: int):
            """ì§„í–‰ ìƒí™© ì¶”ì  ë˜í¼"""
            await process_rent_region(ym, sgg_cd, region_idx, total_regions)
            async with progress_lock:
                region_progress["completed"] += 1
        
        try:
            total_months = len(target_months)
            for month_idx, ym in enumerate(target_months, 1):
                if max_items and total_saved >= max_items:
                    break
                
                ym_display = format_ym(ym)
                logger.info(f"ğŸ“† [{month_idx}/{total_months}] {ym_display} ì‹œì‘: {total_regions}ê°œ ì§€ì—­ ìˆœíšŒ")
                
                # ì§„í–‰ ìƒí™© ì´ˆê¸°í™”
                region_progress["completed"] = 0
                
                tasks = [
                    process_rent_region_with_progress(ym, sgg_cd, idx) 
                    for idx, sgg_cd in enumerate(target_sgg_codes, 1)
                ]
                await asyncio.gather(*tasks, return_exceptions=True)
                
                logger.info(f"âœ… [{month_idx}/{total_months}] {ym_display} ì™„ë£Œ: {region_progress['completed']}/{region_progress['total']}ê°œ ì§€ì—­ ì²˜ë¦¬ë¨")
                
                if max_items and total_saved >= max_items:
                    break
        finally:
            # HTTP í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬
            await http_client.aclose()
        
        # ì‹¤íŒ¨ ìƒ˜í”Œ CSV íŒŒì¼ë¡œ ì €ì¥
        if failure_samples:
            try:
                csv_path = Path("db_backup/fail.csv")
                csv_path.parent.mkdir(parents=True, exist_ok=True)
                
                # íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ append, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
                file_exists = csv_path.exists()
                with open(csv_path, 'a', newline='', encoding='utf-8') as f:
                    writer = csv.DictWriter(f, fieldnames=['type', 'apt_name', 'jibun', 'build_year', 'umd_nm', 'sgg_cd', 'ym', 'reason'])
                    if not file_exists:
                        writer.writeheader()
                    writer.writerows(failure_samples)
                logger.info(f"ğŸ“Š ì‹¤íŒ¨ ìƒ˜í”Œ {len(failure_samples)}ê±´ ì €ì¥: {csv_path}")
            except Exception as e:
                logger.warning(f"âš ï¸ ì‹¤íŒ¨ ìƒ˜í”Œ ì €ì¥ ì‹¤íŒ¨: {e}")

        logger.info(f"âœ… ì „ì›”ì„¸ ìˆ˜ì§‘ ì™„ë£Œ: ì €ì¥ {total_saved}ê±´, ê±´ë„ˆëœ€ {skipped}ê±´, ì˜¤ë¥˜ {len(errors)}ê±´")
        
        return RentCollectionResponse(
            success=True,
            total_fetched=total_fetched,
            total_saved=total_saved,
            skipped=skipped,
            errors=errors[:100],
            message=f"ìˆ˜ì§‘ ì™„ë£Œ: {total_saved}ê±´ ì €ì¥, {skipped}ê±´ ê±´ë„ˆëœ€",
            lawd_cd=None,
            deal_ymd=None
        )

# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
data_collection_service = DataCollectionService()
