"""
ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸

ì•„íŒŒíŠ¸ëª… ì •ê·œí™”, í´ë Œì§•, êµ¬ì¡°ì  ì†ì„± ì¶”ì¶œ ë“±
"""
import re
from typing import Optional, List, Tuple, Dict, Any
from difflib import SequenceMatcher

from .constants import (
    BRAND_DICT,
    BRAND_KEYWORD_TO_STANDARD,
    BRAND_KEYWORDS_SORTED,
    BRAND_ENG_TO_KOR,
    ROMAN_TO_INT,
    BUILDING_SUFFIXES,
)


class ApartmentNameProcessor:
    """
    ì•„íŒŒíŠ¸ëª… ì „ì²˜ë¦¬ í´ë˜ìŠ¤
    
    ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸:
    1. ê¸°ë³¸ í´ë Œì§• (íŠ¹ìˆ˜ë¬¸ì, ê³µë°± ì œê±°)
    2. ìˆ«ì ì •ê·œí™” (í•œê¸€/ì˜ë¬¸/ì „ê° â†’ ì•„ë¼ë¹„ì•„ ìˆ«ì)
    3. êµ¬ì¡°ì  ì†ì„± ì¶”ì¶œ (ë‹¨ì§€, ì°¨ìˆ˜, ë¸Œëœë“œ, ë™)
    4. ì ‘ë¯¸ì‚¬ ì œê±° (ë¹„êµìš©)
    """
    
    def __init__(self):
        # ì „ì²˜ë¦¬ëœ ì´ë¦„ ìºì‹œ (ì„±ëŠ¥ ìµœì í™”)
        self._cache: Dict[str, Dict[str, Any]] = {}
    
    def process(self, name: str) -> Dict[str, Any]:
        """
        ì•„íŒŒíŠ¸ëª… ì „ì²˜ë¦¬ ë° ì†ì„± ì¶”ì¶œ
        
        Args:
            name: ì›ë³¸ ì•„íŒŒíŠ¸ëª…
            
        Returns:
            ì „ì²˜ë¦¬ëœ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬:
            - original: ì›ë³¸ ì´ë¦„
            - cleaned: í´ë Œì§•ëœ ì´ë¦„
            - normalized: ì •ê·œí™”ëœ ì´ë¦„ (ë¹„êµìš©)
            - normalized_strict: ì—„ê²© ì •ê·œí™” (ë‹¨ì§€/ì°¨ìˆ˜ ì œê±°)
            - block: ë‹¨ì§€ ë²ˆí˜¸ (1ë‹¨ì§€ â†’ 1)
            - series: ì°¨ìˆ˜ (1ì°¨ â†’ 1)
            - brand: í‘œì¤€ ë¸Œëœë“œëª…
            - brand_in_parens: ê´„í˜¸ ì•ˆ ë¸Œëœë“œëª…
            - block_in_parens: ê´„í˜¸ ì•ˆ ë‹¨ì§€ë²ˆí˜¸
            - core: í•µì‹¬ ì´ë¦„ (ë¸Œëœë“œ/ë‹¨ì§€/ì°¨ìˆ˜ ì œê±°)
            - village: ë§ˆì„ ì´ë¦„ (ìˆëŠ” ê²½ìš°)
        """
        if not name:
            return self._empty_result()
        
        # ìºì‹œ í™•ì¸
        cache_key = name.strip()
        if cache_key in self._cache:
            return self._cache[cache_key]
        
        # 1ë‹¨ê³„: ê¸°ë³¸ í´ë Œì§•
        cleaned = self.clean_name(name)
        
        # 2ë‹¨ê³„: êµ¬ì¡°ì  ì†ì„± ì¶”ì¶œ
        block = self.extract_block_number(name)
        series = self.extract_series_number(name)
        brand = self.extract_brand(name)
        brand_in_parens = self.extract_brand_from_parentheses(name)
        block_in_parens = self.extract_block_from_parentheses(name)
        village = self.extract_village_name(name)
        
        # 3ë‹¨ê³„: ì •ê·œí™”
        normalized = self.normalize_name(cleaned)
        normalized_strict = self.normalize_name_strict(cleaned)
        
        # 4ë‹¨ê³„: í•µì‹¬ ì´ë¦„ ì¶”ì¶œ
        core = self.extract_core_name(cleaned)
        
        result = {
            'original': name,
            'cleaned': cleaned,
            'normalized': normalized,
            'normalized_strict': normalized_strict,
            'block': block,
            'series': series,
            'brand': brand,
            'brand_in_parens': brand_in_parens,
            'block_in_parens': block_in_parens,
            'core': core,
            'village': village,
        }
        
        # ìºì‹œ ì €ì¥
        self._cache[cache_key] = result
        return result
    
    def _empty_result(self) -> Dict[str, Any]:
        """ë¹ˆ ê²°ê³¼ ë°˜í™˜"""
        return {
            'original': '',
            'cleaned': '',
            'normalized': '',
            'normalized_strict': '',
            'block': None,
            'series': None,
            'brand': None,
            'brand_in_parens': None,
            'block_in_parens': None,
            'core': '',
            'village': None,
        }
    
    # ========================================================
    # 1ë‹¨ê³„: ê¸°ë³¸ í´ë Œì§•
    # ========================================================
    
    def clean_name(self, name: str) -> str:
        """
        ê¸°ë³¸ í´ë Œì§•
        
        - ê´„í˜¸ ì•ˆ ë‚´ìš© ì¶”ì¶œ í›„ ê´„í˜¸ ì œê±°
        - íŠ¹ìˆ˜ë¬¸ì ì œê±° (-, _, ., , ë“±)
        - "ì…ì£¼ìëŒ€í‘œíšŒì˜", "ê´€ë¦¬ì‚¬ë¬´ì†Œ" ë“± ë¶ˆí•„ìš”í•œ ì ‘ë¯¸ì‚¬ ì œê±°
        """
        if not name:
            return ""
        
        result = name.strip()
        
        # ë¶ˆí•„ìš”í•œ ì ‘ë¯¸ì‚¬ ì œê±°
        remove_patterns = [
            r'ì…ì£¼ìëŒ€í‘œíšŒì˜$',
            r'ê´€ë¦¬ì‚¬ë¬´ì†Œ$',
            r'ê´€ë¦¬ì‚¬ë¬´ì‹¤$',
            r'ìì¹˜íšŒ$',
        ]
        for pattern in remove_patterns:
            result = re.sub(pattern, '', result)
        
        # ê´„í˜¸ ì•ˆ ë‚´ìš© ì¶”ì¶œ (ë©”íƒ€ë°ì´í„°ë¡œ ë³´ì¡´)
        # ê´„í˜¸ ì œê±°ëŠ” normalizeì—ì„œ ìˆ˜í–‰
        
        # íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬ (ì—°ì† ê³µë°± í•˜ë‚˜ë¡œ)
        result = re.sub(r'[-_.,Â·]', ' ', result)
        result = re.sub(r'\s+', ' ', result)
        
        return result.strip()
    
    def normalize_numbers(self, text: str) -> str:
        """
        ìˆ«ì ì •ê·œí™”
        
        - í•œê¸€ ìˆ«ì â†’ ì•„ë¼ë¹„ì•„ ìˆ«ì (ì¼, ì´, ì‚¼ â†’ 1, 2, 3)
        - ë¡œë§ˆ ìˆ«ì â†’ ì•„ë¼ë¹„ì•„ ìˆ«ì (â… , â…¡, â…¢ â†’ 1, 2, 3)
        - ì „ê° ìˆ«ì â†’ ë°˜ê° ìˆ«ì (ï¼‘ â†’ 1)
        """
        if not text:
            return ""
        
        result = text
        
        # ì „ê° ìˆ«ì â†’ ë°˜ê°
        fullwidth_to_half = str.maketrans(
            'ï¼ï¼‘ï¼’ï¼“ï¼”ï¼•ï¼–ï¼—ï¼˜ï¼™',
            '0123456789'
        )
        result = result.translate(fullwidth_to_half)
        
        # ë¡œë§ˆ ìˆ«ì â†’ ì•„ë¼ë¹„ì•„ ìˆ«ì
        for roman, num in ROMAN_TO_INT.items():
            result = result.replace(roman, str(num))
        
        # í•œê¸€ ìˆ«ì ë³€í™˜ (ë‹¨ì§€, ì°¨ ì•ì—ì„œë§Œ)
        kor_numbers = {
            'ì¼': '1', 'ì´': '2', 'ì‚¼': '3', 'ì‚¬': '4', 'ì˜¤': '5',
            'ìœ¡': '6', 'ì¹ ': '7', 'íŒ”': '8', 'êµ¬': '9', 'ì‹­': '10'
        }
        for kor, num in kor_numbers.items():
            result = re.sub(f'{kor}(ë‹¨ì§€|ì°¨|ë™)', f'{num}\\1', result)
        
        return result
    
    # ========================================================
    # 2ë‹¨ê³„: êµ¬ì¡°ì  ì†ì„± ì¶”ì¶œ
    # ========================================================
    
    def extract_block_number(self, name: str) -> Optional[int]:
        """
        ë‹¨ì§€ ë²ˆí˜¸ ì¶”ì¶œ
        
        ì˜ˆì‹œ:
        - "1ë‹¨ì§€" â†’ 1
        - "(1ë‹¨ì§€)" â†’ 1
        - "1BL", "Aë¸”ëŸ­" â†’ 1, A (ìˆ«ìë§Œ ë°˜í™˜)
        """
        if not name:
            return None
        
        normalized = self.normalize_numbers(name)
        
        # ìˆ«ì+ë‹¨ì§€ íŒ¨í„´
        match = re.search(r'(\d+)\s*ë‹¨ì§€', normalized)
        if match:
            return int(match.group(1))
        
        # BL, ë¸”ëŸ­ íŒ¨í„´
        match = re.search(r'(\d+)\s*(?:BL|ë¸”ëŸ­|ë¸”ë¡)', normalized, re.IGNORECASE)
        if match:
            return int(match.group(1))
        
        return None
    
    def extract_series_number(self, name: str) -> Optional[int]:
        """
        ì°¨ìˆ˜ ì¶”ì¶œ
        
        ì˜ˆì‹œ:
        - "1ì°¨" â†’ 1
        - "2ì°¨ì•„íŒŒíŠ¸" â†’ 2
        - "IIIì°¨" â†’ 3
        """
        if not name:
            return None
        
        normalized = self.normalize_numbers(name)
        
        # ìˆ«ì+ì°¨ íŒ¨í„´
        match = re.search(r'(\d+)\s*ì°¨(?:ì•„íŒŒíŠ¸)?', normalized)
        if match:
            return int(match.group(1))
        
        return None
    
    def extract_brand(self, name: str) -> Optional[str]:
        """
        ë¸Œëœë“œëª… ì¶”ì¶œ (í‘œì¤€ ë¸Œëœë“œëª… ë°˜í™˜)
        
        - ê¸´ í‚¤ì›Œë“œë¶€í„° ë§¤ì¹­ (eí¸í•œì„¸ìƒ > í¸í•œì„¸ìƒ)
        - ì˜ë¬¸ â†’ í•œê¸€ ë³€í™˜ í›„ ë§¤ì¹­
        """
        if not name:
            return None
        
        # ì†Œë¬¸ì ë³€í™˜ í›„ ì˜ë¬¸ ë¸Œëœë“œ í•œê¸€í™”
        lower_name = name.lower()
        for eng, kor in sorted(BRAND_ENG_TO_KOR.items(), key=lambda x: len(x[0]), reverse=True):
            lower_name = lower_name.replace(eng, kor)
        
        # ê¸´ í‚¤ì›Œë“œë¶€í„° ë§¤ì¹­
        for keyword in BRAND_KEYWORDS_SORTED:
            if keyword in lower_name:
                return BRAND_KEYWORD_TO_STANDARD[keyword]
        
        return None
    
    def extract_brand_from_parentheses(self, name: str) -> Optional[str]:
        """
        ê´„í˜¸ ì•ˆì˜ ë¸Œëœë“œëª… ì¶”ì¶œ
        
        ì˜ˆì‹œ:
        - "íš¨ìì´Œ(í˜„ëŒ€)" â†’ "í˜„ëŒ€"
        - "í›„ê³¡ë§ˆì„(ê±´ì˜15)" â†’ "ê±´ì˜"
        """
        if not name:
            return None
        
        # ê´„í˜¸ ì•ˆ ë‚´ìš© ì¶”ì¶œ
        match = re.search(r'\(([^)]+)\)', name)
        if not match:
            return None
        
        content = match.group(1)
        
        # ìˆ«ì ì œê±° í›„ ë¸Œëœë“œ ì¶”ì¶œ
        content_no_num = re.sub(r'\d+', '', content).strip()
        
        if content_no_num:
            # ë¸Œëœë“œ ì‚¬ì „ì—ì„œ ì°¾ê¸°
            lower_content = content_no_num.lower()
            for keyword in BRAND_KEYWORDS_SORTED:
                if keyword in lower_content or lower_content in keyword:
                    return BRAND_KEYWORD_TO_STANDARD[keyword]
            # ì‚¬ì „ì— ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
            return content_no_num
        
        return None
    
    def extract_block_from_parentheses(self, name: str) -> Optional[int]:
        """
        ê´„í˜¸ ì•ˆì˜ ë‹¨ì§€ ë²ˆí˜¸ ì¶”ì¶œ
        
        ì˜ˆì‹œ:
        - "í›„ê³¡ë§ˆì„(ê±´ì˜15)" â†’ 15
        - "íš¨ìì´Œ(1ë‹¨ì§€)" â†’ 1
        """
        if not name:
            return None
        
        # ê´„í˜¸ ì•ˆ ë‚´ìš© ì¶”ì¶œ
        match = re.search(r'\(([^)]+)\)', name)
        if not match:
            return None
        
        content = match.group(1)
        normalized = self.normalize_numbers(content)
        
        # ìˆ«ì+ë‹¨ì§€ íŒ¨í„´
        match = re.search(r'(\d+)\s*ë‹¨ì§€', normalized)
        if match:
            return int(match.group(1))
        
        # ë¸Œëœë“œëª…+ìˆ«ì íŒ¨í„´ (ê±´ì˜15 â†’ 15)
        match = re.search(r'[ê°€-í£]+(\d+)$', normalized)
        if match:
            return int(match.group(1))
        
        return None
    
    def extract_village_name(self, name: str) -> Optional[str]:
        """
        ë§ˆì„ ì´ë¦„ ì¶”ì¶œ
        
        ì˜ˆì‹œ:
        - "í•œë¹›ë§ˆì„7ë‹¨ì§€" â†’ "í•œë¹›ë§ˆì„"
        - "í›„ê³¡ë§ˆì„" â†’ "í›„ê³¡ë§ˆì„"
        """
        if not name:
            return None
        
        # ë§ˆì„ íŒ¨í„´
        match = re.search(r'([ê°€-í£]+ë§ˆì„)', name)
        if match:
            return match.group(1)
        
        # ë‹¨ì§€ ì•ì˜ ì´ë¦„
        match = re.search(r'([ê°€-í£]+)\d*ë‹¨ì§€', name)
        if match:
            return match.group(1)
        
        return None
    
    # ========================================================
    # 3ë‹¨ê³„: ì •ê·œí™”
    # ========================================================
    
    def normalize_name(self, name: str) -> str:
        """
        ì•„íŒŒíŠ¸ëª… ì •ê·œí™” (ë¹„êµìš©)
        
        - ì†Œë¬¸ì ë³€í™˜
        - ì˜ë¬¸ ë¸Œëœë“œ í•œê¸€í™”
        - ê³µë°±/íŠ¹ìˆ˜ë¬¸ì ì œê±°
        - ì ‘ë¯¸ì‚¬ ì œê±°
        """
        if not name:
            return ""
        
        result = name.lower()
        
        # ì˜ë¬¸ ë¸Œëœë“œ í•œê¸€í™”
        for eng, kor in sorted(BRAND_ENG_TO_KOR.items(), key=lambda x: len(x[0]), reverse=True):
            result = result.replace(eng, kor)
        
        # ìˆ«ì ì •ê·œí™”
        result = self.normalize_numbers(result)
        
        # ê´„í˜¸ ì œê±° (ê´„í˜¸ ì•ˆ ë‚´ìš© í¬í•¨)
        result = re.sub(r'\([^)]*\)', '', result)
        result = re.sub(r'\[[^\]]*\]', '', result)
        
        # íŠ¹ìˆ˜ë¬¸ì/ê³µë°± ì œê±°
        result = re.sub(r'[\s\-_.,Â·\'"!@#$%^&*]', '', result)
        
        # ì ‘ë¯¸ì‚¬ ì œê±°
        for suffix in BUILDING_SUFFIXES:
            if result.endswith(suffix.lower()):
                result = result[:-len(suffix)]
                break
        
        return result
    
    def normalize_name_strict(self, name: str) -> str:
        """
        ì—„ê²© ì •ê·œí™” (ë‹¨ì§€/ì°¨ìˆ˜ê¹Œì§€ ì œê±°)
        
        ìœ ì‚¬ë„ ë¹„êµìš© - ë‹¨ì§€/ì°¨ìˆ˜ ì •ë³´ ì—†ì´ ìˆœìˆ˜ ì´ë¦„ë§Œ ë¹„êµ
        """
        if not name:
            return ""
        
        result = self.normalize_name(name)
        
        # ë‹¨ì§€ ë²ˆí˜¸ ì œê±°
        result = re.sub(r'\d+ë‹¨ì§€', '', result)
        result = re.sub(r'\d+bl', '', result, flags=re.IGNORECASE)
        result = re.sub(r'\d+ë¸”[ëŸ­ë¡]', '', result)
        
        # ì°¨ìˆ˜ ì œê±°
        result = re.sub(r'\d+ì°¨', '', result)
        
        # ì—°ì† ìˆ«ì (ë™ ë²ˆí˜¸ ë“±) ì •ë¦¬
        # ë‹¨, ë¸Œëœë“œëª…ì— í¬í•¨ëœ ìˆ«ìëŠ” ìœ ì§€ (SKë·° ë“±)
        
        return result
    
    # ========================================================
    # 4ë‹¨ê³„: í•µì‹¬ ì´ë¦„ ì¶”ì¶œ
    # ========================================================
    
    def extract_core_name(self, name: str) -> str:
        """
        í•µì‹¬ ì´ë¦„ ì¶”ì¶œ (ë¸Œëœë“œ/ë‹¨ì§€/ì°¨ìˆ˜ ì œê±°)
        
        ì˜ˆì‹œ:
        - "í•œë¹›ë§ˆì„7ë‹¨ì§€ë¡¯ë°ìºìŠ¬1ì°¨" â†’ "í•œë¹›ë§ˆì„"
        - "í‘¸ë¥´ì§€ì˜¤ë”ìƒµ" â†’ ""  (ë¸Œëœë“œë§Œ ìˆëŠ” ê²½ìš°)
        """
        if not name:
            return ""
        
        result = name.lower()
        
        # ë¸Œëœë“œ ì œê±°
        for keyword in BRAND_KEYWORDS_SORTED:
            result = result.replace(keyword, '')
        
        # ë‹¨ì§€/ì°¨ìˆ˜ ì œê±°
        result = re.sub(r'\d+\s*ë‹¨ì§€', '', result)
        result = re.sub(r'\d+\s*ì°¨', '', result)
        
        # íŠ¹ìˆ˜ë¬¸ì/ê³µë°± ì œê±°
        result = re.sub(r'[\s\-_.,Â·\(\)\[\]]', '', result)
        
        # ì ‘ë¯¸ì‚¬ ì œê±°
        for suffix in BUILDING_SUFFIXES:
            if result.endswith(suffix.lower()):
                result = result[:-len(suffix)]
                break
        
        return result


class DongNameProcessor:
    """
    ë™(ìë©´ë¦¬) ì´ë¦„ ì „ì²˜ë¦¬ í´ë˜ìŠ¤
    """
    
    def __init__(self):
        self._cache: Dict[str, List[str]] = {}
    
    def normalize(self, dong_name: str) -> str:
        """
        ë™ ì´ë¦„ ì •ê·œí™”
        
        ì˜ˆì‹œ:
        - "ë´‰í™”ì ë‚´ì„±ë¦¬" â†’ "ë‚´ì„±"
        - "ì¶˜ì–‘ë©´ ì˜ì–‘ë¦¬" â†’ "ì˜ì–‘"
        """
        if not dong_name:
            return ""
        
        parts = dong_name.strip().split()
        if not parts:
            return ""
        
        # ë§ˆì§€ë§‰ ë¶€ë¶„ ì‚¬ìš© (ì/ë©´ ë’¤ì˜ ë™/ë¦¬)
        last_part = parts[-1]
        
        # ìˆ«ì ì œê±°
        normalized = re.sub(r'\d+', '', last_part)
        
        # ì ‘ë¯¸ì‚¬ ì œê±°
        normalized = normalized.replace("ì", "").replace("ë©´", "").replace("ë¦¬", "")
        normalized = normalized.replace("ë™", "").replace("ê°€", "")
        
        return normalized.strip()
    
    def extract_candidates(self, dong_name: str) -> List[str]:
        """
        ë™ ì´ë¦„ì—ì„œ ë§¤ì¹­ í›„ë³´ ì¶”ì¶œ
        
        ì˜ˆì‹œ:
        - "ë´‰í™”ì ë‚´ì„±ë¦¬" â†’ ["ë´‰í™”ì ë‚´ì„±ë¦¬", "ë‚´ì„±ë¦¬", "ë´‰í™”ì", "ë‚´ì„±", "ë´‰í™”"]
        """
        if not dong_name:
            return []
        
        cache_key = dong_name.strip()
        if cache_key in self._cache:
            return self._cache[cache_key]
        
        candidates = [dong_name.strip()]
        parts = dong_name.strip().split()
        
        if len(parts) > 1:
            candidates.append(parts[-1])  # ë§ˆì§€ë§‰ ë¶€ë¶„
            candidates.append(parts[0])   # ì²« ë¶€ë¶„
        
        # ì •ê·œí™”ëœ ë²„ì „ ì¶”ê°€
        for candidate in candidates[:]:
            no_digit = re.sub(r'\d+', '', candidate)
            if no_digit != candidate:
                candidates.append(no_digit)
            
            # ì ‘ë¯¸ì‚¬ ì œê±° ë²„ì „
            cleaned = no_digit.replace("ì", "").replace("ë©´", "").replace("ë¦¬", "")
            cleaned = cleaned.replace("ë™", "").replace("ê°€", "").strip()
            if cleaned and cleaned != candidate:
                candidates.append(cleaned)
        
        # ì¤‘ë³µ ì œê±° ë° ë¹ˆ ë¬¸ìì—´ ì œê±°
        result = list(dict.fromkeys([c for c in candidates if c]))
        
        self._cache[cache_key] = result
        return result


class BunjiProcessor:
    """
    ì§€ë²ˆ ì „ì²˜ë¦¬ í´ë˜ìŠ¤
    """
    
    @staticmethod
    def normalize(jibun: str) -> Tuple[Optional[str], Optional[str]]:
        """
        ì§€ë²ˆ ì •ê·œí™” ë° ë³¸ë²ˆ/ë¶€ë²ˆ ë¶„ë¦¬
        
        ì˜ˆì‹œ:
        - "123-45" â†’ ("123", "45")
        - "123" â†’ ("123", None)
        - "ì‚°37-6" â†’ ("37", "6")  # ì‚°ì§€ë²ˆ ì²˜ë¦¬
        - "ì§€êµ¬BL 34-7" â†’ ("34", "7")  # ì§€êµ¬ ë²ˆí˜¸ ì²˜ë¦¬
        - "2745-2-1" â†’ ("2745", "2")  # ë³¸ë²ˆ-ë¶€ë²ˆ-ë¶€ë¶€ë²ˆ ì²˜ë¦¬ (ë¶€ë¶€ë²ˆì€ ë¶€ë²ˆì— í¬í•¨)
        """
        if not jibun:
            return (None, None)
        
        # ê³µë°± ì •ë¦¬
        normalized = re.sub(r'\s+', '', jibun)
        
        # ğŸ”‘ ì‚°ì§€ë²ˆ ì²˜ë¦¬: "ì‚°37-6" â†’ "37-6"
        if normalized.startswith('ì‚°'):
            normalized = normalized[1:]  # "ì‚°" ì œê±°
        
        # ğŸ”‘ ì§€êµ¬ ë²ˆí˜¸ ì²˜ë¦¬: "ì§€êµ¬BL34-7" â†’ "34-7", "ê°€ì •2ì§€êµ¬34-7" â†’ "34-7"
        # ì§€êµ¬, BL, ë¸”ë¡ ë“± í‚¤ì›Œë“œ ì œê±° í›„ ìˆ«ì íŒ¨í„´ ì¶”ì¶œ
        if 'ì§€êµ¬' in normalized or 'BL' in normalized.upper() or 'ë¸”ë¡' in normalized:
            # ìˆ«ì íŒ¨í„´ë§Œ ì¶”ì¶œ (ì˜ˆ: "ì§€êµ¬BL34-7" â†’ "34-7")
            num_match = re.search(r'(\d+)(?:-(\d+))?(?:-(\d+))?', normalized)
            if num_match:
                main = num_match.group(1).lstrip('0')
                sub = num_match.group(2).lstrip('0') if num_match.group(2) else None
                # ë¶€ë¶€ë²ˆì´ ìˆìœ¼ë©´ ë¶€ë²ˆìœ¼ë¡œ í†µí•© (ì˜ˆ: "2745-2-1" â†’ ë³¸ë²ˆ="2745", ë¶€ë²ˆ="2")
                # ë˜ëŠ” ë¶€ë¶€ë²ˆì„ ë¬´ì‹œí•˜ê³  ë¶€ë²ˆë§Œ ì‚¬ìš©
                return (main, sub)
        
        # ğŸ”‘ ë³¸ë²ˆ-ë¶€ë²ˆ-ë¶€ë¶€ë²ˆ ì²˜ë¦¬: "2745-2-1" â†’ ë³¸ë²ˆ="2745", ë¶€ë²ˆ="2"
        # ë¶€ë¶€ë²ˆì€ ì¼ë°˜ì ìœ¼ë¡œ ë¶€ë²ˆì˜ ì¼ë¶€ì´ë¯€ë¡œ ë¶€ë²ˆìœ¼ë¡œ í†µí•©
        if normalized.count('-') >= 2:
            # ì²« ë²ˆì§¸ í•˜ì´í”ˆê¹Œì§€ë§Œ ë¶„ë¦¬ (ë³¸ë²ˆ-ë¶€ë²ˆ)
            parts = normalized.split('-', 2)
            main = parts[0].lstrip('0')
            # ë¶€ë²ˆê³¼ ë¶€ë¶€ë²ˆì„ í•©ì¹˜ì§€ ì•Šê³  ë¶€ë²ˆë§Œ ì‚¬ìš© (ë¶€ë¶€ë²ˆì€ ë¬´ì‹œ)
            sub = parts[1].lstrip('0') if len(parts) > 1 and parts[1] else None
            return (main, sub)
        
        # ì¼ë°˜ ë³¸ë²ˆ-ë¶€ë²ˆ ë¶„ë¦¬
        if '-' in normalized:
            parts = normalized.split('-', 1)
            main = parts[0].lstrip('0')
            sub = parts[1].lstrip('0') if len(parts) > 1 and parts[1] else None
            return (main, sub)
        
        # ë³¸ë²ˆë§Œ ìˆëŠ” ê²½ìš°
        main = normalized.lstrip('0')
        return (main, None)
    
    @staticmethod
    def match_score(jibun1: str, jibun2: str) -> float:
        """
        ì§€ë²ˆ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚° (0~40)
        
        - ë³¸ë²ˆ+ë¶€ë²ˆ ì™„ì „ ì¼ì¹˜: 40ì 
        - ë³¸ë²ˆë§Œ ì¼ì¹˜: 20ì 
        - ë¶ˆì¼ì¹˜: 0ì 
        """
        main1, sub1 = BunjiProcessor.normalize(jibun1)
        main2, sub2 = BunjiProcessor.normalize(jibun2)
        
        if not main1 or not main2:
            return 0.0
        
        # ë³¸ë²ˆ ë¹„êµ
        if main1 != main2:
            return 0.0
        
        # ë³¸ë²ˆ ì¼ì¹˜ + ë¶€ë²ˆ ë¹„êµ
        if sub1 and sub2 and sub1 == sub2:
            return 40.0  # ì™„ì „ ì¼ì¹˜
        
        return 20.0  # ë³¸ë²ˆë§Œ ì¼ì¹˜


def calculate_similarity(str1: str, str2: str) -> float:
    """
    ë¬¸ìì—´ ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0)
    
    Token Set Ratio ë°©ì‹ ì‚¬ìš© (ë‹¨ì–´ ìˆœì„œ ë¬´ê´€)
    """
    if not str1 or not str2:
        return 0.0
    
    # ê¸°ë³¸ SequenceMatcher ì‚¬ìš©
    return SequenceMatcher(None, str1, str2).ratio()


def token_set_similarity(str1: str, str2: str) -> float:
    """
    í† í° ê¸°ë°˜ ìœ ì‚¬ë„ ê³„ì‚° (ë‹¨ì–´ ìˆœì„œ ë¬´ê´€)
    
    ì˜ˆì‹œ:
    - "ì‚´êµ¬ë§ˆì„ë™ì•„ì„œê´‘" vs "ì‚´êµ¬ê³¨ë§ˆì„ì„œê´‘ì„±ì§€ë™ì•„" â†’ ë†’ì€ ì ìˆ˜
    """
    if not str1 or not str2:
        return 0.0
    
    # ë¬¸ì ë‹¨ìœ„ ì§‘í•© ë¹„êµ (í•œê¸€ íŠ¹ì„±ìƒ)
    set1 = set(str1)
    set2 = set(str2)
    
    intersection = len(set1 & set2)
    union = len(set1 | set2)
    
    if union == 0:
        return 0.0
    
    # Jaccard ìœ ì‚¬ë„ + SequenceMatcher ê²°í•©
    jaccard = intersection / union
    seq_ratio = calculate_similarity(str1, str2)
    
    return (jaccard + seq_ratio) / 2


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
_apt_processor: Optional[ApartmentNameProcessor] = None
_dong_processor: Optional[DongNameProcessor] = None


def get_apt_processor() -> ApartmentNameProcessor:
    """ApartmentNameProcessor ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _apt_processor
    if _apt_processor is None:
        _apt_processor = ApartmentNameProcessor()
    return _apt_processor


def get_dong_processor() -> DongNameProcessor:
    """DongNameProcessor ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _dong_processor
    if _dong_processor is None:
        _dong_processor = DongNameProcessor()
    return _dong_processor
