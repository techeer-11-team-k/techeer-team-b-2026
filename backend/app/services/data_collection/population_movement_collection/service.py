"""
ì¸êµ¬ ì´ë™ ë°ì´í„° ìˆ˜ì§‘ ì„œë¹„ìŠ¤

KOSIS í†µê³„ì²­ APIì—ì„œ ì¸êµ¬ ì´ë™ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤.
"""
import logging
import sys
from typing import Dict, Any, Optional
import httpx
from datetime import datetime

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, and_

from app.models.state import State
from app.models.population_movement import PopulationMovement
from app.core.config import settings
from app.services.data_collection.base import DataCollectionServiceBase

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# í•¸ë“¤ëŸ¬ê°€ ì—†ìœ¼ë©´ ì¶”ê°€
if not logger.handlers:
    handler = logging.StreamHandler(sys.stdout)
    handler.setLevel(logging.INFO)
    formatter = logging.Formatter(
        '%(asctime)s | %(levelname)s | %(name)s | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    logger.propagate = False


class PopulationMovementCollectionService(DataCollectionServiceBase):
    """
    ì¸êµ¬ ì´ë™ ë°ì´í„° ìˆ˜ì§‘ ì„œë¹„ìŠ¤
    """

    async def collect_population_movements(
        self,
        db: AsyncSession,
        start_prd_de: str = "201701",
        end_prd_de: str = "202511"
    ) -> Dict[str, Any]:
        """
        KOSIS í†µê³„ì²­ APIì—ì„œ ì¸êµ¬ ì´ë™ ë§¤íŠ¸ë¦­ìŠ¤(ì¶œë°œì§€->ë„ì°©ì§€) ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ ì €ì¥
        
        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            start_prd_de: ì‹œì‘ ê¸°ê°„ (YYYYMM)
            end_prd_de: ì¢…ë£Œ ê¸°ê°„ (YYYYMM)
        
        Returns:
            ì €ì¥ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        # ì¸êµ¬ ì´ë™ ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ (ì¶œë°œì§€->ë„ì°©ì§€)
        return await self._collect_population_movement_matrix_data(db, start_prd_de, end_prd_de)

    async def _collect_population_movement_matrix_data(
        self,
        db: AsyncSession,
        start_prd_de: str = "202401",
        end_prd_de: str = "202511"
    ) -> Dict[str, Any]:
        """
        KOSIS í†µê³„ì²­ APIì—ì„œ ì¸êµ¬ ì´ë™ ë§¤íŠ¸ë¦­ìŠ¤(ì¶œë°œì§€->ë„ì°©ì§€) ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ ì €ì¥
        
        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            start_prd_de: ì‹œì‘ ê¸°ê°„ (YYYYMM)
            end_prd_de: ì¢…ë£Œ ê¸°ê°„ (YYYYMM)
        
        Returns:
            ì €ì¥ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if not settings.KOSIS_API_KEY:
            raise ValueError("KOSIS_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        try:
            # KOSIS API í˜¸ì¶œ
            kosis_url = "https://kosis.kr/openapi/Param/statisticsParameterData.do"
            params = {
                "method": "getList",
                "apiKey": settings.KOSIS_API_KEY,
                "itmId": "T70+T80+",  # ì´ë™ììˆ˜ + ìˆœì´ë™ììˆ˜
                "objL1": "ALL",   # ì „ì¶œì§€ (Source)
                "objL2": "ALL",   # ì „ì…ì§€ (Target)
                "objL3": "",
                "objL4": "",
                "objL5": "",
                "objL6": "",
                "objL7": "",
                "objL8": "",
                "format": "json",
                "jsonVD": "Y",
                "prdSe": "Q",     # ë¶„ê¸°ë³„ (ì‚¬ìš©ì ìš”ì²­ì‚¬í•­)
                "startPrdDe": start_prd_de,
                "endPrdDe": end_prd_de,
                "orgId": "101",
                "tblId": "DT_1B26003_A01" # ì „ì¶œì§€/ì „ì…ì§€(ì‹œë„)ë³„ ì´ë™ììˆ˜
            }
            
            # API URLê³¼ íŒŒë¼ë¯¸í„° ë¡œê·¸ ì¶œë ¥ (ë¯¼ê° ì •ë³´ ì œì™¸)
            safe_params = {k: (v if k != "apiKey" else "***") for k, v in params.items()}
            logger.info(f"ğŸ“¡ KOSIS Matrix API í˜¸ì¶œ ì‹œì‘: {start_prd_de} ~ {end_prd_de}")
            logger.info(f"   ğŸ“‹ API íŒŒë¼ë¯¸í„°: {safe_params}")
            
            async with httpx.AsyncClient(timeout=120.0) as client:
                response = await client.get(kosis_url, params=params)
                logger.info(f"   ğŸ“Š HTTP ì‘ë‹µ ìƒíƒœ: {response.status_code}")
                response.raise_for_status()
                raw_data = response.json()
            
            # ë°ì´í„° íŒŒì‹± (ì´ì „ ë©”ì„œë“œì™€ ë™ì¼í•œ ë¡œì§ ì‚¬ìš©)
            data = []
            if isinstance(raw_data, dict):
                logger.info(f"   ğŸ“‹ API ì‘ë‹µ íƒ€ì…: dict, í‚¤ ëª©ë¡: {list(raw_data.keys())}")
                
                # ì˜¤ë¥˜ ì‘ë‹µ í™•ì¸
                if "err" in raw_data or "errMsg" in raw_data:
                    err_code = raw_data.get("err", "N/A")
                    err_msg = raw_data.get("errMsg", "N/A")
                    logger.error(f"   âŒ KOSIS Matrix API ì˜¤ë¥˜ ì‘ë‹µ: err={err_code}, errMsg={err_msg}")
                    raise ValueError(f"KOSIS Matrix API ì˜¤ë¥˜: {err_code} - {err_msg}")
                
                # ë‹¤ì–‘í•œ ê°€ëŠ¥í•œ í‚¤ ì‹œë„
                if "StatisticSearch" in raw_data:
                    stat_search = raw_data["StatisticSearch"]
                    if isinstance(stat_search, dict):
                        data = stat_search.get("row", [])
                    elif isinstance(stat_search, list):
                        data = stat_search
                    else:
                        data = []
                elif "row" in raw_data:
                    data = raw_data["row"] if isinstance(raw_data["row"], list) else []
                elif "data" in raw_data:
                    data = raw_data["data"] if isinstance(raw_data["data"], list) else []
                elif "list" in raw_data:
                    data = raw_data["list"] if isinstance(raw_data["list"], list) else []
                elif len(raw_data) == 1:
                    # ë”•ì…”ë„ˆë¦¬ì— ê°’ì´ í•˜ë‚˜ì¸ ê²½ìš° ê·¸ ê°’ì„ ì‹œë„
                    first_value = list(raw_data.values())[0]
                    if isinstance(first_value, list):
                        data = first_value
                    elif isinstance(first_value, dict) and "row" in first_value:
                        data = first_value["row"] if isinstance(first_value["row"], list) else []
                    else:
                        data = []
                else:
                    # dictì˜ ëª¨ë“  ê°’ì´ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
                    list_values = [v for v in raw_data.values() if isinstance(v, list)]
                    if list_values:
                        # ì²« ë²ˆì§¸ ë¦¬ìŠ¤íŠ¸ ê°’ ì‚¬ìš©
                        data = list_values[0]
                    else:
                        logger.warning(f"   âš ï¸ dict ì‘ë‹µì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ, ëª¨ë“  ê°’: {list(raw_data.keys())}")
                        logger.debug(f"   ğŸ” raw_data ë‚´ìš© ìƒ˜í”Œ: {str(raw_data)[:500]}")
                        data = []
            elif isinstance(raw_data, list):
                data = raw_data
            else:
                logger.warning(f"   âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ íƒ€ì…: {type(raw_data)}")
                data = []
            
            data_count = len(data) if isinstance(data, list) else 0
            logger.info(f"âœ… KOSIS Matrix API í˜¸ì¶œ ì„±ê³µ: {data_count}ê±´ì˜ ë°ì´í„° ìˆ˜ì‹ ")
            
            # ë°ì´í„° íƒ€ì… ë° ìƒ˜í”Œ í™•ì¸
            if isinstance(data, list) and len(data) > 0:
                sample_item = data[0]
                logger.info(f"   ğŸ“Š ë°ì´í„° ìƒ˜í”Œ: C1={sample_item.get('C1')}, C2={sample_item.get('C2')}, ITM_ID={sample_item.get('ITM_ID')}, PRD_DE={sample_item.get('PRD_DE')}, PRD_SE={sample_item.get('PRD_SE')}")
            else:
                logger.warning(f"   âš ï¸ ë°ì´í„°ê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆê±°ë‚˜ ë¹„ì–´ìˆìŒ: type={type(data)}, len={len(data) if isinstance(data, list) else 'N/A'}")
            
            # C1(ì „ì¶œì§€), C2(ì „ì…ì§€) ì½”ë“œ ë§¤í•‘
            # KOSIS ì½”ë“œ -> Region ID (State í…Œì´ë¸”)
            # 00=ì „êµ­, 11=ì„œìš¸, 26=ë¶€ì‚°, 27=ëŒ€êµ¬, 28=ì¸ì²œ, 29=ê´‘ì£¼, 30=ëŒ€ì „, 31=ìš¸ì‚°
            # 36=ì„¸ì¢…, 41=ê²½ê¸°, 51=ê°•ì›, 43=ì¶©ë¶, 44=ì¶©ë‚¨, 52=ì „ë¶, 46=ì „ë‚¨, 47=ê²½ë¶, 48=ê²½ë‚¨, 50=ì œì£¼
            
            kosis_city_map = {
                "11": "ì„œìš¸íŠ¹ë³„ì‹œ", "26": "ë¶€ì‚°ê´‘ì—­ì‹œ", "27": "ëŒ€êµ¬ê´‘ì—­ì‹œ", "28": "ì¸ì²œê´‘ì—­ì‹œ",
                "29": "ê´‘ì£¼ê´‘ì—­ì‹œ", "30": "ëŒ€ì „ê´‘ì—­ì‹œ", "31": "ìš¸ì‚°ê´‘ì—­ì‹œ", "36": "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ",
                "41": "ê²½ê¸°ë„", "51": "ê°•ì›íŠ¹ë³„ìì¹˜ë„", "42": "ê°•ì›íŠ¹ë³„ìì¹˜ë„", # 42ëŠ” êµ¬ ì½”ë“œì¼ ìˆ˜ ìˆìŒ
                "43": "ì¶©ì²­ë¶ë„", "44": "ì¶©ì²­ë‚¨ë„", "52": "ì „ë¶íŠ¹ë³„ìì¹˜ë„", "45": "ì „ë¶íŠ¹ë³„ìì¹˜ë„", # 45ëŠ” êµ¬ ì½”ë“œ
                "46": "ì „ë¼ë‚¨ë„", "47": "ê²½ìƒë¶ë„", "48": "ê²½ìƒë‚¨ë„", "50": "ì œì£¼íŠ¹ë³„ìì¹˜ë„"
            }
            
            # DBì—ì„œ State ì •ë³´ ë¡œë“œ to get region_id
            states_result = await db.execute(select(State).where(State.is_deleted == False))
            states_list = states_result.scalars().all()
            
            # City Name -> Region ID (Representative)
            city_to_region_id = {}
            for state in states_list:
                if state.city_name not in city_to_region_id:
                    city_to_region_id[state.city_name] = state.region_id
            
            # KOSIS Code -> Region ID
            code_to_region_id = {}
            for code, city_name in kosis_city_map.items():
                if city_name in city_to_region_id:
                    code_to_region_id[code] = city_to_region_id[city_name]
            
            logger.info(f"   ğŸ”— ì§€ì—­ ë§¤í•‘ ì¤€ë¹„ ì™„ë£Œ: {len(code_to_region_id)}ê°œ ì½”ë“œ ë§¤í•‘")

            # ë°ì´í„° ì²˜ë¦¬ ë° ì €ì¥
            saved_count = 0
            updated_count = 0
            skipped_count = 0
            
            # ê¸°ì¡´ ë°ì´í„° ì¡°íšŒë¥¼ ìœ„í•œ í‚¤ ì…‹ ì¤€ë¹„ (Batch Updateë¥¼ ìœ„í•¨)
            # ë³µí•©í‚¤: (base_ym, from_region_id, to_region_id)
            
            processed_data = []
            
            for item in data:
                prd_de = item.get("PRD_DE")
                c1 = item.get("C1") # ì „ì¶œì§€
                c2 = item.get("C2") # ì „ì…ì§€
                dt = item.get("DT") # ì´ë™ììˆ˜
                itm_id = item.get("ITM_ID") # ì§€í‘œ ID (T70=ì´ë™ììˆ˜, T80=ìˆœì´ë™ììˆ˜)
                prd_se = item.get("PRD_SE", "M") # ê¸°ê°„ êµ¬ë¶„ (M=ì›”, Q=ë¶„ê¸°)
                
                # T70 (ì´ë™ììˆ˜)ë§Œ ì²˜ë¦¬ (T80ì€ ìˆœì´ë™ììˆ˜ì´ë¯€ë¡œ ë§¤íŠ¸ë¦­ìŠ¤ì—ëŠ” ë¶ˆí•„ìš”)
                if itm_id != "T70":
                    continue
                
                # ì „êµ­(00) ë°ì´í„°ëŠ” ì œì™¸ (ìˆœìˆ˜ ì§€ì—­ê°„ ì´ë™ë§Œ)
                if c1 == "00" or c2 == "00":
                    continue
                
                # ë¶„ê¸° ë°ì´í„°ë¥¼ ì›” ë°ì´í„°ë¡œ ë³€í™˜ (ì˜ˆ: 2024Q1 -> 202403, 2024Q2 -> 202406, 2024Q3 -> 202409, 2024Q4 -> 202412)
                base_ym = prd_de
                if prd_se == "Q":
                    # ë¶„ê¸° í˜•ì‹ ì²˜ë¦¬ (ì˜ˆ: 2024Q1, 20241 ë“±)
                    if len(prd_de) == 6 and prd_de[4] == "Q":  # ì˜ˆ: 2024Q1
                        year = prd_de[:4]
                        quarter = prd_de[5]
                        month_map = {"1": "03", "2": "06", "3": "09", "4": "12"}
                        base_ym = year + month_map.get(quarter, "03")
                    elif len(prd_de) == 5 and prd_de[4].isdigit():  # ì˜ˆ: 20241 (2024ë…„ 1ë¶„ê¸°)
                        year = prd_de[:4]
                        quarter = prd_de[4]
                        month_map = {"1": "03", "2": "06", "3": "09", "4": "12"}
                        base_ym = year + month_map.get(quarter, "03")
                # ì´ë¯¸ ì›”ë³„ ë°ì´í„°ì¸ ê²½ìš° (YYYYMM í˜•ì‹) ê·¸ëŒ€ë¡œ ì‚¬ìš©
                
                # ë™ì¼ ì§€ì—­ ì´ë™ ì œì™¸ (SankeyëŠ” íƒ€ ì§€ì—­ ê°„ ì´ë™ë§Œ ì˜ë¯¸ ìˆìŒ, same-region totals ì €ì¥ ì‹œ region_id ì˜¤ë¥˜ ìœ ë°œ)
                if c1 in code_to_region_id and c2 in code_to_region_id:
                    from_id = code_to_region_id[c1]
                    to_id = code_to_region_id[c2]
                    if from_id == to_id:
                        skipped_count += 1
                        continue
                    try:
                        count = int(dt)
                    except Exception:
                        count = 0
                    processed_data.append({
                        "base_ym": base_ym,
                        "from_region_id": from_id,
                        "to_region_id": to_id,
                        "movement_count": count
                    })
                else:
                    skipped_count += 1

            logger.info(f"   ğŸ“¦ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ: {len(processed_data)}ê±´ ìœ íš¨, {skipped_count}ê±´ ìŠ¤í‚µ")
            
            if len(processed_data) == 0:
                logger.warning(f"   âš ï¸ ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. KOSIS API ì‘ë‹µì„ í™•ì¸í•˜ì„¸ìš”.")
                return {
                    "success": True,
                    "saved_count": 0,
                    "updated_count": 0,
                    "message": "ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. KOSIS API ì‘ë‹µì„ í™•ì¸í•˜ì„¸ìš”."
                }

            # ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ (ì„±ëŠ¥ ìµœì í™”)
            logger.info(f"   ğŸ” ê¸°ì¡´ ì¸êµ¬ ì´ë™ ë°ì´í„° ì¡°íšŒ ì¤‘...")
            existing_result = await db.execute(
                select(PopulationMovement).where(
                    PopulationMovement.is_deleted == False
                )
            )
            existing_movements = existing_result.scalars().all()
            
            # ê¸°ì¡´ ë°ì´í„°ë¥¼ (base_ym, from_region_id, to_region_id) íŠœí”Œì„ í‚¤ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            existing_map: Dict[tuple, PopulationMovement] = {}
            for movement in existing_movements:
                key = (movement.base_ym, movement.from_region_id, movement.to_region_id)
                existing_map[key] = movement
            
            logger.info(f"   ğŸ“‹ ê¸°ì¡´ ì¸êµ¬ ì´ë™ ë°ì´í„° {len(existing_map)}ê±´ ì¡°íšŒ ì™„ë£Œ")

            # ì§„í–‰ ìƒí™© ì¶”ì 
            total_rows = len(processed_data)
            processed_rows = 0
            
            # Upsert Logic (ê¸°ì¡´ ë§µ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ ìµœì í™”)
            for row in processed_data:
                processed_rows += 1
                if processed_rows % 100 == 0 or processed_rows == total_rows:
                    logger.info(f"   â³ ì§„í–‰ ì¤‘: {processed_rows}/{total_rows} í–‰ ì²˜ë¦¬ ì¤‘...")
                
                key = (row["base_ym"], row["from_region_id"], row["to_region_id"])
                
                if key in existing_map:
                    # ì—…ë°ì´íŠ¸
                    existing = existing_map[key]
                    existing.movement_count = row["movement_count"]
                    existing.updated_at = datetime.utcnow()
                    updated_count += 1
                else:
                    # ìƒˆë¡œ ìƒì„±
                    new_movement = PopulationMovement(
                        base_ym=row["base_ym"],
                        from_region_id=row["from_region_id"],
                        to_region_id=row["to_region_id"],
                        movement_count=row["movement_count"]
                    )
                    db.add(new_movement)
                    saved_count += 1
            
            await db.commit()
            
            logger.info(f"âœ… ì¸êµ¬ ì´ë™ ë°ì´í„° ì €ì¥ ì™„ë£Œ: ì‹ ê·œ {saved_count}ê±´, ì—…ë°ì´íŠ¸ {updated_count}ê±´")
            
            return {
                "success": True,
                "saved_count": saved_count,
                "updated_count": updated_count
            }
            
        except Exception as e:
            await db.rollback()
            logger.error(f"âŒ ì¸êµ¬ ì´ë™ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {str(e)}", exc_info=True)
            raise
