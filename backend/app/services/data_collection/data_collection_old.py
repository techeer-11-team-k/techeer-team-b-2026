"""
ë°ì´í„° ìˆ˜ì§‘ ì„œë¹„ìŠ¤

êµ­í† êµí†µë¶€ APIì—ì„œ ì§€ì—­ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
"""
import logging
import asyncio
import sys
import csv
import re
import calendar
import xml.etree.ElementTree as ET
from difflib import SequenceMatcher
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from urllib.parse import quote
import httpx
from datetime import datetime, date
import os

from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func, and_, text
from sqlalchemy.orm import joinedload
from app.db.session import AsyncSessionLocal

# ëª¨ë“  ëª¨ë¸ì„ importí•˜ì—¬ SQLAlchemy ê´€ê³„ ì„¤ì •ì´ ì œëŒ€ë¡œ ì‘ë™í•˜ë„ë¡ í•¨
from app.models import (  # noqa: F401
    Account,
    State,
    Apartment,
    ApartDetail,
    Sale,
    Rent,
    HouseScore,
    FavoriteLocation,
    FavoriteApartment,
    MyProperty,
)

from app.core.config import settings
from app.utils.search_utils import BRAND_ENG_TO_KOR
from app.crud.state import state as state_crud

# ìƒˆ ë§¤ì¹­ ëª¨ë“ˆ import
from app.services.apt_matching import (
    BRAND_KEYWORD_TO_STANDARD,
    BUILD_YEAR_TOLERANCE,
    VetoChecker,
    get_apt_processor,
)
from app.crud.apartment import apartment as apartment_crud
from app.crud.apart_detail import apart_detail as apart_detail_crud
from app.crud.house_score import house_score as house_score_crud
from app.crud.rent import rent as rent_crud
from app.schemas.state import StateCreate, StateCollectionResponse
from app.schemas.apartment import ApartmentCreate, ApartmentCollectionResponse
from app.schemas.apart_detail import ApartDetailCreate, ApartDetailCollectionResponse
from app.schemas.house_score import HouseScoreCreate, HouseScoreCollectionResponse
from app.schemas.rent import RentCreate, RentCollectionResponse

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# í•¸ë“¤ëŸ¬ê°€ ì—†ìœ¼ë©´ ì¶”ê°€
if not logger.handlers:
    handler = logging.StreamHandler(sys.stdout)
    handler.setLevel(logging.INFO)
    formatter = logging.Formatter(
        '%(asctime)s | %(levelname)s | %(name)s | %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    logger.propagate = False  # ë¶€ëª¨ ë¡œê±°ë¡œ ì „íŒŒí•˜ì§€ ì•ŠìŒ

# ìƒìˆ˜ëŠ” constants.pyì—ì„œ import
from app.services.data_collection.constants import (
    MOLIT_REGION_API_URL,
    MOLIT_APARTMENT_LIST_API_URL,
    MOLIT_APARTMENT_BASIC_API_URL,
    MOLIT_APARTMENT_DETAIL_API_URL,
    REB_DATA_URL,
    MOLIT_SALE_API_URL,
    MOLIT_RENT_API_URL,
    CITY_NAMES,
)


class DataCollectionService:
    """
    ë°ì´í„° ìˆ˜ì§‘ ì„œë¹„ìŠ¤ í´ë˜ìŠ¤
    
    êµ­í† êµí†µë¶€ APIì—ì„œ ì§€ì—­ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    
    # CSV íŒŒì¼ ê²½ë¡œ ìºì‹œ (í•œ ë²ˆë§Œ í™•ì¸)
    _csv_path_cache: Optional[Path] = None
    _csv_path_checked: bool = False
    
    # HTTP í´ë¼ì´ì–¸íŠ¸ í’€ (ì¬ì‚¬ìš©ìœ¼ë¡œ ì†ë„ í–¥ìƒ)
    _http_client: Optional[httpx.AsyncClient] = None
    
    # ì•„íŒŒíŠ¸ ë§¤ì¹­ ë¡œê·¸ (ì›”ë³„ë¡œ ê´€ë¦¬: YYYYMM -> {apt_id -> set of APIì—ì„œ ë°›ì€ ì•„íŒŒíŠ¸ëª…})
    _apt_matching_log_by_month: Dict[str, Dict[int, set]] = {}
    _apt_name_map_by_month: Dict[str, Dict[int, str]] = {}  # ì›”ë³„ apt_id -> DB ì•„íŒŒíŠ¸ëª…
    
    # ì•„íŒŒíŠ¸ ë§¤ì¹­ ì‹¤íŒ¨ ë¡œê·¸ (ì›”ë³„ë¡œ ê´€ë¦¬: YYYYMM -> List[Dict])
    _apt_fail_log_by_month: Dict[str, List[Dict[str, str]]] = {}
    
    @staticmethod
    def _get_project_root() -> Path:
        """
        í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ë°˜í™˜
        
        Docker ì»¨í…Œì´ë„ˆ ë‚´ì—ì„œëŠ” WORKDIRì´ /appì´ë¯€ë¡œ,
        í˜„ì¬ íŒŒì¼ ê²½ë¡œë¥¼ ê¸°ì¤€ìœ¼ë¡œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
        
        ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ì‹œë„:
        1. í™˜ê²½ë³€ìˆ˜ PROJECT_ROOT í™•ì¸ (ê°€ì¥ ìš°ì„ )
        2. í˜„ì¬ íŒŒì¼ ê²½ë¡œ ê¸°ì¤€ìœ¼ë¡œ /app ì°¾ê¸° (Docker í™˜ê²½)
        3. backend í´ë” ì°¾ê¸° (ë¡œì»¬ ê°œë°œ í™˜ê²½)
        4. ìƒìœ„ ë””ë ‰í† ë¦¬ì—ì„œ db_backup ì°¾ê¸°
        5. í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ì‚¬ìš© (ìµœí›„ì˜ ìˆ˜ë‹¨)
        """
        # ë°©ë²• 1: í™˜ê²½ë³€ìˆ˜ë¡œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì§€ì • (ê°€ì¥ ìš°ì„ )
        project_root_env = os.environ.get("PROJECT_ROOT")
        if project_root_env:
            project_root = Path(project_root_env).resolve()
            if project_root.exists():
                print(f"[LOG_SAVE] ë°©ë²• 1 - í™˜ê²½ë³€ìˆ˜ PROJECT_ROOT ì‚¬ìš©: {project_root}")
                logger.info(f"âœ… [ê²½ë¡œ íƒìƒ‰] í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©: {project_root}")
                return project_root
        
        # í˜„ì¬ íŒŒì¼ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
        current_file = Path(__file__).resolve()
        print(f"[LOG_SAVE] í˜„ì¬ íŒŒì¼ ê²½ë¡œ: {current_file}")
        logger.info(f"ğŸ” [ê²½ë¡œ íƒìƒ‰] í˜„ì¬ íŒŒì¼: {current_file}")
        
        # ë°©ë²• 2: Docker í™˜ê²½ - /appìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ê²½ë¡œì¸ ê²½ìš°
        # /app/app/services/data_collection.py -> /app
        if str(current_file).startswith("/app"):
            # /app/app/... êµ¬ì¡°ì¸ ê²½ìš°
            if current_file.parts[0] == "/" and current_file.parts[1] == "app":
                # /appì´ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì¸ ê²½ìš°
                project_root = Path("/app")
                if project_root.exists():
                    print(f"[LOG_SAVE] ë°©ë²• 2 - Docker /app ê²½ë¡œ ì‚¬ìš©: {project_root}")
                    logger.info(f"âœ… [ê²½ë¡œ íƒìƒ‰] Docker /app ê²½ë¡œ ì‚¬ìš©: {project_root}")
                    return project_root
                # /app/app/... êµ¬ì¡°ì¸ ê²½ìš°, ìƒìœ„ /app ì°¾ê¸°
                for parent in current_file.parents:
                    if str(parent) == "/app" and parent.exists():
                        print(f"[LOG_SAVE] ë°©ë²• 2 - Docker ìƒìœ„ /app ì°¾ìŒ: {parent}")
                        logger.info(f"âœ… [ê²½ë¡œ íƒìƒ‰] Docker ìƒìœ„ /app ì°¾ìŒ: {parent}")
                        return parent
        
        # ë°©ë²• 3: backend í´ë” ì°¾ê¸° (ë¡œì»¬ ê°œë°œ í™˜ê²½)
        for parent in current_file.parents:
            if parent.name == "backend":
                project_root = parent.parent
                if project_root.exists():
                    print(f"[LOG_SAVE] ë°©ë²• 3 - backend í´ë” ì°¾ìŒ: {project_root}")
                    logger.info(f"âœ… [ê²½ë¡œ íƒìƒ‰] ë°©ë²• 3 ì„±ê³µ: {project_root}")
                    return project_root
        
        # ë°©ë²• 4: ìƒìœ„ ë””ë ‰í† ë¦¬ì—ì„œ db_backup ì°¾ê¸°
        for parent in current_file.parents:
            if (parent / "db_backup").exists():
                print(f"[LOG_SAVE] ë°©ë²• 4 - ìƒìœ„ ë””ë ‰í† ë¦¬ì—ì„œ db_backup ë°œê²¬: {parent}")
                logger.info(f"âœ… [ê²½ë¡œ íƒìƒ‰] ë°©ë²• 4 ì„±ê³µ: {parent}")
                return parent
        
        # ë°©ë²• 5: í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ì‚¬ìš©
        cwd = Path.cwd()
        print(f"[LOG_SAVE] í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {cwd}")
        logger.info(f"ğŸ” [ê²½ë¡œ íƒìƒ‰] í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {cwd}")
        
        if str(cwd) != "/" and cwd.exists():
            print(f"[LOG_SAVE] ë°©ë²• 5 - í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ì‚¬ìš©: {cwd}")
            logger.info(f"âœ… [ê²½ë¡œ íƒìƒ‰] í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ì‚¬ìš©: {cwd}")
            return cwd
        
        # ìµœì¢… fallback: /app (Docker ê¸°ë³¸ê°’)
        docker_root = Path("/app")
        if docker_root.exists():
            print(f"[LOG_SAVE] fallback - Docker ê¸°ë³¸ê°’ /app ì‚¬ìš©: {docker_root}")
            logger.warning(f"âš ï¸ [ê²½ë¡œ íƒìƒ‰] fallback Docker ê¸°ë³¸ê°’ ì‚¬ìš©: {docker_root}")
            return docker_root
        
        # ëª¨ë“  ë°©ë²• ì‹¤íŒ¨ ì‹œ ì—ëŸ¬
        error_msg = "í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  íƒìƒ‰ ë°©ë²• ì‹¤íŒ¨."
        logger.error(f"âŒ {error_msg}")
        print(f"[LOG_SAVE] ERROR: {error_msg}")
        raise FileNotFoundError(error_msg)
    
    def __init__(self):
        """ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        if not settings.MOLIT_API_KEY:
            raise ValueError("MOLIT_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        self.api_key = settings.MOLIT_API_KEY
        # ë§¤ì¹­ ë¡œê·¸ ì´ˆê¸°í™” (ì›”ë³„ ê´€ë¦¬)
        self._apt_matching_log_by_month = {}
        self._apt_name_map_by_month = {}
        # ë§¤ì¹­ ì‹¤íŒ¨ ë¡œê·¸ ì´ˆê¸°í™” (ì›”ë³„ ê´€ë¦¬)
        self._apt_fail_log_by_month = {}
    
    def _record_apt_matching(self, apt_id: int, apt_name_db: str, apt_name_api: str, ym: str):
        """
        ì•„íŒŒíŠ¸ ë§¤ì¹­ ê¸°ë¡ ì¶”ê°€ (ì›”ë³„ ê´€ë¦¬)
        
        Args:
            apt_id: ì•„íŒŒíŠ¸ ID
            apt_name_db: DBì— ì €ì¥ëœ ì•„íŒŒíŠ¸ëª…
            apt_name_api: APIì—ì„œ ë°›ì€ ì•„íŒŒíŠ¸ëª…
            ym: ê±°ë˜ ë°œìƒ ì›” (YYYYMM) - ë¡œê·¸ë¥¼ ì €ì¥í•  ì›”
        """
        # í•´ë‹¹ ì›”ì˜ ë¡œê·¸ ë”•ì…”ë„ˆë¦¬ ì´ˆê¸°í™” (ì—†ìœ¼ë©´)
        if ym not in self._apt_matching_log_by_month:
            self._apt_matching_log_by_month[ym] = {}
            self._apt_name_map_by_month[ym] = {}
        
        # ë§¤ì¹­ ê¸°ë¡ ì¶”ê°€
        if apt_id not in self._apt_matching_log_by_month[ym]:
            self._apt_matching_log_by_month[ym][apt_id] = set()
            self._apt_name_map_by_month[ym][apt_id] = apt_name_db
        
        self._apt_matching_log_by_month[ym][apt_id].add(apt_name_api)
    
    def _save_apt_matching_log(self, current_ym: str):
        """
        ì•„íŒŒíŠ¸ ë§¤ì¹­ ë¡œê·¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            current_ym: í˜„ì¬ ìˆ˜ì§‘ ì›” (YYYYMM) - íŒŒì¼ëª…ì— ì‚¬ìš©
        
        ë¡œê·¸ íŒŒì¼ í˜•ì‹ (apart_YYYYMM.log):
        ===== 2025ë…„ 01ì›” ìˆ˜ì§‘ ê¸°ì¤€ =====
        ë”íœíŠ¸í•˜ìš°ìŠ¤ì²­ë‹´ - ë”íœíŠ¸í•˜ìš°ìŠ¤ì²­ë‹´(PH129)
        ë˜ë¯¸ì•ˆê°•ë‚¨íŒŒí¬ - ë˜ë¯¸ì•ˆê°•ë‚¨íŒŒí¬1ë‹¨ì§€, ë˜ë¯¸ì•ˆê°•ë‚¨íŒŒí¬
        ì‚¼ì„±ë™ëŒ€ì„±ìœ ë‹ˆë“œ - ëŒ€ì„±ìœ ë‹ˆë“œ, ì‚¼ì„±ëŒ€ì„±ìœ ë‹ˆë“œ
        """
        # ë¬´ì¡°ê±´ ë¡œê·¸ ì¶œë ¥ (í•¨ìˆ˜ í˜¸ì¶œ í™•ì¸ìš©)
        matching_log = self._apt_matching_log_by_month.get(current_ym, {})
        name_map = self._apt_name_map_by_month.get(current_ym, {})
        data_count = len(matching_log)
        
        print(f"[LOG_SAVE] _save_apt_matching_log í˜¸ì¶œë¨: current_ym={current_ym}, ë°ì´í„°={data_count}ê°œ")
        logger.info(f"ğŸ“ [ë¡œê·¸ ì €ì¥ ì‹œì‘] ì•„íŒŒíŠ¸ ë§¤ì¹­ ë¡œê·¸ ì €ì¥ í•¨ìˆ˜ í˜¸ì¶œë¨ (current_ym={current_ym})")
        logger.info(f"   ë§¤ì¹­ ë¡œê·¸ ë°ì´í„° ê°œìˆ˜: {data_count}")
        
        if not matching_log:
            logger.info(f"âš ï¸ [ë¡œê·¸ ì €ì¥ ê±´ë„ˆëœ€] ì•„íŒŒíŠ¸ ë§¤ì¹­ ë¡œê·¸ ì €ì¥ ì‹œë„: ë§¤ì¹­ ë°ì´í„° ì—†ìŒ")
            return
        
        try:
            # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì°¾ê¸° (_get_project_rootê°€ ì´ë¯¸ ê²€ì¦í•¨)
            logger.info(f"ğŸ” [ê²½ë¡œ íƒìƒ‰] í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì°¾ëŠ” ì¤‘...")
            project_root = self._get_project_root()
            
            # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ìµœì¢… ê²€ì¦
            if not project_root.exists():
                error_msg = f"í”„ë¡œì íŠ¸ ë£¨íŠ¸ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {project_root}"
                logger.error(f"âŒ {error_msg}")
                print(f"[LOG_SAVE] ERROR: {error_msg}")
                raise FileNotFoundError(error_msg)
            
            log_dir = project_root / "db_backup"
            log_path = log_dir / f"apart_{current_ym}.log"
            
            logger.info(f"ğŸ“‚ [ê²½ë¡œ ì •ë³´] í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}")
            logger.info(f"ğŸ“‚ [ê²½ë¡œ ì •ë³´] ë¡œê·¸ ë””ë ‰í† ë¦¬: {log_dir}")
            logger.info(f"ğŸ“‚ [ê²½ë¡œ ì •ë³´] ë¡œê·¸ íŒŒì¼ ê²½ë¡œ: {log_path}")
            logger.info(f"ğŸ“‚ [ê²½ë¡œ ì •ë³´] í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¡´ì¬ ì—¬ë¶€: {project_root.exists()}")
            logger.info(f"ğŸ“‚ [ê²½ë¡œ ì •ë³´] ë¡œê·¸ ë””ë ‰í† ë¦¬ ì¡´ì¬ ì—¬ë¶€: {log_dir.exists()}")
            print(f"[LOG_SAVE] í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}")
            print(f"[LOG_SAVE] ë¡œê·¸ ë””ë ‰í† ë¦¬: {log_dir}")
            print(f"[LOG_SAVE] ë¡œê·¸ íŒŒì¼: {log_path}")
            
            # ë””ë ‰í† ë¦¬ ìƒì„± (ê¶Œí•œ í™•ì¸ ë° ìƒì„±)
            logger.info(f"ğŸ“ [ë””ë ‰í† ë¦¬ ìƒì„±] db_backup ë””ë ‰í† ë¦¬ ìƒì„± ì‹œë„...")
            print(f"[LOG_SAVE] ë””ë ‰í† ë¦¬ ìƒì„± ì‹œë„: {log_dir}")
            print(f"[LOG_SAVE] í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì“°ê¸° ê¶Œí•œ: {os.access(project_root, os.W_OK) if project_root.exists() else 'N/A'}")
            
            try:
                # ë¶€ëª¨ ë””ë ‰í† ë¦¬ ê¶Œí•œ í™•ì¸
                if not project_root.exists():
                    logger.error(f"âŒ í”„ë¡œì íŠ¸ ë£¨íŠ¸ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {project_root}")
                    print(f"[LOG_SAVE] ERROR: í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì—†ìŒ: {project_root}")
                    raise FileNotFoundError(f"í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {project_root}")
                
                if not os.access(project_root, os.W_OK):
                    logger.error(f"âŒ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ì“°ê¸° ê¶Œí•œ ì—†ìŒ: {project_root}")
                    print(f"[LOG_SAVE] ERROR: ì“°ê¸° ê¶Œí•œ ì—†ìŒ: {project_root}")
                    raise PermissionError(f"í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ì“°ê¸° ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤: {project_root}")
                
                # ë””ë ‰í† ë¦¬ ìƒì„±
                log_dir.mkdir(parents=True, exist_ok=True)
                
                if not log_dir.exists():
                    raise FileNotFoundError(f"ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {log_dir}")
                
                logger.info(f"âœ… [ë””ë ‰í† ë¦¬ ìƒì„±] ì™„ë£Œ - ì¡´ì¬ ì—¬ë¶€: {log_dir.exists()}")
                print(f"[LOG_SAVE] ë””ë ‰í† ë¦¬ ìƒì„± ì„±ê³µ: {log_dir}")
            except PermissionError as e:
                logger.error(f"âŒ [ë””ë ‰í† ë¦¬ ìƒì„±] ê¶Œí•œ ì˜¤ë¥˜: {e}")
                print(f"[LOG_SAVE] ERROR: ë””ë ‰í† ë¦¬ ìƒì„± ê¶Œí•œ ì˜¤ë¥˜: {e}")
                raise
            except Exception as e:
                logger.error(f"âŒ [ë””ë ‰í† ë¦¬ ìƒì„±] ì˜¤ë¥˜: {e}")
                print(f"[LOG_SAVE] ERROR: ë””ë ‰í† ë¦¬ ìƒì„± ì˜¤ë¥˜: {e}")
                raise
            
            # ì›” í˜•ì‹ ë³€í™˜
            year = current_ym[:4]
            month = current_ym[4:6]
            header = f"===== {year}ë…„ {month}ì›” ìˆ˜ì§‘ ê¸°ì¤€ ====="
            
            lines = [header, ""]
            
            # í•´ë‹¹ ì›”ì˜ ë°ì´í„°ë§Œ ì‚¬ìš©
            matching_log = self._apt_matching_log_by_month.get(current_ym, {})
            name_map = self._apt_name_map_by_month.get(current_ym, {})
            
            # ì•„íŒŒíŠ¸ëª… ê¸°ì¤€ ì •ë ¬
            sorted_items = sorted(
                matching_log.items(),
                key=lambda x: name_map.get(x[0], "")
            )
            
            logger.info(f"ğŸ“Š [ë°ì´í„° ì¤€ë¹„] {len(sorted_items)}ê°œ ì•„íŒŒíŠ¸ ë°ì´í„° ì •ë ¬ ì™„ë£Œ")
            
            for apt_id, api_names in sorted_items:
                db_name = name_map.get(apt_id, f"ID:{apt_id}")
                api_names_str = ", ".join(sorted(api_names))
                lines.append(f"{db_name} - {api_names_str}")
            
            # íŒŒì¼ ë®ì–´ì“°ê¸° (ì›”ë§ˆë‹¤ ìƒˆë¡œ ê°±ì‹ )
            logger.info(f"ğŸ’¾ [íŒŒì¼ ì“°ê¸°] íŒŒì¼ ì €ì¥ ì‹œë„: {log_path}")
            content = "\n".join(lines)
            logger.info(f"   ì €ì¥í•  ë‚´ìš© í¬ê¸°: {len(content)} bytes, {len(lines)} lines")
            
            with open(log_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            logger.info(f"âœ… [íŒŒì¼ ì“°ê¸°] íŒŒì¼ ì“°ê¸° ì™„ë£Œ")
            
            # íŒŒì¼ ì €ì¥ í™•ì¸
            if log_path.exists():
                file_size = log_path.stat().st_size
                logger.info(f"âœ… [ì €ì¥ ì„±ê³µ] ì•„íŒŒíŠ¸ ë§¤ì¹­ ë¡œê·¸ ì €ì¥ ì™„ë£Œ!")
                logger.info(f"   íŒŒì¼ ê²½ë¡œ: {log_path}")
                logger.info(f"   íŒŒì¼ í¬ê¸°: {file_size} bytes")
                logger.info(f"   ì•„íŒŒíŠ¸ ê°œìˆ˜: {len(matching_log)}ê°œ")
            else:
                logger.error(f"âŒ [ì €ì¥ ì‹¤íŒ¨] íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ!")
                logger.error(f"   ì˜ˆìƒ ê²½ë¡œ: {log_path}")
                logger.error(f"   ì ˆëŒ€ ê²½ë¡œ: {log_path.resolve()}")
                logger.error(f"   ë””ë ‰í† ë¦¬ ì¡´ì¬: {log_dir.exists()}")
                logger.error(f"   ë””ë ‰í† ë¦¬ ì“°ê¸° ê¶Œí•œ: {os.access(log_dir, os.W_OK)}")
            
        except PermissionError as e:
            logger.error(f"âŒ [ì €ì¥ ì‹¤íŒ¨] ê¶Œí•œ ì˜¤ë¥˜: {e}")
            logger.error(f"   ê²½ë¡œ: {log_path if 'log_path' in locals() else 'N/A'}")
            logger.error(f"   í˜„ì¬ ì‚¬ìš©ì: {os.getuid() if hasattr(os, 'getuid') else 'N/A'}")
        except Exception as e:
            logger.error(f"âŒ [ì €ì¥ ì‹¤íŒ¨] ì˜ˆì™¸ ë°œìƒ: {e}", exc_info=True)
            logger.error(f"   ì˜ˆì™¸ íƒ€ì…: {type(e).__name__}")
            if 'log_path' in locals():
                logger.error(f"   ê²½ë¡œ: {log_path}")
    
    def _record_apt_fail(self, trans_type: str, apt_name: str, jibun: str, build_year: str, 
                         umd_nm: str, sgg_cd: str, ym: str, reason: str,
                         normalized_name: str = None, candidates: list = None, 
                         local_apts: list = None, sgg_code_matched: bool = False,
                         dong_matched: bool = False, region_name: str = None):
        """
        ì•„íŒŒíŠ¸ ë§¤ì¹­ ì‹¤íŒ¨ ê¸°ë¡ ì¶”ê°€ (ì›”ë³„ ê´€ë¦¬)
        
        Args:
            trans_type: ê±°ë˜ ìœ í˜• (ë§¤ë§¤/ì „ì›”ì„¸)
            apt_name: APIì—ì„œ ë°›ì€ ì•„íŒŒíŠ¸ëª…
            jibun: ì§€ë²ˆ
            build_year: ê±´ì¶•ë…„ë„
            umd_nm: ë™ ì´ë¦„
            sgg_cd: ì‹œêµ°êµ¬ ì½”ë“œ
            ym: ê±°ë˜ ë°œìƒ ì›” (YYYYMM) - ë¡œê·¸ë¥¼ ì €ì¥í•  ì›”
            reason: ì‹¤íŒ¨ ì‚¬ìœ 
            normalized_name: ì •ê·œí™”ëœ ì•„íŒŒíŠ¸ ì´ë¦„
            candidates: í•„í„°ë§ëœ í›„ë³´ ì•„íŒŒíŠ¸ ëª©ë¡
            local_apts: ì „ì²´ í›„ë³´ ì•„íŒŒíŠ¸ ëª©ë¡
            sgg_code_matched: ì‹œêµ°êµ¬ ì½”ë“œ ë§¤ì¹­ ì—¬ë¶€
            dong_matched: ë™ ë§¤ì¹­ ì—¬ë¶€
            region_name: ì§€ì—­ ì´ë¦„ (ì‹œêµ°êµ¬/ë™)
        """
        # í•´ë‹¹ ì›”ì˜ ì‹¤íŒ¨ ë¡œê·¸ ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™” (ì—†ìœ¼ë©´)
        if ym not in self._apt_fail_log_by_month:
            self._apt_fail_log_by_month[ym] = []
        
        # í›„ë³´ ì•„íŒŒíŠ¸ ì´ë¦„ ëª©ë¡ ì¶”ì¶œ (ìµœëŒ€ 10ê°œ)
        candidate_names = []
        if candidates:
            candidate_names = [apt.apt_name for apt in candidates[:10]]
        elif local_apts:
            candidate_names = [apt.apt_name for apt in local_apts[:10]]
        
        # ì „ì²´ í›„ë³´ ê°œìˆ˜
        total_candidates = len(local_apts) if local_apts else 0
        filtered_candidates = len(candidates) if candidates else 0
        
        self._apt_fail_log_by_month[ym].append({
            'type': trans_type,
            'apt_name': apt_name,
            'normalized_name': normalized_name or '',
            'jibun': jibun or '',
            'build_year': build_year or '',
            'umd_nm': umd_nm or '',
            'region_name': region_name or '',
            'sgg_cd': sgg_cd,
            'sgg_code_matched': sgg_code_matched,
            'dong_matched': dong_matched,
            'total_candidates': total_candidates,
            'filtered_candidates': filtered_candidates,
            'candidate_names': candidate_names,
            'ym': ym,
            'reason': reason
        })
    
    def _save_apt_fail_log(self, current_ym: str):
        """
        ì•„íŒŒíŠ¸ ë§¤ì¹­ ì‹¤íŒ¨ ë¡œê·¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            current_ym: í˜„ì¬ ìˆ˜ì§‘ ì›” (YYYYMM) - íŒŒì¼ëª…ì— ì‚¬ìš©
        
        ë¡œê·¸ íŒŒì¼ í˜•ì‹ (apartfail_YYYYMM.log):
        ===== 2025ë…„ 01ì›” ìˆ˜ì§‘ ê¸°ì¤€ =====
        [ë§¤ë§¤] ê¸ˆí˜¸ | ì§€ë²ˆ:553 | ê±´ì¶•ë…„ë„:1998 | ë™:ì˜ê´‘ì ë‹¨ì£¼ë¦¬ | ì‚¬ìœ :ì´ë¦„ë§¤ì¹­ ì‹¤íŒ¨
        [ì „ì›”ì„¸] ì„ê°€ | ì§€ë²ˆ:14 | ê±´ì¶•ë…„ë„:2001 | ë™:ì˜ê´‘ì ë‚¨ì²œë¦¬ | ì‚¬ìœ :ì´ë¦„ë§¤ì¹­ ì‹¤íŒ¨
        """
        # ë¬´ì¡°ê±´ ë¡œê·¸ ì¶œë ¥ (í•¨ìˆ˜ í˜¸ì¶œ í™•ì¸ìš©)
        fail_log = self._apt_fail_log_by_month.get(current_ym, [])
        data_count = len(fail_log)
        
        print(f"[LOG_SAVE] _save_apt_fail_log í˜¸ì¶œë¨: current_ym={current_ym}, ë°ì´í„°={data_count}ê±´")
        logger.info(f"ğŸ“ [ë¡œê·¸ ì €ì¥ ì‹œì‘] ì•„íŒŒíŠ¸ ë§¤ì¹­ ì‹¤íŒ¨ ë¡œê·¸ ì €ì¥ í•¨ìˆ˜ í˜¸ì¶œë¨ (current_ym={current_ym})")
        logger.info(f"   ì‹¤íŒ¨ ë¡œê·¸ ë°ì´í„° ê°œìˆ˜: {data_count}")
        
        if not fail_log:
            logger.info(f"âš ï¸ [ë¡œê·¸ ì €ì¥ ê±´ë„ˆëœ€] ì•„íŒŒíŠ¸ ë§¤ì¹­ ì‹¤íŒ¨ ë¡œê·¸ ì €ì¥ ì‹œë„: ì‹¤íŒ¨ ë°ì´í„° ì—†ìŒ")
            return
        
        try:
            # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì°¾ê¸° (_get_project_rootê°€ ì´ë¯¸ ê²€ì¦í•¨)
            logger.info(f"ğŸ” [ê²½ë¡œ íƒìƒ‰] í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì°¾ëŠ” ì¤‘...")
            project_root = self._get_project_root()
            
            # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ìµœì¢… ê²€ì¦
            if not project_root.exists():
                error_msg = f"í”„ë¡œì íŠ¸ ë£¨íŠ¸ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {project_root}"
                logger.error(f"âŒ {error_msg}")
                print(f"[LOG_SAVE] ERROR: {error_msg}")
                raise FileNotFoundError(error_msg)
            
            log_dir = project_root / "db_backup"
            log_path = log_dir / f"apartfail_{current_ym}.log"
            
            logger.info(f"ğŸ“‚ [ê²½ë¡œ ì •ë³´] í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}")
            logger.info(f"ğŸ“‚ [ê²½ë¡œ ì •ë³´] ë¡œê·¸ ë””ë ‰í† ë¦¬: {log_dir}")
            logger.info(f"ğŸ“‚ [ê²½ë¡œ ì •ë³´] ë¡œê·¸ íŒŒì¼ ê²½ë¡œ: {log_path}")
            logger.info(f"ğŸ“‚ [ê²½ë¡œ ì •ë³´] í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¡´ì¬ ì—¬ë¶€: {project_root.exists()}")
            logger.info(f"ğŸ“‚ [ê²½ë¡œ ì •ë³´] ë¡œê·¸ ë””ë ‰í† ë¦¬ ì¡´ì¬ ì—¬ë¶€: {log_dir.exists()}")
            print(f"[LOG_SAVE] í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}")
            print(f"[LOG_SAVE] ë¡œê·¸ ë””ë ‰í† ë¦¬: {log_dir}")
            print(f"[LOG_SAVE] ë¡œê·¸ íŒŒì¼: {log_path}")
            
            # ë””ë ‰í† ë¦¬ ìƒì„± (ê¶Œí•œ í™•ì¸ ë° ìƒì„±)
            logger.info(f"ğŸ“ [ë””ë ‰í† ë¦¬ ìƒì„±] db_backup ë””ë ‰í† ë¦¬ ìƒì„± ì‹œë„...")
            print(f"[LOG_SAVE] ë””ë ‰í† ë¦¬ ìƒì„± ì‹œë„: {log_dir}")
            print(f"[LOG_SAVE] í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì“°ê¸° ê¶Œí•œ: {os.access(project_root, os.W_OK) if project_root.exists() else 'N/A'}")
            
            try:
                # ë¶€ëª¨ ë””ë ‰í† ë¦¬ ê¶Œí•œ í™•ì¸
                if not project_root.exists():
                    logger.error(f"âŒ í”„ë¡œì íŠ¸ ë£¨íŠ¸ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {project_root}")
                    print(f"[LOG_SAVE] ERROR: í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì—†ìŒ: {project_root}")
                    raise FileNotFoundError(f"í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {project_root}")
                
                if not os.access(project_root, os.W_OK):
                    logger.error(f"âŒ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ì“°ê¸° ê¶Œí•œ ì—†ìŒ: {project_root}")
                    print(f"[LOG_SAVE] ERROR: ì“°ê¸° ê¶Œí•œ ì—†ìŒ: {project_root}")
                    raise PermissionError(f"í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ì“°ê¸° ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤: {project_root}")
                
                # ë””ë ‰í† ë¦¬ ìƒì„±
                log_dir.mkdir(parents=True, exist_ok=True)
                
                if not log_dir.exists():
                    raise FileNotFoundError(f"ë””ë ‰í† ë¦¬ ìƒì„± ì‹¤íŒ¨: {log_dir}")
                
                logger.info(f"âœ… [ë””ë ‰í† ë¦¬ ìƒì„±] ì™„ë£Œ - ì¡´ì¬ ì—¬ë¶€: {log_dir.exists()}")
                print(f"[LOG_SAVE] ë””ë ‰í† ë¦¬ ìƒì„± ì„±ê³µ: {log_dir}")
            except PermissionError as e:
                logger.error(f"âŒ [ë””ë ‰í† ë¦¬ ìƒì„±] ê¶Œí•œ ì˜¤ë¥˜: {e}")
                print(f"[LOG_SAVE] ERROR: ë””ë ‰í† ë¦¬ ìƒì„± ê¶Œí•œ ì˜¤ë¥˜: {e}")
                raise
            except Exception as e:
                logger.error(f"âŒ [ë””ë ‰í† ë¦¬ ìƒì„±] ì˜¤ë¥˜: {e}")
                print(f"[LOG_SAVE] ERROR: ë””ë ‰í† ë¦¬ ìƒì„± ì˜¤ë¥˜: {e}")
                raise
            
            # ì›” í˜•ì‹ ë³€í™˜
            year = current_ym[:4]
            month = current_ym[4:6]
            header = f"===== {year}ë…„ {month}ì›” ìˆ˜ì§‘ ê¸°ì¤€ ====="
            
            lines = [header, ""]
            
            # í•´ë‹¹ ì›”ì˜ ë°ì´í„°ë§Œ ì‚¬ìš©
            fail_log = self._apt_fail_log_by_month.get(current_ym, [])
            
            # ì•„íŒŒíŠ¸ëª… ê¸°ì¤€ ì •ë ¬
            sorted_fails = sorted(fail_log, key=lambda x: (x['type'], x['apt_name']))
            
            logger.info(f"ğŸ“Š [ë°ì´í„° ì¤€ë¹„] {len(sorted_fails)}ê±´ ì‹¤íŒ¨ ë°ì´í„° ì •ë ¬ ì™„ë£Œ")
            
            for fail in sorted_fails:
                # ê¸°ë³¸ ì •ë³´
                base_info = (f"[{fail['type']}] {fail['apt_name']}")
                
                # ì •ê·œí™”ëœ ì´ë¦„ (ìˆëŠ” ê²½ìš°)
                if fail.get('normalized_name'):
                    base_info += f" (ì •ê·œí™”: {fail['normalized_name']})"
                
                # ìœ„ì¹˜ ì •ë³´
                location_parts = []
                if fail.get('region_name'):
                    location_parts.append(f"ì§€ì—­:{fail['region_name']}")
                if fail.get('umd_nm'):
                    location_parts.append(f"ë™:{fail['umd_nm']}")
                if fail.get('jibun'):
                    location_parts.append(f"ì§€ë²ˆ:{fail['jibun']}")
                if fail.get('sgg_cd'):
                    location_parts.append(f"ì‹œêµ°êµ¬ì½”ë“œ:{fail['sgg_cd']}")
                
                location_info = " | ".join(location_parts) if location_parts else "ìœ„ì¹˜ì •ë³´ì—†ìŒ"
                
                # ê±´ì¶•ë…„ë„
                build_year_info = f"ê±´ì¶•ë…„ë„:{fail['build_year']}" if fail.get('build_year') else "ê±´ì¶•ë…„ë„:ì—†ìŒ"
                
                # ë§¤ì¹­ ì •ë³´
                matching_info_parts = []
                if 'sgg_code_matched' in fail:
                    matching_info_parts.append(f"ì‹œêµ°êµ¬ë§¤ì¹­:{'O' if fail['sgg_code_matched'] else 'X'}")
                if 'dong_matched' in fail:
                    matching_info_parts.append(f"ë™ë§¤ì¹­:{'O' if fail['dong_matched'] else 'X'}")
                
                matching_info = " | ".join(matching_info_parts) if matching_info_parts else ""
                
                # í›„ë³´ ì •ë³´
                candidate_info_parts = []
                if 'total_candidates' in fail and fail['total_candidates'] is not None:
                    candidate_info_parts.append(f"ì „ì²´í›„ë³´:{fail['total_candidates']}ê°œ")
                if 'filtered_candidates' in fail and fail['filtered_candidates'] is not None:
                    candidate_info_parts.append(f"í•„í„°í›„ë³´:{fail['filtered_candidates']}ê°œ")
                
                candidate_count_info = " | ".join(candidate_info_parts) if candidate_info_parts else ""
                
                # í›„ë³´ ì•„íŒŒíŠ¸ ì´ë¦„ ëª©ë¡ (ìµœëŒ€ 5ê°œ)
                candidate_names = fail.get('candidate_names', [])
                if candidate_names:
                    names_str = ", ".join(candidate_names[:5])
                    if len(candidate_names) > 5:
                        names_str += f" ì™¸ {len(candidate_names) - 5}ê°œ"
                    candidate_names_info = f"í›„ë³´ëª©ë¡:[{names_str}]"
                else:
                    candidate_names_info = "í›„ë³´ëª©ë¡:ì—†ìŒ"
                
                # ì‹¤íŒ¨ ì‚¬ìœ 
                reason_info = f"ì‚¬ìœ :{fail['reason']}"
                
                # ëª¨ë“  ì •ë³´ë¥¼ ì¡°í•© (ì—¬ëŸ¬ ì¤„ë¡œ ë‚˜ëˆ„ì–´ ê°€ë…ì„± í–¥ìƒ)
                line_parts = [
                    base_info,
                    f"  ìœ„ì¹˜: {location_info} | {build_year_info}",
                ]
                
                if matching_info:
                    line_parts.append(f"  ë§¤ì¹­: {matching_info}")
                
                if candidate_count_info:
                    line_parts.append(f"  í›„ë³´: {candidate_count_info}")
                
                if candidate_names_info != "í›„ë³´ëª©ë¡:ì—†ìŒ":
                    line_parts.append(f"  {candidate_names_info}")
                
                line_parts.append(f"  {reason_info}")
                
                lines.append("\n".join(line_parts))
                lines.append("")  # ë¹ˆ ì¤„ ì¶”ê°€
            
            # íŒŒì¼ ë®ì–´ì“°ê¸° (ì›”ë§ˆë‹¤ ìƒˆë¡œ ê°±ì‹ )
            logger.info(f"ğŸ’¾ [íŒŒì¼ ì“°ê¸°] íŒŒì¼ ì €ì¥ ì‹œë„: {log_path}")
            content = "\n".join(lines)
            logger.info(f"   ì €ì¥í•  ë‚´ìš© í¬ê¸°: {len(content)} bytes, {len(lines)} lines")
            
            with open(log_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            logger.info(f"âœ… [íŒŒì¼ ì“°ê¸°] íŒŒì¼ ì“°ê¸° ì™„ë£Œ")
            
            # íŒŒì¼ ì €ì¥ í™•ì¸
            if log_path.exists():
                file_size = log_path.stat().st_size
                logger.info(f"âœ… [ì €ì¥ ì„±ê³µ] ì•„íŒŒíŠ¸ ë§¤ì¹­ ì‹¤íŒ¨ ë¡œê·¸ ì €ì¥ ì™„ë£Œ!")
                logger.info(f"   íŒŒì¼ ê²½ë¡œ: {log_path}")
                logger.info(f"   íŒŒì¼ í¬ê¸°: {file_size} bytes")
                logger.info(f"   ì‹¤íŒ¨ ê±´ìˆ˜: {len(fail_log)}ê±´")
            else:
                logger.error(f"âŒ [ì €ì¥ ì‹¤íŒ¨] íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ!")
                logger.error(f"   ì˜ˆìƒ ê²½ë¡œ: {log_path}")
                logger.error(f"   ì ˆëŒ€ ê²½ë¡œ: {log_path.resolve()}")
                logger.error(f"   ë””ë ‰í† ë¦¬ ì¡´ì¬: {log_dir.exists()}")
                logger.error(f"   ë””ë ‰í† ë¦¬ ì“°ê¸° ê¶Œí•œ: {os.access(log_dir, os.W_OK)}")
            
        except PermissionError as e:
            logger.error(f"âŒ [ì €ì¥ ì‹¤íŒ¨] ê¶Œí•œ ì˜¤ë¥˜: {e}")
            logger.error(f"   ê²½ë¡œ: {log_path if 'log_path' in locals() else 'N/A'}")
            logger.error(f"   í˜„ì¬ ì‚¬ìš©ì: {os.getuid() if hasattr(os, 'getuid') else 'N/A'}")
        except Exception as e:
            logger.error(f"âŒ [ì €ì¥ ì‹¤íŒ¨] ì˜ˆì™¸ ë°œìƒ: {e}", exc_info=True)
            logger.error(f"   ì˜ˆì™¸ íƒ€ì…: {type(e).__name__}")
            if 'log_path' in locals():
                logger.error(f"   ê²½ë¡œ: {log_path}")
    
    def _get_http_client(self) -> httpx.AsyncClient:
        """HTTP í´ë¼ì´ì–¸íŠ¸ í’€ ë°˜í™˜ (ì¬ì‚¬ìš©ìœ¼ë¡œ ì†ë„ í–¥ìƒ)"""
        if self._http_client is None:
            # ì—°ê²° í’€ ì„¤ì •ìœ¼ë¡œ ì¬ì‚¬ìš© ìµœì í™”
            limits = httpx.Limits(max_keepalive_connections=50, max_connections=100)
            try:
                self._http_client = httpx.AsyncClient(
                    timeout=httpx.Timeout(15.0, connect=5.0),  # íƒ€ì„ì•„ì›ƒ ìµœì í™” (30ì´ˆ -> 15ì´ˆ)
                    limits=limits,
                    http2=False  # HTTP/2ëŠ” ì¼ë¶€ ì„œë²„ì—ì„œ ë¬¸ì œ ë°œìƒ ê°€ëŠ¥í•˜ë¯€ë¡œ ë¹„í™œì„±í™”
                )
            except Exception as e:
                # HTTP/2 ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ HTTP/1.1ë¡œ í´ë°±
                logger.warning(f"HTTP/2 ì´ˆê¸°í™” ì‹¤íŒ¨, HTTP/1.1ë¡œ í´ë°±: {e}")
                self._http_client = httpx.AsyncClient(
                    timeout=httpx.Timeout(15.0, connect=5.0),
                    limits=limits
                )
        return self._http_client
    
    async def _close_http_client(self):
        """HTTP í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ"""
        if self._http_client:
            await self._http_client.aclose()
            self._http_client = None
    
    async def fetch_with_retry(self, url: str, params: Dict[str, Any], retries: int = 3) -> Dict[str, Any]:
        """
        API í˜¸ì¶œ ì¬ì‹œë„ ë¡œì§ (ì§€ìˆ˜ ë°±ì˜¤í”„)
        """
        for attempt in range(retries):
            try:
                async with httpx.AsyncClient(timeout=10.0) as client:
                    response = await client.get(url, params=params)
                    response.raise_for_status()
                    return response.json()
            except httpx.TimeoutException:
                if attempt == retries - 1:
                    logger.warning(f"â° [Timeout] API í˜¸ì¶œ ì‹œê°„ ì´ˆê³¼ ({url}) - {retries}íšŒ ì‹œë„ ì‹¤íŒ¨")
                    raise
                await asyncio.sleep(0.5 * (2 ** attempt))
            except Exception as e:
                if attempt == retries - 1:
                    logger.warning(f"âŒ [API Error] {e} ({url})")
                    raise
                await asyncio.sleep(0.5 * (2 ** attempt))
        return {}
    
    async def fetch_region_data(
        self,
        city_name: str,
        page_no: int = 1,
        num_of_rows: int = 1000
    ) -> Dict[str, Any]:
        """
        êµ­í† ë¶€ APIì—ì„œ ì§€ì—­ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        
        Args:
            city_name: ì‹œë„ëª… (ì˜ˆ: ì„œìš¸íŠ¹ë³„ì‹œ)
            page_no: í˜ì´ì§€ ë²ˆí˜¸ (ê¸°ë³¸ê°’: 1)
            num_of_rows: í•œ í˜ì´ì§€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 1000)
        
        Returns:
            API ì‘ë‹µ ë°ì´í„° (dict)
        
        Raises:
            httpx.HTTPError: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        # URL ì¸ì½”ë”©
        encoded_city_name = quote(city_name)
        
        # API ìš”ì²­ íŒŒë¼ë¯¸í„°
        # locatadd_nm: ì£¼ì†Œëª…ìœ¼ë¡œ í•„í„°ë§ (ì‹œë„ëª…ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  ì£¼ì†Œ)
        params = {
            "serviceKey": self.api_key,
            "pageNo": str(page_no),
            "numOfRows": str(num_of_rows),
            "type": "json",
            "locatadd_nm": city_name  # ì˜ˆ: "ì„œìš¸íŠ¹ë³„ì‹œ"ë¡œ ê²€ìƒ‰í•˜ë©´ "ì„œìš¸íŠ¹ë³„ì‹œ"ë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  ì£¼ì†Œ ë°˜í™˜
        }
        
        logger.info(f"ğŸ“¡ API í˜¸ì¶œ: {city_name} (í˜ì´ì§€ {page_no}, ìš”ì²­: {num_of_rows}ê°œ)")
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.get(MOLIT_REGION_API_URL, params=params)
            response.raise_for_status()
            data = response.json()
            
            # API ì‘ë‹µ êµ¬ì¡° í™•ì¸ìš© ë¡œê¹… (ì²« í˜ì´ì§€ë§Œ)
            if page_no == 1:
                logger.debug(f"   ğŸ” API ì‘ë‹µ êµ¬ì¡° í™•ì¸: {list(data.keys()) if isinstance(data, dict) else 'ë¦¬ìŠ¤íŠ¸'}")
            
            return data
    
    def parse_region_data(
        self,
        api_response: Dict[str, Any],
        city_name: str
    ) -> tuple[List[Dict[str, str]], int, int]:
        """
        API ì‘ë‹µ ë°ì´í„° íŒŒì‹± (ëª¨ë“  ë ˆë²¨ ìˆ˜ì§‘)
        
        ì‹¤ì œ API ì‘ë‹µ êµ¬ì¡°:
        {
          "StanReginCd": [
            {
              "head": [
                {"totalCount": 493},
                {"numOfRows": "10", "pageNo": "1", "type": "JSON"},
                {"RESULT": {"resultCode": "INFO-0", "resultMsg": "NOMAL SERVICE"}}
              ]
            },
            {
              "row": [
                {
                  "region_cd": "1171000000",
                  "sido_cd": "11",
                  "sgg_cd": "710",
                  "umd_cd": "000",
                  "locatadd_nm": "ì„œìš¸íŠ¹ë³„ì‹œ ì†¡íŒŒêµ¬",
                  "locallow_nm": "ì†¡íŒŒêµ¬",
                  ...
                }
              ]
            }
          ]
        }
        
        Args:
            api_response: API ì‘ë‹µ ë°ì´í„°
            city_name: ì‹œë„ëª… (íŒŒë¼ë¯¸í„°ë¡œ ì „ë‹¬ë°›ì€ ê°’)
        
        Returns:
            (íŒŒì‹±ëœ ì§€ì—­ ë°ì´í„° ëª©ë¡, ì´ ê°œìˆ˜, ì›ë³¸ ë°ì´í„° ìˆ˜)
        """
        regions = []
        total_count = 0
        original_count = 0
        
        try:
            # StanReginCd ë°°ì—´ì—ì„œ ë°ì´í„° ì¶”ì¶œ
            stan_regin_cd = api_response.get("StanReginCd", [])
            
            if not stan_regin_cd or len(stan_regin_cd) < 2:
                logger.warning("âš ï¸ API ì‘ë‹µ êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¦…ë‹ˆë‹¤")
                return [], 0, 0
            
            # headì—ì„œ totalCount ì¶”ì¶œ
            head_data = stan_regin_cd[0].get("head", [])
            for head_item in head_data:
                if isinstance(head_item, dict) and "totalCount" in head_item:
                    total_count = int(head_item["totalCount"])
                    break
            
            # rowì—ì„œ ì‹¤ì œ ë°ì´í„° ì¶”ì¶œ
            row_data = stan_regin_cd[1].get("row", [])
            
            # rowê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
            if not isinstance(row_data, list):
                row_data = [row_data] if row_data else []
            
            # ì›ë³¸ ë°ì´í„° ìˆ˜ ì €ì¥ (í•„í„°ë§ ì „)
            original_count = len(row_data)
            
            for item in row_data:
                # í•„ìˆ˜ í•„ë“œ ì¶”ì¶œ
                region_cd = str(item.get("region_cd", "")).strip()
                locatadd_nm = str(item.get("locatadd_nm", "")).strip()  # ì „ì²´ ì£¼ì†Œëª… (ì˜ˆ: "ì„œìš¸íŠ¹ë³„ì‹œ ì†¡íŒŒêµ¬")
                locallow_nm = str(item.get("locallow_nm", "")).strip()  # ì‹œêµ°êµ¬ëª… (ì˜ˆ: "ì†¡íŒŒêµ¬")
                umd_cd = str(item.get("umd_cd", "")).strip()  # ìë©´ë™ ì½”ë“œ
                sgg_cd = str(item.get("sgg_cd", "")).strip()  # ì‹œêµ°êµ¬ ì½”ë“œ
                ri_cd = str(item.get("ri_cd", "")).strip()  # ë¦¬ ì½”ë“œ
                
                # region_cdê°€ 10ìë¦¬ê°€ ì•„ë‹ˆë©´ ê±´ë„ˆë›°ê¸°
                if len(region_cd) != 10:
                    continue
                
                # ëª¨ë“  ë ˆë²¨ ìˆ˜ì§‘ (ë‚˜ì¤‘ì— ìµœí•˜ìœ„ ë ˆë²¨ë§Œ í•„í„°ë§)
                # ì‹œë„ëª… ì¶”ì¶œ (locatadd_nmì—ì„œ ì¶”ì¶œí•˜ê±°ë‚˜ íŒŒë¼ë¯¸í„° ì‚¬ìš©)
                parsed_city = self._extract_city_name_from_address(locatadd_nm) or city_name
                
                # ì‹œêµ°êµ¬ëª…ì´ ì—†ìœ¼ë©´ locatadd_nmì—ì„œ ì¶”ì¶œ ì‹œë„
                if not locallow_nm:
                    # "ì„œìš¸íŠ¹ë³„ì‹œ ì†¡íŒŒêµ¬" -> "ì†¡íŒŒêµ¬"
                    parts = locatadd_nm.split()
                    if len(parts) >= 2:
                        locallow_nm = parts[-1]
                    else:
                        locallow_nm = locatadd_nm
                
                regions.append({
                    "region_code": region_cd,
                    "region_name": locallow_nm,
                    "city_name": parsed_city
                })
            
            logger.info(f"âœ… íŒŒì‹± ì™„ë£Œ: ì›ë³¸ {original_count}ê°œ â†’ ìˆ˜ì§‘ {len(regions)}ê°œ ì§€ì—­ (ëª¨ë“  ë ˆë²¨ ì €ì¥, ì „ì²´ {total_count}ê°œ ì¤‘)")
            return regions, total_count, original_count
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨: {e}")
            logger.debug(f"API ì‘ë‹µ: {api_response}")
            import traceback
            logger.debug(traceback.format_exc())
            return [], 0, 0
    
    
    def _extract_city_name_from_address(self, locatadd_nm: str) -> str:
        """
        ì£¼ì†Œëª…ì—ì„œ ì‹œë„ëª… ì¶”ì¶œ
        
        Args:
            locatadd_nm: ì „ì²´ ì£¼ì†Œëª… (ì˜ˆ: "ì„œìš¸íŠ¹ë³„ì‹œ ì†¡íŒŒêµ¬")
        
        Returns:
            ì‹œë„ëª… (ì˜ˆ: "ì„œìš¸íŠ¹ë³„ì‹œ")
        """
        if not locatadd_nm:
            return ""
        
        # ì£¼ì†Œëª…ì—ì„œ ì‹œë„ëª… ì¶”ì¶œ
        for city in CITY_NAMES:
            if locatadd_nm.startswith(city):
                return city
        
        return ""
    
    def _extract_city_name_from_code(self, region_code: str) -> str:
        """
        ì§€ì—­ì½”ë“œì—ì„œ ì‹œë„ëª… ì¶”ì¶œ
        
        Args:
            region_code: ì§€ì—­ì½”ë“œ (10ìë¦¬, ì²« 2ìë¦¬ê°€ ì‹œë„ì½”ë“œ)
        
        Returns:
            ì‹œë„ëª…
        """
        if len(region_code) < 2:
            return ""
        
        sido_code = region_code[:2]
        # ì‹œë„ì½”ë“œ ë§¤í•‘
        sido_map = {
            "11": "ì„œìš¸íŠ¹ë³„ì‹œ",
            "26": "ë¶€ì‚°ê´‘ì—­ì‹œ",
            "27": "ëŒ€êµ¬ê´‘ì—­ì‹œ",
            "28": "ì¸ì²œê´‘ì—­ì‹œ",
            "29": "ê´‘ì£¼ê´‘ì—­ì‹œ",
            "30": "ëŒ€ì „ê´‘ì—­ì‹œ",
            "31": "ìš¸ì‚°ê´‘ì—­ì‹œ",
            "36": "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ",
            "41": "ê²½ê¸°ë„",
            "42": "ê°•ì›íŠ¹ë³„ìì¹˜ë„",
            "43": "ì¶©ì²­ë¶ë„",
            "44": "ì¶©ì²­ë‚¨ë„",
            "45": "ì „ë¶íŠ¹ë³„ìì¹˜ë„",
            "46": "ì „ë¼ë‚¨ë„",
            "47": "ê²½ìƒë¶ë„",
            "48": "ê²½ìƒë‚¨ë„",
            "50": "ì œì£¼íŠ¹ë³„ìì¹˜ë„"
        }
        return sido_map.get(sido_code, "")
    
    async def collect_all_regions(
        self,
        db: AsyncSession
    ) -> StateCollectionResponse:
        """
        ëª¨ë“  ì‹œë„ì˜ ì§€ì—­ ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥
        
        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        
        Returns:
            ìˆ˜ì§‘ ê²°ê³¼
        """
        total_fetched = 0
        total_saved = 0
        skipped = 0
        errors = []
        
        logger.info("=" * 60)
        logger.info("ğŸš€ ì§€ì—­ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        logger.info(f"ğŸ“‹ ëŒ€ìƒ ì‹œë„: {len(CITY_NAMES)}ê°œ")
        logger.info(f"ğŸ“‹ ì‹œë„ ëª©ë¡: {', '.join(CITY_NAMES)}")
        logger.info("=" * 60)
        
        for idx, city_name in enumerate(CITY_NAMES, 1):
            logger.info(f"\n{'='*60}")
            logger.info(f"[{idx}/{len(CITY_NAMES)}] {city_name} ì²˜ë¦¬ ì‹œì‘ (í˜„ì¬ê¹Œì§€ ì „ì²´ ìˆ˜ì§‘: {total_fetched}ê°œ)")
            logger.info(f"{'='*60}")
            
            try:
                # API í˜¸ì¶œ
                page_no = 1
                has_more = True
                city_fetched = 0
                city_saved = 0
                city_skipped = 0
                city_total_original = 0  # í•´ë‹¹ ì‹œë„ì˜ ì „ì²´ ì›ë³¸ ë°ì´í„° ìˆ˜ (ëˆ„ì )
                num_of_rows = 700  # í˜ì´ì§€ë‹¹ ìš”ì²­í•  ë ˆì½”ë“œ ìˆ˜
                
                logger.info(f"   ğŸ” {city_name} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (í˜ì´ì§€ë‹¹ {num_of_rows}ê°œ ìš”ì²­, ëª¨ë“  ë ˆë²¨ ì €ì¥)")
                
                while has_more:
                    # API ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                    api_response = await self.fetch_region_data(
                        city_name=city_name,
                        page_no=page_no,
                        num_of_rows=num_of_rows
                    )
                    
                    # ë°ì´í„° íŒŒì‹± (ëª¨ë“  ë ˆë²¨ ìˆ˜ì§‘)
                    regions, _, original_count = self.parse_region_data(api_response, city_name)
                    
                    # ì›ë³¸ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ (APIì—ì„œ ë°ì´í„°ë¥¼ ë” ì´ìƒ ë°˜í™˜í•˜ì§€ ì•ŠìŒ)
                    if original_count == 0:
                        logger.info(f"   â„¹ï¸  í˜ì´ì§€ {page_no}: ì›ë³¸ ë°ì´í„° ì—†ìŒ (ì¢…ë£Œ)")
                        has_more = False
                        break
                    
                    city_total_original += original_count
                    city_fetched += len(regions)
                    total_fetched += len(regions)
                    
                    logger.info(f"   ğŸ“„ í˜ì´ì§€ {page_no}: ì›ë³¸ {original_count}ê°œ â†’ ìˆ˜ì§‘ {len(regions)}ê°œ ì§€ì—­ (ëª¨ë“  ë ˆë²¨, ëˆ„ì : {city_fetched}ê°œ)")
                    
                    # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (ì¤‘ë³µë§Œ ì œì™¸)
                    for region_idx, region_data in enumerate(regions, 1):
                        try:
                            region_code = region_data.get('region_code', 'Unknown')
                            region_name = region_data.get('region_name', 'Unknown')
                            region_city = region_data.get('city_name', city_name)
                            
                            # ìƒì„¸ ë¡œê·¸: ì–´ëŠ ë„ì˜ ì–´ëŠ ì§€ì—­ì„ ì²˜ë¦¬í•˜ëŠ”ì§€
                            logger.info(f"   ğŸ’¾ [{city_name}] {region_city} {region_name} (ì½”ë“œ: {region_code}) ì €ì¥ ì‹œë„... ({region_idx}/{len(regions)}ë²ˆì§¸)")
                            
                            state_create = StateCreate(**region_data)
                            db_obj, is_created = await state_crud.create_or_skip(
                                db,
                                obj_in=state_create
                            )
                            
                            if is_created:
                                city_saved += 1
                                total_saved += 1
                                logger.info(f"      âœ… ì €ì¥ ì™„ë£Œ: {region_city} {region_name} (ì „ì²´ ì €ì¥: {total_saved}ê°œ)")
                            else:
                                city_skipped += 1
                                skipped += 1
                                logger.info(f"      â­ï¸  ê±´ë„ˆëœ€ (ì´ë¯¸ ì¡´ì¬): {region_city} {region_name} (ì „ì²´ ê±´ë„ˆëœ€: {skipped}ê°œ)")
                                
                        except Exception as e:
                            error_msg = f"{city_name} - {region_data.get('region_name', 'Unknown')}: {str(e)}"
                            errors.append(error_msg)
                            logger.warning(f"      âš ï¸ ì €ì¥ ì‹¤íŒ¨: {error_msg}")
                    
                    # ë‹¤ìŒ í˜ì´ì§€ í™•ì¸
                    if original_count < num_of_rows:
                        logger.info(f"   âœ… ë§ˆì§€ë§‰ í˜ì´ì§€ë¡œ íŒë‹¨ (ì›ë³¸ {original_count}ê°œ < ìš”ì²­ {num_of_rows}ê°œ)")
                        has_more = False
                    else:
                        logger.info(f"   â­ï¸  ë‹¤ìŒ í˜ì´ì§€ë¡œ... (ì›ë³¸ {original_count}ê°œ, ë‹¤ìŒ í˜ì´ì§€: {page_no + 1})")
                        page_no += 1
                    
                    # API í˜¸ì¶œ ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ë”œë ˆì´
                    await asyncio.sleep(0.2)
                
                logger.info(f"âœ… {city_name} ì™„ë£Œ: ì´ {page_no}í˜ì´ì§€ ì²˜ë¦¬, ì›ë³¸ {city_total_original}ê°œ â†’ ìˆ˜ì§‘ {city_fetched}ê°œ, ì €ì¥ {city_saved}ê°œ, ê±´ë„ˆëœ€ {city_skipped}ê°œ")
                logger.info(f"   ğŸ“Š í˜„ì¬ê¹Œì§€ ì „ì²´ í†µê³„: ìˆ˜ì§‘ {total_fetched}ê°œ, ì €ì¥ {total_saved}ê°œ, ê±´ë„ˆëœ€ {skipped}ê°œ")
                logger.info(f"   â¡ï¸  ë‹¤ìŒ ì‹œë„ë¡œ ì§„í–‰í•©ë‹ˆë‹¤...")
                
            except Exception as e:
                error_msg = f"{city_name} ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
                errors.append(error_msg)
                logger.error(f"âŒ {error_msg}")
                logger.error(f"   âš ï¸ {city_name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ, ë‹¤ìŒ ì‹œë„ë¡œ ì§„í–‰í•©ë‹ˆë‹¤...")
                import traceback
                logger.error(traceback.format_exc())
                # ì˜ˆì™¸ê°€ ë°œìƒí•´ë„ ë‹¤ìŒ ì‹œë„ë¡œ ê³„ì† ì§„í–‰
                continue
        
        logger.info("=" * 60)
        logger.info("ğŸ‰ ì§€ì—­ ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
        logger.info(f"ğŸ“Š ìµœì¢… í†µê³„:")
        logger.info(f"   - ì²˜ë¦¬í•œ ì‹œë„: {len(CITY_NAMES)}ê°œ")
        logger.info(f"   - ê°€ì ¸ì˜´: {total_fetched}ê°œ")
        logger.info(f"   - ì €ì¥: {total_saved}ê°œ")
        logger.info(f"   - ê±´ë„ˆëœ€: {skipped}ê°œ")
        if errors:
            logger.warning(f"âš ï¸ ì˜¤ë¥˜ {len(errors)}ê°œ ë°œìƒ:")
            for error in errors[:10]:  # ìµœëŒ€ 10ê°œë§Œ ì¶œë ¥
                logger.warning(f"   - {error}")
            if len(errors) > 10:
                logger.warning(f"   ... ì™¸ {len(errors) - 10}ê°œ ì˜¤ë¥˜")
        logger.info("=" * 60)
        
        return StateCollectionResponse(
            success=len(errors) == 0,
            total_fetched=total_fetched,
            total_saved=total_saved,
            skipped=skipped,
            errors=errors,
            message=f"ìˆ˜ì§‘ ì™„ë£Œ: {total_saved}ê°œ ì €ì¥, {skipped}ê°œ ê±´ë„ˆëœ€"
        )


    async def fetch_apartment_data(
        self,
        page_no: int = 1,
        num_of_rows: int = 1000
    ) -> Dict[str, Any]:
        """
        êµ­í† ë¶€ APIì—ì„œ ì•„íŒŒíŠ¸ ëª©ë¡ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        
        Args:
            page_no: í˜ì´ì§€ ë²ˆí˜¸ (ê¸°ë³¸ê°’: 1)
            num_of_rows: í•œ í˜ì´ì§€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 1000)
        
        Returns:
            API ì‘ë‹µ ë°ì´í„° (dict)
        
        Raises:
            httpx.HTTPError: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        # API ìš”ì²­ íŒŒë¼ë¯¸í„°
        params = {
            "serviceKey": self.api_key,
            "pageNo": str(page_no),
            "numOfRows": str(num_of_rows)
        }
        
        logger.info(f"   ğŸ“¡ API í˜¸ì¶œ: í˜ì´ì§€ {page_no}, {num_of_rows}ê°œ ìš”ì²­")
        
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.get(MOLIT_APARTMENT_LIST_API_URL, params=params)
            response.raise_for_status()
            data = response.json()
            
            # ì²« í˜ì´ì§€ì¼ ë•Œë§Œ ë””ë²„ê·¸ ë¡œê·¸ ì¶œë ¥
            if page_no == 1:
                logger.debug(f"   ğŸ” API ì‘ë‹µ êµ¬ì¡°: {data}")
            
            return data
    
    def parse_apartment_data(
        self,
        api_response: Dict[str, Any]
    ) -> tuple[List[Dict[str, Any]], int, int]:
        """
        ì•„íŒŒíŠ¸ ëª©ë¡ API ì‘ë‹µ íŒŒì‹±
        
        Args:
            api_response: API ì‘ë‹µ ë°ì´í„°
        
        Returns:
            (íŒŒì‹±ëœ ì•„íŒŒíŠ¸ ëª©ë¡, ì „ì²´ ê°œìˆ˜, ì›ë³¸ ê°œìˆ˜)
        """
        try:
            # ì‘ë‹µ êµ¬ì¡°: response.body.items
            body = api_response.get("response", {}).get("body", {})
            items = body.get("items", [])
            total_count = int(body.get("totalCount", 0))
            
            # itemsê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš° (ë‹¨ì¼ ê°ì²´)
            if not isinstance(items, list):
                items = [items] if items else []
            
            original_count = len(items)
            apartments = []
            
            for item in items:
                if not item:
                    continue
                
                # API ì‘ë‹µ í•„ë“œ ë§¤í•‘
                kapt_code = item.get("kaptCode", "").strip()
                kapt_name = item.get("kaptName", "").strip()
                bjd_code = item.get("bjdCode", "").strip()
                
                # í•„ìˆ˜ í•„ë“œ ê²€ì¦
                if not kapt_code or not kapt_name or not bjd_code:
                    continue
                
                apartments.append({
                    "kapt_code": kapt_code,
                    "apt_name": kapt_name,
                    "bjd_code": bjd_code,  # ë²•ì •ë™ ì½”ë“œ (region_codeë¡œ ë§¤ì¹­)
                    "as1": item.get("as1"),  # ì‹œë„
                    "as2": item.get("as2"),  # ì‹œêµ°êµ¬
                    "as3": item.get("as3"),  # ìë©´ë™
                    "as4": item.get("as4")   # ë¦¬
                })
            
            logger.info(f"âœ… íŒŒì‹± ì™„ë£Œ: ì›ë³¸ {original_count}ê°œ â†’ ìˆ˜ì§‘ {len(apartments)}ê°œ ì•„íŒŒíŠ¸ (ì „ì²´ {total_count}ê°œ ì¤‘)")
            
            return apartments, total_count, original_count
            
        except Exception as e:
            logger.error(f"âŒ íŒŒì‹± ì˜¤ë¥˜: {e}")
            return [], 0, 0
    
    async def collect_all_apartments(
        self,
        db: AsyncSession
    ) -> ApartmentCollectionResponse:
        """
        ëª¨ë“  ì•„íŒŒíŠ¸ ëª©ë¡ ìˆ˜ì§‘
        
        êµ­í† ë¶€ ì•„íŒŒíŠ¸ ëª©ë¡ APIì—ì„œ ëª¨ë“  ì•„íŒŒíŠ¸ë¥¼ ê°€ì ¸ì™€ì„œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤.
        
        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
        
        Returns:
            ApartmentCollectionResponse: ìˆ˜ì§‘ ê²°ê³¼ í†µê³„
        """
        total_fetched = 0
        total_saved = 0
        skipped = 0
        errors = []
        
        try:
            logger.info("=" * 80)
            logger.info("ğŸ¢ ì•„íŒŒíŠ¸ ëª©ë¡ ìˆ˜ì§‘ ì‹œì‘")
            logger.info("=" * 80)
            
            page_no = 1
            has_more = True
            num_of_rows = 1000  # í˜ì´ì§€ë‹¹ ìš”ì²­í•  ë ˆì½”ë“œ ìˆ˜
            
            logger.info(f"ğŸ” ì•„íŒŒíŠ¸ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (í˜ì´ì§€ë‹¹ {num_of_rows}ê°œ ìš”ì²­)")
            
            while has_more:
                # API ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                api_response = await self.fetch_apartment_data(
                    page_no=page_no,
                    num_of_rows=num_of_rows
                )
                
                # ë°ì´í„° íŒŒì‹±
                apartments, total_count, original_count = self.parse_apartment_data(api_response)
                
                # ì›ë³¸ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ
                if original_count == 0:
                    logger.info(f"   â„¹ï¸  í˜ì´ì§€ {page_no}: ì›ë³¸ ë°ì´í„° ì—†ìŒ (ì¢…ë£Œ)")
                    has_more = False
                    break
                
                total_fetched += len(apartments)
                
                logger.info(f"   ğŸ“„ í˜ì´ì§€ {page_no}: ì›ë³¸ {original_count}ê°œ â†’ ìˆ˜ì§‘ {len(apartments)}ê°œ ì•„íŒŒíŠ¸ (ëˆ„ì : {total_fetched}ê°œ)")
                
                # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
                for apt_idx, apt_data in enumerate(apartments, 1):
                    try:
                        kapt_code = apt_data.get('kapt_code', 'Unknown')
                        apt_name = apt_data.get('apt_name', 'Unknown')
                        bjd_code = apt_data.get('bjd_code', '')
                        
                        # bjdCodeë¥¼ region_codeë¡œ ì‚¬ìš©í•˜ì—¬ region_id ì°¾ê¸°
                        region = await state_crud.get_by_region_code(db, region_code=bjd_code)
                        
                        if not region:
                            error_msg = f"ì•„íŒŒíŠ¸ '{apt_name}' (ì½”ë“œ: {kapt_code}): ë²•ì •ë™ ì½”ë“œ '{bjd_code}'ì— í•´ë‹¹í•˜ëŠ” ì§€ì—­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                            errors.append(error_msg)
                            logger.warning(f"      âš ï¸ {error_msg}")
                            continue
                        
                        # ìƒì„¸ ë¡œê·¸
                        logger.info(f"   ğŸ’¾ [{region.city_name} {region.region_name}] {apt_name} (ë‹¨ì§€ì½”ë“œ: {kapt_code}) ì €ì¥ ì‹œë„... ({apt_idx}/{len(apartments)}ë²ˆì§¸)")
                        
                        apartment_create = ApartmentCreate(
                            region_id=region.region_id,
                            apt_name=apt_name,
                            kapt_code=kapt_code,
                            is_available=None  # ê¸°ë³¸ê°’
                        )
                        
                        db_obj, is_created = await apartment_crud.create_or_skip(
                            db,
                            obj_in=apartment_create
                        )
                        
                        if is_created:
                            total_saved += 1
                            logger.info(f"      âœ… ì €ì¥ ì™„ë£Œ: {apt_name} (ì „ì²´ ì €ì¥: {total_saved}ê°œ)")
                        else:
                            skipped += 1
                            logger.info(f"      â­ï¸  ê±´ë„ˆëœ€ (ì´ë¯¸ ì¡´ì¬): {apt_name} (ì „ì²´ ê±´ë„ˆëœ€: {skipped}ê°œ)")
                            
                    except Exception as e:
                        error_msg = f"ì•„íŒŒíŠ¸ '{apt_data.get('apt_name', 'Unknown')}': {str(e)}"
                        errors.append(error_msg)
                        logger.warning(f"      âš ï¸ ì €ì¥ ì‹¤íŒ¨: {error_msg}")
                
                # ë‹¤ìŒ í˜ì´ì§€ í™•ì¸
                if original_count < num_of_rows:
                    logger.info(f"   âœ… ë§ˆì§€ë§‰ í˜ì´ì§€ë¡œ íŒë‹¨ (ì›ë³¸ {original_count}ê°œ < ìš”ì²­ {num_of_rows}ê°œ)")
                    has_more = False
                else:
                    logger.info(f"   â­ï¸  ë‹¤ìŒ í˜ì´ì§€ë¡œ... (ì›ë³¸ {original_count}ê°œ, ë‹¤ìŒ í˜ì´ì§€: {page_no + 1})")
                    page_no += 1
                
                # API í˜¸ì¶œ ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ë”œë ˆì´
                await asyncio.sleep(0.2)
            
            logger.info("=" * 80)
            logger.info(f"âœ… ì•„íŒŒíŠ¸ ëª©ë¡ ìˆ˜ì§‘ ì™„ë£Œ")
            logger.info(f"   - ì´ {page_no}í˜ì´ì§€ ì²˜ë¦¬")
            logger.info(f"   - ìˆ˜ì§‘: {total_fetched}ê°œ")
            logger.info(f"   - ì €ì¥: {total_saved}ê°œ")
            logger.info(f"   - ê±´ë„ˆëœ€: {skipped}ê°œ")
            if errors:
                logger.info(f"   - ì˜¤ë¥˜: {len(errors)}ê°œ")
            logger.info("=" * 80)
            
            return ApartmentCollectionResponse(
                success=True,
                total_fetched=total_fetched,
                total_saved=total_saved,
                skipped=skipped,
                errors=errors,
                message=f"ìˆ˜ì§‘ ì™„ë£Œ: {total_saved}ê°œ ì €ì¥, {skipped}ê°œ ê±´ë„ˆëœ€"
            )
            
        except Exception as e:
            logger.error(f"âŒ ì•„íŒŒíŠ¸ ëª©ë¡ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}", exc_info=True)
            return ApartmentCollectionResponse(
                success=False,
                total_fetched=total_fetched,
                total_saved=total_saved,
                skipped=skipped,
                errors=errors + [str(e)],
                message=f"ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}"
            )

    async def fetch_apartment_basic_info(self, kapt_code: str, retries: int = 3) -> Dict[str, Any]:
        """
        êµ­í† ë¶€ APIì—ì„œ ì•„íŒŒíŠ¸ ê¸°ë³¸ì •ë³´ ê°€ì ¸ì˜¤ê¸° (Rate Limit ì²˜ë¦¬ í¬í•¨)
        
        HTTP í´ë¼ì´ì–¸íŠ¸ í’€ì„ ì¬ì‚¬ìš©í•˜ê³ , 429 ì—ëŸ¬ ì‹œ ì¬ì‹œë„ ë° ë”œë ˆì´ ì²˜ë¦¬
        
        Args:
            kapt_code: êµ­í† ë¶€ ë‹¨ì§€ì½”ë“œ
            retries: ì¬ì‹œë„ íšŸìˆ˜
        
        Returns:
            API ì‘ë‹µ ë°ì´í„° (dict)
        
        Raises:
            httpx.HTTPError: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        params = {
            "serviceKey": self.api_key,
            "kaptCode": kapt_code
        }
        
        client = self._get_http_client()
        
        for attempt in range(retries):
            try:
                response = await client.get(MOLIT_APARTMENT_BASIC_API_URL, params=params)
                
                # 429 ì—ëŸ¬ ì²˜ë¦¬ (Rate Limit)
                if response.status_code == 429:
                    wait_time = (attempt + 1) * 2  # ì§€ìˆ˜ ë°±ì˜¤í”„: 2ì´ˆ, 4ì´ˆ, 6ì´ˆ
                    logger.warning(f"âš ï¸ Rate Limit (429) ë°œìƒ, {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                    await asyncio.sleep(wait_time)
                    continue
                
                response.raise_for_status()
                logger.info(f"âœ… ì™¸ë¶€ API í˜¸ì¶œ ì„±ê³µ: ê¸°ë³¸ì •ë³´ API (kapt_code: {kapt_code})")
                data = response.json()
                return data
                
            except httpx.HTTPStatusError as e:
                if e.response.status_code == 429 and attempt < retries - 1:
                    wait_time = (attempt + 1) * 2
                    logger.warning(f"âš ï¸ Rate Limit (429) ë°œìƒ, {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                    await asyncio.sleep(wait_time)
                    continue
                raise
        
        raise httpx.HTTPStatusError("Rate Limit ì´ˆê³¼", request=None, response=None)
    
    async def fetch_apartment_detail_info(self, kapt_code: str, retries: int = 3) -> Dict[str, Any]:
        """
        êµ­í† ë¶€ APIì—ì„œ ì•„íŒŒíŠ¸ ìƒì„¸ì •ë³´ ê°€ì ¸ì˜¤ê¸° (Rate Limit ì²˜ë¦¬ í¬í•¨)
        
        HTTP í´ë¼ì´ì–¸íŠ¸ í’€ì„ ì¬ì‚¬ìš©í•˜ê³ , 429 ì—ëŸ¬ ì‹œ ì¬ì‹œë„ ë° ë”œë ˆì´ ì²˜ë¦¬
        
        Args:
            kapt_code: êµ­í† ë¶€ ë‹¨ì§€ì½”ë“œ
            retries: ì¬ì‹œë„ íšŸìˆ˜
        
        Returns:
            API ì‘ë‹µ ë°ì´í„° (dict)
        
        Raises:
            httpx.HTTPError: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        params = {
            "serviceKey": self.api_key,
            "kaptCode": kapt_code
        }
        
        client = self._get_http_client()
        
        for attempt in range(retries):
            try:
                response = await client.get(MOLIT_APARTMENT_DETAIL_API_URL, params=params)
                
                # 429 ì—ëŸ¬ ì²˜ë¦¬ (Rate Limit)
                if response.status_code == 429:
                    wait_time = (attempt + 1) * 2  # ì§€ìˆ˜ ë°±ì˜¤í”„: 2ì´ˆ, 4ì´ˆ, 6ì´ˆ
                    logger.warning(f"âš ï¸ Rate Limit (429) ë°œìƒ, {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                    await asyncio.sleep(wait_time)
                    continue
                
                response.raise_for_status()
                logger.info(f"âœ… ì™¸ë¶€ API í˜¸ì¶œ ì„±ê³µ: ìƒì„¸ì •ë³´ API (kapt_code: {kapt_code})")
                data = response.json()
                return data
                
            except httpx.HTTPStatusError as e:
                if e.response.status_code == 429 and attempt < retries - 1:
                    wait_time = (attempt + 1) * 2
                    logger.warning(f"âš ï¸ Rate Limit (429) ë°œìƒ, {wait_time}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                    await asyncio.sleep(wait_time)
                    continue
                raise
        
        raise httpx.HTTPStatusError("Rate Limit ì´ˆê³¼", request=None, response=None)
    
    def parse_date(self, date_str: Optional[str]) -> Optional[str]:
        """
        ë‚ ì§œ ë¬¸ìì—´ íŒŒì‹± (YYYYMMDD -> YYYY-MM-DD)
        
        Args:
            date_str: YYYYMMDD í˜•ì‹ì˜ ë‚ ì§œ ë¬¸ìì—´
        
        Returns:
            YYYY-MM-DD í˜•ì‹ì˜ ë‚ ì§œ ë¬¸ìì—´ ë˜ëŠ” None
        """
        if not date_str or len(date_str) != 8:
            return None
        try:
            return f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
        except Exception:
            return None
    
    def parse_int(self, value: Any) -> Optional[int]:
        """
        ì •ìˆ˜ë¡œ ë³€í™˜ (ì‹¤íŒ¨ ì‹œ None ë°˜í™˜)
        
        Args:
            value: ë³€í™˜í•  ê°’
        
        Returns:
            ì •ìˆ˜ ë˜ëŠ” None
        """
        if value is None or value == "":
            return None
        try:
            if isinstance(value, str):
                # ë¹ˆ ë¬¸ìì—´ì´ë‚˜ ê³µë°± ì œê±°
                value = value.strip()
                if not value:
                    return None
            return int(value)
        except (ValueError, TypeError):
            return None
    
    def parse_float(self, value: Any) -> Optional[float]:
        """ë¬¸ìì—´/ìˆ«ìë¥¼ floatë¡œ ë³€í™˜"""
        if value is None or value == "": return None
        try:
            if isinstance(value, str):
                value = value.strip()
                if not value: return None
            return float(value)
        except (ValueError, TypeError): return None
    
    def parse_apartment_details(
        self,
        basic_info: Dict[str, Any],
        detail_info: Dict[str, Any],
        apt_id: int
    ) -> Optional[ApartDetailCreate]:
        """
        ë‘ API ì‘ë‹µì„ ì¡°í•©í•˜ì—¬ ApartDetailCreate ê°ì²´ ìƒì„±
        
        Args:
            basic_info: ê¸°ë³¸ì •ë³´ API ì‘ë‹µ
            detail_info: ìƒì„¸ì •ë³´ API ì‘ë‹µ
            apt_id: ì•„íŒŒíŠ¸ ID
        
        Returns:
            ApartDetailCreate ê°ì²´ ë˜ëŠ” None
        """
        try:
            logger.debug(f"íŒŒì‹± ì‹œì‘: apt_id={apt_id}")
            
            # ê¸°ë³¸ì •ë³´ íŒŒì‹±
            basic_item = basic_info.get("response", {}).get("body", {}).get("item", {})
            if not basic_item:
                logger.warning(f"âš ï¸ íŒŒì‹± ì‹¤íŒ¨: ê¸°ë³¸ì •ë³´ API ì‘ë‹µì— itemì´ ì—†ìŠµë‹ˆë‹¤. (apt_id: {apt_id})")
                logger.debug(f"ê¸°ë³¸ì •ë³´ ì‘ë‹µ êµ¬ì¡°: {basic_info}")
                return None
            
            # ìƒì„¸ì •ë³´ íŒŒì‹±
            detail_item = detail_info.get("response", {}).get("body", {}).get("item", {})
            if not detail_item:
                logger.warning(f"âš ï¸ íŒŒì‹± ì‹¤íŒ¨: ìƒì„¸ì •ë³´ API ì‘ë‹µì— itemì´ ì—†ìŠµë‹ˆë‹¤. (apt_id: {apt_id})")
                logger.debug(f"ìƒì„¸ì •ë³´ ì‘ë‹µ êµ¬ì¡°: {detail_info}")
                return None
            
            # í•„ìˆ˜ í•„ë“œ ê²€ì¦: ë„ë¡œëª… ì£¼ì†Œ ë˜ëŠ” ì§€ë²ˆ ì£¼ì†Œ
            doro_juso = basic_item.get("doroJuso", "").strip() if basic_item.get("doroJuso") else ""
            kapt_addr = basic_item.get("kaptAddr", "").strip() if basic_item.get("kaptAddr") else ""
            
            if not doro_juso and not kapt_addr:
                logger.warning(f"âš ï¸ íŒŒì‹± ì‹¤íŒ¨: ë„ë¡œëª… ì£¼ì†Œì™€ ì§€ë²ˆ ì£¼ì†Œê°€ ëª¨ë‘ ì—†ìŠµë‹ˆë‹¤. (apt_id: {apt_id})")
                return None
            
            # ë„ë¡œëª… ì£¼ì†Œê°€ ì—†ìœ¼ë©´ ì§€ë²ˆ ì£¼ì†Œ ì‚¬ìš©
            if not doro_juso:
                doro_juso = kapt_addr
            # ì§€ë²ˆ ì£¼ì†Œê°€ ì—†ìœ¼ë©´ ë„ë¡œëª… ì£¼ì†Œ ì‚¬ìš©
            if not kapt_addr:
                kapt_addr = doro_juso
            
            # ìš°í¸ë²ˆí˜¸ ì²˜ë¦¬ (5ìë¦¬ë¡œ ì œí•œ)
            zipcode = basic_item.get("zipcode", "").strip() if basic_item.get("zipcode") else None
            if zipcode and len(zipcode) > 5:
                zipcode = zipcode[:5]
            
            # ë‚ ì§œ íŒŒì‹±
            use_approval_date_str = self.parse_date(basic_item.get("kaptUsedate"))
            use_approval_date = None
            if use_approval_date_str:
                try:
                    from datetime import datetime
                    use_approval_date = datetime.strptime(use_approval_date_str, "%Y-%m-%d").date()
                except Exception:
                    pass
            
            # ì´ ì„¸ëŒ€ ìˆ˜ (í•„ìˆ˜)
            kaptda_cnt_raw = basic_item.get("kaptdaCnt")
            total_household_cnt = self.parse_int(kaptda_cnt_raw)
            
            if total_household_cnt is None:
                logger.debug(f"ì´ ì„¸ëŒ€ ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤. (ì›ë³¸ ê°’: {kaptda_cnt_raw})")
                return None
            
            # ê´€ë¦¬ ë°©ì‹: ìƒì„¸ì •ë³´ì˜ codeMgr ìš°ì„ , ì—†ìœ¼ë©´ ê¸°ë³¸ì •ë³´ì˜ codeMgrNm
            manage_type = detail_item.get("codeMgr", "").strip()
            if not manage_type:
                manage_type = basic_item.get("codeMgrNm", "").strip()
            if not manage_type:
                manage_type = None
            
            # ì§€í•˜ì²  ì •ë³´: ìƒì„¸ì •ë³´ ìš°ì„  (100ì ì œí•œ)
            subway_line = detail_item.get("subwayLine", "").strip() if detail_item.get("subwayLine") else None
            subway_station = detail_item.get("subwayStation", "").strip() if detail_item.get("subwayStation") else None
            subway_time = detail_item.get("kaptdWtimesub", "").strip() if detail_item.get("kaptdWtimesub") else None
            
            # 100ì ì´ˆê³¼ ì‹œ ìë¥´ê¸° (ìŠ¤í‚¤ë§ˆ ì œí•œì— ë§ì¶¤)
            if subway_line and len(subway_line) > 100:
                subway_line = subway_line[:100]
                logger.debug(f"subway_lineì´ 100ìë¥¼ ì´ˆê³¼í•˜ì—¬ ì˜ë¦¼: {len(detail_item.get('subwayLine', ''))}ì -> 100ì")
            if subway_station and len(subway_station) > 100:
                subway_station = subway_station[:100]
                logger.debug(f"subway_stationì´ 100ìë¥¼ ì´ˆê³¼í•˜ì—¬ ì˜ë¦¼: {len(detail_item.get('subwayStation', ''))}ì -> 100ì")
            if subway_time and len(subway_time) > 100:
                subway_time = subway_time[:100]
                logger.debug(f"subway_timeì´ 100ìë¥¼ ì´ˆê³¼í•˜ì—¬ ì˜ë¦¼: {len(detail_item.get('kaptdWtimesub', ''))}ì -> 100ì")
            
            # êµìœ¡ ì‹œì„¤ (200ì ì œí•œ)
            education_facility = detail_item.get("educationFacility", "").strip() if detail_item.get("educationFacility") else None
            if education_facility and len(education_facility) > 200:
                education_facility = education_facility[:200]
                logger.debug(f"educationFacilityê°€ 200ìë¥¼ ì´ˆê³¼í•˜ì—¬ ì˜ë¦¼: {len(detail_item.get('educationFacility', ''))}ì -> 200ì")
            
            # ApartDetailCreate ê°ì²´ ìƒì„±
            try:
                detail_create = ApartDetailCreate(
                    apt_id=apt_id,
                    road_address=doro_juso,
                    jibun_address=kapt_addr,
                    zip_code=zipcode,
                    code_sale_nm=basic_item.get("codeSaleNm", "").strip() if basic_item.get("codeSaleNm") else None,
                    code_heat_nm=basic_item.get("codeHeatNm", "").strip() if basic_item.get("codeHeatNm") else None,
                    total_household_cnt=total_household_cnt,
                    total_building_cnt=self.parse_int(basic_item.get("kaptDongCnt")),
                    highest_floor=self.parse_int(basic_item.get("kaptTopFloor")),
                    use_approval_date=use_approval_date,
                    total_parking_cnt=self.parse_int(detail_item.get("kaptdPcntu")),
                    builder_name=basic_item.get("kaptBcompany", "").strip() if basic_item.get("kaptBcompany") else None,
                    developer_name=basic_item.get("kaptAcompany", "").strip() if basic_item.get("kaptAcompany") else None,
                    manage_type=manage_type,
                    hallway_type=basic_item.get("codeHallNm", "").strip() if basic_item.get("codeHallNm") else None,
                    subway_time=subway_time,
                    subway_line=subway_line,
                    subway_station=subway_station,
                    educationFacility=education_facility,
                    geometry=None  # APIì—ì„œ ì œê³µë˜ì§€ ì•ŠìŒ
                )
                logger.debug(f"ApartDetailCreate ê°ì²´ ìƒì„± ì™„ë£Œ")
                return detail_create
            except Exception as create_error:
                logger.error(f"ApartDetailCreate ê°ì²´ ìƒì„± ì‹¤íŒ¨: {str(create_error)}")
                import traceback
                logger.debug(f"ìƒì„¸ ìŠ¤íƒ: {traceback.format_exc()}")
                return None
            
        except Exception as e:
            logger.error(f"íŒŒì‹± ì˜¤ë¥˜: {e}")
            import traceback
            logger.debug(f"ìƒì„¸ ìŠ¤íƒ: {traceback.format_exc()}")
            return None
    
    async def _process_single_apartment(
        self,
        apt: Apartment,
        semaphore: asyncio.Semaphore
    ) -> Dict[str, Any]:
        """
        ë‹¨ì¼ ì•„íŒŒíŠ¸ì˜ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ë° ì €ì¥ (ìµœì í™” ë²„ì „)
        
        ì‚¬ì „ ì¤‘ë³µ ì²´í¬ë¥¼ ê±°ì³¤ìœ¼ë¯€ë¡œ ë°”ë¡œ API í˜¸ì¶œí•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
        ê° ì‘ì—…ì´ ë…ë¦½ì ì¸ ì„¸ì…˜ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        
        Args:
            apt: ì•„íŒŒíŠ¸ ê°ì²´
            semaphore: ë™ì‹œì„± ì œì–´ìš© ì„¸ë§ˆí¬ì–´
        
        Returns:
            {
                "success": bool,
                "apt_name": str,
                "saved": bool,  # ì €ì¥ ì„±ê³µ ì—¬ë¶€
                "skipped": bool,  # ê±´ë„ˆëœ€ ì—¬ë¶€
                "error": str ë˜ëŠ” None
            }
        """
        async with semaphore:
            # ë…ë¦½ì ì¸ ì„¸ì…˜ ì‚¬ìš©
            async with AsyncSessionLocal() as local_db:
                try:
                    # ì‚¬ì „ ì¤‘ë³µ ì²´í¬ë¥¼ ê±°ì³¤ì§€ë§Œ, ë™ì‹œì„± ë¬¸ì œë¥¼ ëŒ€ë¹„í•´ í•œ ë²ˆ ë” ì²´í¬
                    exists_stmt = select(ApartDetail).where(
                        and_(
                            ApartDetail.apt_id == apt.apt_id,
                            ApartDetail.is_deleted == False
                        )
                    )
                    exists_result = await local_db.execute(exists_stmt)
                    existing_detail = exists_result.scalars().first()
                    
                    if existing_detail:
                        return {
                            "success": True,
                            "apt_name": apt.apt_name,
                            "saved": False,
                            "skipped": True,
                            "error": None
                        }
                    
                    # ê¸°ë³¸ì •ë³´ì™€ ìƒì„¸ì •ë³´ API í˜¸ì¶œ (Rate Limit ë°©ì§€ë¥¼ ìœ„í•´ ìˆœì°¨ ì²˜ë¦¬)
                    logger.info(f"ğŸŒ ì™¸ë¶€ API í˜¸ì¶œ ì‹œì‘: {apt.apt_name} (kapt_code: {apt.kapt_code})")
                    # 429 ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ ìˆœì°¨ì ìœ¼ë¡œ í˜¸ì¶œ (ê° í˜¸ì¶œ ì‚¬ì´ì— ì‘ì€ ë”œë ˆì´)
                    basic_info = await self.fetch_apartment_basic_info(apt.kapt_code)
                    await asyncio.sleep(0.1)  # API í˜¸ì¶œ ê°„ ì‘ì€ ë”œë ˆì´
                    detail_info = await self.fetch_apartment_detail_info(apt.kapt_code)
                    
                    # ì˜ˆì™¸ ì²˜ë¦¬
                    if isinstance(basic_info, Exception):
                        error_msg = f"ê¸°ë³¸ì •ë³´ API ì˜¤ë¥˜: {str(basic_info)}"
                        logger.debug(f"âŒ {apt.apt_name}: {error_msg}")
                        return {
                            "success": False,
                            "apt_name": apt.apt_name,
                            "saved": False,
                            "skipped": False,
                            "error": error_msg
                        }
                    
                    if isinstance(detail_info, Exception):
                        error_msg = f"ìƒì„¸ì •ë³´ API ì˜¤ë¥˜: {str(detail_info)}"
                        logger.debug(f"âŒ {apt.apt_name}: {error_msg}")
                        return {
                            "success": False,
                            "apt_name": apt.apt_name,
                            "saved": False,
                            "skipped": False,
                            "error": error_msg
                        }
                    
                    # ì‘ë‹µ ê²€ì¦
                    basic_result_code = basic_info.get("response", {}).get("header", {}).get("resultCode", "")
                    detail_result_code = detail_info.get("response", {}).get("header", {}).get("resultCode", "")
                    
                    if basic_result_code != "00":
                        basic_msg = basic_info.get("response", {}).get("header", {}).get("resultMsg", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
                        return {
                            "success": False,
                            "apt_name": apt.apt_name,
                            "saved": False,
                            "skipped": False,
                            "error": f"ê¸°ë³¸ì •ë³´ API ì˜¤ë¥˜: {basic_msg}"
                        }
                    
                    if detail_result_code != "00":
                        detail_msg = detail_info.get("response", {}).get("header", {}).get("resultMsg", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
                        return {
                            "success": False,
                            "apt_name": apt.apt_name,
                            "saved": False,
                            "skipped": False,
                            "error": f"ìƒì„¸ì •ë³´ API ì˜¤ë¥˜: {detail_msg}"
                        }
                    
                    # 3. ë°ì´í„° íŒŒì‹±
                    logger.info(f"ğŸ” íŒŒì‹± ì‹œì‘: {apt.apt_name} (apt_id: {apt.apt_id}, kapt_code: {apt.kapt_code})")
                    detail_create = self.parse_apartment_details(basic_info, detail_info, apt.apt_id)
                    
                    if not detail_create:
                        logger.warning(f"âš ï¸ íŒŒì‹± ì‹¤íŒ¨: {apt.apt_name} (kapt_code: {apt.kapt_code}) - í•„ìˆ˜ í•„ë“œ ëˆ„ë½")
                        return {
                            "success": False,
                            "apt_name": apt.apt_name,
                            "saved": False,
                            "skipped": False,
                            "error": "íŒŒì‹± ì‹¤íŒ¨: í•„ìˆ˜ í•„ë“œ ëˆ„ë½"
                        }
                    
                    logger.info(f"âœ… íŒŒì‹± ì„±ê³µ: {apt.apt_name} (apt_id: {apt.apt_id})")
                    
                    # 4. ì €ì¥ (ë§¤ë§¤/ì „ì›”ì„¸ì™€ ë™ì¼í•œ ë°©ì‹)
                    logger.info(f"ğŸ’¾ ì €ì¥ ì‹œë„: {apt.apt_name} (apt_id: {apt.apt_id})")
                    try:
                        # apt_detail_idë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì œê±°í•˜ì—¬ ìë™ ìƒì„±ë˜ë„ë¡ í•¨
                        detail_dict = detail_create.model_dump()
                        # apt_detail_idê°€ ìˆìœ¼ë©´ ì œê±° (ìë™ ìƒì„±ë˜ì–´ì•¼ í•¨)
                        if 'apt_detail_id' in detail_dict:
                            logger.warning(f"âš ï¸ apt_detail_idê°€ ìŠ¤í‚¤ë§ˆì— í¬í•¨ë˜ì–´ ìˆìŒ: {detail_dict.get('apt_detail_id')} - ì œê±°í•¨")
                            detail_dict.pop('apt_detail_id')
                        
                        # SQLAlchemyê°€ ìë™ìœ¼ë¡œ ì‹œí€€ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë„ë¡ í•¨
                        db_obj = ApartDetail(**detail_dict)
                        # apt_detail_idë¥¼ ëª…ì‹œì ìœ¼ë¡œ Noneìœ¼ë¡œ ì„¤ì • (ì‹œí€€ìŠ¤ ì‚¬ìš© ê°•ì œ)
                        db_obj.apt_detail_id = None
                        local_db.add(db_obj)
                        await local_db.commit()
                        await local_db.refresh(db_obj)  # ìƒì„±ëœ apt_detail_id ê°€ì ¸ì˜¤ê¸°
                        logger.info(f"âœ… ì €ì¥ ì„±ê³µ: {apt.apt_name} (apt_id: {apt.apt_id}, apt_detail_id: {db_obj.apt_detail_id}, kapt_code: {apt.kapt_code})")
                        
                        return {
                            "success": True,
                            "apt_name": apt.apt_name,
                            "saved": True,
                            "skipped": False,
                            "error": None
                        }
                    except Exception as save_error:
                        await local_db.rollback()
                        logger.error(f"âŒ ì €ì¥ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {apt.apt_name} (apt_id: {apt.apt_id}) - {save_error}")
                        raise save_error
                    
                except Exception as e:
                    await local_db.rollback()
                    # ì¤‘ë³µ í‚¤ ì—ëŸ¬ ì²˜ë¦¬
                    from sqlalchemy.exc import IntegrityError
                    if isinstance(e, IntegrityError):
                        error_str = str(e).lower()
                        # apt_id ì¤‘ë³µ (unique constraint) ë˜ëŠ” apt_detail_id ì¤‘ë³µ (primary key)
                        if 'duplicate key' in error_str or 'unique constraint' in error_str:
                            # ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ ë‹¤ì‹œ í™•ì¸
                            verify_stmt = select(ApartDetail).where(
                                and_(
                                    ApartDetail.apt_id == apt.apt_id,
                                    ApartDetail.is_deleted == False
                                )
                            )
                            verify_result = await local_db.execute(verify_stmt)
                            existing = verify_result.scalars().first()
                            
                            if existing:
                                logger.info(f"â­ï¸ ì¤‘ë³µìœ¼ë¡œ ê±´ë„ˆëœ€: {apt.apt_name} (apt_id: {apt.apt_id}, apt_detail_id: {existing.apt_detail_id}) - ì´ë¯¸ ì¡´ì¬í•¨")
                            else:
                                # apt_detail_id ì¤‘ë³µ ì—ëŸ¬ì¸ ê²½ìš° ì‹œí€€ìŠ¤ ë¬¸ì œë¡œ íŒë‹¨
                                if 'apt_detail_id' in str(e) or 'apart_details_pkey' in str(e):
                                    logger.error(
                                        f"âŒ ì‹œí€€ìŠ¤ ë™ê¸°í™” ë¬¸ì œ ê°ì§€: {apt.apt_name} (apt_id: {apt.apt_id}). "
                                        f"apart_details í…Œì´ë¸”ì˜ apt_detail_id ì‹œí€€ìŠ¤ê°€ ì‹¤ì œ ë°ì´í„°ì™€ ë™ê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. "
                                        f"ë‹¤ìŒ SQLì„ ì‹¤í–‰í•˜ì„¸ìš”: "
                                        f"SELECT setval('apart_details_apt_detail_id_seq', COALESCE((SELECT MAX(apt_detail_id) FROM apart_details), 0) + 1, false);"
                                    )
                                else:
                                    logger.warning(
                                        f"âš ï¸ ì¤‘ë³µ ì—ëŸ¬ ë°œìƒí–ˆì§€ë§Œ ì‹¤ì œë¡œëŠ” ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {apt.apt_name} (apt_id: {apt.apt_id}). "
                                        f"ì—ëŸ¬: {str(e)}"
                                    )
                            
                            return {
                                "success": True,
                                "apt_name": apt.apt_name,
                                "saved": False,
                                "skipped": True,
                                "error": None
                            }
                    
                    logger.error(f"âŒ ì•„íŒŒíŠ¸ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨ ({apt.apt_name}): {e}", exc_info=True)
                    return {
                        "success": False,
                        "apt_name": apt.apt_name,
                        "saved": False,
                        "skipped": False,
                        "error": str(e)
                    }
    
    async def collect_apartment_details(
        self,
        db: AsyncSession,
        limit: Optional[int] = None
    ) -> ApartDetailCollectionResponse:
        """
        ëª¨ë“  ì•„íŒŒíŠ¸ì˜ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ (ì´ˆê³ ì† ìµœì í™” ë²„ì „)
        
        ìµœì í™” ë°©ì•ˆ:
        1. ì‚¬ì „ ì¤‘ë³µ ì²´í¬ë¡œ ë¶ˆí•„ìš”í•œ API í˜¸ì¶œ ì œê±° (ê°€ì¥ ì¤‘ìš”!)
        2. HTTP í´ë¼ì´ì–¸íŠ¸ í’€ ì¬ì‚¬ìš©
        3. ë³‘ë ¬ ì²˜ë¦¬ ì¦ê°€
        4. íƒ€ì„ì•„ì›ƒ ìµœì í™”
        
        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜ (ì•„íŒŒíŠ¸ ëª©ë¡ ì¡°íšŒìš©)
            limit: ì²˜ë¦¬í•  ì•„íŒŒíŠ¸ ìˆ˜ ì œí•œ (Noneì´ë©´ ì „ì²´)
        
        Returns:
            ApartDetailCollectionResponse: ìˆ˜ì§‘ ê²°ê³¼ í†µê³„
        """
        total_processed = 0
        total_saved = 0
        skipped = 0
        errors = []
        # ë³‘ë ¬ ì²˜ë¦¬ (API Rate Limit ê³ ë ¤í•˜ì—¬ ì¡°ì •)
        # ê° ì•„íŒŒíŠ¸ë§ˆë‹¤ 2ê°œ API í˜¸ì¶œ(ê¸°ë³¸ì •ë³´+ìƒì„¸ì •ë³´)ì´ ë³‘ë ¬ë¡œ ë°œìƒí•˜ë¯€ë¡œ ì‹¤ì œ ë™ì‹œ ìš”ì²­ì€ 2ë°°
        CONCURRENT_LIMIT = 5  # 429 ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ 5ê°œë¡œ ì œí•œ (ì‹¤ì œ ë™ì‹œ ìš”ì²­: ìµœëŒ€ 10ê°œ)
        semaphore = asyncio.Semaphore(CONCURRENT_LIMIT)
        BATCH_SIZE = 16  # ë°°ì¹˜ í¬ê¸° ê°ì†Œ (100 -> 50 -> 40)
        
        try:
            logger.info("ğŸš€ [ì´ˆê³ ì† ëª¨ë“œ] ì•„íŒŒíŠ¸ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹œì‘")
            logger.info(f"   ì„¤ì •: ë³‘ë ¬ {CONCURRENT_LIMIT}ê°œ, ë°°ì¹˜ {BATCH_SIZE}ê°œ")
            logger.info("   ìµœì í™”: ì‚¬ì „ ì¤‘ë³µ ì²´í¬ + HTTP í’€ ì¬ì‚¬ìš© + Rate Limit ì²˜ë¦¬")
            loop_limit = limit if limit else 1000000
            
            while total_processed < loop_limit:
                fetch_limit = min(BATCH_SIZE, loop_limit - total_processed)
                if fetch_limit <= 0: break
                
                # ì•„íŒŒíŠ¸ ëª©ë¡ ì¡°íšŒ (ë©”ì¸ ì„¸ì…˜ ì‚¬ìš©)
                targets = await apartment_crud.get_multi_missing_details(db, limit=fetch_limit)
                
                if not targets:
                    logger.info("âœ¨ ë” ì´ìƒ ìˆ˜ì§‘í•  ì•„íŒŒíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    break
                
                logger.info(f"   ğŸ” 1ì°¨ í•„í„°ë§: get_multi_missing_details ë°˜í™˜ {len(targets)}ê°œ")
                
                # ğŸš€ ìµœì í™” 1: ì‚¬ì „ ì¤‘ë³µ ì²´í¬ë¡œ ë¶ˆí•„ìš”í•œ API í˜¸ì¶œ ì œê±°
                apt_ids = [apt.apt_id for apt in targets]
                check_stmt = select(ApartDetail.apt_id).where(
                    and_(
                        ApartDetail.apt_id.in_(apt_ids),
                        ApartDetail.is_deleted == False
                    )
                )
                check_result = await db.execute(check_stmt)
                existing_apt_ids = set(check_result.scalars().all())
                
                # ì¤‘ë³µì´ ì•„ë‹Œ ì•„íŒŒíŠ¸ë§Œ í•„í„°ë§
                targets_to_process = [apt for apt in targets if apt.apt_id not in existing_apt_ids]
                pre_skipped = len(existing_apt_ids)
                skipped += pre_skipped
                
                # ğŸš¨ ì¤‘ìš”: 1ì°¨ í•„í„°ë§ ê²°ê³¼ì™€ 2ì°¨ ì²´í¬ ê²°ê³¼ê°€ ë‹¤ë¥´ë©´ ê²½ê³ 
                if pre_skipped > 0:
                    logger.warning(
                        f"   âš ï¸  ì¤‘ë³µ ë°œê²¬: 1ì°¨ í•„í„°ë§ì—ì„œ {len(targets)}ê°œ ë°˜í™˜í–ˆì§€ë§Œ, "
                        f"2ì°¨ ì²´í¬ì—ì„œ {pre_skipped}ê°œê°€ ì´ë¯¸ ì¡´ì¬í•¨. "
                        f"get_multi_missing_details ì¿¼ë¦¬ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤!"
                    )
                
                if not targets_to_process:
                    logger.info(f"   â­ï¸  ë°°ì¹˜ ì „ì²´ ê±´ë„ˆëœ€ ({pre_skipped}ê°œ ì´ë¯¸ ì¡´ì¬) - API í˜¸ì¶œ ì—†ìŒ âœ…")
                    total_processed += len(targets)
                    continue
                
                logger.info(
                    f"   ğŸ“Š ë°°ì¹˜: ì „ì²´ {len(targets)}ê°œ ì¤‘ {pre_skipped}ê°œ ê±´ë„ˆëœ€, "
                    f"{len(targets_to_process)}ê°œ ì²˜ë¦¬ (ì˜ˆìƒ API í˜¸ì¶œ: {len(targets_to_process) * 2}íšŒ)"
                )
                
                # ë³‘ë ¬ë¡œ ì²˜ë¦¬ (ê° ì‘ì—…ì´ ë…ë¦½ì ì¸ ì„¸ì…˜ ì‚¬ìš©)
                # Rate Limitì„ ê³ ë ¤í•˜ì—¬ ì‘ì€ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
                batch_tasks = []
                for i in range(0, len(targets_to_process), CONCURRENT_LIMIT):
                    batch = targets_to_process[i:i + CONCURRENT_LIMIT]
                    tasks = [self._process_single_apartment(apt, semaphore) for apt in batch]
                    batch_tasks.append(tasks)
                
                # ê° ë°°ì¹˜ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬ (Rate Limit ë°©ì§€)
                all_results = []
                for batch_idx, tasks in enumerate(batch_tasks):
                    results = await asyncio.gather(*tasks, return_exceptions=True)
                    all_results.extend(results)
                    
                    # ë°°ì¹˜ ê°„ ë”œë ˆì´ (Rate Limit ë°©ì§€) - 429 ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ ì¦ê°€
                    if batch_idx < len(batch_tasks) - 1:  # ë§ˆì§€ë§‰ ë°°ì¹˜ê°€ ì•„ë‹ˆë©´
                        delay_time = 0.1  # 2ì´ˆ ë”œë ˆì´ë¡œ ì¦ê°€
                        logger.info(f"   â¸ï¸  ë°°ì¹˜ ê°„ {delay_time}ì´ˆ ëŒ€ê¸° ì¤‘... (Rate Limit ë°©ì§€)")
                        await asyncio.sleep(delay_time)
                
                results = all_results
                
                # ê²°ê³¼ ì§‘ê³„
                batch_saved = 0
                batch_skipped = 0
                batch_errors = 0
                error_samples = []  # ì—ëŸ¬ ìƒ˜í”Œ (ì²˜ìŒ 5ê°œë§Œ)
                
                for res in results:
                    if isinstance(res, Exception):
                        batch_errors += 1
                        error_msg = f"ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸: {str(res)}"
                        errors.append(error_msg)
                        if len(error_samples) < 5:
                            error_samples.append(error_msg)
                        continue
                    
                    if res.get("success"):
                        if res.get("saved"):
                            batch_saved += 1
                            total_saved += 1
                        elif res.get("skipped"):
                            batch_skipped += 1
                            skipped += 1
                    else:
                        batch_errors += 1
                        error_msg = f"{res.get('apt_name', 'Unknown')}: {res.get('error', 'Unknown error')}"
                        errors.append(error_msg)
                        if len(error_samples) < 5:
                            error_samples.append(error_msg)
                
                # ì—ëŸ¬ê°€ ìˆìœ¼ë©´ ìƒ˜í”Œ ì¶œë ¥
                if batch_errors > 0 and error_samples:
                    logger.warning(f"   âš ï¸ ì—ëŸ¬ ìƒ˜í”Œ (ì´ {batch_errors}ê°œ ì¤‘): {error_samples[:3]}")
                
                total_processed += len(targets)
                
                # ë¡œê·¸ ì¶œë ¥
                if batch_saved > 0 or batch_skipped > 0 or batch_errors > 0:
                    logger.info(
                        f"   ğŸ’¾ ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ: ì €ì¥ {batch_saved}ê°œ, "
                        f"ê±´ë„ˆëœ€ {batch_skipped}ê°œ, ì‹¤íŒ¨ {batch_errors}ê°œ "
                        f"(ì‚¬ì „ ê±´ë„ˆëœ€ {pre_skipped}ê°œ í¬í•¨, ëˆ„ì : ì €ì¥ {total_saved}ê°œ, ê±´ë„ˆëœ€ {skipped}ê°œ)"
                    )

            # HTTP í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ
            await self._close_http_client()
            
            logger.info("=" * 60)
            logger.info(f"ğŸ‰ ìˆ˜ì§‘ ì™„ë£Œ (ì´ {total_saved}ê°œ ì €ì¥, {skipped}ê°œ ê±´ë„ˆëœ€, {len(errors)}ê°œ ì˜¤ë¥˜)")
            return ApartDetailCollectionResponse(
                success=True,
                total_processed=total_processed,
                total_saved=total_saved,
                skipped=skipped,
                errors=errors[:100],
                message=f"ì´ˆê³ ì† ìˆ˜ì§‘ ì™„ë£Œ: {total_saved}ê°œ ì €ì¥ë¨"
            )

        except Exception as e:
            await self._close_http_client()
            logger.error(f"âŒ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
            return ApartDetailCollectionResponse(success=False, total_processed=total_processed, errors=[str(e)], message=f"ì˜¤ë¥˜: {str(e)}")

    # =========================================================================
    # ì „ì›”ì„¸ ì‹¤ê±°ë˜ê°€ ìˆ˜ì§‘ ë©”ì„œë“œ
    # =========================================================================
    
    async def fetch_rent_data(
        self,
        lawd_cd: str,
        deal_ymd: str
    ) -> str:
        """
        êµ­í† êµí†µë¶€ APIì—ì„œ ì•„íŒŒíŠ¸ ì „ì›”ì„¸ ì‹¤ê±°ë˜ê°€ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        
        Args:
            lawd_cd: ì§€ì—­ì½”ë“œ (ë²•ì •ë™ì½”ë“œ ì• 5ìë¦¬)
            deal_ymd: ê³„ì•½ë…„ì›” (YYYYMM)
        
        Returns:
            XML ì‘ë‹µ ë¬¸ìì—´
        
        Raises:
            httpx.HTTPError: API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        
        Note:
            - API ì¸ì¦í‚¤ëŠ” ì„œë²„ì˜ MOLIT_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
            - êµ­í† ë¶€ ì „ì›”ì„¸ APIëŠ” XML í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•©ë‹ˆë‹¤.
            - JSON ë³€í™˜ì€ parse_rent_xml_to_json() ë©”ì„œë“œì—ì„œ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        """
        
        params = {
            "serviceKey": self.api_key,
            "LAWD_CD": lawd_cd,
            "DEAL_YMD": deal_ymd
        }
        
        logger.info(f"ğŸ“¡ ì „ì›”ì„¸ API í˜¸ì¶œ: ì§€ì—­ì½”ë“œ={lawd_cd}, ê³„ì•½ë…„ì›”={deal_ymd}")
        
        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.get(MOLIT_RENT_API_URL, params=params)
            response.raise_for_status()
            
            # ì‘ë‹µì´ XMLì´ë¯€ë¡œ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜
            return response.text
    
    def parse_rent_xml_to_json(
        self,
        xml_data: str
    ) -> tuple[List[Dict[str, Any]], str, str]:
        """
        êµ­í† ë¶€ ì „ì›”ì„¸ API XML ì‘ë‹µì„ JSONìœ¼ë¡œ ë³€í™˜
        
        Args:
            xml_data: XML ì‘ë‹µ ë¬¸ìì—´
        
        Returns:
            (ê±°ë˜ ë°ì´í„° ë¦¬ìŠ¤íŠ¸, ê²°ê³¼ì½”ë“œ, ê²°ê³¼ë©”ì‹œì§€)
        
        Note:
            - xmltodict ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ XML â†’ dict ë³€í™˜
            - API ì‘ë‹µì˜ ë¹ˆ ê°’(" ")ì€ Noneìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        """
        try:
            # XML â†’ dict ë³€í™˜
            data = xmltodict.parse(xml_data)
            
            # ì‘ë‹µ êµ¬ì¡° ì¶”ì¶œ
            response = data.get("response", {})
            header = response.get("header", {})
            body = response.get("body", {})
            
            result_code = header.get("resultCode", "")
            result_msg = header.get("resultMsg", "")
            
            # ê²°ê³¼ ì½”ë“œ í™•ì¸ (000 ë˜ëŠ” 00ì´ ì„±ê³µ)
            if result_code not in ["000", "00"]:
                logger.warning(f"âš ï¸ API ì‘ë‹µ ì˜¤ë¥˜: {result_code} - {result_msg}")
                return [], result_code, result_msg
            
            # items ì¶”ì¶œ
            items = body.get("items", {})
            if not items:
                logger.info("   â„¹ï¸ ì¡°íšŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return [], result_code, result_msg
            
            item_list = items.get("item", [])
            
            # ë‹¨ì¼ ì•„ì´í…œì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            if isinstance(item_list, dict):
                item_list = [item_list]
            
            # ë¹ˆ ê°’(" ") â†’ None ë³€í™˜
            cleaned_items = []
            for item in item_list:
                cleaned_item = {}
                for key, value in item.items():
                    if isinstance(value, str) and value.strip() == "":
                        cleaned_item[key] = None
                    else:
                        cleaned_item[key] = value
                cleaned_items.append(cleaned_item)
            
            logger.info(f"âœ… XML â†’ JSON ë³€í™˜ ì™„ë£Œ: {len(cleaned_items)}ê°œ ê±°ë˜ ë°ì´í„°")
            
            return cleaned_items, result_code, result_msg
            
        except Exception as e:
            logger.error(f"âŒ XML íŒŒì‹± ì‹¤íŒ¨: {e}")
            return [], "PARSE_ERROR", str(e)
    
    def parse_rent_item_from_xml(
        self,
        item: ET.Element,
        apt_id: int,
        apt_name: str = ""
    ) -> Optional[RentCreate]:
        """
        ì „ì›”ì„¸ ê±°ë˜ ë°ì´í„° íŒŒì‹± (XML Element)
        
        API ì‘ë‹µì˜ ë‹¨ì¼ XML ì•„ì´í…œì„ RentCreate ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            item: API ì‘ë‹µ ì•„ì´í…œ (XML Element)
            apt_id: ë§¤ì¹­ëœ ì•„íŒŒíŠ¸ ID
        
        Returns:
            RentCreate ìŠ¤í‚¤ë§ˆ ë˜ëŠ” None (íŒŒì‹± ì‹¤íŒ¨ ì‹œ)
        
        Note:
            - ë³´ì¦ê¸ˆê³¼ ì›”ì„¸ì˜ ì‰¼í‘œ(,)ë¥¼ ì œê±°í•˜ê³  ì •ìˆ˜ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
            - ê±°ë˜ì¼ì€ dealYear, dealMonth, dealDayë¥¼ ì¡°í•©í•˜ì—¬ ìƒì„±í•©ë‹ˆë‹¤.
            - ê³„ì•½ìœ í˜•ì€ "ê°±ì‹ "ì´ë©´ True, ê·¸ ì™¸ì—ëŠ” False ë˜ëŠ” Noneì…ë‹ˆë‹¤.
            - monthlyRentê°€ 0ì´ë©´ ì „ì„¸, 0ì´ ì•„ë‹ˆë©´ ì›”ì„¸ì…ë‹ˆë‹¤.
        """
        try:
            # ê±°ë˜ì¼ íŒŒì‹± (í•„ìˆ˜)
            deal_year_elem = item.find("dealYear")
            deal_month_elem = item.find("dealMonth")
            deal_day_elem = item.find("dealDay")
            
            deal_year = deal_year_elem.text.strip() if deal_year_elem is not None and deal_year_elem.text else None
            deal_month = deal_month_elem.text.strip() if deal_month_elem is not None and deal_month_elem.text else None
            deal_day = deal_day_elem.text.strip() if deal_day_elem is not None and deal_day_elem.text else None
            
            if not deal_year or not deal_month or not deal_day:
                apt_nm_elem = item.find("aptNm")
                apt_nm = apt_nm_elem.text if apt_nm_elem is not None and apt_nm_elem.text else "Unknown"
                logger.warning(f"   âš ï¸ ê±°ë˜ì¼ ì •ë³´ ëˆ„ë½: {apt_nm}")
                return None
            
            try:
                deal_date_obj = date(
                    int(deal_year),
                    int(deal_month),
                    int(deal_day)
                )
            except (ValueError, TypeError) as e:
                logger.warning(f"   âš ï¸ ê±°ë˜ì¼ ë³€í™˜ ì‹¤íŒ¨: {deal_year}-{deal_month}-{deal_day}, ì˜¤ë¥˜: {e}")
                return None
            
            # ì „ìš©ë©´ì  íŒŒì‹± (í•„ìˆ˜)
            exclu_use_ar_elem = item.find("excluUseAr")
            exclu_use_ar = exclu_use_ar_elem.text.strip() if exclu_use_ar_elem is not None and exclu_use_ar_elem.text else None
            
            if not exclu_use_ar:
                apt_nm_elem = item.find("aptNm")
                apt_nm = apt_nm_elem.text if apt_nm_elem is not None and apt_nm_elem.text else "Unknown"
                logger.warning(f"   âš ï¸ ì „ìš©ë©´ì  ì •ë³´ ëˆ„ë½: {apt_nm}")
                return None
            
            try:
                exclusive_area = float(exclu_use_ar)
            except (ValueError, TypeError):
                logger.warning(f"   âš ï¸ ì „ìš©ë©´ì  ë³€í™˜ ì‹¤íŒ¨: {exclu_use_ar}")
                return None
            
            # ì¸µ íŒŒì‹± (í•„ìˆ˜)
            floor_elem = item.find("floor")
            floor_str = floor_elem.text.strip() if floor_elem is not None and floor_elem.text else None
            
            if not floor_str:
                apt_nm_elem = item.find("aptNm")
                apt_nm = apt_nm_elem.text if apt_nm_elem is not None and apt_nm_elem.text else "Unknown"
                logger.warning(f"   âš ï¸ ì¸µ ì •ë³´ ëˆ„ë½: {apt_nm}")
                return None
            
            try:
                floor = int(floor_str)
            except (ValueError, TypeError):
                logger.warning(f"   âš ï¸ ì¸µ ë³€í™˜ ì‹¤íŒ¨: {floor_str}")
                return None
            
            # ë³´ì¦ê¸ˆ íŒŒì‹± (ì‰¼í‘œ ì œê±°)
            deposit_elem = item.find("deposit")
            deposit_str = deposit_elem.text.strip() if deposit_elem is not None and deposit_elem.text else None
            deposit_price = None
            if deposit_str:
                try:
                    deposit_price = int(deposit_str.replace(",", ""))
                except (ValueError, TypeError, AttributeError):
                    pass
            
            # ì›”ì„¸ íŒŒì‹±
            monthly_rent_elem = item.find("monthlyRent")
            monthly_rent_str = monthly_rent_elem.text.strip() if monthly_rent_elem is not None and monthly_rent_elem.text else None
            monthly_rent = None
            if monthly_rent_str:
                try:
                    monthly_rent = int(monthly_rent_str.replace(",", ""))
                except (ValueError, TypeError, AttributeError):
                    pass
            
            # ì „ì„¸/ì›”ì„¸ êµ¬ë¶„: monthlyRentê°€ 0ì´ë©´ ì „ì„¸, 0ì´ ì•„ë‹ˆë©´ ì›”ì„¸
            # ì „ì„¸ì¸ ê²½ìš°: deposit_priceê°€ ì „ì„¸ê°€, monthly_rentëŠ” None
            # ì›”ì„¸ì¸ ê²½ìš°: deposit_priceê°€ ë³´ì¦ê¸ˆ, monthly_rentê°€ ì›”ì„¸ê°€
            if monthly_rent == 0:
                # ì „ì„¸
                monthly_rent = None
            # ì›”ì„¸ì¸ ê²½ìš°ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€
            
            # ê³„ì•½ìœ í˜• íŒŒì‹± (ê°±ì‹ =True, ì‹ ê·œ/None=False)
            contract_type_elem = item.find("contractType")
            contract_type_str = contract_type_elem.text.strip() if contract_type_elem is not None and contract_type_elem.text else None
            contract_type = None
            if contract_type_str:
                contract_type = contract_type_str.strip() == "ê°±ì‹ "
            
            # apt_seq ì¶”ì¶œ
            apt_seq_elem = item.find("aptSeq")
            apt_seq = apt_seq_elem.text.strip() if apt_seq_elem is not None and apt_seq_elem.text else None
            if apt_seq and len(apt_seq) > 10:
                apt_seq = apt_seq[:10]  # DB ì»¬ëŸ¼ ì œí•œì— ë§ê²Œ ìë¥´ê¸°
            
            # ê±´ì¶•ë…„ë„
            build_year_elem = item.find("buildYear")
            build_year = build_year_elem.text.strip() if build_year_elem is not None and build_year_elem.text else None
            
            return RentCreate(
                apt_id=apt_id,
                build_year=build_year,
                contract_type=contract_type,
                deposit_price=deposit_price,
                monthly_rent=monthly_rent,
                exclusive_area=exclusive_area,
                floor=floor,
                apt_seq=apt_seq,
                deal_date=deal_date_obj,
                contract_date=None,  # APIì—ì„œ ë³„ë„ ì œê³µí•˜ì§€ ì•ŠìŒ
                remarks=apt_name  # ì•„íŒŒíŠ¸ ì´ë¦„ ì €ì¥
            )
            
        except Exception as e:
            logger.error(f"   âŒ ê±°ë˜ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨: {e}")
            import traceback
            logger.debug(f"   ìƒì„¸: {traceback.format_exc()}")
            return None
    
    def parse_rent_item(
        self,
        item: Dict[str, Any],
        apt_id: int
    ) -> Optional[RentCreate]:
        """
        ì „ì›”ì„¸ ê±°ë˜ ë°ì´í„° íŒŒì‹± (Dict - ë ˆê±°ì‹œ)
        
        API ì‘ë‹µì˜ ë‹¨ì¼ ì•„ì´í…œì„ RentCreate ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            item: API ì‘ë‹µ ì•„ì´í…œ (dict)
            apt_id: ë§¤ì¹­ëœ ì•„íŒŒíŠ¸ ID
        
        Returns:
            RentCreate ìŠ¤í‚¤ë§ˆ ë˜ëŠ” None (íŒŒì‹± ì‹¤íŒ¨ ì‹œ)
        
        Note:
            - ë³´ì¦ê¸ˆê³¼ ì›”ì„¸ì˜ ì‰¼í‘œ(,)ë¥¼ ì œê±°í•˜ê³  ì •ìˆ˜ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
            - ê±°ë˜ì¼ì€ dealYear, dealMonth, dealDayë¥¼ ì¡°í•©í•˜ì—¬ ìƒì„±í•©ë‹ˆë‹¤.
            - ê³„ì•½ìœ í˜•ì€ "ê°±ì‹ "ì´ë©´ True, ê·¸ ì™¸ì—ëŠ” False ë˜ëŠ” Noneì…ë‹ˆë‹¤.
        """
        try:
            # ê±°ë˜ì¼ íŒŒì‹± (í•„ìˆ˜)
            deal_year = item.get("dealYear")
            deal_month = item.get("dealMonth")
            deal_day = item.get("dealDay")
            
            if not deal_year or not deal_month or not deal_day:
                logger.warning(f"   âš ï¸ ê±°ë˜ì¼ ì •ë³´ ëˆ„ë½: {item.get('aptNm', 'Unknown')}")
                return None
            
            try:
                deal_date_obj = date(
                    int(deal_year),
                    int(deal_month),
                    int(deal_day)
                )
            except (ValueError, TypeError) as e:
                logger.warning(f"   âš ï¸ ê±°ë˜ì¼ ë³€í™˜ ì‹¤íŒ¨: {deal_year}-{deal_month}-{deal_day}, ì˜¤ë¥˜: {e}")
                return None
            
            # ì „ìš©ë©´ì  íŒŒì‹± (í•„ìˆ˜)
            exclu_use_ar = item.get("excluUseAr")
            if not exclu_use_ar:
                logger.warning(f"   âš ï¸ ì „ìš©ë©´ì  ì •ë³´ ëˆ„ë½: {item.get('aptNm', 'Unknown')}")
                return None
            
            try:
                exclusive_area = float(exclu_use_ar)
            except (ValueError, TypeError):
                logger.warning(f"   âš ï¸ ì „ìš©ë©´ì  ë³€í™˜ ì‹¤íŒ¨: {exclu_use_ar}")
                return None
            
            # ì¸µ íŒŒì‹± (í•„ìˆ˜)
            floor_str = item.get("floor")
            if not floor_str:
                logger.warning(f"   âš ï¸ ì¸µ ì •ë³´ ëˆ„ë½: {item.get('aptNm', 'Unknown')}")
                return None
            
            try:
                floor = int(floor_str)
            except (ValueError, TypeError):
                logger.warning(f"   âš ï¸ ì¸µ ë³€í™˜ ì‹¤íŒ¨: {floor_str}")
                return None
            
            # ë³´ì¦ê¸ˆ íŒŒì‹± (ì‰¼í‘œ ì œê±°)
            deposit_str = item.get("deposit")
            deposit_price = None
            if deposit_str:
                try:
                    deposit_price = int(deposit_str.replace(",", ""))
                except (ValueError, TypeError, AttributeError):
                    pass
            
            # ì›”ì„¸ íŒŒì‹±
            monthly_rent_str = item.get("monthlyRent")
            monthly_rent = None
            if monthly_rent_str:
                try:
                    monthly_rent = int(monthly_rent_str.replace(",", ""))
                except (ValueError, TypeError, AttributeError):
                    pass
            
            # ê³„ì•½ìœ í˜• íŒŒì‹± (ê°±ì‹ =True, ì‹ ê·œ/None=False)
            contract_type_str = item.get("contractType")
            contract_type = None
            if contract_type_str:
                contract_type = contract_type_str.strip() == "ê°±ì‹ "
            
            # apt_seq ì¶”ì¶œ
            apt_seq = item.get("aptSeq")
            if apt_seq and len(apt_seq) > 10:
                apt_seq = apt_seq[:10]  # DB ì»¬ëŸ¼ ì œí•œì— ë§ê²Œ ìë¥´ê¸°
            
            # ê±´ì¶•ë…„ë„
            build_year = item.get("buildYear")
            
            return RentCreate(
                apt_id=apt_id,
                build_year=build_year,
                contract_type=contract_type,
                deposit_price=deposit_price,
                monthly_rent=monthly_rent,
                exclusive_area=exclusive_area,
                floor=floor,
                apt_seq=apt_seq,
                deal_date=deal_date_obj,
                contract_date=None  # APIì—ì„œ ë³„ë„ ì œê³µí•˜ì§€ ì•ŠìŒ
            )
            
        except Exception as e:
            logger.error(f"   âŒ ê±°ë˜ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨: {e}")
            import traceback
            logger.debug(f"   ìƒì„¸: {traceback.format_exc()}")
            return None
    
    async def find_apartment_by_name_and_region(
        self,
        db: AsyncSession,
        apt_name: str,
        sgg_cd: str
    ) -> Optional[Apartment]:
        """
        ì•„íŒŒíŠ¸ ì´ë¦„ê³¼ ì‹œêµ°êµ¬ ì½”ë“œë¡œ ì•„íŒŒíŠ¸ ê²€ìƒ‰
        
        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            apt_name: ì•„íŒŒíŠ¸ ì´ë¦„
            sgg_cd: ì‹œêµ°êµ¬ ì½”ë“œ (5ìë¦¬)
        
        Returns:
            Apartment ê°ì²´ ë˜ëŠ” None
        
        Note:
            - ë¨¼ì € ì‹œêµ°êµ¬ ì½”ë“œë¡œ ì‹œì‘í•˜ëŠ” region_codeë¥¼ ê°€ì§„ ì§€ì—­ì„ ì°¾ìŠµë‹ˆë‹¤.
            - í•´ë‹¹ ì§€ì—­ì— ì†í•œ ì•„íŒŒíŠ¸ ì¤‘ ì´ë¦„ì´ ì¼ì¹˜í•˜ëŠ” ê²ƒì„ ì°¾ìŠµë‹ˆë‹¤.
            - ì´ë¦„ì´ ì •í™•íˆ ì¼ì¹˜í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ LIKE ê²€ìƒ‰ë„ ì‹œë„í•©ë‹ˆë‹¤.
        """
        from app.models.state import State
        
        try:
            # 1ë‹¨ê³„: ì‹œêµ°êµ¬ ì½”ë“œë¡œ ì‹œì‘í•˜ëŠ” regionì„ ê°€ì§„ ì•„íŒŒíŠ¸ ì°¾ê¸° (ì •í™•í•œ ì´ë¦„ ë§¤ì¹­)
            result = await db.execute(
                select(Apartment)
                .join(State, Apartment.region_id == State.region_id)
                .where(
                    State.region_code.like(f"{sgg_cd}%"),
                    Apartment.apt_name == apt_name,
                    Apartment.is_deleted == False
                )
                .limit(1)
            )
            apartment = result.scalar_one_or_none()
            
            if apartment:
                return apartment
            
            # 2ë‹¨ê³„: ì´ë¦„ ë¶€ë¶„ ë§¤ì¹­ ì‹œë„ (ì˜ˆ: "ì•„íŒŒíŠ¸" ì ‘ë¯¸ì‚¬ ì œê±° ë“±)
            # "â—‹â—‹ì•„íŒŒíŠ¸" â†’ "â—‹â—‹" ë˜ëŠ” "â—‹â—‹" â†’ "â—‹â—‹ì•„íŒŒíŠ¸"
            search_names = [apt_name]
            if apt_name.endswith("ì•„íŒŒíŠ¸"):
                search_names.append(apt_name[:-3])  # "ì•„íŒŒíŠ¸" ì œê±°
            else:
                search_names.append(apt_name + "ì•„íŒŒíŠ¸")  # "ì•„íŒŒíŠ¸" ì¶”ê°€
            
            for name in search_names:
                result = await db.execute(
                    select(Apartment)
                    .join(State, Apartment.region_id == State.region_id)
                    .where(
                        State.region_code.like(f"{sgg_cd}%"),
                        Apartment.apt_name.like(f"%{name}%"),
                        Apartment.is_deleted == False
                    )
                    .limit(1)
                )
                apartment = result.scalar_one_or_none()
                if apartment:
                    return apartment
            
            return None
            
        except Exception as e:
            logger.error(f"   âŒ ì•„íŒŒíŠ¸ ê²€ìƒ‰ ì‹¤íŒ¨ ({apt_name}): {e}")
            return None
    
    async def collect_rent_transactions(
        self,
        db: AsyncSession,
        lawd_cd: str,
        deal_ymd: str
    ) -> RentCollectionResponse:
        """
        ì „ì›”ì„¸ ì‹¤ê±°ë˜ê°€ ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥
        
        êµ­í† êµí†µë¶€ APIì—ì„œ ì „ì›”ì„¸ ì‹¤ê±°ë˜ê°€ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ DBì— ì €ì¥í•©ë‹ˆë‹¤.
        
        Args:
            db: ë°ì´í„°ë² ì´ìŠ¤ ì„¸ì…˜
            lawd_cd: ì§€ì—­ì½”ë“œ (ë²•ì •ë™ì½”ë“œ ì• 5ìë¦¬)
            deal_ymd: ê³„ì•½ë…„ì›” (YYYYMM)
        
        Returns:
            RentCollectionResponse: ìˆ˜ì§‘ ê²°ê³¼ í†µê³„
        
        Note:
            - API ì¸ì¦í‚¤ëŠ” ì„œë²„ì˜ MOLIT_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
            - XML ì‘ë‹µì„ JSONìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
            - ì•„íŒŒíŠ¸ ì´ë¦„ê³¼ ì§€ì—­ì½”ë“œë¡œ apartments í…Œì´ë¸”ì—ì„œ apt_idë¥¼ ì°¾ìŠµë‹ˆë‹¤.
            - ì¤‘ë³µ ê±°ë˜ ë°ì´í„°ëŠ” ê±´ë„ˆëœë‹ˆë‹¤.
        """
        total_fetched = 0
        total_saved = 0
        skipped = 0
        errors = []
        
        try:
            logger.info("=" * 80)
            logger.info(f"ğŸ  ì „ì›”ì„¸ ì‹¤ê±°ë˜ê°€ ìˆ˜ì§‘ ì‹œì‘")
            logger.info(f"   ğŸ“ ì§€ì—­ì½”ë“œ: {lawd_cd}")
            logger.info(f"   ğŸ“… ê³„ì•½ë…„ì›”: {deal_ymd}")
            logger.info("=" * 80)
            
            # 1ë‹¨ê³„: API í˜¸ì¶œí•˜ì—¬ XML ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (MOLIT_API_KEY ì‚¬ìš©)
            try:
                xml_data = await self.fetch_rent_data(lawd_cd, deal_ymd)
            except httpx.HTTPError as e:
                error_msg = f"API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}"
                logger.error(f"âŒ {error_msg}")
                return RentCollectionResponse(
                    success=False,
                    total_fetched=0,
                    total_saved=0,
                    skipped=0,
                    errors=[error_msg],
                    message=error_msg,
                    lawd_cd=lawd_cd,
                    deal_ymd=deal_ymd
                )
            
            # 2ë‹¨ê³„: XML â†’ JSON ë³€í™˜
            items, result_code, result_msg = self.parse_rent_xml_to_json(xml_data)
            
            if result_code not in ["000", "00"]:
                error_msg = f"API ì‘ë‹µ ì˜¤ë¥˜: {result_code} - {result_msg}"
                logger.error(f"âŒ {error_msg}")
                return RentCollectionResponse(
                    success=False,
                    total_fetched=0,
                    total_saved=0,
                    skipped=0,
                    errors=[error_msg],
                    message=error_msg,
                    lawd_cd=lawd_cd,
                    deal_ymd=deal_ymd
                )
            
            total_fetched = len(items)
            logger.info(f"ğŸ“Š ìˆ˜ì§‘ëœ ê±°ë˜ ë°ì´í„°: {total_fetched}ê°œ")
            
            if total_fetched == 0:
                return RentCollectionResponse(
                    success=True,
                    total_fetched=0,
                    total_saved=0,
                    skipped=0,
                    errors=[],
                    message="ì¡°íšŒëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.",
                    lawd_cd=lawd_cd,
                    deal_ymd=deal_ymd
                )
            
            # 3ë‹¨ê³„: ê° ê±°ë˜ ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ì—¬ DBì— ì €ì¥
            apt_cache = {}  # ì•„íŒŒíŠ¸ ì´ë¦„ â†’ apt_id ìºì‹œ (ë°˜ë³µ ê²€ìƒ‰ ë°©ì§€)
            
            for idx, item in enumerate(items, 1):
                apt_name = item.get("aptNm", "Unknown")
                sgg_cd = item.get("sggCd", lawd_cd)  # ì‹œêµ°êµ¬ ì½”ë“œ (ì—†ìœ¼ë©´ lawd_cd ì‚¬ìš©)
                
                try:
                    # 3-1: ì•„íŒŒíŠ¸ ID ì°¾ê¸° (ìºì‹œ í™œìš©)
                    cache_key = f"{sgg_cd}:{apt_name}"
                    
                    if cache_key in apt_cache:
                        apt_id = apt_cache[cache_key]
                    else:
                        apartment = await self.find_apartment_by_name_and_region(
                            db, apt_name, sgg_cd
                        )
                        
                        if not apartment:
                            error_msg = f"ì•„íŒŒíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {apt_name} (ì§€ì—­: {sgg_cd})"
                            errors.append(error_msg)
                            logger.warning(f"   âš ï¸ [{idx}/{total_fetched}] {error_msg}")
                            continue
                        
                        apt_id = apartment.apt_id
                        apt_cache[cache_key] = apt_id
                    
                    # 3-2: ê±°ë˜ ë°ì´í„° íŒŒì‹±
                    rent_create = self.parse_rent_item(item, apt_id)
                    
                    if not rent_create:
                        error_msg = f"ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨: {apt_name}"
                        errors.append(error_msg)
                        logger.warning(f"   âš ï¸ [{idx}/{total_fetched}] {error_msg}")
                        continue
                    
                    # 3-3: DBì— ì €ì¥ (ì¤‘ë³µ ì²´í¬)
                    db_obj, is_created = await rent_crud.create_or_skip(
                        db,
                        obj_in=rent_create
                    )
                    
                    if is_created:
                        total_saved += 1
                        if total_saved % 10 == 0 or total_saved == 1:
                            logger.info(f"   ğŸ’¾ [{idx}/{total_fetched}] {apt_name} ì €ì¥ ì™„ë£Œ (í˜„ì¬ê¹Œì§€: {total_saved}ê°œ)")
                    else:
                        skipped += 1
                        logger.debug(f"   â­ï¸ [{idx}/{total_fetched}] {apt_name} ê±´ë„ˆëœ€ (ì¤‘ë³µ)")
                    
                except Exception as e:
                    # savepoint ë¡¤ë°±
                    try:
                        await savepoint.rollback()
                    except Exception:
                        pass
                    
                    error_msg = f"ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
                    errors.append(f"ì•„íŒŒíŠ¸ '{apt_name}' (ID: {apt_id}, ì½”ë“œ: {kapt_code}): {error_msg}")
                    total_processed += 1
                    logger.error(f"[{idx}/{len(apartments)}] {apt_name} | âŒ ì‹¤íŒ¨: {error_msg}")
                    import traceback
                    logger.debug(f"ìƒì„¸ ìŠ¤íƒ: {traceback.format_exc()}")
            
            # ë§ˆì§€ë§‰ ë‚¨ì€ ë°ì´í„° ì»¤ë°‹ (ë°˜ë“œì‹œ ì‹¤í–‰ë˜ì–´ì•¼ í•¨)
            remaining_count = total_saved - last_commit_count
            if remaining_count > 0:
                try:
                    await db.commit()  # ìµœìƒìœ„ íŠ¸ëœì­ì…˜ ì»¤ë°‹ (ì‹¤ì œ DB ë°˜ì˜)
                    last_commit_count = total_saved
                    logger.info(f"ğŸ’¾ ìµœì¢… ì»¤ë°‹ ì™„ë£Œ: ì´ {total_saved}ê°œ ì €ì¥ë¨")
                except Exception as commit_error:
                    logger.error(f"âŒ ìµœì¢… ì»¤ë°‹ ì‹¤íŒ¨: {remaining_count}ê°œ ë°ì´í„° ì†ì‹¤ ê°€ëŠ¥ - {str(commit_error)}")
                    try:
                        await db.rollback()
                    except Exception:
                        pass
                    errors.append(f"ìµœì¢… ì»¤ë°‹ ì‹¤íŒ¨ ({remaining_count}ê°œ ë°ì´í„° ì†ì‹¤): {str(commit_error)}")
            
            logger.info(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ: ì²˜ë¦¬ {total_processed}ê°œ | ì €ì¥ {total_saved}ê°œ | ê±´ë„ˆëœ€ {skipped}ê°œ")
            if errors:
                logger.warning(f"âš ï¸ ì˜¤ë¥˜ {len(errors)}ê°œ ë°œìƒ")
                for error in errors[:10]:
                    logger.warning(f"   - {error}")
                if len(errors) > 10:
                    logger.warning(f"   ... ì™¸ {len(errors) - 10}ê°œ ì˜¤ë¥˜")
            
            # ìµœì¢… ì»¤ë°‹ ì‹¤íŒ¨ê°€ ìˆì—ˆìœ¼ë©´ success=Falseë¡œ ë°˜í™˜
            final_success = len([e for e in errors if "ìµœì¢… ì»¤ë°‹ ì‹¤íŒ¨" in e]) == 0
            
            return ApartDetailCollectionResponse(
                success=final_success,
                total_processed=total_processed,
                total_saved=total_saved,
                skipped=skipped,
                errors=errors,
                message=f"ìˆ˜ì§‘ ì™„ë£Œ: {total_saved}ê°œ ì €ì¥, {skipped}ê°œ ê±´ë„ˆëœ€" if final_success else f"ìˆ˜ì§‘ ì™„ë£Œ (ì¼ë¶€ ì˜¤ë¥˜): {total_saved}ê°œ ì €ì¥, {skipped}ê°œ ê±´ë„ˆëœ€"
            )
            
        except Exception as e:
            logger.error(f"âŒ ì•„íŒŒíŠ¸ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}", exc_info=True)
            # ì˜ˆì™¸ ë°œìƒ ì‹œ ë‚¨ì€ ë°ì´í„° ì»¤ë°‹ ì‹œë„
            try:
                remaining_count = total_saved - last_commit_count
                if remaining_count > 0:
                    logger.warning(f"   âš ï¸ ì˜ˆì™¸ ë°œìƒ ì „ ë‚¨ì€ {remaining_count}ê°œ ë°ì´í„° ì»¤ë°‹ ì‹œë„...")
                    try:
                        await db.commit()
                        logger.info(f"   âœ… ì˜ˆì™¸ ë°œìƒ ì „ ë°ì´í„° ì»¤ë°‹ ì™„ë£Œ")
                    except Exception as commit_error:
                        logger.error(f"   âŒ ì˜ˆì™¸ ë°œìƒ ì „ ë°ì´í„° ì»¤ë°‹ ì‹¤íŒ¨: {str(commit_error)}")
                        await db.rollback()
            except Exception:
                pass  # ì´ë¯¸ ì˜ˆì™¸ê°€ ë°œìƒí•œ ìƒíƒœì´ë¯€ë¡œ ë¬´ì‹œ
            
            return ApartDetailCollectionResponse(
                success=False,
                total_processed=total_processed,
                total_saved=total_saved,
                skipped=skipped,
                errors=errors + [str(e)],
                message=f"ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}"
            )
    
    def _get_area_code_from_csv(self, region_code_prefix: str) -> Optional[int]:
        """
        CSV íŒŒì¼ì—ì„œ region_code ì• 5ìë¦¬ë¡œ area_code(CLS_ID)ë¥¼ ì°¾ì•„ ë°˜í™˜
        
        Args:
            region_code_prefix: region_code ì• 5ìë¦¬
        
        Returns:
            area_code (int) ë˜ëŠ” None
        """
        try:
            # CSV íŒŒì¼ ê²½ë¡œ ìºì‹± (í•œ ë²ˆë§Œ í™•ì¸)
            if not DataCollectionService._csv_path_checked:
                current_file = Path(__file__).resolve()
                current_file_str = str(current_file)
                
                if current_file_str.startswith('/app'):
                    # Docker ì»¨í…Œì´ë„ˆ ë‚´ë¶€
                    csv_path = Path('/app/legion_code.csv')
                else:
                    # ë¡œì»¬ ì‹¤í–‰: backend/app/services/data_collection.py -> í”„ë¡œì íŠ¸ ë£¨íŠ¸
                    csv_path = current_file.parent.parent.parent.parent / 'legion_code.csv'
                
                if not csv_path.exists():
                    logger.error(f"âŒ CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {csv_path}")
                    logger.error(f"   í˜„ì¬ íŒŒì¼ ê²½ë¡œ: {current_file_str}")
                    DataCollectionService._csv_path_checked = True
                    DataCollectionService._csv_path_cache = None
                    return None
                
                DataCollectionService._csv_path_cache = csv_path
                DataCollectionService._csv_path_checked = True
            
            # ìºì‹œëœ ê²½ë¡œê°€ ì—†ìœ¼ë©´ (íŒŒì¼ì´ ì—†ëŠ” ê²½ìš°)
            if DataCollectionService._csv_path_cache is None:
                return None
            
            csv_path = DataCollectionService._csv_path_cache
            
            region_code_prefix = str(region_code_prefix)
            if len(region_code_prefix) < 5:
                region_code_prefix = region_code_prefix[:5].ljust(5, '0')
            
            # CSV íŒŒì¼ ì½ê¸°
            with open(csv_path, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                rows = list(reader)
            
            # 1. 5ìë¦¬ ì¼ì¹˜ ê²€ìƒ‰
            for row in rows:
                region_code = str(row.get('region_code', '')).strip()
                if region_code.startswith(region_code_prefix):
                    return int(row.get('area_code', 0))
            
            # 2. ì• 2ìë¦¬ ì¼ì¹˜ ê²€ìƒ‰ (fallback)
            prefix_2 = region_code_prefix[:2]
            for row in rows:
                region_code = str(row.get('region_code', '')).strip()
                if region_code.startswith(prefix_2):
                    return int(row.get('area_code', 0))
            
            return None
        except Exception as e:
            logger.error(f"âŒ CSV íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
            return None
    
    async def collect_house_scores(
        self,
        db: AsyncSession
    ) -> HouseScoreCollectionResponse:
        """
        ë¶€ë™ì‚° ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘
        
        STATES í…Œì´ë¸”ì˜ region_codeë¥¼ ì‚¬ìš©í•˜ì—¬ í•œêµ­ë¶€ë™ì‚°ì› APIì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì™€ì„œ
        HOUSE_SCORES í…Œì´ë¸”ì— ì €ì¥í•©ë‹ˆë‹¤.
        """
        total_fetched = 0
        total_saved = 0
        skipped = 0
        errors = []
        
        # ì—ëŸ¬ ì œí•œ ì„¤ì •
        MAX_CONSECUTIVE_ERRORS = 10  # ì—°ì† ì—ëŸ¬ ìµœëŒ€ íšŸìˆ˜
        MAX_ERROR_RATIO = 0.5  # ì „ì²´ ì—ëŸ¬ ë¹„ìœ¨ ìµœëŒ€ê°’ (50%)
        MIN_PROCESSED_FOR_RATIO_CHECK = 10  # ì—ëŸ¬ ë¹„ìœ¨ ì²´í¬ë¥¼ ìœ„í•œ ìµœì†Œ ì²˜ë¦¬ íšŸìˆ˜
        consecutive_errors = 0  # ì—°ì† ì—ëŸ¬ ì¹´ìš´í„°
        total_processed = 0  # ì²˜ë¦¬í•œ ì§€ì—­ ìˆ˜
        
        try:
            # REB_API_KEY í™•ì¸
            if not settings.REB_API_KEY:
                raise ValueError("REB_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
            
            logger.info("=" * 60)
            logger.info("ğŸ  ë¶€ë™ì‚° ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
            logger.info("=" * 60)
            
            # STATES í…Œì´ë¸”ì—ì„œ ëª¨ë“  region_code ì¡°íšŒ
            from app.models.state import State
            result = await db.execute(
                select(State.region_id, State.region_code)
                .where(State.is_deleted == False)
            )
            states = result.fetchall()
            
            if not states:
                logger.warning("âš ï¸ STATES í…Œì´ë¸”ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return HouseScoreCollectionResponse(
                    success=False,
                    total_fetched=0,
                    total_saved=0,
                    skipped=0,
                    errors=[],
                    message=f"ëª¨ë“  ì§€ì—­ ìˆ˜ì§‘ ì™„ë£Œ (ì‹œì‘ ì¸ë±ìŠ¤ {start_region_index} >= ì´ ì§€ì—­ ìˆ˜ {len(region_codes)})",
                    api_calls_used=0
                )
            
            # 2ë‹¨ê³„: ìˆ˜ì§‘í•  ë…„ì›” ëª©ë¡ ìƒì„±
            year_months = self.generate_year_months(start_year, start_month)
            
            # ì‹œì‘ ì¸ë±ìŠ¤ë¶€í„°ì˜ ì§€ì—­ì½”ë“œë§Œ ì‚¬ìš©
            remaining_region_codes = region_codes[start_region_index:]
            
            total_combinations = len(remaining_region_codes) * len(year_months)
            
            logger.info(f"ğŸ“ ìˆ˜ì§‘ ëŒ€ìƒ: {len(remaining_region_codes)}ê°œ ì§€ì—­ Ã— {len(year_months)}ê°œì›”")
            logger.info(f"ğŸ“… ìˆ˜ì§‘ ê¸°ê°„: {year_months[0]} ~ {year_months[-1]}")
            logger.info(f"ğŸ“Š ì´ ì˜ˆìƒ API í˜¸ì¶œ: {total_combinations}íšŒ")
            logger.info(f"ğŸš€ ì‹œì‘ ì§€ì—­ ì¸ë±ìŠ¤: {start_region_index} ({remaining_region_codes[0] if remaining_region_codes else 'N/A'})")
            logger.info("=" * 80)
            
            # 3ë‹¨ê³„: ê° ì§€ì—­ì½”ë“œ Ã— ë…„ì›” ì¡°í•©ì— ëŒ€í•´ ìˆ˜ì§‘
            current_idx = 0
            stopped_by_limit = False
            
            for region_offset, lawd_cd in enumerate(remaining_region_codes):
                actual_region_index = start_region_index + region_offset
                
                logger.info(f"\n{'='*60}")
                logger.info(f"ğŸ“ [ì§€ì—­ {actual_region_index + 1}/{len(region_codes)}] ì§€ì—­ì½”ë“œ: {lawd_cd}")
                logger.info(f"   API í˜¸ì¶œ: {api_calls_used}/{max_api_calls}")
                logger.info(f"{'='*60}")
                
                for ym_idx, deal_ymd in enumerate(year_months):
                    # API í˜¸ì¶œ ì œí•œ ì²´í¬
                    if api_calls_used >= max_api_calls:
                        logger.warning(f"âš ï¸ ì¼ì¼ API í˜¸ì¶œ ì œí•œ ë„ë‹¬! ({api_calls_used}/{max_api_calls})")
                        stopped_by_limit = True
                        next_region_index = actual_region_index  # í˜„ì¬ ì§€ì—­ë¶€í„° ì¬ì‹œì‘
                        break
                    
                    current_idx += 1
                    progress = (current_idx / total_combinations) * 100
                    
                    logger.info(f"   [{current_idx}/{total_combinations}] ({progress:.1f}%) {lawd_cd} - {deal_ymd}")
                    
                    try:
                        # API í˜¸ì¶œ
                        xml_data = await self.fetch_rent_data(lawd_cd, deal_ymd)
                        api_calls_used += 1
                        last_lawd_cd = lawd_cd
                        last_deal_ymd = deal_ymd
                        
                        # XML â†’ JSON ë³€í™˜
                        items, result_code, result_msg = self.parse_rent_xml_to_json(xml_data)
                        
                        if result_code not in ["000", "00"]:
                            error_msg = f"{lawd_cd}/{deal_ymd}: API ì˜¤ë¥˜ - {result_msg}"
                            all_errors.append(error_msg)
                            logger.warning(f"      âš ï¸ {error_msg}")
                            await asyncio.sleep(0.3)
                            continue
                        
                        if not items:
                            logger.debug(f"      â„¹ï¸ ë°ì´í„° ì—†ìŒ")
                            await asyncio.sleep(0.2)
                            continue
                        
                        total_fetched += len(items)
                        
                        # ì•„íŒŒíŠ¸ ìºì‹œ (ë°˜ë³µ ê²€ìƒ‰ ë°©ì§€)
                        apt_cache = {}
                        saved_count = 0
                        skipped_count = 0
                        
                        for item in items:
                            apt_name = item.get("aptNm", "Unknown")
                            sgg_cd = item.get("sggCd", lawd_cd)
                            
                            try:
                                # ì•„íŒŒíŠ¸ ID ì°¾ê¸°
                                cache_key = f"{sgg_cd}:{apt_name}"
                                
                                if cache_key in apt_cache:
                                    apt_id = apt_cache[cache_key]
                                elif cache_key not in apt_cache:
                                    apartment = await self.find_apartment_by_name_and_region(
                                        db, apt_name, sgg_cd
                                    )
                                    
                                    if not apartment:
                                        apt_cache[cache_key] = None
                                        continue
                                    
                                    apt_id = apartment.apt_id
                                    apt_cache[cache_key] = apt_id
                                
                                if apt_cache.get(cache_key) is None:
                                    continue
                                
                                # í˜ì´ì§€ ì‘ë‹µ ì„±ê³µ í™•ì¸
                                page_head_data = page_stts_data[0].get("head", [])
                                page_result_data = {}
                                for item in page_head_data:
                                    if isinstance(item, dict) and "RESULT" in item:
                                        page_result_data = item["RESULT"]
                                        break
                                
                                page_response_code = page_result_data.get("CODE", "UNKNOWN")
                                if page_response_code != "INFO-000":
                                    logger.warning(f"   âš ï¸ {region_code_str}: í˜ì´ì§€ {page_index} API ì˜¤ë¥˜ [CODE: {page_response_code}] - ê±´ë„ˆëœ€")
                                    continue
                                
                                # DB ì €ì¥
                                _, is_created = await rent_crud.create_or_skip(
                                    db,
                                    obj_in=rent_create
                                )
                                
                                if is_created:
                                    saved_count += 1
                                else:
                                    skipped_count += 1
                                    
                            except Exception as e:
                                pass  # ê°œë³„ ì˜¤ë¥˜ëŠ” ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
                        
                        total_saved += saved_count
                        total_skipped += skipped_count
                        
                        if saved_count > 0:
                            logger.info(f"      âœ… {len(items)}ê±´ ì¤‘ {saved_count}ê±´ ì €ì¥, {skipped_count}ê±´ ê±´ë„ˆëœ€")
                        
                    except httpx.HTTPError as e:
                        error_msg = f"{lawd_cd}/{deal_ymd}: HTTP ì˜¤ë¥˜ - {str(e)}"
                        all_errors.append(error_msg)
                        logger.warning(f"      âš ï¸ {error_msg}")
                    except Exception as e:
                        error_msg = f"{lawd_cd}/{deal_ymd}: ì˜¤ë¥˜ - {str(e)}"
                        all_errors.append(error_msg)
                        logger.warning(f"      âš ï¸ {error_msg}")
                    
                    # API í˜¸ì¶œ ì œí•œ ë°©ì§€ ë”œë ˆì´
                    await asyncio.sleep(0.3)
                
                # API ì œí•œìœ¼ë¡œ ì¤‘ë‹¨ëœ ê²½ìš°
                if stopped_by_limit:
                    break
            
            # ëª¨ë“  ì§€ì—­ ì™„ë£Œ ì²´í¬
            if not stopped_by_limit:
                next_region_index = None  # ëª¨ë‘ ì™„ë£Œ
            
            # ê²°ê³¼ ì¶œë ¥
            logger.info("\n" + "=" * 80)
            if stopped_by_limit:
                logger.info("â¸ï¸ ì „ì›”ì„¸ ì‹¤ê±°ë˜ê°€ ìˆ˜ì§‘ ì¼ì‹œ ì¤‘ë‹¨ (ì¼ì¼ API í˜¸ì¶œ ì œí•œ)")
                logger.info(f"   â¡ï¸ ë‹¤ìŒì— ì‹œì‘í•  ì§€ì—­ ì¸ë±ìŠ¤: {next_region_index}")
            else:
                logger.info("ğŸ‰ ì „ì›”ì„¸ ì‹¤ê±°ë˜ê°€ ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ!")
            logger.info(f"   ğŸ“Š ì´ ìˆ˜ì§‘: {total_fetched}ê±´")
            logger.info(f"   ğŸ’¾ ì €ì¥: {total_saved}ê±´")
            logger.info(f"   â­ï¸ ê±´ë„ˆëœ€: {total_skipped}ê±´")
            logger.info(f"   ğŸ”„ API í˜¸ì¶œ: {api_calls_used}íšŒ")
            logger.info(f"   âš ï¸ ì˜¤ë¥˜: {len(all_errors)}ê±´")
            logger.info("=" * 80)
            
            message = f"ìˆ˜ì§‘ ì™„ë£Œ: {total_saved}ê±´ ì €ì¥, {total_skipped}ê±´ ê±´ë„ˆëœ€"
            if stopped_by_limit:
                message = f"ì¼ì¼ ì œí•œìœ¼ë¡œ ì¤‘ë‹¨ (ë‹¤ìŒ ì‹œì‘: ì§€ì—­ ì¸ë±ìŠ¤ {next_region_index}): {total_saved}ê±´ ì €ì¥"
            
            return RentCollectionResponse(
                success=True,
                total_fetched=total_fetched,
                total_saved=total_saved,
                skipped=total_skipped,
                errors=all_errors[:100],  # ìµœëŒ€ 100ê°œë§Œ
                message=message,
                lawd_cd=last_lawd_cd,
                deal_ymd=last_deal_ymd,
                api_calls_used=api_calls_used,
                next_region_index=next_region_index
            )
            
        except Exception as e:
            logger.error(f"âŒ ì „ì²´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}", exc_info=True)
            return RentCollectionResponse(
                success=False,
                total_fetched=total_fetched,
                total_saved=total_saved,
                skipped=total_skipped,
                errors=all_errors + [str(e)],
                message=f"ì „ì²´ ìˆ˜ì§‘ ì‹¤íŒ¨: {str(e)}",
                api_calls_used=api_calls_used,
                next_region_index=start_region_index  # ì‹¤íŒ¨ ì‹œ í˜„ì¬ ìœ„ì¹˜ ë°˜í™˜
            )


    def _convert_sgg_code_to_db_format(self, sgg_cd: str) -> Optional[str]:
        """5ìë¦¬ ì‹œêµ°êµ¬ ì½”ë“œë¥¼ 10ìë¦¬ DB í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        if not sgg_cd or len(sgg_cd) != 5:
            return None
        return f"{sgg_cd}00000"
    
    def _normalize_dong_name(self, dong_name: str) -> str:
        """
        ë™ ì´ë¦„ ì •ê·œí™” (ì/ë©´/ë¦¬/ë™/ê°€ ì²˜ë¦¬)
        
        ì˜ˆì‹œ:
        - "ì˜ê´‘ì ë‹¨ì£¼ë¦¬" â†’ "ë‹¨ì£¼ë¦¬"
        - "ì‚¬ì§1ë™" â†’ "ì‚¬ì§"
        - "ì˜ë“±í¬ë™1ê°€" â†’ "ì˜ë“±í¬"
        """
        if not dong_name:
            return ""
        
        # ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ë§ˆì§€ë§‰ ë¶€ë¶„(ì‹¤ì œ ë™/ë¦¬ ì´ë¦„) ì¶”ì¶œ
        parts = dong_name.strip().split()
        if not parts:
            return ""
        
        # ë§ˆì§€ë§‰ ë¶€ë¶„ ì‚¬ìš© (ì˜ˆ: "ì˜ê´‘ì ë‹¨ì£¼ë¦¬" â†’ "ë‹¨ì£¼ë¦¬")
        last_part = parts[-1]
        
        # ìˆ«ì ì œê±° (ì˜ˆ: "ì‚¬ì§1ë™" â†’ "ì‚¬ì§ë™")
        normalized = re.sub(r'\d+', '', last_part)
        
        # ì/ë©´/ë¦¬/ë™/ê°€ ì œê±°
        normalized = normalized.replace("ì", "").replace("ë©´", "").replace("ë¦¬", "").replace("ë™", "").replace("ê°€", "").strip()
        
        return normalized
    
    def _extract_dong_parts(self, dong_name: str) -> List[str]:
        """
        ë™ ì´ë¦„ì—ì„œ ê°€ëŠ¥í•œ ëª¨ë“  ë§¤ì¹­ í›„ë³´ ì¶”ì¶œ
        
        ì˜ˆì‹œ:
        - "ë´‰í™”ì ë‚´ì„±ë¦¬" â†’ ["ë‚´ì„±ë¦¬", "ë´‰í™”ì ë‚´ì„±ë¦¬", "ë´‰í™”ì", "ë‚´ì„±", "ë´‰í™”"]
        - "ì‚¬ì§1ë™" â†’ ["ì‚¬ì§1ë™", "ì‚¬ì§ë™", "ì‚¬ì§"]
        
        ìš°ì„ ìˆœìœ„: ë§ˆì§€ë§‰ ë¶€ë¶„(ì‹¤ì œ ë™/ë¦¬ ì´ë¦„)ì„ ê°€ì¥ ë¨¼ì € í™•ì¸
        """
        if not dong_name:
            return []
        
        candidates = []
        dong_name = dong_name.strip()
        
        # ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬ëœ ê²½ìš° ê° ë¶€ë¶„ ì¶”ê°€
        parts = dong_name.split()
        if len(parts) > 1:
            # ë§ˆì§€ë§‰ ë¶€ë¶„ (ì‹¤ì œ ë™/ë¦¬ ì´ë¦„)ì„ ê°€ì¥ ë¨¼ì € ì¶”ê°€ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
            candidates.append(parts[-1])
            # ì›ë³¸ ì „ì²´
            candidates.append(dong_name)
            # ì²« ë²ˆì§¸ ë¶€ë¶„ (ì/ë©´ ì´ë¦„)
            candidates.append(parts[0])
        else:
            # ê³µë°±ì´ ì—†ëŠ” ê²½ìš° ì›ë³¸ë§Œ ì¶”ê°€
            candidates.append(dong_name)
        
        # ìˆ«ì ì œê±° ë²„ì „ë“¤ ì¶”ê°€
        for candidate in candidates[:]:
            # ìˆ«ì ì œê±°
            no_digit = re.sub(r'\d+', '', candidate)
            if no_digit != candidate and no_digit not in candidates:
                candidates.append(no_digit)
            
            # ì/ë©´/ë¦¬/ë™/ê°€ ì œê±°
            cleaned = no_digit.replace("ì", "").replace("ë©´", "").replace("ë¦¬", "").replace("ë™", "").replace("ê°€", "").strip()
            if cleaned and cleaned not in candidates:
                candidates.append(cleaned)
        
        # ì¤‘ë³µ ì œê±° ë° ë¹ˆ ë¬¸ìì—´ ì œê±° (ìˆœì„œ ìœ ì§€)
        result = []
        seen = set()
        for c in candidates:
            if c and c not in seen:
                result.append(c)
                seen.add(c)
        
        return result
    
    # í•œêµ­ ëŒ€í‘œ ì•„íŒŒíŠ¸ ë¸Œëœë“œëª… ì‚¬ì „ (ì •ê·œí™”ëœ í˜•íƒœë¡œ ì €ì¥, ê¸´ ê²ƒ ìš°ì„ )
    APARTMENT_BRANDS = [
        # ë³µí•© ë¸Œëœë“œëª… (ë¨¼ì € ë§¤ì¹­, ê¸´ ê²ƒë¶€í„°)
        'ë¡¯ë°ìºìŠ¬íŒŒí¬íƒ€ìš´', 'ë¡¯ë°ìºìŠ¬ê³¨ë“œíƒ€ìš´', 'ë¡¯ë°ìºìŠ¬', 
        'í˜„ëŒ€íìŠ¤í…Œì´íŠ¸', 'íìŠ¤í…Œì´íŠ¸',
        'ì´í¸í•œì„¸ìƒ', 'eí¸í•œì„¸ìƒ', 'í¸í•œì„¸ìƒ',
        'í•œë¼ë¹„ë°œë””', 'ë¹„ë°œë””',
        'í˜¸ë°˜ì¨ë°‹', 'ì¨ë°‹',
        'ìš°ë¯¸ë¦°',
        'ë˜ë¯¸ì•ˆ', 'ë¼ë¯¸ì•ˆ',
        'í‘¸ë¥´ì§€ì˜¤',
        'ë”ìƒµ', 'theìƒµ',
        'ì•„ì´íŒŒí¬',
        'ìì´', 'xi',
        'ìœ„ë¸Œ', 'ë‘ì‚°ìœ„ë¸Œ',
        'skë·°', 'skìŠ¤ì¹´ì´ë·°', 'ì—ìŠ¤ì¼€ì´ë·°',
        'ê¿ˆì—ê·¸ë¦°', 'í¬ë ˆë‚˜',
        'ë² ìŠ¤íŠ¸ë¹Œ', 'ì–´ìš¸ë¦¼',
        'ë¡œì–„ë“€í¬',
        'ìŠ¤ìœ—ë‹·í™ˆ', 'ì˜ˆê°€',
        'ì„¼íŠ¸ë ˆë¹Œ',
        'ì•„í¬ë¡œ',
        'ì‚¬ë‘ìœ¼ë¡œ',
        'sí´ë˜ìŠ¤', 'ì¤‘í¥sí´ë˜ìŠ¤', 'ì¤‘í¥',
        'ìˆ˜ìì¸', 'ë‚˜ë¹Œë˜', 'ìŠ¤íƒ€í´ë˜ìŠ¤', 'ë…¸ë¹Œë¦¬í‹°', 'ìŠ¤ì¹´ì´ë·°',
        # ì¶”ê°€ ë¸Œëœë“œ (ëˆ„ë½ë˜ì–´ ìˆë˜ ê²ƒë“¤)
        'ìŠ¤ìœ„ì²¸', 'kccìŠ¤ìœ„ì²¸',  # KCCê±´ì„¤
        'íŠ¸ë¼íŒ°ë¦¬ìŠ¤', 'ì‚¼ì„±íŠ¸ë¼íŒ°ë¦¬ìŠ¤',  # ì‚¼ì„±ë¬¼ì‚°
        'íŒŒí¬ë¦¬ì˜¤', 'ë°˜í¬íŒŒí¬ë¦¬ì˜¤',  # ì‚¼ì„±ë¬¼ì‚°
        'íœ´ë¨¼ì‹œì•„',  # LHê³µì‚¬
        'ë§ˆì œìŠ¤í‹°', 'ì‹ ì„¸ê³„ë¹Œë¦¬ë¸Œ',  # ì‹ ì„¸ê³„ê±´ì„¤
        'í•˜ì´ì¸ ',  # ì¼ë°˜ ì ‘ë¯¸ì‚¬
        'ì•„ë„ˆìŠ¤ë¹Œ', 'ê²½ë‚¨ì•„ë„ˆìŠ¤ë¹Œ',  # ê²½ë‚¨ê¸°ì—…
        'ì‹œê·¸ë‹ˆì²˜', 'ë”í¼ìŠ¤íŠ¸',  # ì¼ë°˜ ë¸Œëœë“œ
        'íŠ¸ë ˆì§€ì›€', 'ë‘ë ˆë¯¸ë‹´',  # í•œí™”ê±´ì„¤
        'í”„ë ˆìŠ¤í‹°ì§€', 'ë¥´ë„¤ìƒìŠ¤',  # ì¼ë°˜ ë¸Œëœë“œ
        'ìºìŠ¬ê³¨ë“œ', 'ë“œë¦¼íƒ€ìš´',  # ì¼ë°˜ ë¸Œëœë“œ
        # ê±´ì„¤ì‚¬ ë¸Œëœë“œ
        'í˜„ëŒ€', 'ì‚¼ì„±', 'ëŒ€ë¦¼', 'ëŒ€ìš°', 'ë™ì•„', 'ê·¹ë™', 'ë²½ì‚°', 'ê¸ˆí˜¸', 'ë™ë¶€',
        'ì‹ ë™ì•„', 'ì‹ ì„±', 'ì£¼ê³µ', 'í•œì‹ ', 'íƒœì˜', 'ì§„í¥', 'ë™ì¼', 'ê±´ì˜',
        'ìš°ë°©', 'í•œì–‘', 'ì„±ì›', 'ê²½ë‚¨', 'ë™ë¬¸', 'í’ë¦¼', 'ì‹ ì•ˆ', 'ì„ ê²½',
        'íš¨ì„±', 'ì½”ì˜¤ë¡±', 'ëŒ€ë°©', 'ë™ì„±', 'ì¼ì‹ ', 'ì²­êµ¬', 'ì‚¼ìµ', 'ì§„ë¡œ',
        'ë¶€ì˜', 'ìŒìš©', 'ìºìŠ¬', 'ë¦°', 'ê¸ˆê°•', 'ëŸ­í‚¤', 'ì„ê´‘', 'ë™ì‹ ',
        'í™”ì„±', 'ëŒ€ì°½', 'ì„œì•ˆ', 'ì˜í’', 'ì„¸ì˜', 'ë™ì–‘', 'í•œì§„',
    ]
    
    # ë§ˆì„/ë‹¨ì§€ ì ‘ë¯¸ì‚¬ íŒ¨í„´
    VILLAGE_SUFFIXES = ['ë§ˆì„', 'ë‹¨ì§€', 'íƒ€ìš´', 'ë¹Œë¦¬ì§€', 'íŒŒí¬', 'ì‹œí‹°', 'íìŠ¤', 'ë·°']
    
    def _extract_danji_number(self, name: str) -> Optional[int]:
        """
        ë‹¨ì§€ ë²ˆí˜¸ ì¶”ì¶œ (ì˜ˆ: '4ë‹¨ì§€' â†’ 4, '9ë‹¨ì§€' â†’ 9, '101ë™' â†’ 101)
        
        ë‹¤ì–‘í•œ íŒ¨í„´ ì§€ì›:
        - "4ë‹¨ì§€", "9ë‹¨ì§€" â†’ 4, 9
        - "ì œ4ë‹¨ì§€", "ì œ9ë‹¨ì§€" â†’ 4, 9
        - "101ë™", "102ë™" â†’ 101, 102 (ì£¼ì˜: ì¸µìˆ˜ì™€ êµ¬ë¶„ í•„ìš”)
        - "1ì°¨", "2ì°¨" â†’ 1, 2
        - "â… ", "â…¡" â†’ 1, 2
        """
        if not name:
            return None
        
        # ì •ê·œí™” (ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ì œê±°)
        normalized = re.sub(r'\s+', '', name)
        
        # ë¡œë§ˆìˆ«ìë¥¼ ì•„ë¼ë¹„ì•„ ìˆ«ìë¡œ ë³€í™˜
        roman_map = {'â…°': '1', 'â…±': '2', 'â…²': '3', 'â…³': '4', 'â…´': '5', 
                     'â…µ': '6', 'â…¶': '7', 'â…·': '8', 'â…¸': '9', 'â…¹': '10',
                     'â… ': '1', 'â…¡': '2', 'â…¢': '3', 'â…£': '4', 'â…¤': '5',
                     'â…¥': '6', 'â…¦': '7', 'â…§': '8', 'â…¨': '9', 'â…©': '10'}
        for roman, arabic in roman_map.items():
            normalized = normalized.replace(roman, arabic)
        
        # ë‹¨ì§€ ë²ˆí˜¸ ì¶”ì¶œ íŒ¨í„´ë“¤ (ìš°ì„ ìˆœìœ„ìˆœ)
        patterns = [
            r'ì œ?(\d+)ë‹¨ì§€',      # "4ë‹¨ì§€", "ì œ4ë‹¨ì§€"
            r'(\d+)ì°¨',           # "1ì°¨", "2ì°¨" (ì°¨ìˆ˜)
            r'ì œ(\d+)ì°¨',         # "ì œ1ì°¨"
            r'(\d{3,})ë™',        # "101ë™", "102ë™" (3ìë¦¬ ì´ìƒ, ì¸µìˆ˜ êµ¬ë¶„)
        ]
        
        for pattern in patterns:
            match = re.search(pattern, normalized)
            if match:
                num = int(match.group(1))
                # ë™ ë²ˆí˜¸ëŠ” ë³´í†µ 100 ì´ìƒ (101ë™, 102ë™ ë“±)
                if 'ë™' in pattern and num < 100:
                    continue
                return num
        
        return None
    
    def _extract_cha_number(self, name: str) -> Optional[int]:
        """
        ì°¨ìˆ˜ ì¶”ì¶œ (ì˜ˆ: '1ì°¨' â†’ 1, 'â…¡' â†’ 2)
        
        ë‹¤ì–‘í•œ íŒ¨í„´ ì§€ì›:
        - "1ì°¨", "2ì°¨" â†’ 1, 2
        - "ì œ1ì°¨", "ì œ2ì°¨" â†’ 1, 2
        - "â… ", "â…¡" â†’ 1, 2 (ë¡œë§ˆìˆ«ì)
        - ëì— ë¶™ì€ ìˆ«ì (1~20 ì‚¬ì´ë§Œ ì°¨ìˆ˜ë¡œ ê°„ì£¼)
        """
        if not name:
            return None
        
        normalized = re.sub(r'\s+', '', name)
        
        # ë¡œë§ˆìˆ«ìë¥¼ ì•„ë¼ë¹„ì•„ ìˆ«ìë¡œ ë³€í™˜
        roman_map = {'â…°': '1', 'â…±': '2', 'â…²': '3', 'â…³': '4', 'â…´': '5', 
                     'â…µ': '6', 'â…¶': '7', 'â…·': '8', 'â…¸': '9', 'â…¹': '10',
                     'â… ': '1', 'â…¡': '2', 'â…¢': '3', 'â…£': '4', 'â…¤': '5',
                     'â…¥': '6', 'â…¦': '7', 'â…§': '8', 'â…¨': '9', 'â…©': '10',
                     'i': '1', 'ii': '2', 'iii': '3', 'iv': '4', 'v': '5',
                     'vi': '6', 'vii': '7', 'viii': '8', 'ix': '9', 'x': '10'}
        # ì†Œë¬¸ì ë¡œë§ˆìˆ«ìë„ ì²˜ë¦¬
        normalized_lower = normalized.lower()
        for roman, arabic in roman_map.items():
            normalized_lower = normalized_lower.replace(roman, arabic)
        
        # ì°¨ìˆ˜ ì¶”ì¶œ íŒ¨í„´ë“¤
        patterns = [
            (normalized, r'ì œ?(\d+)ì°¨'),      # "1ì°¨", "ì œ1ì°¨"
            (normalized_lower, r'(\d+)ì°¨'),   # ì†Œë¬¸ì ë¡œë§ˆìˆ«ì ë³€í™˜ í›„
        ]
        
        for text, pattern in patterns:
            match = re.search(pattern, text)
            if match:
                return int(match.group(1))
        
        # ëì— ë¶™ì€ ìˆ«ì (1~20 ì‚¬ì´ë§Œ ì°¨ìˆ˜ë¡œ ê°„ì£¼, ê·¸ ì´ìƒì€ ë™ ë²ˆí˜¸ì¼ ê°€ëŠ¥ì„±)
        match = re.search(r'(\d+)$', normalized)
        if match:
            num = int(match.group(1))
            if 1 <= num <= 20:
                return num
        
        return None
    
    def _extract_parentheses_content(self, name: str) -> Optional[str]:
        """
        ê´„í˜¸ ì•ˆì˜ ë‚´ìš© ì¶”ì¶œ
        
        ì˜ˆì‹œ:
        - "íš¨ìì´Œ(í˜„ëŒ€)" â†’ "í˜„ëŒ€"
        - "í›„ê³¡ë§ˆì„(ê±´ì˜15)" â†’ "ê±´ì˜15"
        - "í›„ê³¡ë§ˆì„(ë™ì•„10)" â†’ "ë™ì•„10"
        """
        if not name:
            return None
        
        # ë‹¤ì–‘í•œ ê´„í˜¸ í˜•íƒœì—ì„œ ë‚´ìš© ì¶”ì¶œ: (), [], {}, ã€ˆã€‰, ã€Šã€‹
        patterns = [
            r'\(([^)]+)\)',      # ()
            r'\[([^\]]+)\]',     # []
            r'\{([^}]+)\}',      # {}
            r'ã€ˆ([^ã€‰]+)ã€‰',      # ã€ˆã€‰
            r'ã€Š([^ã€‹]+)ã€‹',      # ã€Šã€‹
        ]
        
        for pattern in patterns:
            match = re.search(pattern, name)
            if match:
                return match.group(1).strip()
        
        return None
    
    def _extract_brand_from_parentheses(self, name: str) -> Optional[str]:
        """
        ê´„í˜¸ ì•ˆì˜ ë¸Œëœë“œëª… ì¶”ì¶œ
        
        ì˜ˆì‹œ:
        - "íš¨ìì´Œ(í˜„ëŒ€)" â†’ "í˜„ëŒ€"
        - "í›„ê³¡ë§ˆì„(ê±´ì˜15)" â†’ "ê±´ì˜"
        - "í›„ê³¡ë§ˆì„(ë™ì•„10)" â†’ "ë™ì•„"
        """
        content = self._extract_parentheses_content(name)
        if not content:
            return None
        
        # ìˆ«ì ì œê±° í›„ ë¸Œëœë“œëª… ì¶”ì¶œ
        # "ê±´ì˜15" â†’ "ê±´ì˜", "ë™ì•„10" â†’ "ë™ì•„"
        normalized = re.sub(r'\d+', '', content).strip()
        
        # ì•Œë ¤ì§„ ë¸Œëœë“œëª…ì¸ì§€ í™•ì¸
        normalized_lower = normalized.lower()
        for brand in self.APARTMENT_BRANDS:
            brand_lower = brand.lower()
            if brand_lower in normalized_lower or normalized_lower in brand_lower:
                return brand_lower
        
        # ë¸Œëœë“œëª…ì´ ì•„ë‹ˆë©´ ê·¸ëƒ¥ ë°˜í™˜ (ì˜ˆ: "í˜„ëŒ€", "ëŒ€ìš°" ë“±)
        return normalized if normalized else None
    
    def _extract_danji_from_parentheses(self, name: str) -> Optional[int]:
        """
        ê´„í˜¸ ì•ˆì˜ ë‹¨ì§€ ë²ˆí˜¸ ì¶”ì¶œ
        
        ì˜ˆì‹œ:
        - "í›„ê³¡ë§ˆì„(ê±´ì˜15)" â†’ 15
        - "í›„ê³¡ë§ˆì„(ë™ì•„10)" â†’ 10
        - "í›„ê³¡ë§ˆì„(íƒœì˜13)" â†’ 13
        """
        content = self._extract_parentheses_content(name)
        if not content:
            return None
        
        # ê´„í˜¸ ì•ˆì—ì„œ ìˆ«ì ì¶”ì¶œ
        # "ê±´ì˜15" â†’ 15, "ë™ì•„10" â†’ 10
        match = re.search(r'(\d+)', content)
        if match:
            num = int(match.group(1))
            # ë‹¨ì§€ ë²ˆí˜¸ëŠ” ë³´í†µ 1~99 ì‚¬ì´
            if 1 <= num <= 99:
                return num
        
        return None
    
    def _extract_village_name(self, name: str) -> Optional[str]:
        """ë§ˆì„/ë‹¨ì§€ëª… ì¶”ì¶œ (ì˜ˆ: 'í•œë¹›ë§ˆì„4ë‹¨ì§€' â†’ 'í•œë¹›')"""
        if not name:
            return None
        
        normalized = re.sub(r'\s+', '', name).lower()
        
        # ë§ˆì„ëª… ì¶”ì¶œ íŒ¨í„´ë“¤
        for suffix in ['ë§ˆì„', 'ë‹¨ì§€']:
            pattern = rf'([ê°€-í£]+){suffix}'
            match = re.search(pattern, normalized)
            if match:
                village = match.group(1)
                # ìˆ«ì ì œê±° (ì˜ˆ: "í•œë¹›9" â†’ "í•œë¹›")
                village = re.sub(r'\d+', '', village)
                if len(village) >= 2:
                    return village
        
        return None
    
    def _extract_all_brands(self, name: str) -> List[str]:
        """ì•„íŒŒíŠ¸ ì´ë¦„ì—ì„œ ëª¨ë“  ë¸Œëœë“œëª… ì¶”ì¶œ (ë³µìˆ˜ ê°€ëŠ¥)"""
        if not name:
            return []
        
        normalized = re.sub(r'\s+', '', name).lower()
        
        # ë¡œë§ˆìˆ«ì ë³€í™˜
        roman_map = {'â…°': '1', 'â…±': '2', 'â…²': '3', 'â…³': '4', 'â…´': '5', 
                     'â…µ': '6', 'â…¶': '7', 'â…·': '8', 'â…¸': '9', 'â…¹': '10',
                     'â… ': '1', 'â…¡': '2', 'â…¢': '3', 'â…£': '4', 'â…¤': '5',
                     'â…¥': '6', 'â…¦': '7', 'â…§': '8', 'â…¨': '9', 'â…©': '10'}
        for roman, arabic in roman_map.items():
            normalized = normalized.replace(roman, arabic)
        
        # eí¸í•œì„¸ìƒ í†µì¼
        normalized = normalized.replace('eí¸í•œì„¸ìƒ', 'ì´í¸í•œì„¸ìƒ')
        
        found_brands = []
        for brand in self.APARTMENT_BRANDS:
            brand_lower = brand.lower()
            if brand_lower in normalized:
                found_brands.append(brand_lower)
        
        # ì¤‘ë³µ ì œê±° ë° ê¸´ ë¸Œëœë“œ ìš°ì„  (ì˜ˆ: 'ë¡¯ë°ìºìŠ¬íŒŒí¬íƒ€ìš´'ì´ ìˆìœ¼ë©´ 'ë¡¯ë°ìºìŠ¬' ì œê±°)
        final_brands = []
        for brand in found_brands:
            is_subset = False
            for other in found_brands:
                if brand != other and brand in other:
                    is_subset = True
                    break
            if not is_subset:
                final_brands.append(brand)
        
        return final_brands
    
    def _clean_apt_name(self, name: str) -> str:
        """
        ì•„íŒŒíŠ¸ ì´ë¦„ ì •ì œ (ê´„í˜¸ ë° ë¶€ê°€ ì •ë³´ ì œê±°, íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬)
        
        ì²˜ë¦¬ ë‚´ìš©:
        - ì…ì£¼ìëŒ€í‘œíšŒì˜, ê´€ë¦¬ì‚¬ë¬´ì†Œ ë“± ë¶€ê°€ ì •ë³´ ì œê±°
        - ê´„í˜¸ ë° ë‚´ìš© ì œê±°: (), [], {}
        - íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬: &, /, Â·, ~ ë“±
        """
        if not name:
            return ""
        
        # ì…ì£¼ìëŒ€í‘œíšŒì˜, ê´€ë¦¬ì‚¬ë¬´ì†Œ ë“± ë¶€ê°€ ì •ë³´ ì œê±°
        cleaned = re.sub(r'ì…ì£¼ìëŒ€í‘œíšŒì˜', '', name, flags=re.IGNORECASE)
        cleaned = re.sub(r'ê´€ë¦¬ì‚¬ë¬´ì†Œ', '', cleaned, flags=re.IGNORECASE)
        cleaned = re.sub(r'ì œ\d+ê´€ë¦¬ì‚¬ë¬´ì†Œ', '', cleaned)
        
        # ë‹¤ì–‘í•œ ê´„í˜¸ í˜•íƒœ ì œê±°: (), [], {}, ã€ˆã€‰, ã€Šã€‹
        cleaned = re.sub(r'[\(\[\{ã€ˆã€Š][^\)\]\}ã€‰ã€‹]*[\)\]\}ã€‰ã€‹]', '', cleaned)
        
        # & ê¸°í˜¸ë¥¼ ê³µë°±ìœ¼ë¡œ ë³€í™˜
        cleaned = cleaned.replace('&', ' ')
        
        # / ê¸°í˜¸ë¥¼ ê³µë°±ìœ¼ë¡œ ë³€í™˜ (ì˜ˆ: "íìŠ¤í…Œì´íŠ¸/íŒŒí¬" â†’ "íìŠ¤í…Œì´íŠ¸ íŒŒí¬")
        cleaned = cleaned.replace('/', ' ')
        
        # ì¤‘ê°„ì (Â·) ì œê±°
        cleaned = cleaned.replace('Â·', ' ')
        
        # ë¬¼ê²°í‘œ(~) ì œê±°
        cleaned = cleaned.replace('~', '')
        
        # ì—°ì†ëœ ê³µë°± ì œê±°
        cleaned = re.sub(r'\s+', ' ', cleaned)
        
        return cleaned.strip()
    
    def _normalize_apt_name(self, name: str) -> str:
        """
        ì•„íŒŒíŠ¸ ì´ë¦„ ì •ê·œí™” (ëŒ€í•œë¯¼êµ­ ì•„íŒŒíŠ¸ íŠ¹ì„± ê³ ë ¤, ì˜ë¬¸â†”í•œê¸€ ë¸Œëœë“œëª… í†µì¼)
        
        ì •ê·œí™” ê·œì¹™:
        - ê³µë°± ì œê±°
        - ì˜ë¬¸ ì†Œë¬¸ì ë³€í™˜
        - ë¡œë§ˆìˆ«ì â†’ ì•„ë¼ë¹„ì•„ ìˆ«ì
        - ì˜ë¬¸ ë¸Œëœë“œëª… â†’ í•œê¸€ í†µì¼
        - ì¼ë°˜ì ì¸ ì˜¤íƒ€ íŒ¨í„´ ì •ê·œí™”
        - íŠ¹ìˆ˜ë¬¸ì ì œê±°
        """
        if not name:
            return ""
        
        # ê³µë°± ì œê±°
        normalized = re.sub(r'\s+', '', name)
        
        # ì˜ë¬¸ ëŒ€ì†Œë¬¸ì í†µì¼ (ì†Œë¬¸ìë¡œ ë³€í™˜)
        normalized = normalized.lower()
        
        # ë¡œë§ˆìˆ«ìë¥¼ ì•„ë¼ë¹„ì•„ ìˆ«ìë¡œ ë³€í™˜
        roman_map = {'â…°': '1', 'â…±': '2', 'â…²': '3', 'â…³': '4', 'â…´': '5', 
                     'â…µ': '6', 'â…¶': '7', 'â…·': '8', 'â…¸': '9', 'â…¹': '10',
                     'â… ': '1', 'â…¡': '2', 'â…¢': '3', 'â…£': '4', 'â…¤': '5',
                     'â…¥': '6', 'â…¦': '7', 'â…§': '8', 'â…¨': '9', 'â…©': '10'}
        for roman, arabic in roman_map.items():
            normalized = normalized.replace(roman, arabic)
        
        # ğŸ”‘ í•˜ì´í”ˆ/ëŒ€ì‹œ ì œê±°ë¥¼ ë¸Œëœë“œ ë³€í™˜ ì „ì— ìˆ˜í–‰ (e-í¸í•œì„¸ìƒ â†’ eí¸í•œì„¸ìƒ)
        normalized = re.sub(r'[-â€“â€”]', '', normalized)
        
        # ì˜ë¬¸ ë¸Œëœë“œëª… â†’ í•œê¸€ë¡œ í†µì¼ (ê¸´ ê²ƒë¶€í„° ë¨¼ì € ì¹˜í™˜)
        sorted_brands = sorted(BRAND_ENG_TO_KOR.items(), key=lambda x: len(x[0]), reverse=True)
        for eng, kor in sorted_brands:
            normalized = normalized.replace(eng, kor)
        
        # ì¼ë°˜ì ì¸ ì˜¤íƒ€ íŒ¨í„´ ì •ê·œí™” (í•œê¸€)
        typo_map = {
            'íìŠ¤í…Œì‡': 'íìŠ¤í…Œì´íŠ¸',
            'í…Œì‡': 'í…Œì´íŠ¸',
            'ì¼€ìŠ¬': 'ìºìŠ¬',
            'ì¨ë°‹': 'ì„œë°‹',
            'ì¨ë¯¸íŠ¸': 'ì„œë°‹',
            'ë ˆë¯¸ì•ˆ': 'ë˜ë¯¸ì•ˆ',  # ì‹¤ì œë¡œëŠ” ë˜ë¯¸ì•ˆì´ ë§ì§€ë§Œ, ë ˆë¯¸ì•ˆìœ¼ë¡œ ì“°ëŠ” ê²½ìš°ê°€ ë§ìŒ
            'í‘¸ë¥´ì§€ì˜¤': 'í‘¸ë¥´ì§€ì˜¤',  # ì‹¤ì œ ë¸Œëœë“œëª…
            'í‘¸ë¥´ì§€ì›€': 'í‘¸ë¥´ì§€ì˜¤',
            'ìì´': 'ìì´',  # ì‹¤ì œ ë¸Œëœë“œëª…
            'ìŸˆì´': 'ìì´',
            'ì‰ë¥´ë¹Œ': 'ì…°ë¥´ë¹Œ',
            'ì‰ë¥´ë¹Œ': 'ì‰ë¥´ë¹Œ',
        }
        for typo, correct in typo_map.items():
            normalized = normalized.replace(typo, correct)
        
        # ì•„í¬ìŠ¤íŠ¸ë¡œí”¼ ì œê±°
        normalized = re.sub(r"[''`]", '', normalized)
        
        # íŠ¹ìˆ˜ë¬¸ì ì œê±° (í•œê¸€, ì˜ë¬¸, ìˆ«ìë§Œ ìœ ì§€)
        normalized = re.sub(r'[^\wê°€-í£]', '', normalized)
        
        return normalized
    
    def _normalize_apt_name_strict(self, name: str) -> str:
        """
        ì•„íŒŒíŠ¸ ì´ë¦„ ì—„ê²© ì •ê·œí™” (ì°¨ìˆ˜/ë‹¨ì§€ ë²ˆí˜¸ ì œê±°, ë‹¤ì–‘í•œ ì ‘ë¯¸ì‚¬ ì²˜ë¦¬)
        
        ì²˜ë¦¬ ë‚´ìš©:
        - ì°¨ìˆ˜/ë‹¨ì§€ ë²ˆí˜¸ ì œê±°
        - ë‹¤ì–‘í•œ ì•„íŒŒíŠ¸ ì ‘ë¯¸ì‚¬ ì œê±°: ì•„íŒŒíŠ¸, APT, ë¹Œë¼, ë¹Œ, íƒ€ìš´, í•˜ìš°ìŠ¤ ë“±
        """
        if not name:
            return ""
        
        normalized = self._normalize_apt_name(name)
        
        # ì°¨ìˆ˜/ë‹¨ì§€ í‘œê¸° ì œê±°
        normalized = re.sub(r'ì œ?\d+ì°¨', '', normalized)
        normalized = re.sub(r'ì œ?\d+ë‹¨ì§€', '', normalized)
        normalized = re.sub(r'\d{3,}ë™', '', normalized)  # 101ë™, 102ë™ ë“±
        
        # ëì— ë¶™ì€ ìˆ«ì ì œê±° (ì˜ˆ: "ì‚¼ì„±1" â†’ "ì‚¼ì„±", ë‹¨ 1~2ìë¦¬ë§Œ)
        normalized = re.sub(r'\d{1,2}$', '', normalized)
        
        # ë‹¤ì–‘í•œ ì•„íŒŒíŠ¸ ì ‘ë¯¸ì‚¬ ì œê±° (ëŒ€ì†Œë¬¸ì ë¬´ê´€)
        suffixes = [
            'apartment', 'apt', 'apts',
            'ì•„íŒŒíŠ¸', 'ì•„íŒŒì•„íŠ¸',  # ì˜¤íƒ€ í¬í•¨
            'ë¹Œë¼', 'ë¹Œ', 'ë¹Œë¦¬ì§€',
            'íƒ€ìš´', 'town',
            'í•˜ìš°ìŠ¤', 'house',
            'ë§¨ì…˜', 'mansion',
            'ìºìŠ¬', 'castle',
            'ë¹Œë”©', 'building',
            'ì˜¤í”¼ìŠ¤í…”', 'officetel',
        ]
        
        for suffix in suffixes:
            # ëì— ìˆëŠ” ê²½ìš°ë§Œ ì œê±°
            if normalized.endswith(suffix):
                normalized = normalized[:-len(suffix)]
        
        return normalized
    
    def _extract_brand_and_name(self, name: str) -> Tuple[Optional[str], str]:
        """ì•„íŒŒíŠ¸ ì´ë¦„ì—ì„œ ë¸Œëœë“œëª…ê³¼ ë‚˜ë¨¸ì§€ ë¶€ë¶„ ì¶”ì¶œ"""
        if not name:
            return None, ""
        
        normalized = self._normalize_apt_name(name)
        
        # ë¸Œëœë“œëª… ì°¾ê¸° (ê¸´ ê²ƒë¶€í„° ë§¤ì¹­)
        sorted_brands = sorted(self.APARTMENT_BRANDS, key=len, reverse=True)
        for brand in sorted_brands:
            brand_lower = brand.lower()
            if brand_lower in normalized:
                # ë¸Œëœë“œëª… ì œê±°í•œ ë‚˜ë¨¸ì§€ ë°˜í™˜
                remaining = normalized.replace(brand_lower, '', 1)
                return brand, remaining
        
        return None, normalized
    
    def _calculate_similarity(self, str1: str, str2: str) -> float:
        """ë‘ ë¬¸ìì—´ ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0)"""
        if not str1 or not str2:
            return 0.0
        return SequenceMatcher(None, str1, str2).ratio()
    
    def _extract_core_name(self, name: str) -> str:
        """í•µì‹¬ ì´ë¦„ ì¶”ì¶œ (ì§€ì—­ëª…, ë§ˆì„ëª… ë“± ì œê±°)"""
        if not name:
            return ""
        
        normalized = self._normalize_apt_name_strict(name)
        
        # ë§ˆì„/ë‹¨ì§€ ì ‘ë¯¸ì‚¬ì™€ ê·¸ ì•ì˜ ì§€ì—­ëª… ì œê±° ì‹œë„
        for suffix in self.VILLAGE_SUFFIXES:
            if suffix in normalized:
                # suffix ì´í›„ ë¶€ë¶„ë§Œ ì¶”ì¶œ (ë¸Œëœë“œëª…ì´ ë³´í†µ ë’¤ì— ì˜´)
                idx = normalized.find(suffix)
                after_suffix = normalized[idx + len(suffix):]
                if len(after_suffix) >= 2:
                    return after_suffix
        
        return normalized
    
    def _find_matching_regions(self, umd_nm: str, all_regions: Dict[int, Any]) -> set:
        """
        ë™ ì´ë¦„ìœ¼ë¡œ ë§¤ì¹­ë˜ëŠ” ì§€ì—­ ID ì°¾ê¸° (ì/ë©´/ë¦¬/ë™ ë§¤ì¹­ ê°•í™”)
        
        ë§¤ì¹­ ì „ëµ:
        1. ì›ë³¸ ë¬¸ìì—´ ì •í™• ë§¤ì¹­
        2. í›„ë³´ ì¶”ì¶œ ë° ì •í™• ë§¤ì¹­ (ì˜ˆ: "ë´‰í™”ì ë‚´ì„±ë¦¬" â†’ "ë‚´ì„±ë¦¬" ë§¤ì¹­)
        3. ì •ê·œí™”ëœ ì´ë¦„ ì •í™• ë§¤ì¹­
        4. ë¶€ë¶„ ë¬¸ìì—´ í¬í•¨ ê´€ê³„ í™•ì¸ (ì–‘ë°©í–¥, ë” ë„ë„í•˜ê²Œ)
        5. ì •ê·œí™”ëœ ì´ë¦„ í¬í•¨ ê´€ê³„ í™•ì¸
        """
        if not umd_nm:
            return set()
        
        matching_region_ids = set()
        
        # ë§¤ì¹­ í›„ë³´ ì¶”ì¶œ (ì˜ˆ: "ë´‰í™”ì ë‚´ì„±ë¦¬" â†’ ["ë´‰í™”ì ë‚´ì„±ë¦¬", "ë‚´ì„±ë¦¬", "ë´‰í™”ì", "ë‚´ì„±", "ë´‰í™”"])
        umd_candidates = self._extract_dong_parts(umd_nm)
        
        # ì •ê·œí™”ëœ í›„ë³´ë„ ì¶”ê°€
        normalized_umd = self._normalize_dong_name(umd_nm)
        if normalized_umd and normalized_umd not in umd_candidates:
            umd_candidates.append(normalized_umd)
        
        for region_id, region in all_regions.items():
            region_name = region.region_name
            normalized_region = self._normalize_dong_name(region_name)
            
            # 1ë‹¨ê³„: ì›ë³¸ ë¬¸ìì—´ ì •í™• ë§¤ì¹­
            if region_name == umd_nm:
                matching_region_ids.add(region_id)
                continue
            
            # 2ë‹¨ê³„: í›„ë³´ ì¶”ì¶œëœ ì´ë¦„ ì •í™• ë§¤ì¹­ (ê°€ì¥ ì¤‘ìš”!)
            # ì˜ˆ: "ë´‰í™”ì ë‚´ì„±ë¦¬"ì˜ í›„ë³´ "ë‚´ì„±ë¦¬"ì™€ DBì˜ "ë‚´ì„±ë¦¬" ë§¤ì¹­
            for umd_candidate in umd_candidates:
                if region_name == umd_candidate:
                    matching_region_ids.add(region_id)
                    break
            
            if region_id in matching_region_ids:
                continue
            
            # 3ë‹¨ê³„: ì •ê·œí™”ëœ ì´ë¦„ ì •í™• ë§¤ì¹­
            if normalized_umd and normalized_region:
                if normalized_region == normalized_umd:
                    matching_region_ids.add(region_id)
                    continue
                
                # í›„ë³´ë“¤ì˜ ì •ê·œí™” ë²„ì „ë„ í™•ì¸
                for umd_candidate in umd_candidates:
                    normalized_candidate = self._normalize_dong_name(umd_candidate)
                    if normalized_region == normalized_candidate and normalized_region:
                        matching_region_ids.add(region_id)
                        break
            
            if region_id in matching_region_ids:
                continue
            
            # 4ë‹¨ê³„: ë¶€ë¶„ ë¬¸ìì—´ í¬í•¨ ê´€ê³„ í™•ì¸ (ì–‘ë°©í–¥, ë” ë„ë„í•˜ê²Œ)
            # ì›ë³¸ ë¬¸ìì—´ í¬í•¨ ê´€ê³„
            if umd_nm in region_name or region_name in umd_nm:
                matching_region_ids.add(region_id)
                continue
            
            # í›„ë³´ë“¤ë¡œ í¬í•¨ ê´€ê³„ í™•ì¸ (ë” ë„ë„í•˜ê²Œ)
            for umd_candidate in umd_candidates:
                # í›„ë³´ê°€ region_nameì— í¬í•¨ë˜ê±°ë‚˜, region_nameì´ í›„ë³´ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
                if umd_candidate in region_name or region_name in umd_candidate:
                    matching_region_ids.add(region_id)
                    break
            
            if region_id in matching_region_ids:
                continue
            
            # 5ë‹¨ê³„: ì •ê·œí™”ëœ ì´ë¦„ í¬í•¨ ê´€ê³„ í™•ì¸
            if normalized_umd and normalized_region:
                if normalized_umd in normalized_region or normalized_region in normalized_umd:
                    matching_region_ids.add(region_id)
        
        return matching_region_ids
    
    def _match_apartment(
        self,
        apt_name_api: str,
        candidates: List[Apartment],
        sgg_cd: str,
        umd_nm: Optional[str] = None,
        jibun: Optional[str] = None,
        build_year: Optional[str] = None,
        apt_details: Optional[Dict[int, ApartDetail]] = None,
        normalized_cache: Optional[Dict[str, Any]] = None,
        all_regions: Optional[Dict[int, Any]] = None,
        require_dong_match: bool = False
    ) -> Optional[Apartment]:
        """
        ì•„íŒŒíŠ¸ ë§¤ì¹­ (í•œêµ­ ì•„íŒŒíŠ¸ íŠ¹ì„±ì— ìµœì í™”ëœ ê°•í™” ë²„ì „)

        ì§€ì—­ê³¼ ë²•ì •ë™ì´ ì¼ì¹˜í•œë‹¤ëŠ” ê°€ì • í•˜ì— ë‹¤ë‹¨ê³„ ë§¤ì¹­ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        í•µì‹¬ ë§¤ì¹­ ì „ëµ:
        1. ì •ê·œí™”ëœ ì´ë¦„ ì •í™• ë§¤ì¹­
        2. ë¸Œëœë“œëª… + ë‹¨ì§€ë²ˆí˜¸ ë³µí•© ë§¤ì¹­ (ê°€ì¥ ì¤‘ìš”!)
        3. ë¸Œëœë“œëª… + ë§ˆì„ëª… ë³µí•© ë§¤ì¹­
        4. ì§€ë²ˆ ê¸°ë°˜ ë§¤ì¹­ (NEW!)
        5. ê±´ì¶•ë…„ë„ ê¸°ë°˜ ë§¤ì¹­ (NEW!)
        6. ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­ (SequenceMatcher)
        7. í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤ì¹­

        ì˜ˆì‹œ:
        - "í•œë¹›ë§ˆì„4ë‹¨ì§€ë¡¯ë°ìºìŠ¬â…¡" â†” "ë¡¯ë°ìºìŠ¬ íŒŒí¬íƒ€ìš´ â…¡" (ë¸Œëœë“œ+ë‹¨ì§€ë²ˆí˜¸ ë¬´ì‹œ, ê°™ì€ ë™)
        - "í•œë¹›9ë‹¨ì§€ ë¡¯ë°ìºìŠ¬íŒŒí¬íƒ€ìš´" â†” "í•œë¹›ë§ˆì„9ë‹¨ì§€ë¡¯ë°ìºìŠ¬1ì°¨" (ë¸Œëœë“œ+ë‹¨ì§€ë²ˆí˜¸)

        Args:
            apt_name_api: APIì—ì„œ ë°›ì€ ì•„íŒŒíŠ¸ ì´ë¦„
            candidates: í›„ë³´ ì•„íŒŒíŠ¸ ë¦¬ìŠ¤íŠ¸
            sgg_cd: 5ìë¦¬ ì‹œêµ°êµ¬ ì½”ë“œ
            umd_nm: ë™ ì´ë¦„ (ì„ íƒ)
            jibun: API ì§€ë²ˆ (ì„ íƒ)
            build_year: API ê±´ì¶•ë…„ë„ (ì„ íƒ)
            apt_details: ì•„íŒŒíŠ¸ ìƒì„¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬ (ì„ íƒ)
            normalized_cache: ì •ê·œí™” ê²°ê³¼ ìºì‹œ (ì„±ëŠ¥ ìµœì í™”)
            all_regions: ì§€ì—­ ì •ë³´ ë”•ì…”ë„ˆë¦¬ - ë™ ê²€ì¦ìš© (ì„ íƒ)
            require_dong_match: Trueë©´ ë™ ì¼ì¹˜ ê²€ì¦ í•„ìˆ˜ (ê¸°ë³¸ê°’: False)

        Returns:
            ë§¤ì¹­ëœ Apartment ê°ì²´ ë˜ëŠ” None
        """
        if not apt_name_api or not candidates:
            return None
        
        # ì •ê·œí™” ê²°ê³¼ ìºì‹± (ì„±ëŠ¥ ìµœì í™”)
        if normalized_cache is None:
            normalized_cache = {}
        
        # API ì´ë¦„ ë¶„ì„ (ìºì‹±)
        cache_key_api = f"api:{apt_name_api}"
        if cache_key_api not in normalized_cache:
            cleaned_api = self._clean_apt_name(apt_name_api)
            normalized_api = self._normalize_apt_name(cleaned_api)
            normalized_strict_api = self._normalize_apt_name_strict(cleaned_api)
            brands_api = self._extract_all_brands(apt_name_api)
            danji_api = self._extract_danji_number(apt_name_api)
            cha_api = self._extract_cha_number(apt_name_api)
            village_api = self._extract_village_name(apt_name_api)
            core_api = self._extract_core_name(cleaned_api)
            # ê´„í˜¸ ì•ˆì˜ ë¸Œëœë“œëª…ê³¼ ë‹¨ì§€ ë²ˆí˜¸ ì¶”ì¶œ
            brand_in_parens_api = self._extract_brand_from_parentheses(apt_name_api)
            danji_in_parens_api = self._extract_danji_from_parentheses(apt_name_api)
            normalized_cache[cache_key_api] = {
                'cleaned': cleaned_api,
                'normalized': normalized_api,
                'strict': normalized_strict_api,
                'brands': brands_api,
                'danji': danji_api,
                'cha': cha_api,
                'village': village_api,
                'core': core_api,
                'brand_in_parens': brand_in_parens_api,
                'danji_in_parens': danji_in_parens_api
            }
        api_cache = normalized_cache[cache_key_api]
        
        if not api_cache['cleaned'] or not api_cache['normalized']:
            return None
        
        # API ì´ë¦„ì´ ì§€ë²ˆë§Œ ìˆëŠ”ì§€ í™•ì¸ (ì˜ˆ: "(1101-1)", "(627-41)")
        # í•œê¸€ ì—†ì´ ìˆ«ìì™€ íŠ¹ìˆ˜ë¬¸ìë§Œ ìˆìœ¼ë©´ ì§€ë²ˆìœ¼ë¡œ ê°„ì£¼
        api_is_jibun_only = not re.search(r'[ê°€-í£a-zA-Z]', api_cache['cleaned'])
        
        # í›„ë³´ ì•„íŒŒíŠ¸ ì •ê·œí™” ë° ì ìˆ˜ ê³„ì‚°
        best_match = None
        best_score = 0.0
        
        for apt in candidates:
            cache_key_db = f"db:{apt.apt_name}"
            if cache_key_db not in normalized_cache:
                cleaned_db = self._clean_apt_name(apt.apt_name)
                normalized_db = self._normalize_apt_name(cleaned_db)
                normalized_strict_db = self._normalize_apt_name_strict(cleaned_db)
                brands_db = self._extract_all_brands(apt.apt_name)
                danji_db = self._extract_danji_number(apt.apt_name)
                cha_db = self._extract_cha_number(apt.apt_name)
                village_db = self._extract_village_name(apt.apt_name)
                core_db = self._extract_core_name(cleaned_db)
                # ê´„í˜¸ ì•ˆì˜ ë¸Œëœë“œëª…ê³¼ ë‹¨ì§€ ë²ˆí˜¸ ì¶”ì¶œ
                brand_in_parens_db = self._extract_brand_from_parentheses(apt.apt_name)
                danji_in_parens_db = self._extract_danji_from_parentheses(apt.apt_name)
                normalized_cache[cache_key_db] = {
                    'cleaned': cleaned_db,
                    'normalized': normalized_db,
                    'strict': normalized_strict_db,
                    'brands': brands_db,
                    'danji': danji_db,
                    'cha': cha_db,
                    'village': village_db,
                    'core': core_db,
                    'brand_in_parens': brand_in_parens_db,
                    'danji_in_parens': danji_in_parens_db
                }
            db_cache = normalized_cache[cache_key_db]
            
            score = 0.0
            
            # === 0ë‹¨ê³„: ë‹¨ì§€ ë²ˆí˜¸ í•„í„°ë§ (ì¤‘ìš”!) ===
            # API ì´ë¦„ì— ë‹¨ì§€ ë²ˆí˜¸ê°€ ìˆìœ¼ë©´, ë‹¨ì§€ ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” í›„ë³´ëŠ” ì œì™¸
            api_danji = api_cache['danji']
            api_cha = api_cache['cha']
            db_danji = db_cache['danji']
            db_cha = db_cache['cha']
            
            # ì§€ë²ˆ/ê±´ì¶•ë…„ë„ ë§¤ì¹­ ì—¬ë¶€ë¥¼ ë¨¼ì € í™•ì¸ (ë‹¨ì§€ ë²ˆí˜¸ê°€ ë‹¬ë¼ë„ ì§€ë²ˆ/ê±´ì¶•ë…„ë„ê°€ ì¼ì¹˜í•˜ë©´ ë§¤ì¹­)
            jibun_match_early = False
            build_year_match_early = False
            
            if jibun and apt_details and apt.apt_id in apt_details:
                detail = apt_details[apt.apt_id]
                if detail.jibun_address:
                    norm_jibun_api = re.sub(r'[\s\-]+', '', jibun)
                    norm_jibun_db = re.sub(r'[\s\-]+', '', detail.jibun_address)
                    jibun_api_parts = norm_jibun_api.split(',')[0] if ',' in norm_jibun_api else norm_jibun_api
                    if jibun_api_parts in norm_jibun_db or norm_jibun_api in norm_jibun_db:
                        jibun_match_early = True
            
            # ğŸ”‘ ì´ë¦„ ì •í™• ë§¤ì¹­ ìš°ì„  ê²€ì‚¬ (ê±´ì¶•ë…„ë„ Veto ì „ì—!)
            # ì´ë¦„ì´ ì •í™•íˆ ì¼ì¹˜í•˜ë©´ ê±´ì¶•ë…„ë„ ì°¨ì´ì™€ ìƒê´€ì—†ì´ ë°”ë¡œ ë°˜í™˜
            if api_cache['normalized'] == db_cache['normalized']:
                return apt  # ì •í™• ë§¤ì¹­ì€ ë°”ë¡œ ë°˜í™˜
            
            if build_year and apt_details and apt.apt_id in apt_details:
                detail = apt_details[apt.apt_id]
                if detail.use_approval_date:
                    try:
                        approval_year = detail.use_approval_date.split('-')[0]
                        year_diff = abs(int(build_year) - int(approval_year))
                        
                        # ğŸš« VETO: ê±´ì¶•ë…„ë„ 3ë…„ ì´ˆê³¼ ì°¨ì´ â†’ ì¦‰ì‹œ ì œì™¸
                        # (ë‹¨, ì´ë¦„ ì •í™• ë§¤ì¹­ì€ ìœ„ì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë¨)
                        if year_diff > BUILD_YEAR_TOLERANCE:
                            continue  # ë‹¤ë¥¸ ì•„íŒŒíŠ¸ì¼ ê°€ëŠ¥ì„± ë†’ìŒ
                        
                        if year_diff <= 1:
                            build_year_match_early = True
                    except (ValueError, AttributeError):
                        pass
            
            # ì§€ë²ˆê³¼ ê±´ì¶•ë…„ë„ê°€ ëª¨ë‘ ì¼ì¹˜í•˜ë©´ ë‹¨ì§€ ë²ˆí˜¸ê°€ ë‹¬ë¼ë„ ë§¤ì¹­ í—ˆìš©
            skip_danji_check = jibun_match_early and build_year_match_early
            
            # === 0.5ë‹¨ê³„: ê´„í˜¸ ì•ˆì˜ ë¸Œëœë“œëª…ê³¼ ë‹¨ì§€ ë²ˆí˜¸ í•„í„°ë§ (ì¤‘ìš”!) ===
            brand_in_parens_api = api_cache.get('brand_in_parens')
            danji_in_parens_api = api_cache.get('danji_in_parens')
            brand_in_parens_db = db_cache.get('brand_in_parens')
            danji_in_parens_db = db_cache.get('danji_in_parens')
            
            # APIì— ê´„í˜¸ ì•ˆì˜ ë¸Œëœë“œëª…ì´ ìˆìœ¼ë©´, DBì—ë„ ê°™ì€ ë¸Œëœë“œëª…ì´ ìˆì–´ì•¼ í•¨
            # ë‹¨, ê´„í˜¸ ì•ˆ ë‚´ìš©ì´ DB ì•„íŒŒíŠ¸ëª…ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì§„í–‰ (ì‹¤ì œ ì•„íŒŒíŠ¸ëª…ì¸ ê²½ìš°)
            if brand_in_parens_api:
                if brand_in_parens_db:
                    # ë‘˜ ë‹¤ ê´„í˜¸ ì•ˆì— ë¸Œëœë“œëª…ì´ ìˆìœ¼ë©´ ì¼ì¹˜í•´ì•¼ í•¨
                    if brand_in_parens_api.lower() != brand_in_parens_db.lower():
                        # ê´„í˜¸ ì•ˆì˜ ë¸Œëœë“œëª…ì´ ë‹¤ë¥´ë©´ ì œì™¸ (ì˜ˆ: "íš¨ìì´Œ(í˜„ëŒ€)" vs "íš¨ìì´Œ(ëŒ€ìš°)")
                        continue
                else:
                    # APIì—ëŠ” ê´„í˜¸ ì•ˆ ë¸Œëœë“œëª…ì´ ìˆì§€ë§Œ DBì—ëŠ” ì—†ëŠ” ê²½ìš°
                    # ê´„í˜¸ ì•ˆ ì›ë³¸ ë‚´ìš©ì´ DB ì•„íŒŒíŠ¸ëª…ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                    # (ì˜ˆ: "íŒêµì›ë§ˆì„6ë‹¨ì§€(íŒêµëŒ€ê´‘ë¡œì œë¹„ì•™)" vs "íŒêµëŒ€ê´‘ë¡œì œë¹„ì•™ì•„íŒŒíŠ¸")
                    
                    # ì›ë³¸ ê´„í˜¸ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° (ë¸Œëœë“œ ì¶”ì¶œ ì „)
                    original_parens = self._extract_parentheses_content(apt_name_api) or ""
                    original_parens_lower = original_parens.lower()
                    parens_content_lower = brand_in_parens_api.lower()
                    
                    db_name_lower = db_cache['normalized'].lower()
                    db_cleaned_lower = db_cache['cleaned'].lower() if db_cache.get('cleaned') else ''
                    apt_name_db = apt.apt_name.lower()
                    
                    # 1. ì›ë³¸ ê´„í˜¸ ë‚´ìš©ì´ DB ì•„íŒŒíŠ¸ëª…ì— í¬í•¨
                    # (ì˜ˆ: "íŒêµëŒ€ê´‘ë¡œì œë¹„ì•™" in "íŒêµëŒ€ê´‘ë¡œì œë¹„ì•™ì•„íŒŒíŠ¸")
                    if original_parens_lower and (
                        original_parens_lower in db_name_lower or 
                        original_parens_lower in db_cleaned_lower or
                        original_parens_lower in apt_name_db
                    ):
                        pass  # ì§„í–‰ - ê´„í˜¸ ì•ˆ ë‚´ìš©ì´ ì‹¤ì œ ì•„íŒŒíŠ¸ëª…
                    # 2. ì¶”ì¶œëœ ë¸Œëœë“œëª…ì´ DB ì•„íŒŒíŠ¸ëª…ì— í¬í•¨
                    elif parens_content_lower in db_name_lower or parens_content_lower in db_cleaned_lower:
                        pass  # ì§„í–‰
                    # 3. DB ì•„íŒŒíŠ¸ëª…ì´ ê´„í˜¸ ë‚´ìš©ì— í¬í•¨ (ì—­ë°©í–¥)
                    elif db_name_lower in original_parens_lower or db_name_lower in parens_content_lower:
                        pass  # ì§„í–‰ (ì—­ë°©í–¥ í¬í•¨)
                    else:
                        # ë¸Œëœë“œ ì‚¬ì „ì— ìˆëŠ” ë¸Œëœë“œì¸ë° DBì— ì—†ìœ¼ë©´ ì œì™¸
                        # (ì˜ˆ: "íš¨ìì´Œ(í˜„ëŒ€)" vs "íš¨ìì´Œ" - ë‹¤ë¥¸ ì•„íŒŒíŠ¸)
                        if brand_in_parens_api.lower() in [b.lower() for b in self.APARTMENT_BRANDS]:
                            continue
            
            # === ë‹¨ì§€ ë²ˆí˜¸ í†µí•© ë¹„êµ ===
            # APIì™€ DBì˜ ë‹¨ì§€ ë²ˆí˜¸ë¥¼ í†µí•©í•˜ì—¬ ë¹„êµ (ì¼ë°˜ ë‹¨ì§€ ë²ˆí˜¸ + ê´„í˜¸ ì•ˆ ë‹¨ì§€ ë²ˆí˜¸)
            api_danji_final = api_danji if api_danji is not None else danji_in_parens_api
            db_danji_final = db_danji if db_danji is not None else danji_in_parens_db
            
            # APIì— ê´„í˜¸ ì•ˆì˜ ë‹¨ì§€ ë²ˆí˜¸ê°€ ìˆìœ¼ë©´, DBì—ë„ ê°™ì€ ë‹¨ì§€ ë²ˆí˜¸ê°€ ìˆì–´ì•¼ í•¨
            if danji_in_parens_api is not None:
                if danji_in_parens_db is not None:
                    if danji_in_parens_api != danji_in_parens_db:
                        # ê´„í˜¸ ì•ˆì˜ ë‹¨ì§€ ë²ˆí˜¸ê°€ ë‹¤ë¥´ë©´ ì œì™¸ (ì˜ˆ: "í›„ê³¡ë§ˆì„10ë‹¨ì§€" vs "í›„ê³¡ë§ˆì„(ê±´ì˜15)")
                        continue
            
            # APIì— ë‹¨ì§€ ë²ˆí˜¸ë‚˜ ì°¨ìˆ˜ê°€ ìˆìœ¼ë©´ ë¹„êµ
            # ğŸ”‘ í•µì‹¬ ë¡œì§ ê°œì„ :
            # - DBì— ë‹¨ì§€ ë²ˆí˜¸ê°€ "ë‹¤ë¥´ë©´" ì œì™¸ (7ë‹¨ì§€ â†’ 4ë‹¨ì§€ X)
            # - DBì— ë‹¨ì§€ ë²ˆí˜¸ê°€ "ì—†ìœ¼ë©´" ì¡°ê±´ë¶€ í—ˆìš©:
            #   - ê´„í˜¸ ì•ˆ ë¸Œëœë“œëª…ì´ ìˆìœ¼ë©´ ì œì™¸ (í›„ê³¡ë§ˆì„10ë‹¨ì§€ vs í›„ê³¡ë§ˆì„(ëŒ€ì°½) X)
            #   - ê´„í˜¸ ì•ˆ ë¸Œëœë“œëª…ì´ ì—†ìœ¼ë©´ í—ˆìš© (ê²½ë‚¨ì•„ë„ˆìŠ¤ë¹Œ1ë‹¨ì§€ vs ê²½ë‚¨ì•„ë„ˆìŠ¤ë¹Œì•„íŒŒíŠ¸ O)
            if api_danji_final is not None:
                if db_danji_final is not None:
                    # ë‘˜ ë‹¤ ë‹¨ì§€ ë²ˆí˜¸ê°€ ìˆìœ¼ë©´ ê°™ì•„ì•¼ í•¨
                    if db_danji_final != api_danji_final:
                        # ë‹¨ì§€ ë²ˆí˜¸ê°€ ë‹¤ë¥´ë©´ ë¬´ì¡°ê±´ ì œì™¸ (ì§€ë²ˆ/ê±´ì¶•ë…„ë„ ì¼ì¹˜í•´ë„)
                        continue
                else:
                    # DBì— ë‹¨ì§€ ë²ˆí˜¸ê°€ ì—†ëŠ” ê²½ìš°
                    # ê´„í˜¸ ì•ˆì— ë¸Œëœë“œëª…ì´ ìˆìœ¼ë©´ ë‹¤ë¥¸ ë‹¨ì§€ë¡œ ê°„ì£¼í•˜ì—¬ ì œì™¸
                    # (ì˜ˆ: "í›„ê³¡ë§ˆì„10ë‹¨ì§€" vs "í›„ê³¡ë§ˆì„(ëŒ€ì°½)" - ëŒ€ì°½ì€ ë³„ë„ ë‹¨ì§€)
                    if brand_in_parens_db:
                        continue
                    # ê´„í˜¸ ì•ˆì— ë¸Œëœë“œëª…ì´ ì—†ìœ¼ë©´ ì¼ë°˜ ì•„íŒŒíŠ¸ëª…ìœ¼ë¡œ ê°„ì£¼í•˜ì—¬ í—ˆìš©
                    # (ì˜ˆ: "ê²½ë‚¨ì•„ë„ˆìŠ¤ë¹Œ1ë‹¨ì§€" vs "ê²½ë‚¨ì•„ë„ˆìŠ¤ë¹Œì•„íŒŒíŠ¸" - ë§¤ì¹­ í—ˆìš©)
            elif api_cha is not None:
                # APIì— ì°¨ìˆ˜ê°€ ìˆìœ¼ë©´ ë¹„êµ
                if db_cha is not None:
                    # ë‘˜ ë‹¤ ì°¨ìˆ˜ê°€ ìˆìœ¼ë©´ ê°™ì•„ì•¼ í•¨
                    if db_cha != api_cha:
                        continue
                else:
                    # DBì— ì°¨ìˆ˜ê°€ ì—†ëŠ” ê²½ìš°
                    # ê´„í˜¸ ì•ˆì— ë¸Œëœë“œëª…ì´ ìˆìœ¼ë©´ ë‹¤ë¥¸ ë‹¨ì§€ë¡œ ê°„ì£¼í•˜ì—¬ ì œì™¸
                    if brand_in_parens_db:
                        continue
                    # ê´„í˜¸ ì•ˆì— ë¸Œëœë“œëª…ì´ ì—†ìœ¼ë©´ í—ˆìš©
            
            # === 0.7ë‹¨ê³„: ë¸Œëœë“œ ê·¸ë£¹ ë¶ˆì¼ì¹˜ Veto ===
            # ë‘˜ ë‹¤ ëª…í™•í•œ ë¸Œëœë“œê°€ ì‹ë³„ë˜ì—ˆëŠ”ë° ë‹¤ë¥´ë©´ â†’ VETO
            api_brands = set(api_cache['brands'])
            db_brands = set(db_cache['brands'])
            common_brands = api_brands & db_brands
            has_common_brand = len(common_brands) > 0
            
            # ì£¼ìš” ë¸Œëœë“œ ëª©ë¡ (ì´ ë¸Œëœë“œê°€ APIì— ìˆìœ¼ë©´ DBì—ë„ ìˆì–´ì•¼ í•¨)
            MAJOR_BRANDS = {
                'ìì´', 'ë˜ë¯¸ì•ˆ', 'í‘¸ë¥´ì§€ì˜¤', 'íìŠ¤í…Œì´íŠ¸', 'ì´í¸í•œì„¸ìƒ', 'eí¸í•œì„¸ìƒ',
                'ë”ìƒµ', 'ì•„ì´íŒŒí¬', 'ì„¼íŠ¸ë ˆë¹Œ', 'ë¡¯ë°ìºìŠ¬', 'ìœ„ë¸Œ', 'í˜¸ë°˜ì¨ë°‹',
                'ì•„í¬ë¡œ', 'í¬ë ˆë‚˜', 'ê¿ˆì—ê·¸ë¦°', 'ìŠ¤ìœ„ì²¸', 'íŠ¸ë¼íŒ°ë¦¬ìŠ¤', 'íœ´ë¨¼ì‹œì•„'
            }
            
            # ë‘˜ ë‹¤ ë¸Œëœë“œê°€ ìˆëŠ”ë° ê³µí†µ ë¸Œëœë“œê°€ ì—†ìœ¼ë©´ Veto
            # ë‹¨, ë¸Œëœë“œê°€ í•˜ë‚˜ë„ ì—†ëŠ” ê²½ìš°ëŠ” í†µê³¼ (ì¼ë°˜ ì•„íŒŒíŠ¸ëª…)
            if api_brands and db_brands and not has_common_brand:
                # í‘œì¤€ ë¸Œëœë“œëª…ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë‹¤ì‹œ ë¹„êµ
                api_std = {BRAND_KEYWORD_TO_STANDARD.get(b.lower(), b) for b in api_brands}
                db_std = {BRAND_KEYWORD_TO_STANDARD.get(b.lower(), b) for b in db_brands}
                if api_std and db_std and not (api_std & db_std):
                    # ğŸš« VETO: ë¸Œëœë“œ ê·¸ë£¹ ë¶ˆì¼ì¹˜ (ìì´ vs ë˜ë¯¸ì•ˆ ë“±)
                    continue
            
            # ğŸ”‘ ì¶”ê°€ Veto: APIì— ì£¼ìš” ë¸Œëœë“œê°€ ìˆëŠ”ë° DBì— ì—†ìœ¼ë©´ Veto
            # (ì˜ˆ: "LGì‹ ì‚°ë³¸ìì´2ì°¨" vs "ë‹¹ì •ë§ˆì„ì—˜ì§€" - ìì´ê°€ ì—†ìœ¼ë¯€ë¡œ Veto)
            api_brands_lower = {b.lower() for b in api_brands}
            db_brands_lower = {b.lower() for b in db_brands}
            api_major_brands = api_brands_lower & {b.lower() for b in MAJOR_BRANDS}
            
            if api_major_brands:
                # APIì— ì£¼ìš” ë¸Œëœë“œê°€ ìˆìœ¼ë©´, DBì—ë„ í•´ë‹¹ ë¸Œëœë“œê°€ ìˆì–´ì•¼ í•¨
                db_has_api_major = bool(api_major_brands & db_brands_lower)
                if not db_has_api_major:
                    # ğŸš« VETO: APIì˜ ì£¼ìš” ë¸Œëœë“œê°€ DBì— ì—†ìŒ
                    continue
            
            # === 1ë‹¨ê³„: ì •ê·œí™”ëœ ì´ë¦„ ì •í™• ë§¤ì¹­ (ìµœê³  ì ìˆ˜) ===
            if api_cache['normalized'] == db_cache['normalized']:
                return apt  # ì •í™• ë§¤ì¹­ì€ ë°”ë¡œ ë°˜í™˜
            
            # === 2ë‹¨ê³„: ì—„ê²© ì •ê·œí™” í›„ ì •í™• ë§¤ì¹­ ===
            # ë‹¨, ë‹¨ì§€ ë²ˆí˜¸ê°€ ìˆëŠ” ê²½ìš°ëŠ” ì—„ê²© ì •ê·œí™” ë§¤ì¹­ì„ ê±´ë„ˆë›°ì–´ì•¼ í•¨
            # (ë‹¨ì§€ ë²ˆí˜¸ê°€ ì œê±°ë˜ë©´ ë‹¤ë¥¸ ë‹¨ì§€ì™€ êµ¬ë¶„ì´ ì•ˆ ë¨)
            if api_danji is None and api_cha is None:
                if api_cache['strict'] == db_cache['strict']:
                    return apt  # ì°¨ìˆ˜/ë‹¨ì§€ ì œê±° í›„ ì •í™• ë§¤ì¹­ (ë‹¨ì§€ ë²ˆí˜¸ê°€ ì—†ëŠ” ê²½ìš°ë§Œ)
            
            # === 3ë‹¨ê³„: ë¸Œëœë“œëª… + ë‹¨ì§€ë²ˆí˜¸ ë³µí•© ë§¤ì¹­ (í•µì‹¬!) ===
            # (common_brands, has_common_brandëŠ” 0.7ë‹¨ê³„ì—ì„œ ì´ë¯¸ ê³„ì‚°ë¨)
            
            # ë‹¨ì§€ë²ˆí˜¸ ì¼ì¹˜ í™•ì¸ (ì´ë¯¸ 0ë‹¨ê³„ì—ì„œ í•„í„°ë§í–ˆìœ¼ë¯€ë¡œ ì¼ì¹˜í•¨)
            danji_match = (api_danji is not None and 
                          db_danji is not None and 
                          api_danji == db_danji)
            
            # ë§ˆì„ëª… ì¼ì¹˜ í™•ì¸
            village_match = False
            if api_cache['village'] and db_cache['village']:
                v_api = api_cache['village'].lower()
                v_db = db_cache['village'].lower()
                village_match = (v_api == v_db or v_api in v_db or v_db in v_api)
            
            # ë¸Œëœë“œ + ë‹¨ì§€ë²ˆí˜¸ ì¼ì¹˜ â†’ ë§¤ìš° ë†’ì€ ì ìˆ˜ (ê±°ì˜ í™•ì‹¤íˆ ê°™ì€ ì•„íŒŒíŠ¸)
            if has_common_brand and danji_match:
                score = max(score, 0.95)
            
            # ë¸Œëœë“œ + ë§ˆì„ëª… ì¼ì¹˜ â†’ ë†’ì€ ì ìˆ˜
            if has_common_brand and village_match:
                score = max(score, 0.90)
            
            # ë‹¨ì§€ë²ˆí˜¸ + ë§ˆì„ëª… ì¼ì¹˜ â†’ ë†’ì€ ì ìˆ˜ (ë¸Œëœë“œ ì—†ì–´ë„)
            if danji_match and village_match:
                score = max(score, 0.88)
            
            # ë¸Œëœë“œë§Œ ì¼ì¹˜ (ê°™ì€ ë™ì— í•´ë‹¹ ë¸Œëœë“œ ì•„íŒŒíŠ¸ê°€ í•˜ë‚˜ë¿ì¼ ê°€ëŠ¥ì„±)
            if has_common_brand and len(candidates) <= 3:
                score = max(score, 0.75)
            elif has_common_brand:
                score = max(score, 0.60)
            
            # ë‹¨ì§€ë²ˆí˜¸ë§Œ ì¼ì¹˜ (ê°™ì€ ë™ì— í•´ë‹¹ ë‹¨ì§€ê°€ í•˜ë‚˜ë¿ì¼ ê°€ëŠ¥ì„±)
            if danji_match and len(candidates) <= 3:
                score = max(score, 0.70)
            
            # === 3.5ë‹¨ê³„: ì§€ë²ˆ ê¸°ë°˜ ë§¤ì¹­ (NEW!) ===
            jibun_match = False
            jibun_full_match = False  # ë³¸ë²ˆ+ë¶€ë²ˆ ì™„ì „ ì¼ì¹˜
            if jibun and apt_details and apt.apt_id in apt_details:
                detail = apt_details[apt.apt_id]
                if detail.jibun_address:
                    # API ì§€ë²ˆì—ì„œ ë³¸ë²ˆ-ë¶€ë²ˆ ì¶”ì¶œ (ì˜ˆ: "1101-1" â†’ ë³¸ë²ˆ=1101, ë¶€ë²ˆ=1)
                    jibun_clean = jibun.strip()
                    jibun_parts = re.match(r'(\d+)(?:-(\d+))?', jibun_clean)
                    api_main = jibun_parts.group(1) if jibun_parts else None
                    api_sub = jibun_parts.group(2) if jibun_parts and jibun_parts.group(2) else None
                    
                    # DB ì§€ë²ˆ ì£¼ì†Œì—ì„œ ë²ˆì§€ ì¶”ì¶œ (ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„)
                    # ì˜ˆ: "ì„œìš¸ì‹œ ì˜ë“±í¬êµ¬ ëŒ€ë¦¼ë™ 1101-1" â†’ 1101-1
                    db_jibun_match = re.search(r'(\d+)(?:-(\d+))?(?:\s|$)', detail.jibun_address)
                    db_main = db_jibun_match.group(1) if db_jibun_match else None
                    db_sub = db_jibun_match.group(2) if db_jibun_match and db_jibun_match.group(2) else None
                    
                    if api_main and db_main:
                        # ë³¸ë²ˆ ë¹„êµ
                        if api_main == db_main:
                            jibun_match = True
                            # ë¶€ë²ˆë„ ë¹„êµ (ë‘˜ ë‹¤ ìˆëŠ” ê²½ìš°)
                            if api_sub and db_sub and api_sub == db_sub:
                                jibun_full_match = True
                            elif not api_sub and not db_sub:
                                jibun_full_match = True
                    
                    # ê¸°ì¡´ í¬í•¨ í™•ì¸ë„ ìœ ì§€ (fallback)
                    if not jibun_match:
                        norm_jibun_api = re.sub(r'[\s\-]+', '', jibun)
                        norm_jibun_db = re.sub(r'[\s\-]+', '', detail.jibun_address)
                        if norm_jibun_api in norm_jibun_db or jibun in detail.jibun_address:
                            jibun_match = True
                    
                    # ğŸ”‘ ì§€ë²ˆ ì¼ì¹˜ ì‹œ ì ìˆ˜ ìƒìŠ¹ (ë‹¨, ì´ë¦„ ìœ ì‚¬ë„ ìµœì†Œ ê¸°ì¤€ ì ìš©)
                    # ì´ë¦„ì´ ì „í˜€ ë‹¤ë¥¸ë° ì§€ë²ˆë§Œ ê°™ì€ ê²½ìš° ë°©ì§€
                    name_similarity_for_jibun = SequenceMatcher(None, 
                        api_cache['normalized'], db_cache['normalized']).ratio()
                    
                    if jibun_full_match:
                        # ë³¸ë²ˆ+ë¶€ë²ˆ ì™„ì „ ì¼ì¹˜: ë†’ì€ ì ìˆ˜ (ë‹¨, ì´ë¦„ ìœ ì‚¬ë„ 0.15 ì´ìƒ)
                        if name_similarity_for_jibun >= 0.15 or has_common_brand:
                            score = max(score, 0.95)
                        elif name_similarity_for_jibun >= 0.10:
                            score = max(score, 0.85)
                        # ì´ë¦„ ìœ ì‚¬ë„ 0.10 ë¯¸ë§Œì´ë©´ ì§€ë²ˆë§Œìœ¼ë¡œëŠ” ë§¤ì¹­ ì•ˆ í•¨
                    elif jibun_match:
                        # ë³¸ë²ˆë§Œ ì¼ì¹˜: ì¤‘ê°„ ì ìˆ˜ (ì´ë¦„ ìœ ì‚¬ë„ ê¸°ì¤€ ì ìš©)
                        if name_similarity_for_jibun >= 0.25 or (score >= 0.5):
                            score = max(score, 0.90)
                        elif name_similarity_for_jibun >= 0.15 or has_common_brand:
                            score = max(score, 0.75)
                        # ì´ë¦„ ìœ ì‚¬ë„ 0.15 ë¯¸ë§Œì´ë©´ ì§€ë²ˆë§Œìœ¼ë¡œëŠ” ë§¤ì¹­ ì•ˆ í•¨
            
            # === 3.6ë‹¨ê³„: ê±´ì¶•ë…„ë„ ê¸°ë°˜ ê²€ì¦ (NEW!) ===
            build_year_match = False
            if build_year and apt_details and apt.apt_id in apt_details:
                detail = apt_details[apt.apt_id]
                # use_approval_dateì—ì„œ ë…„ë„ ì¶”ì¶œ (YYYY-MM-DD í˜•ì‹)
                if detail.use_approval_date:
                    try:
                        approval_year = detail.use_approval_date.split('-')[0]
                        # ê±´ì¶•ë…„ë„ ì¼ì¹˜ í™•ì¸ (Â±1ë…„ í—ˆìš©)
                        if abs(int(build_year) - int(approval_year)) <= 1:
                            build_year_match = True
                            # ê±´ì¶•ë…„ë„ ì¼ì¹˜ ì‹œ ì ìˆ˜ ë³´ì • (ì‹ ë¢°ë„ ì¦ê°€, 5% ë³´ë„ˆìŠ¤)
                            if score >= 0.5:
                                score = max(score, score * 1.05)
                    except (ValueError, AttributeError):
                        pass
            
            # ğŸ”‘ ì§€ë²ˆ + ê±´ì¶•ë…„ë„ ëª¨ë‘ ì¼ì¹˜ ì‹œ ë†’ì€ ì ìˆ˜ (ë‹¨, ì´ë¦„ ìœ ì‚¬ë„ ìµœì†Œ ê¸°ì¤€)
            # ì´ë¦„ì´ ì „í˜€ ë‹¤ë¥¸ë° ì§€ë²ˆ+ê±´ì¶•ë…„ë„ë§Œ ê°™ì€ ê²½ìš° ë°©ì§€
            if jibun_match and build_year_match:
                name_sim = SequenceMatcher(None, api_cache['normalized'], db_cache['normalized']).ratio()
                if name_sim >= 0.20 or has_common_brand:
                    score = max(score, 0.97)
                elif name_sim >= 0.15:
                    score = max(score, 0.90)
                # ì´ë¦„ ìœ ì‚¬ë„ 0.15 ë¯¸ë§Œì´ë©´ ì§€ë²ˆ+ê±´ì¶•ë…„ë„ë§Œìœ¼ë¡œ ë†’ì€ ì ìˆ˜ ë¶€ì—¬ ì•ˆ í•¨
            
            # === 4ë‹¨ê³„: í¬í•¨ ê´€ê³„ í™•ì¸ (ì–‘ë°©í–¥) ===
            norm_api = api_cache['normalized']
            norm_db = db_cache['normalized']
            if len(norm_api) >= 4 and len(norm_db) >= 4:
                if norm_api in norm_db:
                    ratio = len(norm_api) / len(norm_db)
                    score = max(score, 0.70 + ratio * 0.2)
                elif norm_db in norm_api:
                    ratio = len(norm_db) / len(norm_api)
                    score = max(score, 0.70 + ratio * 0.2)
            
            # === 5ë‹¨ê³„: ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­ ===
            similarity = self._calculate_similarity(norm_api, norm_db)
            if similarity >= 0.85:
                score = max(score, similarity)
            elif similarity >= 0.70:
                score = max(score, similarity * 0.95)
            elif similarity >= 0.60:
                score = max(score, similarity * 0.90)
            
            # === 6ë‹¨ê³„: ì—„ê²© ì •ê·œí™” ìœ ì‚¬ë„ ===
            # ë‹¨ì§€ ë²ˆí˜¸ê°€ ìˆëŠ” ê²½ìš°ëŠ” ì—„ê²© ì •ê·œí™” ìœ ì‚¬ë„ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
            # (ë‹¨ì§€ ë²ˆí˜¸ê°€ ì œê±°ë˜ë©´ ë‹¤ë¥¸ ë‹¨ì§€ì™€ êµ¬ë¶„ì´ ì•ˆ ë¨)
            if api_danji is None and api_cha is None:
                strict_similarity = self._calculate_similarity(
                    api_cache['strict'], 
                    db_cache['strict']
                )
                if strict_similarity >= 0.75:
                    score = max(score, strict_similarity * 0.90)
                elif strict_similarity >= 0.60:
                    score = max(score, strict_similarity * 0.85)
            
            # === 7ë‹¨ê³„: í•µì‹¬ ì´ë¦„ ë§¤ì¹­ ===
            if api_cache['core'] and db_cache['core']:
                core_similarity = self._calculate_similarity(
                    api_cache['core'], 
                    db_cache['core']
                )
                if core_similarity >= 0.80:
                    score = max(score, core_similarity * 0.85)
            
            # === 8ë‹¨ê³„: í•œê¸€ í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤ì¹­ ===
            api_keywords = set(re.findall(r'[ê°€-í£]{2,}', norm_api))
            db_keywords = set(re.findall(r'[ê°€-í£]{2,}', norm_db))
            
            if api_keywords and db_keywords:
                # ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­
                common_keywords = api_keywords & db_keywords
                
                # ë¶€ë¶„ í‚¤ì›Œë“œ ë§¤ì¹­ (í¬í•¨ ê´€ê³„)
                partial_matches = 0
                for api_kw in api_keywords:
                    for db_kw in db_keywords:
                        if api_kw != db_kw and len(api_kw) >= 2 and len(db_kw) >= 2:
                            if api_kw in db_kw or db_kw in api_kw:
                                partial_matches += 1
                                break
                
                total_matches = len(common_keywords) + partial_matches * 0.7
                total_keywords = max(len(api_keywords), len(db_keywords))
                
                if total_keywords > 0:
                    keyword_ratio = total_matches / total_keywords
                    if keyword_ratio >= 0.6:
                        score = max(score, 0.65 + keyword_ratio * 0.25)
                    elif keyword_ratio >= 0.4:
                        score = max(score, 0.55 + keyword_ratio * 0.20)
            
            # === 9ë‹¨ê³„: ë¸Œëœë“œ + ìœ ì‚¬ë„ ë³µí•© ì ìˆ˜ ===
            if has_common_brand and similarity >= 0.50:
                combined_score = 0.60 + similarity * 0.35
                score = max(score, combined_score)
            
            # === 10ë‹¨ê³„: í›„ë³´ê°€ ì ì„ ë•Œ ë” ê´€ëŒ€í•œ ë§¤ì¹­ ===
            # ğŸ”‘ í›„ë³´ê°€ ì ì–´ë„ ìµœì†Œí•œì˜ ì´ë¦„ ìœ ì‚¬ë„ ê¸°ì¤€ ì ìš© (ë¯¸ìŠ¤ë§¤ì¹­ ë°©ì§€)
            if len(candidates) == 1:
                # í›„ë³´ê°€ í•˜ë‚˜ë¿ì´ì–´ë„ ì´ë¦„ ìœ ì‚¬ë„ ìµœì†Œ 0.15 ì´ìƒ í•„ìš”
                if similarity >= 0.25 or strict_similarity >= 0.25 or has_common_brand:
                    score = max(score, 0.50)
                elif similarity >= 0.15 or strict_similarity >= 0.15:
                    score = max(score, 0.42)
                # ìœ ì‚¬ë„ 0.15 ë¯¸ë§Œì´ë©´ ë¬´ì¡°ê±´ ë§¤ì¹­ ì•ˆ í•¨ (í›„ë³´ê°€ 1ê°œì—¬ë„)
            elif len(candidates) <= 3:
                # í›„ë³´ê°€ 3ê°œ ì´í•˜: ìœ ì‚¬ë„ 0.20 ì´ìƒ ë˜ëŠ” ë¸Œëœë“œ ì¼ì¹˜ í•„ìš”
                if similarity >= 0.25 or strict_similarity >= 0.25 or has_common_brand:
                    score = max(score, 0.42)
                elif similarity >= 0.20 or strict_similarity >= 0.20:
                    score = max(score, 0.38)
            elif len(candidates) <= 5:
                # í›„ë³´ê°€ 5ê°œ ì´í•˜: ìœ ì‚¬ë„ 0.25 ì´ìƒ ë˜ëŠ” ë¸Œëœë“œ ì¼ì¹˜ í•„ìš”
                if similarity >= 0.30 or strict_similarity >= 0.30 or has_common_brand:
                    score = max(score, 0.38)
                elif similarity >= 0.25 or strict_similarity >= 0.25:
                    score = max(score, 0.35)
            elif len(candidates) <= 10:
                # í›„ë³´ê°€ 10ê°œ ì´í•˜: ìœ ì‚¬ë„ 0.30 ì´ìƒ í•„ìš”
                if similarity >= 0.35 or strict_similarity >= 0.35:
                    score = max(score, 0.35)
                elif similarity >= 0.30 or strict_similarity >= 0.30:
                    score = max(score, 0.32)
            
            # ìµœê³  ì ìˆ˜ ì—…ë°ì´íŠ¸
            if score > best_score:
                best_score = score
                best_match = apt
        
        # ë™ ê²€ì¦ì´ í•„ìš”í•œ ê²½ìš° (ì „ì²´ í›„ë³´ë¡œ ì¬ì‹œë„ ì‹œ)
        if require_dong_match and best_match and umd_nm and all_regions:
            # ë§¤ì¹­ëœ ì•„íŒŒíŠ¸ì˜ ë™ì´ APIì˜ ë™ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
            if best_match.region_id in all_regions:
                matched_region = all_regions[best_match.region_id]
                matched_dong = matched_region.region_name if matched_region else ""
                
                # ë™ ì´ë¦„ ì •ê·œí™” í›„ ë¹„êµ
                normalized_umd = self._normalize_dong_name(umd_nm)
                normalized_matched_dong = self._normalize_dong_name(matched_dong)
                
                # ë™ì´ ë¶ˆì¼ì¹˜í•˜ë©´ ë§¤ì¹­ ê±°ë¶€ (ë¯¸ìŠ¤ë§¤ì¹­ ë°©ì§€!)
                dong_matches = (
                    normalized_umd == normalized_matched_dong or
                    (normalized_umd and normalized_matched_dong and 
                     (normalized_umd in normalized_matched_dong or normalized_matched_dong in normalized_umd))
                )
                
                if not dong_matches:
                    logger.debug(f"âš ï¸ ë™ ë¶ˆì¼ì¹˜ë¡œ ë§¤ì¹­ ê±°ë¶€: APIë™={umd_nm}, ë§¤ì¹­ë™={matched_dong}, ì•„íŒŒíŠ¸={best_match.apt_name}")
                    return None
        
        # ë™ì  ì„ê³„ê°’ ì ìš© - ë™ ê²€ì¦ í•„ìš”ì‹œ ë” ì—„ê²©í•œ ê¸°ì¤€
        if require_dong_match:
            # ì „ì²´ í›„ë³´ ì¬ì‹œë„ ì‹œ ë” ë†’ì€ ì„ê³„ê°’ (ë¯¸ìŠ¤ë§¤ì¹­ ë°©ì§€)
            threshold = 0.70  # ë§¤ìš° ë†’ì€ ê¸°ì¤€
            if best_score >= 0.90:  # ê±°ì˜ í™•ì‹¤í•œ ê²½ìš°ë§Œ í—ˆìš©
                threshold = 0.70
            elif best_score >= 0.80:
                threshold = 0.75
            else:
                threshold = 0.80  # ê·¸ ì™¸ì—ëŠ” ë§¤ìš° ì—„ê²©
        else:
            # ì¼ë°˜ ë§¤ì¹­: í›„ë³´ ìˆ˜ì— ë”°ë¼ ë™ì  ì„ê³„ê°’ ì ìš©
            threshold = 0.40  # ê¸°ë³¸ ì„ê³„ê°’ ìƒí–¥ (0.30 â†’ 0.40)
            if len(candidates) == 1:
                threshold = 0.30  # í›„ë³´ 1ê°œ (0.10 â†’ 0.30 ìƒí–¥)
            elif len(candidates) <= 3:
                threshold = 0.35  # í›„ë³´ 3ê°œ ì´í•˜ (0.20 â†’ 0.35 ìƒí–¥)
            elif len(candidates) <= 5:
                threshold = 0.38  # í›„ë³´ 5ê°œ ì´í•˜ (0.25 â†’ 0.38 ìƒí–¥)
            elif len(candidates) <= 10:
                threshold = 0.40  # í›„ë³´ 10ê°œ ì´í•˜ (0.28 â†’ 0.40 ìƒí–¥)
        
        if best_score >= threshold:
            return best_match
        
        return None

    async def collect_sales_data(
        self,
        db: AsyncSession,
        start_ym: str,
        end_ym: str,
        max_items: Optional[int] = None,
        allow_duplicate: bool = False
    ) -> Any:
        """
        ì•„íŒŒíŠ¸ ë§¤ë§¤ ì‹¤ê±°ë˜ê°€ ë°ì´í„° ìˆ˜ì§‘ (ìƒˆë¡œìš´ JSON API ì‚¬ìš©)
        
        Args:
            start_ym: ì‹œì‘ ì—°ì›” (YYYYMM)
            end_ym: ì¢…ë£Œ ì—°ì›” (YYYYMM)
            max_items: ìµœëŒ€ ìˆ˜ì§‘ ê°œìˆ˜ ì œí•œ (ê¸°ë³¸ê°’: None, ì œí•œ ì—†ìŒ)
            allow_duplicate: ì¤‘ë³µ ì €ì¥ í—ˆìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: False, False=ê±´ë„ˆë›°ê¸°, True=ì—…ë°ì´íŠ¸)
        """
        from app.schemas.sale import SalesCollectionResponse, SaleCreate
        
        total_fetched = 0
        total_saved = 0
        skipped = 0
        errors = []
        
        logger.info(f"ğŸ’° ë§¤ë§¤ ìˆ˜ì§‘ ì‹œì‘: {start_ym} ~ {end_ym}")
        
        # 1. ê¸°ê°„ ìƒì„±
        def get_months(start, end):
            try:
                start_date = datetime.strptime(start, "%Y%m")
                end_date = datetime.strptime(end, "%Y%m")
            except ValueError:
                raise ValueError("ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. YYYYMM í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
            
            months = []
            curr = start_date
            while curr <= end_date:
                months.append(curr.strftime("%Y%m"))
                if curr.month == 12:
                    curr = curr.replace(year=curr.year + 1, month=1)
                else:
                    curr = curr.replace(month=curr.month + 1)
            return months
        
        try:
            target_months = get_months(start_ym, end_ym)
        except ValueError as e:
            return SalesCollectionResponse(success=False, message=str(e))
        
        # 2. ì§€ì—­ ì½”ë“œ ì¶”ì¶œ
        try:
            stmt = text("SELECT DISTINCT SUBSTR(region_code, 1, 5) FROM states WHERE length(region_code) >= 5")
            result = await db.execute(stmt)
            target_sgg_codes = [row[0] for row in result.fetchall() if row[0] and len(row[0]) == 5]
            logger.info(f"ğŸ“ {len(target_sgg_codes)}ê°œ ì§€ì—­ ì½”ë“œ ì¶”ì¶œ")
        except Exception as e:
            logger.error(f"âŒ ì§€ì—­ ì½”ë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return SalesCollectionResponse(success=False, message=f"DB ì˜¤ë¥˜: {e}")
        
        # 2.5. ì§€ì—­ë³„ ì•„íŒŒíŠ¸/ì§€ì—­ ì •ë³´ ì‚¬ì „ ë¡œë“œ (ì„±ëŠ¥ ìµœì í™”)
        apt_cache: Dict[str, List[Apartment]] = {}
        region_cache: Dict[str, Dict[int, State]] = {}
        detail_cache: Dict[str, Dict[int, ApartDetail]] = {}
        
        async def load_apts_and_regions(sgg_cd: str) -> tuple[List[Apartment], Dict[int, State], Dict[int, ApartDetail]]:
            """ì§€ì—­ë³„ ì•„íŒŒíŠ¸, ì§€ì—­ ì •ë³´, ì•„íŒŒíŠ¸ ìƒì„¸ ì •ë³´ ë¡œë“œ (ìºì‹±)"""
            if sgg_cd in apt_cache:
                return apt_cache[sgg_cd], region_cache[sgg_cd], detail_cache.get(sgg_cd, {})
            
            async with AsyncSessionLocal() as cache_db:
                # ì•„íŒŒíŠ¸ ë¡œë“œ
                stmt = select(Apartment).options(joinedload(Apartment.region)).join(State).where(
                    State.region_code.like(f"{sgg_cd}%")
                )
                apt_result = await cache_db.execute(stmt)
                local_apts = apt_result.scalars().all()
                
                # ë™ ì •ë³´ ìºì‹œ
                region_stmt = select(State).where(State.region_code.like(f"{sgg_cd}%"))
                region_result = await cache_db.execute(region_stmt)
                all_regions = {r.region_id: r for r in region_result.scalars().all()}
                
                # ì•„íŒŒíŠ¸ ìƒì„¸ ì •ë³´ ë¡œë“œ (ì§€ë²ˆ í¬í•¨)
                apt_ids = [apt.apt_id for apt in local_apts]
                if apt_ids:
                    detail_stmt = select(ApartDetail).where(ApartDetail.apt_id.in_(apt_ids))
                    detail_result = await cache_db.execute(detail_stmt)
                    apt_details = {d.apt_id: d for d in detail_result.scalars().all()}
                else:
                    apt_details = {}
                
                apt_cache[sgg_cd] = local_apts
                region_cache[sgg_cd] = all_regions
                detail_cache[sgg_cd] = apt_details
                
                return local_apts, all_regions, apt_details
        
        # 3. ë³‘ë ¬ ì²˜ë¦¬ (DB ì—°ê²° í’€ í¬ê¸°ì— ë§ì¶° 10ê°œë¡œ ì œí•œ - QueuePool ì—ëŸ¬ ë°©ì§€)
        # DB pool_size=5, max_overflow=10 â†’ ìµœëŒ€ 15ê°œ ì—°ê²° ê°€ëŠ¥
        semaphore = asyncio.Semaphore(10)
        
        # ì§„í–‰ ìƒí™© ì¶”ì ìš© ë³€ìˆ˜
        total_regions = len(target_sgg_codes)
        
        def format_ym(ym: str) -> str:
            """ì—°ì›” í˜•ì‹ ë³€í™˜: YYYYMM -> YYYYë…„ MMì›”"""
            try:
                y = int(ym[:4])
                m = int(ym[4:])
                return f"{y}ë…„ {m}ì›”"
            except:
                return ym
        
        # ê³µìœ  HTTP í´ë¼ì´ì–¸íŠ¸ (ì—°ê²° ì¬ì‚¬ìš©ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ)
        http_client = httpx.AsyncClient(
            timeout=httpx.Timeout(60.0, connect=10.0),
            limits=httpx.Limits(max_connections=15, max_keepalive_connections=10)
        )
        
        async def process_sale_region(ym: str, sgg_cd: str):
            """ë§¤ë§¤ ë°ì´í„° ìˆ˜ì§‘ ì‘ì—…"""
            ym_formatted = format_ym(ym)
            async with semaphore:
                async with AsyncSessionLocal() as local_db:
                    nonlocal total_fetched, total_saved, skipped, errors
                    
                    try:
                        # ê¸°ì¡´ ë°ì´í„° í™•ì¸
                        y = int(ym[:4])
                        m = int(ym[4:])
                        start_date = date(y, m, 1)
                        last_day = calendar.monthrange(y, m)[1]
                        end_date = date(y, m, last_day)
                        
                        check_stmt = select(func.count(Sale.trans_id)).join(Apartment).join(State).where(
                            and_(
                                State.region_code.like(f"{sgg_cd}%"),
                                Sale.contract_date >= start_date,
                                Sale.contract_date <= end_date
                            )
                        )
                        count_result = await local_db.execute(check_stmt)
                        existing_count = count_result.scalar() or 0
                        
                        if existing_count > 0 and not allow_duplicate:
                            skipped += existing_count
                            logger.info(f"â­ï¸ {sgg_cd}/{ym} ({ym_formatted}): ê±´ë„ˆëœ€ ({existing_count}ê±´ ì¡´ì¬)")
                            return
                        
                        # max_items ì œí•œ í™•ì¸
                        if max_items and total_saved >= max_items:
                            return
                        
                        # API í˜¸ì¶œ (XML) - ê³µìœ  í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©
                        params = {
                            "serviceKey": self.api_key,
                            "LAWD_CD": sgg_cd,
                            "DEAL_YMD": ym,
                            "numOfRows": 4000
                        }
                        
                        response = await http_client.get(MOLIT_SALE_API_URL, params=params)
                        response.raise_for_status()
                        xml_content = response.text
                        
                        # XML íŒŒì‹±
                        try:
                            root = ET.fromstring(xml_content)
                        except ET.ParseError as e:
                            errors.append(f"{sgg_cd}/{ym} ({ym_formatted}): XML íŒŒì‹± ì‹¤íŒ¨ - {str(e)}")
                            logger.error(f"âŒ {sgg_cd}/{ym} ({ym_formatted}): XML íŒŒì‹± ì‹¤íŒ¨ - {str(e)}")
                            return
                        
                        # ê²°ê³¼ ì½”ë“œ í™•ì¸
                        result_code_elem = root.find(".//resultCode")
                        result_msg_elem = root.find(".//resultMsg")
                        result_code = result_code_elem.text if result_code_elem is not None else ""
                        result_msg = result_msg_elem.text if result_msg_elem is not None else ""
                        
                        if result_code != "000":
                            errors.append(f"{sgg_cd}/{ym} ({ym_formatted}): {result_msg}")
                            logger.error(f"âŒ {sgg_cd}/{ym} ({ym_formatted}): {result_msg}")
                            return
                        
                        # items ì¶”ì¶œ
                        items = root.findall(".//item")
                        
                        if not items:
                            return
                        
                        total_fetched += len(items)
                        
                        # ì•„íŒŒíŠ¸ ë° ì§€ì—­ ì •ë³´ ë¡œë“œ (ìºì‹± í™œìš©)
                        local_apts, all_regions, apt_details = await load_apts_and_regions(sgg_cd)
                        
                        if not local_apts:
                            return
                        
                        sales_to_save = []
                        success_count = 0
                        skip_count = 0
                        error_count = 0
                        apt_name_log = ""
                        normalized_cache: Dict[str, Any] = {}  # ì •ê·œí™” ê²°ê³¼ ìºì‹±
                        batch_size = 100  # ë°°ì¹˜ ì»¤ë°‹ í¬ê¸°
                        
                        for item in items:
                            # max_items ì œí•œ í™•ì¸
                            if max_items and total_saved >= max_items:
                                break
                            
                            try:
                                # XML Elementì—ì„œ í•„ë“œ ì¶”ì¶œ (Dev API: camelCase í•„ë“œëª…)
                                apt_nm_elem = item.find("aptNm")
                                apt_nm = apt_nm_elem.text.strip() if apt_nm_elem is not None and apt_nm_elem.text else ""
                                
                                umd_nm_elem = item.find("umdNm")
                                umd_nm = umd_nm_elem.text.strip() if umd_nm_elem is not None and umd_nm_elem.text else ""
                                
                                # ğŸ†• ìƒˆ API ì¶”ê°€ í•„ë“œ: umdCd (ìë©´ë™ì½”ë“œ) - ë” ì •í™•í•œ ë™ ë§¤ì¹­ì— í™œìš©
                                umd_cd_elem = item.find("umdCd")
                                umd_cd = umd_cd_elem.text.strip() if umd_cd_elem is not None and umd_cd_elem.text else ""
                                
                                sgg_cd_elem = item.find("sggCd")
                                sgg_cd_item = sgg_cd_elem.text.strip() if sgg_cd_elem is not None and sgg_cd_elem.text else sgg_cd
                                
                                # ì§€ë²ˆ ì¶”ì¶œ (ê¸°ì¡´ í•„ë“œ ìœ ì§€)
                                jibun_elem = item.find("jibun")
                                jibun = jibun_elem.text.strip() if jibun_elem is not None and jibun_elem.text else ""
                                
                                # ğŸ†• ìƒˆ API ì¶”ê°€ í•„ë“œ: bonbun/bubun (ë³¸ë²ˆ/ë¶€ë²ˆ) - ë” ì •í™•í•œ ì§€ë²ˆ ë§¤ì¹­
                                bonbun_elem = item.find("bonbun")
                                bonbun = bonbun_elem.text.strip().lstrip('0') if bonbun_elem is not None and bonbun_elem.text else ""
                                bubun_elem = item.find("bubun")
                                bubun = bubun_elem.text.strip().lstrip('0') if bubun_elem is not None and bubun_elem.text else ""
                                
                                # ë³¸ë²ˆ/ë¶€ë²ˆìœ¼ë¡œ ì •í™•í•œ ì§€ë²ˆ ìƒì„± (bonbunì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©)
                                if bonbun:
                                    jibun_precise = bonbun
                                    if bubun and bubun != "0" and bubun != "":
                                        jibun_precise += f"-{bubun}"
                                    # ê¸°ì¡´ jibunê³¼ ë¹„êµí•˜ì—¬ ë” ì •í™•í•œ ê²ƒ ì‚¬ìš©
                                    if not jibun or len(jibun_precise) >= len(jibun):
                                        jibun = jibun_precise
                                
                                # ğŸ†• ìƒˆ API ì¶”ê°€ í•„ë“œ: aptSeq (ë‹¨ì§€ ì¼ë ¨ë²ˆí˜¸) - ì¤‘ë³µ ì²´í¬ ë° ì¶”ì ì— í™œìš©
                                apt_seq_elem = item.find("aptSeq")
                                apt_seq = apt_seq_elem.text.strip() if apt_seq_elem is not None and apt_seq_elem.text else ""
                                
                                # ê±´ì¶•ë…„ë„ ì¶”ì¶œ (ë§¤ì¹­ì— í™œìš©)
                                build_year_elem = item.find("buildYear")
                                build_year_for_match = build_year_elem.text.strip() if build_year_elem is not None and build_year_elem.text else ""
                                
                                if not apt_nm:
                                    continue
                                
                                if not apt_name_log:
                                    apt_name_log = apt_nm
                                
                                # ğŸ”‘ ìµœìš°ì„  ë§¤ì¹­: ì‹œêµ°êµ¬+ë™ì½”ë“œ(10ìë¦¬)+ì§€ë²ˆ ë§¤ì¹­
                                # ì•„íŒŒíŠ¸ ì´ë¦„ì´ ë‹¤ë¥´ë”ë¼ë„, ì‹œêµ°êµ¬+ë™ì½”ë“œ ì¼ì¹˜í•˜ê³  ì§€ë²ˆì´ ì¼ì¹˜í•˜ë©´ ê°™ì€ ì•„íŒŒíŠ¸
                                matched_apt = None
                                candidates = local_apts
                                sgg_code_matched = True
                                dong_matched = False
                                
                                # 1ë‹¨ê³„: ì‹œêµ°êµ¬+ë™ì½”ë“œ(10ìë¦¬)+ì§€ë²ˆ ë§¤ì¹­ (ìµœìš°ì„ )
                                if sgg_cd_item and umd_cd and jibun:
                                    full_region_code = f"{sgg_cd_item}{umd_cd}"
                                    # ì§€ë²ˆ ì •ê·œí™” (ë³¸ë²ˆ-ë¶€ë²ˆ í˜•ì‹)
                                    jibun_normalized = re.sub(r'[\s\-]+', '', jibun)
                                    
                                    # ì‹œêµ°êµ¬+ë™ì½”ë“œ ì¼ì¹˜í•˜ê³  ì§€ë²ˆ ì¼ì¹˜í•˜ëŠ” ì•„íŒŒíŠ¸ ì°¾ê¸°
                                    for apt in local_apts:
                                        if apt.region_id not in all_regions:
                                            continue
                                        
                                        region = all_regions[apt.region_id]
                                        if region.region_code != full_region_code:
                                            continue
                                        
                                        # ì§€ë²ˆ ë§¤ì¹­ í™•ì¸
                                        if apt.apt_id in apt_details:
                                            detail = apt_details[apt.apt_id]
                                            if detail.jibun_address:
                                                db_jibun_normalized = re.sub(r'[\s\-]+', '', detail.jibun_address)
                                                # ì§€ë²ˆ í¬í•¨ ê´€ê³„ í™•ì¸ (ë³¸ë²ˆ ì¼ì¹˜ ë˜ëŠ” í¬í•¨)
                                                if jibun_normalized in db_jibun_normalized or db_jibun_normalized in jibun_normalized:
                                                    # ë³¸ë²ˆ-ë¶€ë²ˆ ì •í™• ë§¤ì¹­ ì‹œë„
                                                    api_bunji_match = re.match(r'(\d+)(?:-(\d+))?', jibun.strip())
                                                    db_bunji_match = re.search(r'(\d+)(?:-(\d+))?(?:\s|$)', detail.jibun_address)
                                                    
                                                    if api_bunji_match and db_bunji_match:
                                                        api_main = api_bunji_match.group(1).lstrip('0')
                                                        api_sub = api_bunji_match.group(2) if api_bunji_match.group(2) else None
                                                        db_main = db_bunji_match.group(1).lstrip('0')
                                                        db_sub = db_bunji_match.group(2) if db_bunji_match.group(2) else None
                                                        
                                                        # ë³¸ë²ˆ ì¼ì¹˜ í™•ì¸
                                                        if api_main == db_main:
                                                            # ë¶€ë²ˆë„ í™•ì¸ (ìˆëŠ” ê²½ìš°)
                                                            if (not api_sub and not db_sub) or (api_sub and db_sub and api_sub == db_sub):
                                                                matched_apt = apt
                                                                candidates = [apt]
                                                                sgg_code_matched = True
                                                                dong_matched = True
                                                                logger.debug(f"âœ… ìµœìš°ì„  ë§¤ì¹­ ì„±ê³µ: ì‹œêµ°êµ¬+ë™ì½”ë“œ+ì§€ë²ˆ ({apt.apt_name})")
                                                                break
                                    
                                    # ì§€ë²ˆ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ì‹œêµ°êµ¬+ë™ì½”ë“œë§Œìœ¼ë¡œ í•„í„°ë§
                                    if not matched_apt and sgg_cd_item and umd_cd:
                                        full_region_code = f"{sgg_cd_item}{umd_cd}"
                                        filtered = [
                                            apt for apt in local_apts
                                            if apt.region_id in all_regions
                                            and all_regions[apt.region_id].region_code == full_region_code
                                        ]
                                        if filtered:
                                            candidates = filtered
                                            sgg_code_matched = True
                                            dong_matched = True
                                
                                # 2ë‹¨ê³„: ì‹œêµ°êµ¬+ë™ì½”ë“œ ë§¤ì¹­ (ì§€ë²ˆ ì—†ì„ ë•Œ)
                                if not matched_apt and not dong_matched and sgg_cd_item and umd_cd:
                                    full_region_code = f"{sgg_cd_item}{umd_cd}"
                                    filtered = [
                                        apt for apt in local_apts
                                        if apt.region_id in all_regions
                                        and all_regions[apt.region_id].region_code == full_region_code
                                    ]
                                    if filtered:
                                        candidates = filtered
                                        sgg_code_matched = True
                                        dong_matched = True
                                
                                # 3ë‹¨ê³„: ì‹œêµ°êµ¬ ì½”ë“œë§Œ ë§¤ì¹­ (fallback)
                                if not matched_apt and not dong_matched and sgg_cd_item and str(sgg_cd_item).strip():
                                    sgg_cd_item_str = str(sgg_cd_item).strip()
                                    sgg_cd_db = self._convert_sgg_code_to_db_format(sgg_cd_item_str)
                                    
                                    if sgg_cd_db:
                                        filtered = [
                                            apt for apt in local_apts
                                            if apt.region_id in all_regions
                                            and all_regions[apt.region_id].region_code == sgg_cd_db
                                        ]
                                        if not filtered:
                                            filtered = [
                                                apt for apt in local_apts
                                                if apt.region_id in all_regions
                                                and all_regions[apt.region_id].region_code.startswith(sgg_cd_item_str)
                                            ]
                                        if filtered:
                                            candidates = filtered
                                            sgg_code_matched = True
                                
                                # 4ë‹¨ê³„: ë™ ì´ë¦„ ë§¤ì¹­ (fallback)
                                if not matched_apt and not dong_matched and umd_nm and candidates:
                                    matching_region_ids = self._find_matching_regions(umd_nm, all_regions)
                                    
                                    if matching_region_ids:
                                        filtered = [
                                            apt for apt in candidates
                                            if apt.region_id in matching_region_ids
                                        ]
                                        if filtered:
                                            candidates = filtered
                                            dong_matched = True
                                
                                # í›„ë³´ê°€ ì—†ìœ¼ë©´ ì›ë˜ í›„ë³´ë¡œ ë³µì›
                                if not candidates:
                                    candidates = local_apts
                                    sgg_code_matched = True
                                    dong_matched = False
                                
                                # 5ë‹¨ê³„: ì´ë¦„ ë§¤ì¹­ (ì‹œêµ°êµ¬+ë™ì½”ë“œ+ì§€ë²ˆ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œì—ë§Œ ì‚¬ìš©)
                                if not matched_apt:
                                    matched_apt = self._match_apartment(
                                        apt_nm, candidates, sgg_cd, umd_nm, 
                                        jibun, build_year_for_match, apt_details, normalized_cache,
                                        all_regions=all_regions, require_dong_match=False
                                    )
                                
                                # í•„í„°ë§ëœ í›„ë³´ì—ì„œ ì‹¤íŒ¨ ì‹œ ì „ì²´ í›„ë³´ë¡œ ì¬ì‹œë„ (ë‹¨, ë™ ê²€ì¦ í•„ìˆ˜!)
                                if not matched_apt and len(candidates) < len(local_apts) and dong_matched:
                                    matched_apt = self._match_apartment(
                                        apt_nm, local_apts, sgg_cd, umd_nm, 
                                        jibun, build_year_for_match, apt_details, normalized_cache,
                                        all_regions=all_regions, require_dong_match=True
                                    )
                                
                                if not matched_apt:
                                    error_count += 1
                                    # ì •ê·œí™”ëœ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
                                    normalized_name = normalized_cache.get(apt_nm)
                                    if not normalized_name:
                                        normalized_name = self._normalize_apt_name(apt_nm)
                                        normalized_cache[apt_nm] = normalized_name
                                    
                                    # ì§€ì—­ ì´ë¦„ ê°€ì ¸ì˜¤ê¸° (ì‹œêµ°êµ¬/ë™)
                                    region_name = None
                                    if umd_nm:
                                        # ë™ ì´ë¦„ìœ¼ë¡œ ì§€ì—­ ì°¾ê¸°
                                        matching_region_ids = self._find_matching_regions(umd_nm, all_regions)
                                        if matching_region_ids:
                                            first_region_id = list(matching_region_ids)[0]
                                            if first_region_id in all_regions:
                                                region_name = all_regions[first_region_id].region_name
                                    elif sgg_cd_item:
                                        # ì‹œêµ°êµ¬ ì½”ë“œë¡œ ì§€ì—­ ì°¾ê¸°
                                        sgg_cd_db = self._convert_sgg_code_to_db_format(str(sgg_cd_item).strip())
                                        if sgg_cd_db:
                                            for region in all_regions.values():
                                                if region.region_code == sgg_cd_db:
                                                    region_name = region.region_name
                                                    break
                                    
                                    # ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ë¡œê¹… (apartfail_YYYYMM.log íŒŒì¼ë¡œ ì €ì¥)
                                    self._record_apt_fail(
                                        trans_type='ë§¤ë§¤',
                                        apt_name=apt_nm,
                                        jibun=jibun,
                                        build_year=build_year_for_match,
                                        umd_nm=umd_nm,
                                        sgg_cd=sgg_cd,
                                        ym=ym,  # ê±°ë˜ ë°œìƒ ì›”
                                        reason='ì´ë¦„ë§¤ì¹­ ì‹¤íŒ¨',
                                        normalized_name=normalized_name,
                                        candidates=candidates,
                                        local_apts=local_apts,
                                        sgg_code_matched=sgg_code_matched,
                                        dong_matched=dong_matched,
                                        region_name=region_name
                                    )
                                    continue
                                
                                # ë§¤ì¹­ ë¡œê·¸ ê¸°ë¡ (apart_YYYYMM.logìš©) - ê±°ë˜ ë°œìƒ ì›”(ym) ì‚¬ìš©
                                self._record_apt_matching(
                                    matched_apt.apt_id,
                                    matched_apt.apt_name,
                                    apt_nm,
                                    ym  # ê±°ë˜ ë°œìƒ ì›”
                                )
                                
                                # ê±°ë˜ ë°ì´í„° íŒŒì‹± (XML Elementì—ì„œ ì¶”ì¶œ)
                                deal_amount_elem = item.find("dealAmount")
                                deal_amount = deal_amount_elem.text.replace(",", "").strip() if deal_amount_elem is not None and deal_amount_elem.text else "0"
                                
                                build_year_elem = item.find("buildYear")
                                build_year = build_year_elem.text.strip() if build_year_elem is not None and build_year_elem.text else None
                                
                                deal_year_elem = item.find("dealYear")
                                deal_year = deal_year_elem.text.strip() if deal_year_elem is not None and deal_year_elem.text else None
                                
                                deal_month_elem = item.find("dealMonth")
                                deal_month = deal_month_elem.text.strip() if deal_month_elem is not None and deal_month_elem.text else None
                                
                                deal_day_elem = item.find("dealDay")
                                deal_day = deal_day_elem.text.strip() if deal_day_elem is not None and deal_day_elem.text else None
                                
                                exclu_use_ar_elem = item.find("excluUseAr")
                                exclu_use_ar = exclu_use_ar_elem.text.strip() if exclu_use_ar_elem is not None and exclu_use_ar_elem.text else None
                                
                                floor_elem = item.find("floor")
                                floor = floor_elem.text.strip() if floor_elem is not None and floor_elem.text else None
                                
                                contract_date = None
                                if deal_year and deal_month and deal_day:
                                    try:
                                        contract_date = date(int(deal_year), int(deal_month), int(deal_day))
                                    except:
                                        pass
                                
                                sale_create = SaleCreate(
                                    apt_id=matched_apt.apt_id,
                                    build_year=build_year,
                                    trans_type="ë§¤ë§¤",
                                    trans_price=int(deal_amount) if deal_amount else 0,
                                    exclusive_area=float(exclu_use_ar) if exclu_use_ar else 0.0,
                                    floor=int(floor) if floor else 0,
                                    contract_date=contract_date,
                                    is_canceled=False,
                                    remarks=matched_apt.apt_name
                                )
                                
                                # ì¤‘ë³µ ì²´í¬ ë° ì €ì¥
                                exists_stmt = select(Sale).where(
                                    and_(
                                        Sale.apt_id == sale_create.apt_id,
                                        Sale.contract_date == sale_create.contract_date,
                                        Sale.trans_price == sale_create.trans_price,
                                        Sale.floor == sale_create.floor,
                                        Sale.exclusive_area == sale_create.exclusive_area
                                    )
                                )
                                exists = await local_db.execute(exists_stmt)
                                existing_sale = exists.scalars().first()
                                
                                if existing_sale:
                                    if allow_duplicate:
                                        # ì—…ë°ì´íŠ¸
                                        existing_sale.build_year = build_year
                                        existing_sale.trans_price = sale_create.trans_price
                                        existing_sale.exclusive_area = sale_create.exclusive_area
                                        existing_sale.floor = sale_create.floor
                                        existing_sale.remarks = matched_apt.apt_name
                                        local_db.add(existing_sale)
                                        success_count += 1
                                        total_saved += 1
                                    else:
                                        skip_count += 1
                                    continue
                                
                                db_obj = Sale(**sale_create.model_dump())
                                local_db.add(db_obj)
                                sales_to_save.append(sale_create)
                                
                                # ì•„íŒŒíŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸
                                if matched_apt.is_available != "1":
                                    matched_apt.is_available = "1"
                                    local_db.add(matched_apt)
                                
                                # ë°°ì¹˜ ì»¤ë°‹ (ì„±ëŠ¥ ìµœì í™”)
                                if len(sales_to_save) >= batch_size:
                                    await local_db.commit()
                                    total_saved += len(sales_to_save)
                                    success_count += len(sales_to_save)
                                    sales_to_save = []
                            
                            except Exception as e:
                                error_count += 1
                                continue
                        
                        # ë‚¨ì€ ë°ì´í„° ì»¤ë°‹
                        if sales_to_save or (allow_duplicate and success_count > 0):
                            await local_db.commit()
                            if sales_to_save:
                                total_saved += len(sales_to_save)
                                success_count += len(sales_to_save)
                        
                        # ê°„ê²°í•œ ë¡œê·¸ (í•œ ì¤„)
                        if success_count > 0 or skip_count > 0 or error_count > 0:
                            logger.info(
                                f"{sgg_cd}/{ym} ({ym_formatted}): "
                                f"âœ…{success_count} â­ï¸{skip_count} âŒ{error_count} "
                                f"({apt_name_log})"
                            )
                        
                        skipped += skip_count
                        
                        # max_items ì œí•œ í™•ì¸
                        if max_items and total_saved >= max_items:
                            return
                        
                    except Exception as e:
                        errors.append(f"{sgg_cd}/{ym}: {str(e)}")
                        logger.error(f"âŒ {sgg_cd}/{ym}: {str(e)}")
                        await local_db.rollback()
        
        # ë³‘ë ¬ ì‹¤í–‰
        try:
            total_months = len(target_months)
            for month_idx, ym in enumerate(target_months, 1):
                if max_items and total_saved >= max_items:
                    break
                
                ym_formatted = format_ym(ym)
                # ì›” ì‹œì‘ ë¡œê·¸
                logger.info(f"ğŸ“Š {ym_formatted} | {month_idx}/{total_months}ê°œ ì›” | {total_regions}ê°œ ì§€ì—­ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
                
                tasks = [process_sale_region(ym, sgg_cd) for sgg_cd in target_sgg_codes]
                await asyncio.gather(*tasks, return_exceptions=True)
                
                # ì›” ì™„ë£Œ ë¡œê·¸
                logger.info(f"âœ… {ym_formatted} ì™„ë£Œ | ëˆ„ì  ì €ì¥: {total_saved}ê±´")
                
                # í•´ë‹¹ ì›”ì˜ ë¡œê·¸ ì €ì¥ (apart_YYYYMM.log, apartfail_YYYYMM.log)
                print(f"[LOG_SAVE] ì›” ì™„ë£Œ - {ym_formatted} ë¡œê·¸ ì €ì¥ ì‹œì‘ (ym={ym})")
                logger.info(f"=" * 60)
                logger.info(f"ğŸ“ [ë§¤ë§¤] {ym_formatted} ë¡œê·¸ ì €ì¥ ì‹œì‘")
                logger.info(f"   ë§¤ì¹­ ë¡œê·¸: {len(self._apt_matching_log_by_month.get(ym, {}))}ê°œ ì•„íŒŒíŠ¸")
                logger.info(f"   ì‹¤íŒ¨ ë¡œê·¸: {len(self._apt_fail_log_by_month.get(ym, []))}ê±´")
                logger.info(f"=" * 60)
                
                try:
                    print(f"[LOG_SAVE] {ym} - _save_apt_matching_log í˜¸ì¶œ")
                    self._save_apt_matching_log(ym)
                    print(f"[LOG_SAVE] {ym} - _save_apt_matching_log ì™„ë£Œ")
                except Exception as e:
                    print(f"[LOG_SAVE] ERROR: {ym} ë§¤ì¹­ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨ - {e}")
                    logger.error(f"âŒ [ë§¤ë§¤] {ym_formatted} ë§¤ì¹­ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}", exc_info=True)
                
                try:
                    print(f"[LOG_SAVE] {ym} - _save_apt_fail_log í˜¸ì¶œ")
                    self._save_apt_fail_log(ym)
                    print(f"[LOG_SAVE] {ym} - _save_apt_fail_log ì™„ë£Œ")
                except Exception as e:
                    print(f"[LOG_SAVE] ERROR: {ym} ì‹¤íŒ¨ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨ - {e}")
                    logger.error(f"âŒ [ë§¤ë§¤] {ym_formatted} ì‹¤íŒ¨ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}", exc_info=True)
                
                logger.info(f"=" * 60)
                logger.info(f"ğŸ“ [ë§¤ë§¤] {ym_formatted} ë¡œê·¸ ì €ì¥ ì™„ë£Œ")
                logger.info(f"=" * 60)
                print(f"[LOG_SAVE] {ym_formatted} ë¡œê·¸ ì €ì¥ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ")
                
                if max_items and total_saved >= max_items:
                    break
        finally:
            # HTTP í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬
            await http_client.aclose()
        
        logger.info(f"ğŸ‰ ë§¤ë§¤ ìˆ˜ì§‘ ì™„ë£Œ: ì €ì¥ {total_saved}ê±´, ê±´ë„ˆëœ€ {skipped}ê±´, ì˜¤ë¥˜ {len(errors)}ê±´")
        # ì°¸ê³ : ê° ì›”ì˜ ë¡œê·¸ëŠ” ì›”ë³„ë¡œ ì´ë¯¸ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.
        
        return SalesCollectionResponse(
            success=True,
            total_fetched=total_fetched,
            total_saved=total_saved,
            skipped=skipped,
            errors=errors,
            message=f"ìˆ˜ì§‘ ì™„ë£Œ: {total_saved}ê±´ ì €ì¥"
        )

    async def collect_rent_data(
        self,
        db: AsyncSession,
        start_ym: str,
        end_ym: str,
        max_items: Optional[int] = None,
        allow_duplicate: bool = False
    ) -> RentCollectionResponse:
        """
        ì•„íŒŒíŠ¸ ì „ì›”ì„¸ ì‹¤ê±°ë˜ê°€ ë°ì´í„° ìˆ˜ì§‘ (ë§¤ë§¤ì™€ ë™ì¼í•œ ë°©ì‹)
        
        Args:
            start_ym: ì‹œì‘ ì—°ì›” (YYYYMM)
            end_ym: ì¢…ë£Œ ì—°ì›” (YYYYMM)
            max_items: ìµœëŒ€ ìˆ˜ì§‘ ê°œìˆ˜ ì œí•œ (ê¸°ë³¸ê°’: None, ì œí•œ ì—†ìŒ)
            allow_duplicate: ì¤‘ë³µ ì €ì¥ í—ˆìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: False, False=ê±´ë„ˆë›°ê¸°, True=ì—…ë°ì´íŠ¸)
        """
        total_fetched = 0
        total_saved = 0
        skipped = 0
        errors = []
        
        logger.info(f"ğŸ  ì „ì›”ì„¸ ìˆ˜ì§‘ ì‹œì‘: {start_ym} ~ {end_ym}")
        
        # 1. ê¸°ê°„ ìƒì„±
        def get_months(start, end):
            try:
                start_date = datetime.strptime(start, "%Y%m")
                end_date = datetime.strptime(end, "%Y%m")
            except ValueError:
                raise ValueError("ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. YYYYMM í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
            
            months = []
            curr = start_date
            while curr <= end_date:
                months.append(curr.strftime("%Y%m"))
                if curr.month == 12:
                    curr = curr.replace(year=curr.year + 1, month=1)
                else:
                    curr = curr.replace(month=curr.month + 1)
            return months
        
        try:
            target_months = get_months(start_ym, end_ym)
        except ValueError as e:
            return RentCollectionResponse(
                success=False,
                total_fetched=0,
                total_saved=0,
                skipped=0,
                errors=[str(e)],
                message=f"ë‚ ì§œ í˜•ì‹ ì˜¤ë¥˜: {str(e)}",
                lawd_cd=None,
                deal_ymd=None
            )
        
        # 2. ì§€ì—­ ì½”ë“œ ì¶”ì¶œ
        try:
            stmt = text("SELECT DISTINCT SUBSTR(region_code, 1, 5) FROM states WHERE length(region_code) >= 5")
            result = await db.execute(stmt)
            target_sgg_codes = [row[0] for row in result.fetchall() if row[0] and len(row[0]) == 5]
            logger.info(f"ğŸ“ {len(target_sgg_codes)}ê°œ ì§€ì—­ ì½”ë“œ ì¶”ì¶œ")
        except Exception as e:
            logger.error(f"âŒ ì§€ì—­ ì½”ë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return RentCollectionResponse(
                success=False,
                total_fetched=0,
                total_saved=0,
                skipped=0,
                errors=[f"DB ì˜¤ë¥˜: {e}"],
                message=f"DB ì˜¤ë¥˜: {e}",
                lawd_cd=None,
                deal_ymd=None
            )
        
        # 2.5. ì§€ì—­ë³„ ì•„íŒŒíŠ¸/ì§€ì—­ ì •ë³´ ì‚¬ì „ ë¡œë“œ (ì„±ëŠ¥ ìµœì í™”)
        apt_cache: Dict[str, List[Apartment]] = {}
        region_cache: Dict[str, Dict[int, State]] = {}
        detail_cache: Dict[str, Dict[int, ApartDetail]] = {}
        
        async def load_apts_and_regions(sgg_cd: str) -> tuple[List[Apartment], Dict[int, State], Dict[int, ApartDetail]]:
            """ì§€ì—­ë³„ ì•„íŒŒíŠ¸, ì§€ì—­ ì •ë³´, ì•„íŒŒíŠ¸ ìƒì„¸ ì •ë³´ ë¡œë“œ (ìºì‹±)"""
            if sgg_cd in apt_cache:
                return apt_cache[sgg_cd], region_cache[sgg_cd], detail_cache.get(sgg_cd, {})
            
            async with AsyncSessionLocal() as cache_db:
                # ì•„íŒŒíŠ¸ ë¡œë“œ
                stmt = select(Apartment).options(joinedload(Apartment.region)).join(State).where(
                    State.region_code.like(f"{sgg_cd}%")
                )
                apt_result = await cache_db.execute(stmt)
                local_apts = apt_result.scalars().all()
                
                # ë™ ì •ë³´ ìºì‹œ
                region_stmt = select(State).where(State.region_code.like(f"{sgg_cd}%"))
                region_result = await cache_db.execute(region_stmt)
                all_regions = {r.region_id: r for r in region_result.scalars().all()}
                
                # ì•„íŒŒíŠ¸ ìƒì„¸ ì •ë³´ ë¡œë“œ (ì§€ë²ˆ í¬í•¨)
                apt_ids = [apt.apt_id for apt in local_apts]
                if apt_ids:
                    detail_stmt = select(ApartDetail).where(ApartDetail.apt_id.in_(apt_ids))
                    detail_result = await cache_db.execute(detail_stmt)
                    apt_details = {d.apt_id: d for d in detail_result.scalars().all()}
                else:
                    apt_details = {}
                
                apt_cache[sgg_cd] = local_apts
                region_cache[sgg_cd] = all_regions
                detail_cache[sgg_cd] = apt_details
                
                return local_apts, all_regions, apt_details
        
        # 3. ë³‘ë ¬ ì²˜ë¦¬ (DB ì—°ê²° í’€ í¬ê¸°ì— ë§ì¶° 10ê°œë¡œ ì œí•œ - QueuePool ì—ëŸ¬ ë°©ì§€)
        # DB pool_size=5, max_overflow=10 â†’ ìµœëŒ€ 15ê°œ ì—°ê²° ê°€ëŠ¥
        semaphore = asyncio.Semaphore(10)
        
        # ì§„í–‰ ìƒí™© ì¶”ì ìš© ë³€ìˆ˜
        total_regions = len(target_sgg_codes)
        
        def format_ym(ym: str) -> str:
            """ì—°ì›” í˜•ì‹ ë³€í™˜: YYYYMM -> YYYYë…„ MMì›”"""
            try:
                y = int(ym[:4])
                m = int(ym[4:])
                return f"{y}ë…„ {m}ì›”"
            except:
                return ym
        
        # ê³µìœ  HTTP í´ë¼ì´ì–¸íŠ¸ (ì—°ê²° ì¬ì‚¬ìš©ìœ¼ë¡œ ì„±ëŠ¥ í–¥ìƒ)
        http_client = httpx.AsyncClient(
            timeout=httpx.Timeout(60.0, connect=10.0),
            limits=httpx.Limits(max_connections=15, max_keepalive_connections=10)
        )
        
        async def process_rent_region(ym: str, sgg_cd: str):
            """ì „ì›”ì„¸ ë°ì´í„° ìˆ˜ì§‘ ì‘ì—…"""
            ym_formatted = format_ym(ym)
            async with semaphore:
                async with AsyncSessionLocal() as local_db:
                    nonlocal total_fetched, total_saved, skipped, errors
                    
                    # max_items ì œí•œ í™•ì¸
                    if max_items and total_saved >= max_items:
                        return
                    
                    try:
                        # ê¸°ì¡´ ë°ì´í„° í™•ì¸
                        y = int(ym[:4])
                        m = int(ym[4:])
                        start_date = date(y, m, 1)
                        last_day = calendar.monthrange(y, m)[1]
                        end_date = date(y, m, last_day)
                        
                        check_stmt = select(func.count(Rent.trans_id)).join(Apartment).join(State).where(
                            and_(
                                State.region_code.like(f"{sgg_cd}%"),
                                Rent.deal_date >= start_date,
                                Rent.deal_date <= end_date
                            )
                        )
                        count_result = await local_db.execute(check_stmt)
                        existing_count = count_result.scalar() or 0
                        
                        if existing_count > 0 and not allow_duplicate:
                            skipped += existing_count
                            logger.info(f"â­ï¸ {sgg_cd}/{ym} ({ym_formatted}): ê±´ë„ˆëœ€ ({existing_count}ê±´ ì¡´ì¬)")
                            return
                        
                        # API í˜¸ì¶œ (XML) - ê³µìœ  í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©
                        params = {
                            "serviceKey": self.api_key,
                            "LAWD_CD": sgg_cd,
                            "DEAL_YMD": ym,
                            "numOfRows": 4000
                        }
                        
                        response = await http_client.get(MOLIT_RENT_API_URL, params=params)
                        response.raise_for_status()
                        xml_content = response.text
                        
                        # XML íŒŒì‹±
                        try:
                            root = ET.fromstring(xml_content)
                        except ET.ParseError as e:
                            errors.append(f"{sgg_cd}/{ym} ({ym_formatted}): XML íŒŒì‹± ì‹¤íŒ¨ - {str(e)}")
                            logger.error(f"âŒ {sgg_cd}/{ym} ({ym_formatted}): XML íŒŒì‹± ì‹¤íŒ¨ - {str(e)}")
                            return
                        
                        # ê²°ê³¼ ì½”ë“œ í™•ì¸
                        result_code_elem = root.find(".//resultCode")
                        result_msg_elem = root.find(".//resultMsg")
                        result_code = result_code_elem.text if result_code_elem is not None else ""
                        result_msg = result_msg_elem.text if result_msg_elem is not None else ""
                        
                        if result_code != "000":
                            errors.append(f"{sgg_cd}/{ym} ({ym_formatted}): {result_msg}")
                            logger.error(f"âŒ {sgg_cd}/{ym} ({ym_formatted}): {result_msg}")
                            return
                        
                        # items ì¶”ì¶œ
                        items = root.findall(".//item")
                        
                        if not items:
                            return
                        
                        total_fetched += len(items)
                        
                        # ì•„íŒŒíŠ¸ ë° ì§€ì—­ ì •ë³´ ë¡œë“œ (ìºì‹± í™œìš©)
                        local_apts, all_regions, apt_details = await load_apts_and_regions(sgg_cd)
                        
                        if not local_apts:
                            return
                        
                        rents_to_save = []
                        success_count = 0
                        skip_count = 0
                        error_count = 0
                        jeonse_count = 0
                        wolse_count = 0
                        apt_name_log = ""
                        normalized_cache: Dict[str, Any] = {}  # ì •ê·œí™” ê²°ê³¼ ìºì‹±
                        batch_size = 100  # ë°°ì¹˜ ì»¤ë°‹ í¬ê¸°
                        
                        for item in items:
                            # max_items ì œí•œ í™•ì¸
                            if max_items and total_saved >= max_items:
                                break
                            
                            try:
                                # XML Elementì—ì„œ í•„ë“œ ì¶”ì¶œ
                                apt_nm_elem = item.find("aptNm")
                                apt_nm = apt_nm_elem.text.strip() if apt_nm_elem is not None and apt_nm_elem.text else ""
                                
                                umd_nm_elem = item.find("umdNm")
                                umd_nm = umd_nm_elem.text.strip() if umd_nm_elem is not None and umd_nm_elem.text else ""
                                
                                sgg_cd_elem = item.find("sggCd")
                                sgg_cd_item = sgg_cd_elem.text.strip() if sgg_cd_elem is not None and sgg_cd_elem.text else sgg_cd
                                
                                # ì§€ë²ˆ ì¶”ì¶œ (ë§¤ì¹­ì— í™œìš©)
                                jibun_elem = item.find("jibun")
                                jibun = jibun_elem.text.strip() if jibun_elem is not None and jibun_elem.text else ""
                                
                                # ê±´ì¶•ë…„ë„ ì¶”ì¶œ (ë§¤ì¹­ì— í™œìš©)
                                build_year_elem = item.find("buildYear")
                                build_year_for_match = build_year_elem.text.strip() if build_year_elem is not None and build_year_elem.text else ""
                                
                                if not apt_nm:
                                    continue
                                
                                if not apt_name_log:
                                    apt_name_log = apt_nm
                                
                                # ë™ ê¸°ë°˜ í•„í„°ë§ (ê°œì„ ëœ ë²„ì „)
                                candidates = local_apts
                                sgg_code_matched = True
                                dong_matched = False
                                
                                # ì‹œêµ°êµ¬ ì½”ë“œ ê¸°ë°˜ í•„í„°ë§ (ê°œì„ : 5ìë¦¬ â†’ 10ìë¦¬ ë³€í™˜)
                                if sgg_cd_item and str(sgg_cd_item).strip():
                                    sgg_cd_item_str = str(sgg_cd_item).strip()
                                    sgg_cd_str = str(sgg_cd).strip()
                                    
                                    # DB í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (5ìë¦¬ â†’ 10ìë¦¬)
                                    sgg_cd_db = self._convert_sgg_code_to_db_format(sgg_cd_item_str)
                                    
                                    if sgg_cd_db:
                                        # ì •í™•í•œ ë§¤ì¹­ ì‹œë„
                                        filtered = [
                                            apt for apt in local_apts
                                            if apt.region_id in all_regions
                                            and all_regions[apt.region_id].region_code == sgg_cd_db
                                        ]
                                        # ì •í™•í•œ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ì‹œì‘ ë¶€ë¶„ ë§¤ì¹­
                                        if not filtered:
                                            filtered = [
                                                apt for apt in local_apts
                                                if apt.region_id in all_regions
                                                and all_regions[apt.region_id].region_code.startswith(sgg_cd_item_str)
                                            ]
                                        if filtered:
                                            candidates = filtered
                                            sgg_code_matched = True
                                
                                # ë™ ê¸°ë°˜ í•„í„°ë§ (ê°œì„ : ë” ë„ë„í•œ ë§¤ì¹­)
                                if umd_nm and candidates:
                                    matching_region_ids = self._find_matching_regions(umd_nm, all_regions)
                                    
                                    if matching_region_ids:
                                        filtered = [
                                            apt for apt in candidates
                                            if apt.region_id in matching_region_ids
                                        ]
                                        if filtered:
                                            candidates = filtered
                                            dong_matched = True
                                    # í•„í„°ë§ ì‹¤íŒ¨í•´ë„ í›„ë³´ ìœ ì§€ (ë” ë„ë„í•˜ê²Œ)
                                
                                # í›„ë³´ê°€ ì—†ìœ¼ë©´ ì›ë˜ í›„ë³´ë¡œ ë³µì›
                                if not candidates:
                                    candidates = local_apts
                                    sgg_code_matched = True
                                    dong_matched = False
                                
                                # ì•„íŒŒíŠ¸ ë§¤ì¹­ (ì •ê·œí™” ìºì‹œ, ì§€ë²ˆ, ê±´ì¶•ë…„ë„, ìƒì„¸ì •ë³´ ì „ë‹¬)
                                matched_apt = self._match_apartment(
                                    apt_nm, candidates, sgg_cd, umd_nm, 
                                    jibun, build_year_for_match, apt_details, normalized_cache,
                                    all_regions=all_regions, require_dong_match=False
                                )
                                
                                # í•„í„°ë§ëœ í›„ë³´ì—ì„œ ì‹¤íŒ¨ ì‹œ ì „ì²´ í›„ë³´ë¡œ ì¬ì‹œë„ (ë‹¨, ë™ ê²€ì¦ í•„ìˆ˜!)
                                if not matched_apt and len(candidates) < len(local_apts) and dong_matched:
                                    # ì „ì²´ í›„ë³´ë¡œ ì¬ì‹œë„ ì‹œ ë°˜ë“œì‹œ ë™ ì¼ì¹˜ ê²€ì¦ ìˆ˜í–‰
                                    matched_apt = self._match_apartment(
                                        apt_nm, local_apts, sgg_cd, umd_nm, 
                                        jibun, build_year_for_match, apt_details, normalized_cache,
                                        all_regions=all_regions, require_dong_match=True
                                    )
                                
                                if not matched_apt:
                                    error_count += 1
                                    # ì •ê·œí™”ëœ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
                                    normalized_name = normalized_cache.get(apt_nm)
                                    if not normalized_name:
                                        normalized_name = self._normalize_apt_name(apt_nm)
                                        normalized_cache[apt_nm] = normalized_name
                                    
                                    # ì§€ì—­ ì´ë¦„ ê°€ì ¸ì˜¤ê¸° (ì‹œêµ°êµ¬/ë™)
                                    region_name = None
                                    if umd_nm:
                                        # ë™ ì´ë¦„ìœ¼ë¡œ ì§€ì—­ ì°¾ê¸°
                                        matching_region_ids = self._find_matching_regions(umd_nm, all_regions)
                                        if matching_region_ids:
                                            first_region_id = list(matching_region_ids)[0]
                                            if first_region_id in all_regions:
                                                region_name = all_regions[first_region_id].region_name
                                    elif sgg_cd_item:
                                        # ì‹œêµ°êµ¬ ì½”ë“œë¡œ ì§€ì—­ ì°¾ê¸°
                                        sgg_cd_db = self._convert_sgg_code_to_db_format(str(sgg_cd_item).strip())
                                        if sgg_cd_db:
                                            for region in all_regions.values():
                                                if region.region_code == sgg_cd_db:
                                                    region_name = region.region_name
                                                    break
                                    
                                    # ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ë¡œê¹… (apartfail_YYYYMM.log íŒŒì¼ë¡œ ì €ì¥)
                                    self._record_apt_fail(
                                        trans_type='ì „ì›”ì„¸',
                                        apt_name=apt_nm,
                                        jibun=jibun,
                                        build_year=build_year_for_match,
                                        umd_nm=umd_nm,
                                        sgg_cd=sgg_cd,
                                        ym=ym,  # ê±°ë˜ ë°œìƒ ì›”
                                        reason='ì´ë¦„ë§¤ì¹­ ì‹¤íŒ¨',
                                        normalized_name=normalized_name,
                                        candidates=candidates,
                                        local_apts=local_apts,
                                        sgg_code_matched=sgg_code_matched,
                                        dong_matched=dong_matched,
                                        region_name=region_name
                                    )
                                    continue
                                
                                # ë§¤ì¹­ ë¡œê·¸ ê¸°ë¡ (apart_YYYYMM.logìš©)
                                self._record_apt_matching(
                                    matched_apt.apt_id,
                                    matched_apt.apt_name,
                                    apt_nm,
                                    ym
                                )
                                
                                # ê±°ë˜ ë°ì´í„° íŒŒì‹± (XML Elementì—ì„œ ì¶”ì¶œ) - ì¸ë¼ì¸ìœ¼ë¡œ ìµœì í™”
                                try:
                                    # ê±°ë˜ì¼ íŒŒì‹±
                                    deal_year_elem = item.find("dealYear")
                                    deal_month_elem = item.find("dealMonth")
                                    deal_day_elem = item.find("dealDay")
                                    
                                    deal_year = deal_year_elem.text.strip() if deal_year_elem is not None and deal_year_elem.text else None
                                    deal_month = deal_month_elem.text.strip() if deal_month_elem is not None and deal_month_elem.text else None
                                    deal_day = deal_day_elem.text.strip() if deal_day_elem is not None and deal_day_elem.text else None
                                    
                                    if not deal_year or not deal_month or not deal_day:
                                        error_count += 1
                                        continue
                                    
                                    deal_date_obj = date(int(deal_year), int(deal_month), int(deal_day))
                                    
                                    # ì „ìš©ë©´ì  íŒŒì‹±
                                    exclu_use_ar_elem = item.find("excluUseAr")
                                    exclu_use_ar = exclu_use_ar_elem.text.strip() if exclu_use_ar_elem is not None and exclu_use_ar_elem.text else None
                                    if not exclu_use_ar:
                                        error_count += 1
                                        continue
                                    exclusive_area = float(exclu_use_ar)
                                    
                                    # ì¸µ íŒŒì‹±
                                    floor_elem = item.find("floor")
                                    floor_str = floor_elem.text.strip() if floor_elem is not None and floor_elem.text else None
                                    if not floor_str:
                                        error_count += 1
                                        continue
                                    floor = int(floor_str)
                                    
                                    # ë³´ì¦ê¸ˆ íŒŒì‹±
                                    deposit_elem = item.find("deposit")
                                    deposit_str = deposit_elem.text.strip() if deposit_elem is not None and deposit_elem.text else None
                                    deposit_price = None
                                    if deposit_str:
                                        try:
                                            deposit_price = int(deposit_str.replace(",", ""))
                                        except:
                                            pass
                                    
                                    # ì›”ì„¸ íŒŒì‹±
                                    monthly_rent_elem = item.find("monthlyRent")
                                    monthly_rent_str = monthly_rent_elem.text.strip() if monthly_rent_elem is not None and monthly_rent_elem.text else None
                                    monthly_rent = None
                                    if monthly_rent_str:
                                        try:
                                            monthly_rent = int(monthly_rent_str.replace(",", ""))
                                            if monthly_rent == 0:
                                                monthly_rent = None  # ì „ì„¸ì¸ ê²½ìš°
                                        except:
                                            pass
                                    
                                    # ì „ì„¸/ì›”ì„¸ êµ¬ë¶„ ì¹´ìš´íŠ¸
                                    if monthly_rent and monthly_rent > 0:
                                        wolse_count += 1
                                    else:
                                        jeonse_count += 1
                                    
                                    # ì¤‘ë³µ ì²´í¬ (ì¸ë¼ì¸ìœ¼ë¡œ ìµœì í™” - ë§¤ë§¤ì™€ ë™ì¼í•œ ë°©ì‹)
                                    exists_stmt = select(Rent).where(
                                        and_(
                                            Rent.apt_id == matched_apt.apt_id,
                                            Rent.deal_date == deal_date_obj,
                                            Rent.floor == floor,
                                            Rent.exclusive_area == exclusive_area,
                                            Rent.deposit_price == deposit_price,
                                            Rent.monthly_rent == monthly_rent
                                        )
                                    )
                                    exists = await local_db.execute(exists_stmt)
                                    existing_rent = exists.scalars().first()
                                    
                                    if existing_rent:
                                        if allow_duplicate:
                                            # ì—…ë°ì´íŠ¸
                                            build_year_elem = item.find("buildYear")
                                            build_year = build_year_elem.text.strip() if build_year_elem is not None and build_year_elem.text else None
                                            contract_type_elem = item.find("contractType")
                                            contract_type_str = contract_type_elem.text.strip() if contract_type_elem is not None and contract_type_elem.text else None
                                            contract_type = contract_type_str == "ê°±ì‹ " if contract_type_str else None
                                            
                                            existing_rent.build_year = build_year
                                            existing_rent.deposit_price = deposit_price
                                            existing_rent.monthly_rent = monthly_rent
                                            existing_rent.contract_type = contract_type
                                            existing_rent.remarks = apt_nm
                                            local_db.add(existing_rent)
                                            success_count += 1
                                            total_saved += 1
                                        else:
                                            skip_count += 1
                                        continue
                                    
                                    # ìƒˆë¡œ ìƒì„±
                                    build_year_elem = item.find("buildYear")
                                    build_year = build_year_elem.text.strip() if build_year_elem is not None and build_year_elem.text else None
                                    contract_type_elem = item.find("contractType")
                                    contract_type_str = contract_type_elem.text.strip() if contract_type_elem is not None and contract_type_elem.text else None
                                    contract_type = contract_type_str == "ê°±ì‹ " if contract_type_str else None
                                    
                                    apt_seq_elem = item.find("aptSeq")
                                    apt_seq = apt_seq_elem.text.strip() if apt_seq_elem is not None and apt_seq_elem.text else None
                                    if apt_seq and len(apt_seq) > 10:
                                        apt_seq = apt_seq[:10]
                                    
                                    rent_create = RentCreate(
                                        apt_id=matched_apt.apt_id,
                                        build_year=build_year,
                                        contract_type=contract_type,
                                        deposit_price=deposit_price,
                                        monthly_rent=monthly_rent,
                                        exclusive_area=exclusive_area,
                                        floor=floor,
                                        apt_seq=apt_seq,
                                        deal_date=deal_date_obj,
                                        contract_date=None,
                                        remarks=apt_nm
                                    )
                                    
                                    db_obj = Rent(**rent_create.model_dump())
                                    local_db.add(db_obj)
                                    rents_to_save.append(rent_create)
                                    success_count += 1
                                    total_saved += 1
                                    
                                    # ë°°ì¹˜ ì»¤ë°‹ (ì„±ëŠ¥ ìµœì í™”)
                                    if len(rents_to_save) >= batch_size:
                                        await local_db.commit()
                                        rents_to_save = []
                                        
                                except Exception as e:
                                    error_count += 1
                                    continue
                                
                                # ì•„íŒŒíŠ¸ ìƒíƒœ ì—…ë°ì´íŠ¸
                                if matched_apt.is_available != "1":
                                    matched_apt.is_available = "1"
                                    local_db.add(matched_apt)
                                
                            except Exception as e:
                                error_count += 1
                                continue
                        
                        # ë‚¨ì€ ë°ì´í„° ì»¤ë°‹
                        if rents_to_save:
                            await local_db.commit()
                        
                        # ê°„ê²°í•œ ë¡œê·¸ (í•œ ì¤„)
                        if success_count > 0 or skip_count > 0 or error_count > 0:
                            logger.info(
                                f"{sgg_cd}/{ym} ({ym_formatted}): "
                                f"âœ…{success_count} â­ï¸{skip_count} âŒ{error_count} "
                                f"(ì „ì„¸:{jeonse_count} ì›”ì„¸:{wolse_count}) ({apt_name_log})"
                            )
                        
                        skipped += skip_count
                        
                        # max_items ì œí•œ í™•ì¸
                        if max_items and total_saved >= max_items:
                            return
                        
                    except Exception as e:
                        errors.append(f"{sgg_cd}/{ym} ({ym_formatted}): {str(e)}")
                        logger.error(f"âŒ {sgg_cd}/{ym} ({ym_formatted}): {str(e)}")
                        await local_db.rollback()
        
        # ë³‘ë ¬ ì‹¤í–‰
        try:
            total_months = len(target_months)
            for month_idx, ym in enumerate(target_months, 1):
                if max_items and total_saved >= max_items:
                    break
                
                ym_formatted = format_ym(ym)
                # ì›” ì‹œì‘ ë¡œê·¸
                logger.info(f"ğŸ“Š {ym_formatted} | {month_idx}/{total_months}ê°œ ì›” | {total_regions}ê°œ ì§€ì—­ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
                
                tasks = [process_rent_region(ym, sgg_cd) for sgg_cd in target_sgg_codes]
                await asyncio.gather(*tasks, return_exceptions=True)
                
                # ì›” ì™„ë£Œ ë¡œê·¸
                logger.info(f"âœ… {ym_formatted} ì™„ë£Œ | ëˆ„ì  ì €ì¥: {total_saved}ê±´")
                
                # í•´ë‹¹ ì›”ì˜ ë¡œê·¸ ì €ì¥ (apart_YYYYMM.log, apartfail_YYYYMM.log)
                print(f"[LOG_SAVE] ì›” ì™„ë£Œ - {ym_formatted} ë¡œê·¸ ì €ì¥ ì‹œì‘ (ym={ym})")
                logger.info(f"=" * 60)
                logger.info(f"ğŸ“ [ì „ì›”ì„¸] {ym_formatted} ë¡œê·¸ ì €ì¥ ì‹œì‘")
                logger.info(f"   ë§¤ì¹­ ë¡œê·¸: {len(self._apt_matching_log_by_month.get(ym, {}))}ê°œ ì•„íŒŒíŠ¸")
                logger.info(f"   ì‹¤íŒ¨ ë¡œê·¸: {len(self._apt_fail_log_by_month.get(ym, []))}ê±´")
                logger.info(f"=" * 60)
                
                try:
                    print(f"[LOG_SAVE] {ym} - _save_apt_matching_log í˜¸ì¶œ")
                    self._save_apt_matching_log(ym)
                    print(f"[LOG_SAVE] {ym} - _save_apt_matching_log ì™„ë£Œ")
                except Exception as e:
                    print(f"[LOG_SAVE] ERROR: {ym} ë§¤ì¹­ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨ - {e}")
                    logger.error(f"âŒ [ì „ì›”ì„¸] {ym_formatted} ë§¤ì¹­ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}", exc_info=True)
                
                try:
                    print(f"[LOG_SAVE] {ym} - _save_apt_fail_log í˜¸ì¶œ")
                    self._save_apt_fail_log(ym)
                    print(f"[LOG_SAVE] {ym} - _save_apt_fail_log ì™„ë£Œ")
                except Exception as e:
                    print(f"[LOG_SAVE] ERROR: {ym} ì‹¤íŒ¨ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨ - {e}")
                    logger.error(f"âŒ [ì „ì›”ì„¸] {ym_formatted} ì‹¤íŒ¨ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}", exc_info=True)
                
                logger.info(f"=" * 60)
                logger.info(f"ğŸ“ [ì „ì›”ì„¸] {ym_formatted} ë¡œê·¸ ì €ì¥ ì™„ë£Œ")
                logger.info(f"=" * 60)
                print(f"[LOG_SAVE] {ym_formatted} ë¡œê·¸ ì €ì¥ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ")
                
                if max_items and total_saved >= max_items:
                    break
        finally:
            # HTTP í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬
            await http_client.aclose()
        
        logger.info(f"ğŸ‰ ì „ì›”ì„¸ ìˆ˜ì§‘ ì™„ë£Œ: ì €ì¥ {total_saved}ê±´, ê±´ë„ˆëœ€ {skipped}ê±´, ì˜¤ë¥˜ {len(errors)}ê±´")
        # ì°¸ê³ : ê° ì›”ì˜ ë¡œê·¸ëŠ” ì›”ë³„ë¡œ ì´ë¯¸ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.
        
        return RentCollectionResponse(
            success=True,
            total_fetched=total_fetched,
            total_saved=total_saved,
            skipped=skipped,
            errors=errors[:100],
            message=f"ìˆ˜ì§‘ ì™„ë£Œ: {total_saved}ê±´ ì €ì¥, {skipped}ê±´ ê±´ë„ˆëœ€",
            lawd_cd=None,
            deal_ymd=None
        )

# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
data_collection_service = DataCollectionService()
