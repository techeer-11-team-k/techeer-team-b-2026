"""
ì•„íŒŒíŠ¸ ë§¤ì¹­ ìœ í‹¸ë¦¬í‹° ëª¨ë“ˆ

ì•„íŒŒíŠ¸ ì´ë¦„ ì •ê·œí™” ë° ë§¤ì¹­ ê´€ë ¨ í•¨ìˆ˜ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤.
"""
import re
import logging
from typing import List, Dict, Any, Optional, Tuple
from difflib import SequenceMatcher

from app.models import Apartment, ApartDetail
from app.utils.search_utils import BRAND_ENG_TO_KOR
from app.services.apt_matching import (
    BRAND_KEYWORD_TO_STANDARD,
    BUILD_YEAR_TOLERANCE,
)

logger = logging.getLogger(__name__)

# í•œêµ­ ëŒ€í‘œ ì•„íŒŒíŠ¸ ë¸Œëœë“œëª… ì‚¬ì „ (ì •ê·œí™”ëœ í˜•íƒœë¡œ ì €ì¥, ê¸´ ê²ƒ ìš°ì„ )
APARTMENT_BRANDS = [
    # ë³µí•© ë¸Œëœë“œëª… (ë¨¼ì € ë§¤ì¹­, ê¸´ ê²ƒë¶€í„°)
    'ë¡¯ë°ìºìŠ¬íŒŒí¬íƒ€ìš´', 'ë¡¯ë°ìºìŠ¬ê³¨ë“œíƒ€ìš´', 'ë¡¯ë°ìºìŠ¬', 
    'í˜„ëŒ€íìŠ¤í…Œì´íŠ¸', 'íìŠ¤í…Œì´íŠ¸',
    'ì´í¸í•œì„¸ìƒ', 'eí¸í•œì„¸ìƒ', 'í¸í•œì„¸ìƒ',
    'í•œë¼ë¹„ë°œë””', 'ë¹„ë°œë””',
    'í˜¸ë°˜ì¨ë°‹', 'ì¨ë°‹',
    'ìš°ë¯¸ë¦°',
    'ë˜ë¯¸ì•ˆ', 'ë¼ë¯¸ì•ˆ',
    'í‘¸ë¥´ì§€ì˜¤',
    'ë”ìƒµ', 'theìƒµ',
    'ì•„ì´íŒŒí¬',
    'ìì´', 'xi',
    'ìœ„ë¸Œ', 'ë‘ì‚°ìœ„ë¸Œ',
    'skë·°', 'skìŠ¤ì¹´ì´ë·°', 'ì—ìŠ¤ì¼€ì´ë·°',
    'ê¿ˆì—ê·¸ë¦°', 'í¬ë ˆë‚˜',
    'ë² ìŠ¤íŠ¸ë¹Œ', 'ì–´ìš¸ë¦¼',
    'ë¡œì–„ë“€í¬',
    'ìŠ¤ìœ—ë‹·í™ˆ', 'ì˜ˆê°€',
    'ì„¼íŠ¸ë ˆë¹Œ',
    'ì•„í¬ë¡œ',
    'ì‚¬ë‘ìœ¼ë¡œ',
    'sí´ë˜ìŠ¤', 'ì¤‘í¥sí´ë˜ìŠ¤', 'ì¤‘í¥',
    'ìˆ˜ìì¸', 'ë‚˜ë¹Œë˜', 'ìŠ¤íƒ€í´ë˜ìŠ¤', 'ë…¸ë¹Œë¦¬í‹°', 'ìŠ¤ì¹´ì´ë·°',
    # ì¶”ê°€ ë¸Œëœë“œ (ëˆ„ë½ë˜ì–´ ìˆë˜ ê²ƒë“¤)
    'ìŠ¤ìœ„ì²¸', 'kccìŠ¤ìœ„ì²¸',  # KCCê±´ì„¤
    'íŠ¸ë¼íŒ°ë¦¬ìŠ¤', 'ì‚¼ì„±íŠ¸ë¼íŒ°ë¦¬ìŠ¤',  # ì‚¼ì„±ë¬¼ì‚°
    'íŒŒí¬ë¦¬ì˜¤', 'ë°˜í¬íŒŒí¬ë¦¬ì˜¤',  # ì‚¼ì„±ë¬¼ì‚°
    'íœ´ë¨¼ì‹œì•„',  # LHê³µì‚¬
    'ë§ˆì œìŠ¤í‹°', 'ì‹ ì„¸ê³„ë¹Œë¦¬ë¸Œ',  # ì‹ ì„¸ê³„ê±´ì„¤
    'í•˜ì´ì¸ ',  # ì¼ë°˜ ì ‘ë¯¸ì‚¬
    'ì•„ë„ˆìŠ¤ë¹Œ', 'ê²½ë‚¨ì•„ë„ˆìŠ¤ë¹Œ',  # ê²½ë‚¨ê¸°ì—…
    'ì‹œê·¸ë‹ˆì²˜', 'ë”í¼ìŠ¤íŠ¸',  # ì¼ë°˜ ë¸Œëœë“œ
    'íŠ¸ë ˆì§€ì›€', 'ë‘ë ˆë¯¸ë‹´',  # í•œí™”ê±´ì„¤
    'í”„ë ˆìŠ¤í‹°ì§€', 'ë¥´ë„¤ìƒìŠ¤',  # ì¼ë°˜ ë¸Œëœë“œ
    'ìºìŠ¬ê³¨ë“œ', 'ë“œë¦¼íƒ€ìš´',  # ì¼ë°˜ ë¸Œëœë“œ
    # ê±´ì„¤ì‚¬ ë¸Œëœë“œ
    'í˜„ëŒ€', 'ì‚¼ì„±', 'ëŒ€ë¦¼', 'ëŒ€ìš°', 'ë™ì•„', 'ê·¹ë™', 'ë²½ì‚°', 'ê¸ˆí˜¸', 'ë™ë¶€',
    'ì‹ ë™ì•„', 'ì‹ ì„±', 'ì£¼ê³µ', 'í•œì‹ ', 'íƒœì˜', 'ì§„í¥', 'ë™ì¼', 'ê±´ì˜',
    'ìš°ë°©', 'í•œì–‘', 'ì„±ì›', 'ê²½ë‚¨', 'ë™ë¬¸', 'í’ë¦¼', 'ì‹ ì•ˆ', 'ì„ ê²½',
    'íš¨ì„±', 'ì½”ì˜¤ë¡±', 'ëŒ€ë°©', 'ë™ì„±', 'ì¼ì‹ ', 'ì²­êµ¬', 'ì‚¼ìµ', 'ì§„ë¡œ',
    'ë¶€ì˜', 'ìŒìš©', 'ìºìŠ¬', 'ë¦°', 'ê¸ˆê°•', 'ëŸ­í‚¤', 'ì„ê´‘', 'ë™ì‹ ',
    'í™”ì„±', 'ëŒ€ì°½', 'ì„œì•ˆ', 'ì˜í’', 'ì„¸ì˜', 'ë™ì–‘', 'í•œì§„',
]

# ë§ˆì„/ë‹¨ì§€ ì ‘ë¯¸ì‚¬ íŒ¨í„´
VILLAGE_SUFFIXES = ['ë§ˆì„', 'ë‹¨ì§€', 'íƒ€ìš´', 'ë¹Œë¦¬ì§€', 'íŒŒí¬', 'ì‹œí‹°', 'íìŠ¤', 'ë·°']


class ApartmentMatcher:
    """
    ì•„íŒŒíŠ¸ ë§¤ì¹­ ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤
    
    ì•„íŒŒíŠ¸ ì´ë¦„ ì •ê·œí™” ë° ë§¤ì¹­ ê´€ë ¨ í•¨ìˆ˜ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤.
    """
    
    @staticmethod
    def match_by_apt_seq(
        apt_seq: str,
        candidates: List[Apartment]
    ) -> Optional[Apartment]:
        """
        ğŸ”‘ 0ë‹¨ê³„ (ìµœìš°ì„ ): apt_seq ì§ì ‘ ë§¤ì¹­
        
        ë§¤ë§¤/ì „ì›”ì„¸ APIì—ì„œ ì œê³µí•˜ëŠ” aptSeqë¥¼ DBì˜ apt_seqì™€ ì§ì ‘ ë¹„êµí•©ë‹ˆë‹¤.
        ì´ ë°©ë²•ì€ ê°€ì¥ ë¹ ë¥´ê³  ì •í™•í•©ë‹ˆë‹¤.
        
        Args:
            apt_seq: APIì—ì„œ ë°›ì€ aptSeq (ì˜ˆ: "41480-40")
            candidates: í›„ë³´ ì•„íŒŒíŠ¸ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ë§¤ì¹­ëœ Apartment ê°ì²´ ë˜ëŠ” None
        """
        if not apt_seq or not candidates:
            return None
        
        # ì •ê·œí™”: ì•ë’¤ ê³µë°± ì œê±°
        apt_seq_clean = apt_seq.strip()
        
        for apt in candidates:
            # apt_seq ì†ì„±ì´ ìˆê³  ì¼ì¹˜í•˜ë©´ ë°”ë¡œ ë°˜í™˜
            if hasattr(apt, 'apt_seq') and apt.apt_seq:
                if apt.apt_seq.strip() == apt_seq_clean:
                    logger.debug(f"âœ… apt_seq ì§ì ‘ ë§¤ì¹­ ì„±ê³µ: {apt_seq} â†’ {apt.apt_name}")
                    return apt
        
        return None
    
    @staticmethod
    def match_by_jibun_parts(
        jibun_bonbun: str,
        jibun_bubun: Optional[str],
        region_id: int,
        candidates: List[Apartment],
        apt_details: Optional[Dict[int, 'ApartDetail']] = None
    ) -> Optional[Apartment]:
        """
        ğŸ”‘ ì§€ë²ˆ ë³¸ë²ˆ/ë¶€ë²ˆ ë¶„ë¦¬ ë§¤ì¹­
        
        apart_details í…Œì´ë¸”ì˜ jibun_bonbun, jibun_bubun ì»¬ëŸ¼ì„ í™œìš©í•œ ë¹ ë¥¸ ë§¤ì¹­ì…ë‹ˆë‹¤.
        
        Args:
            jibun_bonbun: ì§€ë²ˆ ë³¸ë²ˆ (ì˜ˆ: "553")
            jibun_bubun: ì§€ë²ˆ ë¶€ë²ˆ (ì˜ˆ: "2" ë˜ëŠ” None)
            region_id: ì§€ì—­ ID (ë™ í•„í„°ë§ìš©)
            candidates: í›„ë³´ ì•„íŒŒíŠ¸ ë¦¬ìŠ¤íŠ¸
            apt_details: ì•„íŒŒíŠ¸ ìƒì„¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬
            
        Returns:
            ë§¤ì¹­ëœ Apartment ê°ì²´ ë˜ëŠ” None
        """
        if not jibun_bonbun or not candidates or not apt_details:
            return None
        
        bonbun_clean = jibun_bonbun.strip().lstrip('0')
        bubun_clean = jibun_bubun.strip().lstrip('0') if jibun_bubun else None
        
        for apt in candidates:
            # ì§€ì—­ ID í•„í„°ë§
            if apt.region_id != region_id:
                continue
            
            if apt.apt_id not in apt_details:
                continue
            
            detail = apt_details[apt.apt_id]
            
            # jibun_bonbun/bubun ì†ì„± í™•ì¸
            if hasattr(detail, 'jibun_bonbun') and detail.jibun_bonbun:
                db_bonbun = detail.jibun_bonbun.strip().lstrip('0')
                db_bubun = detail.jibun_bubun.strip().lstrip('0') if hasattr(detail, 'jibun_bubun') and detail.jibun_bubun else None
                
                # ë³¸ë²ˆ ì¼ì¹˜ í™•ì¸
                if db_bonbun == bonbun_clean:
                    # ë¶€ë²ˆ ì¼ì¹˜ í™•ì¸
                    if bubun_clean is None and db_bubun is None:
                        logger.debug(f"âœ… ì§€ë²ˆ ë³¸ë²ˆ ë§¤ì¹­ ì„±ê³µ: {bonbun_clean} â†’ {apt.apt_name}")
                        return apt
                    elif bubun_clean is not None and db_bubun is not None and bubun_clean == db_bubun:
                        logger.debug(f"âœ… ì§€ë²ˆ ë³¸ë²ˆ+ë¶€ë²ˆ ë§¤ì¹­ ì„±ê³µ: {bonbun_clean}-{bubun_clean} â†’ {apt.apt_name}")
                        return apt
        
        return None
    
    @staticmethod
    def match_by_address_and_jibun(
        full_region_code: str,
        jibun: str,
        bonbun: Optional[str] = None,
        bubun: Optional[str] = None,
        candidates: List[Apartment] = None,
        apt_details: Optional[Dict[int, ApartDetail]] = None,
        all_regions: Optional[Dict[int, Any]] = None
    ) -> Optional[Apartment]:
        """
        ğŸ”‘ ìµœìš°ì„  ë§¤ì¹­: ë²•ì •ë™ ì½”ë“œ 10ìë¦¬ + ì§€ë²ˆ(ë¶€ë²ˆê¹Œì§€) ì •í™• ë§¤ì¹­
        
        ë²•ì •ë™ ì½”ë“œ 10ìë¦¬ì™€ ì§€ë²ˆ(ë³¸ë²ˆ-ë¶€ë²ˆ)ì´ ëª¨ë‘ ì¼ì¹˜í•˜ë©´ ì´ë¦„ê³¼ ê´€ê³„ì—†ì´ ë§¤ì¹­í•©ë‹ˆë‹¤.
        ì´ëŠ” 95% ì‹ ë¢°êµ¬ê°„ì—ì„œ ê°™ì€ ë¶€ë™ì‚°ì„ ê°€ë¦¬í‚¤ëŠ” ê²ƒìœ¼ë¡œ ê°„ì£¼ë©ë‹ˆë‹¤.
        
        Args:
            full_region_code: ë²•ì •ë™ ì½”ë“œ 10ìë¦¬ (ì‹œë„ 2 + ì‹œêµ°êµ¬ 3 + ìë©´ë™ 5)
            jibun: ì§€ë²ˆ ë¬¸ìì—´ (ì˜ˆ: "1101-1")
            bonbun: ë³¸ë²ˆ (APIì—ì„œ ì§ì ‘ ì œê³µë˜ëŠ” ê²½ìš°)
            bubun: ë¶€ë²ˆ (APIì—ì„œ ì§ì ‘ ì œê³µë˜ëŠ” ê²½ìš°)
            candidates: í›„ë³´ ì•„íŒŒíŠ¸ ë¦¬ìŠ¤íŠ¸
            apt_details: ì•„íŒŒíŠ¸ ìƒì„¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬
            all_regions: ì§€ì—­ ì •ë³´ ë”•ì…”ë„ˆë¦¬
            
        Returns:
            ë§¤ì¹­ëœ Apartment ê°ì²´ ë˜ëŠ” None
        """
        if not full_region_code or not jibun or not candidates:
            return None
        
        # ë³¸ë²ˆ-ë¶€ë²ˆ ì¶”ì¶œ (bonbun/bubunì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©)
        if bonbun:
            api_main = bonbun.lstrip('0') if bonbun else None
            api_sub = bubun.lstrip('0') if bubun and bubun != "0" and bubun != "" else None
        else:
            # ğŸ”‘ ê°œì„ : jibunì—ì„œ ë³¸ë²ˆ-ë¶€ë²ˆ ì¶”ì¶œ (ì‚°ì§€ë²ˆ, ì§€êµ¬ë²ˆí˜¸, ë³¸ë²ˆ-ë¶€ë²ˆ-ë¶€ë¶€ë²ˆ ì²˜ë¦¬)
            jibun_clean = jibun.strip()
            
            # ì‚°ì§€ë²ˆ ì²˜ë¦¬: "ì‚°37-6" â†’ ë³¸ë²ˆ="37", ë¶€ë²ˆ="6"
            if jibun_clean.startswith('ì‚°'):
                jibun_clean = jibun_clean[1:]  # "ì‚°" ì œê±°
            
            # ì§€êµ¬ ë²ˆí˜¸ ì²˜ë¦¬: "ì§€êµ¬BL 34-7" â†’ ë³¸ë²ˆ="34", ë¶€ë²ˆ="7"
            if 'ì§€êµ¬' in jibun_clean or 'BL' in jibun_clean.upper() or 'ë¸”ë¡' in jibun_clean:
                # ìˆ«ì íŒ¨í„´ë§Œ ì¶”ì¶œ
                jibun_parts = re.search(r'(\d+)(?:-(\d+))?(?:-(\d+))?', jibun_clean)
                if jibun_parts:
                    api_main = jibun_parts.group(1).lstrip('0')
                    # ë¶€ë¶€ë²ˆì´ ìˆìœ¼ë©´ ë¶€ë²ˆìœ¼ë¡œ í†µí•© (ë˜ëŠ” ë¬´ì‹œ)
                    api_sub = jibun_parts.group(2).lstrip('0') if jibun_parts.group(2) else None
                else:
                    api_main = None
                    api_sub = None
            else:
                # ì¼ë°˜ ì§€ë²ˆ ì²˜ë¦¬ (ë³¸ë²ˆ-ë¶€ë²ˆ-ë¶€ë¶€ë²ˆ í¬í•¨)
                jibun_parts = re.match(r'(\d+)(?:-(\d+))?(?:-(\d+))?', jibun_clean)
                if jibun_parts:
                    api_main = jibun_parts.group(1).lstrip('0')
                    # ë¶€ë¶€ë²ˆì´ ìˆìœ¼ë©´ ë¶€ë²ˆë§Œ ì‚¬ìš© (ë¶€ë¶€ë²ˆì€ ë¬´ì‹œ)
                    api_sub = jibun_parts.group(2).lstrip('0') if jibun_parts.group(2) else None
                else:
                    api_main = None
                    api_sub = None
        
        if not api_main:
            return None
        
        # ë²•ì •ë™ ì½”ë“œ 10ìë¦¬ ì¼ì¹˜í•˜ëŠ” í›„ë³´ í•„í„°ë§
        matching_apts = []
        for apt in candidates:
            if apt.region_id not in all_regions:
                continue
            
            region = all_regions[apt.region_id]
            if region.region_code != full_region_code:
                continue
            
            matching_apts.append(apt)
        
        if not matching_apts:
            return None
        
        # ì§€ë²ˆ ì£¼ì†Œì—ì„œ ë³¸ë²ˆ-ë¶€ë²ˆ ì¶”ì¶œí•˜ì—¬ ì •í™• ë§¤ì¹­
        for apt in matching_apts:
            if apt.apt_id not in apt_details:
                continue
            
            detail = apt_details[apt.apt_id]
            if not detail.jibun_address:
                continue
            
            # ğŸ”‘ ê°œì„ : DB ì§€ë²ˆ ì£¼ì†Œì—ì„œ ë™ ì´ë¦„ê³¼ ì§€ë²ˆì„ ë” ì •í™•íˆ ì¶”ì¶œ
            # íŒ¨í„´: "ë™ì´ë¦„ ì§€ë²ˆ" ë˜ëŠ” "ë™ì´ë¦„ ì§€ë²ˆ-ë¶€ë²ˆ" ë˜ëŠ” "ë™ì´ë¦„ ì§€ë²ˆ-ë¶€ë²ˆ-ë¶€ë¶€ë²ˆ"
            # ì‚°ì§€ë²ˆ, ì§€êµ¬ë²ˆí˜¸ë„ ì²˜ë¦¬
            dong_jibun_pattern = r'([ê°€-í£]+(?:ë™|ê°€|ë¦¬|ì|ë©´))\s+(?:ì‚°)?(\d+)(?:-(\d+))?(?:-(\d+))?(?:\s|$)'
            db_dong_jibun_match = re.search(dong_jibun_pattern, detail.jibun_address)
            
            if db_dong_jibun_match:
                db_main = db_dong_jibun_match.group(2).lstrip('0')  # ë³¸ë²ˆ
                # ë¶€ë¶€ë²ˆì´ ìˆìœ¼ë©´ ë¶€ë²ˆë§Œ ì‚¬ìš© (ë¶€ë¶€ë²ˆì€ ë¬´ì‹œ)
                db_sub = db_dong_jibun_match.group(3).lstrip('0') if db_dong_jibun_match.group(3) else None  # ë¶€ë²ˆ
            else:
                # ğŸ”‘ ê°œì„ : ì‚°ì§€ë²ˆ, ì§€êµ¬ë²ˆí˜¸, ë³¸ë²ˆ-ë¶€ë²ˆ-ë¶€ë¶€ë²ˆ ì²˜ë¦¬
                # ì‚°ì§€ë²ˆ íŒ¨í„´: "ì‚°37-6"
                san_match = re.search(r'ì‚°\s*(\d+)(?:-(\d+))?(?:-(\d+))?', detail.jibun_address)
                if san_match:
                    db_main = san_match.group(1).lstrip('0')
                    db_sub = san_match.group(2).lstrip('0') if san_match.group(2) else None
                else:
                    # ì§€êµ¬ ë²ˆí˜¸ íŒ¨í„´: "ì§€êµ¬BL 34-7" ë˜ëŠ” "ê°€ì •2ì§€êµ¬34-7"
                    jigu_match = re.search(r'ì§€êµ¬[^\d]*(\d+)(?:-(\d+))?(?:-(\d+))?', detail.jibun_address)
                    if not jigu_match:
                        jigu_match = re.search(r'BL[^\d]*(\d+)(?:-(\d+))?(?:-(\d+))?', detail.jibun_address, re.IGNORECASE)
                    if jigu_match:
                        db_main = jigu_match.group(1).lstrip('0')
                        db_sub = jigu_match.group(2).lstrip('0') if jigu_match.group(2) else None
                    else:
                        # ì¼ë°˜ ì§€ë²ˆ íŒ¨í„´ (ë³¸ë²ˆ-ë¶€ë²ˆ-ë¶€ë¶€ë²ˆ í¬í•¨)
                        db_jibun_match = re.search(r'(\d+)(?:-(\d+))?(?:-(\d+))?(?:\s|$)', detail.jibun_address)
                        if not db_jibun_match:
                            continue
                        db_main = db_jibun_match.group(1).lstrip('0')
                        # ë¶€ë¶€ë²ˆì´ ìˆìœ¼ë©´ ë¶€ë²ˆë§Œ ì‚¬ìš© (ë¶€ë¶€ë²ˆì€ ë¬´ì‹œ)
                        db_sub = db_jibun_match.group(2).lstrip('0') if db_jibun_match.group(2) else None
            
            # ë³¸ë²ˆ ì¼ì¹˜ í™•ì¸
            if api_main == db_main:
                # ğŸ”‘ ê°œì„ : ë¶€ë²ˆ ë§¤ì¹­ ë¡œì§ ê°•í™”
                # 1. ë‘˜ ë‹¤ ë¶€ë²ˆì´ ì—†ìœ¼ë©´ ë§¤ì¹­
                # 2. ë‘˜ ë‹¤ ë¶€ë²ˆì´ ìˆê³  ê°™ìœ¼ë©´ ë§¤ì¹­
                # 3. APIì— ë¶€ë²ˆì´ ìˆê³  DBì— ë¶€ë²ˆì´ ì—†ìœ¼ë©´ ì¡°ê±´ë¶€ ë§¤ì¹­ (ìœ ì—°í•œ ë§¤ì¹­)
                if api_sub is None and db_sub is None:
                    # ë‘˜ ë‹¤ ë¶€ë²ˆì´ ì—†ìŒ â†’ ì •í™• ë§¤ì¹­
                    logger.debug(f"âœ… ì£¼ì†Œ+ì§€ë²ˆ ì •í™• ë§¤ì¹­ (ë³¸ë²ˆë§Œ): ë²•ì •ë™ì½”ë“œ={full_region_code}, ì§€ë²ˆ={jibun}, ì•„íŒŒíŠ¸={apt.apt_name}")
                    return apt
                elif api_sub is not None and db_sub is not None:
                    # ë‘˜ ë‹¤ ë¶€ë²ˆì´ ìˆìŒ â†’ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•¨
                    if api_sub == db_sub:
                        logger.debug(f"âœ… ì£¼ì†Œ+ì§€ë²ˆ ì •í™• ë§¤ì¹­ (ë³¸ë²ˆ+ë¶€ë²ˆ): ë²•ì •ë™ì½”ë“œ={full_region_code}, ì§€ë²ˆ={jibun}, ì•„íŒŒíŠ¸={apt.apt_name}")
                        return apt
                elif api_sub is not None and db_sub is None:
                    # ğŸ”‘ APIì— ë¶€ë²ˆì´ ìˆê³  DBì— ë¶€ë²ˆì´ ì—†ìŒ â†’ ì¡°ê±´ë¶€ ë§¤ì¹­
                    # ë³¸ë²ˆì´ ê¸¸ìˆ˜ë¡(4ìë¦¬ ì´ìƒ) ê³ ìœ ì„±ì´ ë†’ì•„ ë§¤ì¹­ í—ˆìš©
                    # ë˜ëŠ” ë³¸ë²ˆì´ ì§§ìœ¼ë©´(3ìë¦¬ ì´í•˜) ë¶€ë²ˆì´ ì—†ìœ¼ë©´ ë‹¤ë¥¸ ì•„íŒŒíŠ¸ì¼ ê°€ëŠ¥ì„± ë†’ìŒ
                    if len(api_main) >= 4:
                        # ë³¸ë²ˆì´ 4ìë¦¬ ì´ìƒì´ë©´ ê³ ìœ ì„±ì´ ë†’ì•„ ë¶€ë²ˆ ì—†ì–´ë„ ë§¤ì¹­ í—ˆìš©
                        logger.debug(f"âœ… ì£¼ì†Œ+ì§€ë²ˆ ìœ ì—° ë§¤ì¹­ (ë³¸ë²ˆ ê¸¸ì´ 4ìë¦¬ ì´ìƒ, DB ë¶€ë²ˆ ì—†ìŒ): ë²•ì •ë™ì½”ë“œ={full_region_code}, ì§€ë²ˆ={jibun}, ì•„íŒŒíŠ¸={apt.apt_name}")
                        return apt
                    # ë³¸ë²ˆì´ 3ìë¦¬ ì´í•˜ëŠ” ë¶€ë²ˆì´ ì—†ìœ¼ë©´ ë§¤ì¹­ ì•ˆ í•¨ (ë‹¤ë¥¸ ì•„íŒŒíŠ¸ì¼ ê°€ëŠ¥ì„±)
                elif api_sub is None and db_sub is not None:
                    # APIì— ë¶€ë²ˆì´ ì—†ê³  DBì— ë¶€ë²ˆì´ ìˆìŒ â†’ ì •í™• ë§¤ì¹­ (ë¶€ë²ˆ ì—†ëŠ” ê²ƒìœ¼ë¡œ ê°„ì£¼)
                    logger.debug(f"âœ… ì£¼ì†Œ+ì§€ë²ˆ ì •í™• ë§¤ì¹­ (API ë¶€ë²ˆ ì—†ìŒ, DB ë¶€ë²ˆ ìˆìŒ): ë²•ì •ë™ì½”ë“œ={full_region_code}, ì§€ë²ˆ={jibun}, ì•„íŒŒíŠ¸={apt.apt_name}")
                    return apt
        
        return None
    
    @staticmethod
    def convert_sgg_code_to_db_format(sgg_cd: str) -> Optional[str]:
        """5ìë¦¬ ì‹œêµ°êµ¬ ì½”ë“œë¥¼ 10ìë¦¬ DB í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        if not sgg_cd or len(sgg_cd) != 5:
            return None
        return f"{sgg_cd}00000"
    
    @staticmethod
    def normalize_dong_name(dong_name: str) -> str:
        """
        ë™ ì´ë¦„ ì •ê·œí™” (ì/ë©´/ë¦¬/ë™/ê°€ ì²˜ë¦¬)
        
        ì˜ˆì‹œ:
        - "ì˜ê´‘ì ë‹¨ì£¼ë¦¬" â†’ "ë‹¨ì£¼ë¦¬"
        - "ì‚¬ì§1ë™" â†’ "ì‚¬ì§"
        - "ì˜ë“±í¬ë™1ê°€" â†’ "ì˜ë“±í¬"
        """
        if not dong_name:
            return ""
        
        # ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ë§ˆì§€ë§‰ ë¶€ë¶„(ì‹¤ì œ ë™/ë¦¬ ì´ë¦„) ì¶”ì¶œ
        parts = dong_name.strip().split()
        if not parts:
            return ""
        
        # ë§ˆì§€ë§‰ ë¶€ë¶„ ì‚¬ìš© (ì˜ˆ: "ì˜ê´‘ì ë‹¨ì£¼ë¦¬" â†’ "ë‹¨ì£¼ë¦¬")
        last_part = parts[-1]
        
        # ìˆ«ì ì œê±° (ì˜ˆ: "ì‚¬ì§1ë™" â†’ "ì‚¬ì§ë™")
        normalized = re.sub(r'\d+', '', last_part)
        
        # ì/ë©´/ë¦¬/ë™/ê°€ ì œê±°
        normalized = normalized.replace("ì", "").replace("ë©´", "").replace("ë¦¬", "").replace("ë™", "").replace("ê°€", "").strip()
        
        return normalized
    
    @staticmethod
    def extract_dong_parts(dong_name: str) -> List[str]:
        """
        ë™ ì´ë¦„ì—ì„œ ê°€ëŠ¥í•œ ëª¨ë“  ë§¤ì¹­ í›„ë³´ ì¶”ì¶œ
        
        ì˜ˆì‹œ:
        - "ë´‰í™”ì ë‚´ì„±ë¦¬" â†’ ["ë‚´ì„±ë¦¬", "ë´‰í™”ì ë‚´ì„±ë¦¬", "ë´‰í™”ì", "ë‚´ì„±", "ë´‰í™”"]
        - "ì‚¬ì§1ë™" â†’ ["ì‚¬ì§1ë™", "ì‚¬ì§ë™", "ì‚¬ì§"]
        
        ìš°ì„ ìˆœìœ„: ë§ˆì§€ë§‰ ë¶€ë¶„(ì‹¤ì œ ë™/ë¦¬ ì´ë¦„)ì„ ê°€ì¥ ë¨¼ì € í™•ì¸
        """
        if not dong_name:
            return []
        
        candidates = []
        dong_name = dong_name.strip()
        
        # ê³µë°±ìœ¼ë¡œ ë¶„ë¦¬ëœ ê²½ìš° ê° ë¶€ë¶„ ì¶”ê°€
        parts = dong_name.split()
        if len(parts) > 1:
            # ë§ˆì§€ë§‰ ë¶€ë¶„ (ì‹¤ì œ ë™/ë¦¬ ì´ë¦„)ì„ ê°€ì¥ ë¨¼ì € ì¶”ê°€ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
            candidates.append(parts[-1])
            # ì›ë³¸ ì „ì²´
            candidates.append(dong_name)
            # ì²« ë²ˆì§¸ ë¶€ë¶„ (ì/ë©´ ì´ë¦„)
            candidates.append(parts[0])
        else:
            # ê³µë°±ì´ ì—†ëŠ” ê²½ìš° ì›ë³¸ë§Œ ì¶”ê°€
            candidates.append(dong_name)
        
        # ìˆ«ì ì œê±° ë²„ì „ë“¤ ì¶”ê°€
        for candidate in candidates[:]:
            # ìˆ«ì ì œê±°
            no_digit = re.sub(r'\d+', '', candidate)
            if no_digit != candidate and no_digit not in candidates:
                candidates.append(no_digit)
            
            # ì/ë©´/ë¦¬/ë™/ê°€ ì œê±°
            cleaned = no_digit.replace("ì", "").replace("ë©´", "").replace("ë¦¬", "").replace("ë™", "").replace("ê°€", "").strip()
            if cleaned and cleaned not in candidates:
                candidates.append(cleaned)
        
        # ì¤‘ë³µ ì œê±° ë° ë¹ˆ ë¬¸ìì—´ ì œê±° (ìˆœì„œ ìœ ì§€)
        result = []
        seen = set()
        for c in candidates:
            if c and c not in seen:
                result.append(c)
                seen.add(c)
        
        return result
    
    @staticmethod
    def extract_danji_number(name: str) -> Optional[int]:
        """
        ë‹¨ì§€ ë²ˆí˜¸ ì¶”ì¶œ (ì˜ˆ: '4ë‹¨ì§€' â†’ 4, '9ë‹¨ì§€' â†’ 9, '101ë™' â†’ 101)
        
        ë‹¤ì–‘í•œ íŒ¨í„´ ì§€ì›:
        - "4ë‹¨ì§€", "9ë‹¨ì§€" â†’ 4, 9
        - "ì œ4ë‹¨ì§€", "ì œ9ë‹¨ì§€" â†’ 4, 9
        - "101ë™", "102ë™" â†’ 101, 102 (ì£¼ì˜: ì¸µìˆ˜ì™€ êµ¬ë¶„ í•„ìš”)
        - "1ì°¨", "2ì°¨" â†’ 1, 2
        - "â… ", "â…¡" â†’ 1, 2
        """
        if not name:
            return None
        
        # ì •ê·œí™” (ê³µë°±, íŠ¹ìˆ˜ë¬¸ì ì œê±°)
        normalized = re.sub(r'\s+', '', name)
        
        # ë¡œë§ˆìˆ«ìë¥¼ ì•„ë¼ë¹„ì•„ ìˆ«ìë¡œ ë³€í™˜
        roman_map = {'â…°': '1', 'â…±': '2', 'â…²': '3', 'â…³': '4', 'â…´': '5', 
                     'â…µ': '6', 'â…¶': '7', 'â…·': '8', 'â…¸': '9', 'â…¹': '10',
                     'â… ': '1', 'â…¡': '2', 'â…¢': '3', 'â…£': '4', 'â…¤': '5',
                     'â…¥': '6', 'â…¦': '7', 'â…§': '8', 'â…¨': '9', 'â…©': '10'}
        for roman, arabic in roman_map.items():
            normalized = normalized.replace(roman, arabic)
        
        # ë‹¨ì§€ ë²ˆí˜¸ ì¶”ì¶œ íŒ¨í„´ë“¤ (ìš°ì„ ìˆœìœ„ìˆœ)
        patterns = [
            r'ì œ?(\d+)ë‹¨ì§€',      # "4ë‹¨ì§€", "ì œ4ë‹¨ì§€"
            r'(\d+)ì°¨',           # "1ì°¨", "2ì°¨" (ì°¨ìˆ˜)
            r'ì œ(\d+)ì°¨',         # "ì œ1ì°¨"
            r'(\d{3,})ë™',        # "101ë™", "102ë™" (3ìë¦¬ ì´ìƒ, ì¸µìˆ˜ êµ¬ë¶„)
        ]
        
        for pattern in patterns:
            match = re.search(pattern, normalized)
            if match:
                num = int(match.group(1))
                # ë™ ë²ˆí˜¸ëŠ” ë³´í†µ 100 ì´ìƒ (101ë™, 102ë™ ë“±)
                if 'ë™' in pattern and num < 100:
                    continue
                return num
        
        return None
    
    @staticmethod
    def extract_cha_number(name: str) -> Optional[int]:
        """
        ì°¨ìˆ˜ ì¶”ì¶œ (ì˜ˆ: '1ì°¨' â†’ 1, 'â…¡' â†’ 2)
        
        ë‹¤ì–‘í•œ íŒ¨í„´ ì§€ì›:
        - "1ì°¨", "2ì°¨" â†’ 1, 2
        - "ì œ1ì°¨", "ì œ2ì°¨" â†’ 1, 2
        - "â… ", "â…¡" â†’ 1, 2 (ë¡œë§ˆìˆ«ì)
        - ëì— ë¶™ì€ ìˆ«ì (1~20 ì‚¬ì´ë§Œ ì°¨ìˆ˜ë¡œ ê°„ì£¼)
        """
        if not name:
            return None
        
        normalized = re.sub(r'\s+', '', name)
        
        # ë¡œë§ˆìˆ«ìë¥¼ ì•„ë¼ë¹„ì•„ ìˆ«ìë¡œ ë³€í™˜
        roman_map = {'â…°': '1', 'â…±': '2', 'â…²': '3', 'â…³': '4', 'â…´': '5', 
                     'â…µ': '6', 'â…¶': '7', 'â…·': '8', 'â…¸': '9', 'â…¹': '10',
                     'â… ': '1', 'â…¡': '2', 'â…¢': '3', 'â…£': '4', 'â…¤': '5',
                     'â…¥': '6', 'â…¦': '7', 'â…§': '8', 'â…¨': '9', 'â…©': '10',
                     'i': '1', 'ii': '2', 'iii': '3', 'iv': '4', 'v': '5',
                     'vi': '6', 'vii': '7', 'viii': '8', 'ix': '9', 'x': '10'}
        # ì†Œë¬¸ì ë¡œë§ˆìˆ«ìë„ ì²˜ë¦¬
        normalized_lower = normalized.lower()
        for roman, arabic in roman_map.items():
            normalized_lower = normalized_lower.replace(roman, arabic)
        
        # ì°¨ìˆ˜ ì¶”ì¶œ íŒ¨í„´ë“¤
        patterns = [
            (normalized, r'ì œ?(\d+)ì°¨'),      # "1ì°¨", "ì œ1ì°¨"
            (normalized_lower, r'(\d+)ì°¨'),   # ì†Œë¬¸ì ë¡œë§ˆìˆ«ì ë³€í™˜ í›„
        ]
        
        for text, pattern in patterns:
            match = re.search(pattern, text)
            if match:
                return int(match.group(1))
        
        # ëì— ë¶™ì€ ìˆ«ì (1~20 ì‚¬ì´ë§Œ ì°¨ìˆ˜ë¡œ ê°„ì£¼, ê·¸ ì´ìƒì€ ë™ ë²ˆí˜¸ì¼ ê°€ëŠ¥ì„±)
        match = re.search(r'(\d+)$', normalized)
        if match:
            num = int(match.group(1))
            if 1 <= num <= 20:
                return num
        
        return None
    
    @staticmethod
    def extract_parentheses_content(name: str) -> Optional[str]:
        """
        ê´„í˜¸ ì•ˆì˜ ë‚´ìš© ì¶”ì¶œ
        
        ì˜ˆì‹œ:
        - "íš¨ìì´Œ(í˜„ëŒ€)" â†’ "í˜„ëŒ€"
        - "í›„ê³¡ë§ˆì„(ê±´ì˜15)" â†’ "ê±´ì˜15"
        - "í›„ê³¡ë§ˆì„(ë™ì•„10)" â†’ "ë™ì•„10"
        """
        if not name:
            return None
        
        # ë‹¤ì–‘í•œ ê´„í˜¸ í˜•íƒœì—ì„œ ë‚´ìš© ì¶”ì¶œ: (), [], {}, ã€ˆã€‰, ã€Šã€‹
        patterns = [
            r'\(([^)]+)\)',      # ()
            r'\[([^\]]+)\]',     # []
            r'\{([^}]+)\}',      # {}
            r'ã€ˆ([^ã€‰]+)ã€‰',      # ã€ˆã€‰
            r'ã€Š([^ã€‹]+)ã€‹',      # ã€Šã€‹
        ]
        
        for pattern in patterns:
            match = re.search(pattern, name)
            if match:
                return match.group(1).strip()
        
        return None
    
    @staticmethod
    def extract_brand_from_parentheses(name: str) -> Optional[str]:
        """
        ê´„í˜¸ ì•ˆì˜ ë¸Œëœë“œëª… ì¶”ì¶œ
        
        ì˜ˆì‹œ:
        - "íš¨ìì´Œ(í˜„ëŒ€)" â†’ "í˜„ëŒ€"
        - "í›„ê³¡ë§ˆì„(ê±´ì˜15)" â†’ "ê±´ì˜"
        - "í›„ê³¡ë§ˆì„(ë™ì•„10)" â†’ "ë™ì•„"
        """
        content = ApartmentMatcher.extract_parentheses_content(name)
        if not content:
            return None
        
        # ìˆ«ì ì œê±° í›„ ë¸Œëœë“œëª… ì¶”ì¶œ
        # "ê±´ì˜15" â†’ "ê±´ì˜", "ë™ì•„10" â†’ "ë™ì•„"
        normalized = re.sub(r'\d+', '', content).strip()
        
        # ì•Œë ¤ì§„ ë¸Œëœë“œëª…ì¸ì§€ í™•ì¸
        normalized_lower = normalized.lower()
        for brand in APARTMENT_BRANDS:
            brand_lower = brand.lower()
            if brand_lower in normalized_lower or normalized_lower in brand_lower:
                return brand_lower
        
        # ë¸Œëœë“œëª…ì´ ì•„ë‹ˆë©´ ê·¸ëƒ¥ ë°˜í™˜ (ì˜ˆ: "í˜„ëŒ€", "ëŒ€ìš°" ë“±)
        return normalized if normalized else None
    
    @staticmethod
    def extract_danji_from_parentheses(name: str) -> Optional[int]:
        """
        ê´„í˜¸ ì•ˆì˜ ë‹¨ì§€ ë²ˆí˜¸ ì¶”ì¶œ
        
        ì˜ˆì‹œ:
        - "í›„ê³¡ë§ˆì„(ê±´ì˜15)" â†’ 15
        - "í›„ê³¡ë§ˆì„(ë™ì•„10)" â†’ 10
        - "í›„ê³¡ë§ˆì„(íƒœì˜13)" â†’ 13
        """
        content = ApartmentMatcher.extract_parentheses_content(name)
        if not content:
            return None
        
        # ê´„í˜¸ ì•ˆì—ì„œ ìˆ«ì ì¶”ì¶œ
        # "ê±´ì˜15" â†’ 15, "ë™ì•„10" â†’ 10
        match = re.search(r'(\d+)', content)
        if match:
            num = int(match.group(1))
            # ë‹¨ì§€ ë²ˆí˜¸ëŠ” ë³´í†µ 1~99 ì‚¬ì´
            if 1 <= num <= 99:
                return num
        
        return None
    
    @staticmethod
    def extract_village_name(name: str) -> Optional[str]:
        """ë§ˆì„/ë‹¨ì§€ëª… ì¶”ì¶œ (ì˜ˆ: 'í•œë¹›ë§ˆì„4ë‹¨ì§€' â†’ 'í•œë¹›')"""
        if not name:
            return None
        
        normalized = re.sub(r'\s+', '', name).lower()
        
        # ë§ˆì„ëª… ì¶”ì¶œ íŒ¨í„´ë“¤
        for suffix in ['ë§ˆì„', 'ë‹¨ì§€']:
            pattern = rf'([ê°€-í£]+){suffix}'
            match = re.search(pattern, normalized)
            if match:
                village = match.group(1)
                # ìˆ«ì ì œê±° (ì˜ˆ: "í•œë¹›9" â†’ "í•œë¹›")
                village = re.sub(r'\d+', '', village)
                if len(village) >= 2:
                    return village
        
        return None
    
    @staticmethod
    def extract_all_brands(name: str) -> List[str]:
        """ì•„íŒŒíŠ¸ ì´ë¦„ì—ì„œ ëª¨ë“  ë¸Œëœë“œëª… ì¶”ì¶œ (ë³µìˆ˜ ê°€ëŠ¥)"""
        if not name:
            return []
        
        normalized = re.sub(r'\s+', '', name).lower()
        
        # ë¡œë§ˆìˆ«ì ë³€í™˜
        roman_map = {'â…°': '1', 'â…±': '2', 'â…²': '3', 'â…³': '4', 'â…´': '5', 
                     'â…µ': '6', 'â…¶': '7', 'â…·': '8', 'â…¸': '9', 'â…¹': '10',
                     'â… ': '1', 'â…¡': '2', 'â…¢': '3', 'â…£': '4', 'â…¤': '5',
                     'â…¥': '6', 'â…¦': '7', 'â…§': '8', 'â…¨': '9', 'â…©': '10'}
        for roman, arabic in roman_map.items():
            normalized = normalized.replace(roman, arabic)
        
        # eí¸í•œì„¸ìƒ í†µì¼
        normalized = normalized.replace('eí¸í•œì„¸ìƒ', 'ì´í¸í•œì„¸ìƒ')
        
        found_brands = []
        for brand in APARTMENT_BRANDS:
            brand_lower = brand.lower()
            if brand_lower in normalized:
                found_brands.append(brand_lower)
        
        # ì¤‘ë³µ ì œê±° ë° ê¸´ ë¸Œëœë“œ ìš°ì„  (ì˜ˆ: 'ë¡¯ë°ìºìŠ¬íŒŒí¬íƒ€ìš´'ì´ ìˆìœ¼ë©´ 'ë¡¯ë°ìºìŠ¬' ì œê±°)
        final_brands = []
        for brand in found_brands:
            is_subset = False
            for other in found_brands:
                if brand != other and brand in other:
                    is_subset = True
                    break
            if not is_subset:
                final_brands.append(brand)
        
        return final_brands
    
    @staticmethod
    def clean_apt_name(name: str) -> str:
        """
        ì•„íŒŒíŠ¸ ì´ë¦„ ì •ì œ (ê´„í˜¸ ë° ë¶€ê°€ ì •ë³´ ì œê±°, íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬)
        
        ì²˜ë¦¬ ë‚´ìš©:
        - ì…ì£¼ìëŒ€í‘œíšŒì˜, ê´€ë¦¬ì‚¬ë¬´ì†Œ ë“± ë¶€ê°€ ì •ë³´ ì œê±°
        - ê´„í˜¸ ë° ë‚´ìš© ì œê±°: (), [], {}
        - íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬: &, /, Â·, ~ ë“±
        """
        if not name:
            return ""
        
        # ì…ì£¼ìëŒ€í‘œíšŒì˜, ê´€ë¦¬ì‚¬ë¬´ì†Œ ë“± ë¶€ê°€ ì •ë³´ ì œê±°
        cleaned = re.sub(r'ì…ì£¼ìëŒ€í‘œíšŒì˜', '', name, flags=re.IGNORECASE)
        cleaned = re.sub(r'ê´€ë¦¬ì‚¬ë¬´ì†Œ', '', cleaned, flags=re.IGNORECASE)
        cleaned = re.sub(r'ì œ\d+ê´€ë¦¬ì‚¬ë¬´ì†Œ', '', cleaned)
        
        # ë‹¤ì–‘í•œ ê´„í˜¸ í˜•íƒœ ì œê±°: (), [], {}, ã€ˆã€‰, ã€Šã€‹
        cleaned = re.sub(r'[\(\[\{ã€ˆã€Š][^\)\]\}ã€‰ã€‹]*[\)\]\}ã€‰ã€‹]', '', cleaned)
        
        # & ê¸°í˜¸ë¥¼ ê³µë°±ìœ¼ë¡œ ë³€í™˜
        cleaned = cleaned.replace('&', ' ')
        
        # / ê¸°í˜¸ë¥¼ ê³µë°±ìœ¼ë¡œ ë³€í™˜ (ì˜ˆ: "íìŠ¤í…Œì´íŠ¸/íŒŒí¬" â†’ "íìŠ¤í…Œì´íŠ¸ íŒŒí¬")
        cleaned = cleaned.replace('/', ' ')
        
        # ì¤‘ê°„ì (Â·) ì œê±°
        cleaned = cleaned.replace('Â·', ' ')
        
        # ë¬¼ê²°í‘œ(~) ì œê±°
        cleaned = cleaned.replace('~', '')
        
        # ì—°ì†ëœ ê³µë°± ì œê±°
        cleaned = re.sub(r'\s+', ' ', cleaned)
        
        return cleaned.strip()
    
    @staticmethod
    def normalize_apt_name(name: str) -> str:
        """
        ì•„íŒŒíŠ¸ ì´ë¦„ ì •ê·œí™” (ëŒ€í•œë¯¼êµ­ ì•„íŒŒíŠ¸ íŠ¹ì„± ê³ ë ¤, ì˜ë¬¸â†”í•œê¸€ ë¸Œëœë“œëª… í†µì¼)
        
        ì •ê·œí™” ê·œì¹™:
        - ê³µë°± ì œê±°
        - ì˜ë¬¸ ì†Œë¬¸ì ë³€í™˜
        - ë¡œë§ˆìˆ«ì â†’ ì•„ë¼ë¹„ì•„ ìˆ«ì
        - ì˜ë¬¸ ë¸Œëœë“œëª… â†’ í•œê¸€ í†µì¼
        - ì¼ë°˜ì ì¸ ì˜¤íƒ€ íŒ¨í„´ ì •ê·œí™”
        - íŠ¹ìˆ˜ë¬¸ì ì œê±°
        """
        if not name:
            return ""
        
        # ê³µë°± ì œê±°
        normalized = re.sub(r'\s+', '', name)
        
        # ì˜ë¬¸ ëŒ€ì†Œë¬¸ì í†µì¼ (ì†Œë¬¸ìë¡œ ë³€í™˜)
        normalized = normalized.lower()
        
        # ë¡œë§ˆìˆ«ìë¥¼ ì•„ë¼ë¹„ì•„ ìˆ«ìë¡œ ë³€í™˜
        roman_map = {'â…°': '1', 'â…±': '2', 'â…²': '3', 'â…³': '4', 'â…´': '5', 
                     'â…µ': '6', 'â…¶': '7', 'â…·': '8', 'â…¸': '9', 'â…¹': '10',
                     'â… ': '1', 'â…¡': '2', 'â…¢': '3', 'â…£': '4', 'â…¤': '5',
                     'â…¥': '6', 'â…¦': '7', 'â…§': '8', 'â…¨': '9', 'â…©': '10'}
        for roman, arabic in roman_map.items():
            normalized = normalized.replace(roman, arabic)
        
        # ğŸ”‘ í•˜ì´í”ˆ/ëŒ€ì‹œ ì œê±°ë¥¼ ë¸Œëœë“œ ë³€í™˜ ì „ì— ìˆ˜í–‰ (e-í¸í•œì„¸ìƒ â†’ eí¸í•œì„¸ìƒ)
        normalized = re.sub(r'[-â€“â€”]', '', normalized)
        
        # ì˜ë¬¸ ë¸Œëœë“œëª… â†’ í•œê¸€ë¡œ í†µì¼ (ê¸´ ê²ƒë¶€í„° ë¨¼ì € ì¹˜í™˜)
        sorted_brands = sorted(BRAND_ENG_TO_KOR.items(), key=lambda x: len(x[0]), reverse=True)
        for eng, kor in sorted_brands:
            normalized = normalized.replace(eng, kor)
        
        # ì¼ë°˜ì ì¸ ì˜¤íƒ€ íŒ¨í„´ ì •ê·œí™” (í•œê¸€)
        typo_map = {
            'íìŠ¤í…Œì‡': 'íìŠ¤í…Œì´íŠ¸',
            'í…Œì‡': 'í…Œì´íŠ¸',
            'ì¼€ìŠ¬': 'ìºìŠ¬',
            'ì¨ë°‹': 'ì„œë°‹',
            'ì¨ë¯¸íŠ¸': 'ì„œë°‹',
            'ë ˆë¯¸ì•ˆ': 'ë˜ë¯¸ì•ˆ',  # ì‹¤ì œë¡œëŠ” ë˜ë¯¸ì•ˆì´ ë§ì§€ë§Œ, ë ˆë¯¸ì•ˆìœ¼ë¡œ ì“°ëŠ” ê²½ìš°ê°€ ë§ìŒ
            'í‘¸ë¥´ì§€ì˜¤': 'í‘¸ë¥´ì§€ì˜¤',  # ì‹¤ì œ ë¸Œëœë“œëª…
            'í‘¸ë¥´ì§€ì›€': 'í‘¸ë¥´ì§€ì˜¤',
            'ìì´': 'ìì´',  # ì‹¤ì œ ë¸Œëœë“œëª…
            'ìŸˆì´': 'ìì´',
            'ì‰ë¥´ë¹Œ': 'ì…°ë¥´ë¹Œ',
            'ì‰ë¥´ë¹Œ': 'ì‰ë¥´ë¹Œ',
        }
        for typo, correct in typo_map.items():
            normalized = normalized.replace(typo, correct)
        
        # ì•„í¬ìŠ¤íŠ¸ë¡œí”¼ ì œê±°
        normalized = re.sub(r"[''`]", '', normalized)
        
        # íŠ¹ìˆ˜ë¬¸ì ì œê±° (í•œê¸€, ì˜ë¬¸, ìˆ«ìë§Œ ìœ ì§€)
        normalized = re.sub(r'[^\wê°€-í£]', '', normalized)
        
        return normalized
    
    @staticmethod
    def normalize_apt_name_strict(name: str) -> str:
        """
        ì•„íŒŒíŠ¸ ì´ë¦„ ì—„ê²© ì •ê·œí™” (ì°¨ìˆ˜/ë‹¨ì§€ ë²ˆí˜¸ ì œê±°, ë‹¤ì–‘í•œ ì ‘ë¯¸ì‚¬ ì²˜ë¦¬)
        
        ì²˜ë¦¬ ë‚´ìš©:
        - ì°¨ìˆ˜/ë‹¨ì§€ ë²ˆí˜¸ ì œê±°
        - ë‹¤ì–‘í•œ ì•„íŒŒíŠ¸ ì ‘ë¯¸ì‚¬ ì œê±°: ì•„íŒŒíŠ¸, APT, ë¹Œë¼, ë¹Œ, íƒ€ìš´, í•˜ìš°ìŠ¤ ë“±
        """
        if not name:
            return ""
        
        normalized = ApartmentMatcher.normalize_apt_name(name)
        
        # ì°¨ìˆ˜/ë‹¨ì§€ í‘œê¸° ì œê±°
        normalized = re.sub(r'ì œ?\d+ì°¨', '', normalized)
        normalized = re.sub(r'ì œ?\d+ë‹¨ì§€', '', normalized)
        normalized = re.sub(r'\d{3,}ë™', '', normalized)  # 101ë™, 102ë™ ë“±
        
        # ëì— ë¶™ì€ ìˆ«ì ì œê±° (ì˜ˆ: "ì‚¼ì„±1" â†’ "ì‚¼ì„±", ë‹¨ 1~2ìë¦¬ë§Œ)
        normalized = re.sub(r'\d{1,2}$', '', normalized)
        
        # ë‹¤ì–‘í•œ ì•„íŒŒíŠ¸ ì ‘ë¯¸ì‚¬ ì œê±° (ëŒ€ì†Œë¬¸ì ë¬´ê´€)
        suffixes = [
            'apartment', 'apt', 'apts',
            'ì•„íŒŒíŠ¸', 'ì•„íŒŒì•„íŠ¸',  # ì˜¤íƒ€ í¬í•¨
            'ë¹Œë¼', 'ë¹Œ', 'ë¹Œë¦¬ì§€',
            'íƒ€ìš´', 'town',
            'í•˜ìš°ìŠ¤', 'house',
            'ë§¨ì…˜', 'mansion',
            'ìºìŠ¬', 'castle',
            'ë¹Œë”©', 'building',
            'ì˜¤í”¼ìŠ¤í…”', 'officetel',
        ]
        
        for suffix in suffixes:
            # ëì— ìˆëŠ” ê²½ìš°ë§Œ ì œê±°
            if normalized.endswith(suffix):
                normalized = normalized[:-len(suffix)]
        
        return normalized
    
    @staticmethod
    def extract_brand_and_name(name: str) -> Tuple[Optional[str], str]:
        """ì•„íŒŒíŠ¸ ì´ë¦„ì—ì„œ ë¸Œëœë“œëª…ê³¼ ë‚˜ë¨¸ì§€ ë¶€ë¶„ ì¶”ì¶œ"""
        if not name:
            return None, ""
        
        normalized = ApartmentMatcher.normalize_apt_name(name)
        
        # ë¸Œëœë“œëª… ì°¾ê¸° (ê¸´ ê²ƒë¶€í„° ë§¤ì¹­)
        sorted_brands = sorted(APARTMENT_BRANDS, key=len, reverse=True)
        for brand in sorted_brands:
            brand_lower = brand.lower()
            if brand_lower in normalized:
                # ë¸Œëœë“œëª… ì œê±°í•œ ë‚˜ë¨¸ì§€ ë°˜í™˜
                remaining = normalized.replace(brand_lower, '', 1)
                return brand, remaining
        
        return None, normalized
    
    @staticmethod
    def calculate_similarity(str1: str, str2: str) -> float:
        """ë‘ ë¬¸ìì—´ ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚° (0.0 ~ 1.0)"""
        if not str1 or not str2:
            return 0.0
        return SequenceMatcher(None, str1, str2).ratio()
    
    @staticmethod
    def extract_core_name(name: str) -> str:
        """í•µì‹¬ ì´ë¦„ ì¶”ì¶œ (ì§€ì—­ëª…, ë§ˆì„ëª… ë“± ì œê±°)"""
        if not name:
            return ""
        
        normalized = ApartmentMatcher.normalize_apt_name_strict(name)
        
        # ë§ˆì„/ë‹¨ì§€ ì ‘ë¯¸ì‚¬ì™€ ê·¸ ì•ì˜ ì§€ì—­ëª… ì œê±° ì‹œë„
        for suffix in VILLAGE_SUFFIXES:
            if suffix in normalized:
                # suffix ì´í›„ ë¶€ë¶„ë§Œ ì¶”ì¶œ (ë¸Œëœë“œëª…ì´ ë³´í†µ ë’¤ì— ì˜´)
                idx = normalized.find(suffix)
                after_suffix = normalized[idx + len(suffix):]
                if len(after_suffix) >= 2:
                    return after_suffix
        
        return normalized
    
    @staticmethod
    def find_matching_regions(umd_nm: str, all_regions: Dict[int, Any]) -> set:
        """
        ë™ ì´ë¦„ìœ¼ë¡œ ë§¤ì¹­ë˜ëŠ” ì§€ì—­ ID ì°¾ê¸° (ì/ë©´/ë¦¬/ë™ ë§¤ì¹­ ê°•í™”)
        
        ë§¤ì¹­ ì „ëµ:
        1. ì›ë³¸ ë¬¸ìì—´ ì •í™• ë§¤ì¹­
        2. í›„ë³´ ì¶”ì¶œ ë° ì •í™• ë§¤ì¹­ (ì˜ˆ: "ë´‰í™”ì ë‚´ì„±ë¦¬" â†’ "ë‚´ì„±ë¦¬" ë§¤ì¹­)
        3. ì •ê·œí™”ëœ ì´ë¦„ ì •í™• ë§¤ì¹­
        4. ë¶€ë¶„ ë¬¸ìì—´ í¬í•¨ ê´€ê³„ í™•ì¸ (ì–‘ë°©í–¥, ë” ë„ë„í•˜ê²Œ)
        5. ì •ê·œí™”ëœ ì´ë¦„ í¬í•¨ ê´€ê³„ í™•ì¸
        """
        if not umd_nm:
            return set()
        
        matching_region_ids = set()
        
        # ë§¤ì¹­ í›„ë³´ ì¶”ì¶œ (ì˜ˆ: "ë´‰í™”ì ë‚´ì„±ë¦¬" â†’ ["ë´‰í™”ì ë‚´ì„±ë¦¬", "ë‚´ì„±ë¦¬", "ë´‰í™”ì", "ë‚´ì„±", "ë´‰í™”"])
        umd_candidates = ApartmentMatcher.extract_dong_parts(umd_nm)
        
        # ì •ê·œí™”ëœ í›„ë³´ë„ ì¶”ê°€
        normalized_umd = ApartmentMatcher.normalize_dong_name(umd_nm)
        if normalized_umd and normalized_umd not in umd_candidates:
            umd_candidates.append(normalized_umd)
        
        for region_id, region in all_regions.items():
            region_name = region.region_name
            normalized_region = ApartmentMatcher.normalize_dong_name(region_name)
            
            # 1ë‹¨ê³„: ì›ë³¸ ë¬¸ìì—´ ì •í™• ë§¤ì¹­
            if region_name == umd_nm:
                matching_region_ids.add(region_id)
                continue
            
            # 2ë‹¨ê³„: í›„ë³´ ì¶”ì¶œëœ ì´ë¦„ ì •í™• ë§¤ì¹­ (ê°€ì¥ ì¤‘ìš”!)
            # ì˜ˆ: "ë´‰í™”ì ë‚´ì„±ë¦¬"ì˜ í›„ë³´ "ë‚´ì„±ë¦¬"ì™€ DBì˜ "ë‚´ì„±ë¦¬" ë§¤ì¹­
            for umd_candidate in umd_candidates:
                if region_name == umd_candidate:
                    matching_region_ids.add(region_id)
                    break
            
            if region_id in matching_region_ids:
                continue
            
            # 3ë‹¨ê³„: ì •ê·œí™”ëœ ì´ë¦„ ì •í™• ë§¤ì¹­
            if normalized_umd and normalized_region:
                if normalized_region == normalized_umd:
                    matching_region_ids.add(region_id)
                    continue
                
                # í›„ë³´ë“¤ì˜ ì •ê·œí™” ë²„ì „ë„ í™•ì¸
                for umd_candidate in umd_candidates:
                    normalized_candidate = ApartmentMatcher.normalize_dong_name(umd_candidate)
                    if normalized_region == normalized_candidate and normalized_region:
                        matching_region_ids.add(region_id)
                        break
            
            if region_id in matching_region_ids:
                continue
            
            # 4ë‹¨ê³„: ë¶€ë¶„ ë¬¸ìì—´ í¬í•¨ ê´€ê³„ í™•ì¸ (ì–‘ë°©í–¥, ë” ë„ë„í•˜ê²Œ)
            # ì›ë³¸ ë¬¸ìì—´ í¬í•¨ ê´€ê³„
            if umd_nm in region_name or region_name in umd_nm:
                matching_region_ids.add(region_id)
                continue
            
            # í›„ë³´ë“¤ë¡œ í¬í•¨ ê´€ê³„ í™•ì¸ (ë” ë„ë„í•˜ê²Œ)
            for umd_candidate in umd_candidates:
                # í›„ë³´ê°€ region_nameì— í¬í•¨ë˜ê±°ë‚˜, region_nameì´ í›„ë³´ì— í¬í•¨ë˜ëŠ”ì§€ í™•ì¸
                if umd_candidate in region_name or region_name in umd_candidate:
                    matching_region_ids.add(region_id)
                    break
            
            if region_id in matching_region_ids:
                continue
            
            # 5ë‹¨ê³„: ì •ê·œí™”ëœ ì´ë¦„ í¬í•¨ ê´€ê³„ í™•ì¸
            if normalized_umd and normalized_region:
                if normalized_umd in normalized_region or normalized_region in normalized_umd:
                    matching_region_ids.add(region_id)
        
        return matching_region_ids
    
    @staticmethod
    def match_apartment(
        apt_name_api: str,
        candidates: List[Apartment],
        sgg_cd: str,
        umd_nm: Optional[str] = None,
        jibun: Optional[str] = None,
        build_year: Optional[str] = None,
        apt_details: Optional[Dict[int, ApartDetail]] = None,
        normalized_cache: Optional[Dict[str, Any]] = None,
        all_regions: Optional[Dict[int, Any]] = None,
        require_dong_match: bool = True  # ğŸ”‘ ê¸°ë³¸ê°’ì„ Trueë¡œ ë³€ê²½ (ë™ ê²€ì¦ ê¸°ë³¸ í™œì„±í™”)
    ) -> Optional[Apartment]:
        """
        ì•„íŒŒíŠ¸ ë§¤ì¹­ (í•œêµ­ ì•„íŒŒíŠ¸ íŠ¹ì„±ì— ìµœì í™”ëœ ê°•í™” ë²„ì „)

        ì§€ì—­ê³¼ ë²•ì •ë™ì´ ì¼ì¹˜í•œë‹¤ëŠ” ê°€ì • í•˜ì— ë‹¤ë‹¨ê³„ ë§¤ì¹­ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        í•µì‹¬ ë§¤ì¹­ ì „ëµ:
        1. ì •ê·œí™”ëœ ì´ë¦„ ì •í™• ë§¤ì¹­
        2. ë¸Œëœë“œëª… + ë‹¨ì§€ë²ˆí˜¸ ë³µí•© ë§¤ì¹­ (ê°€ì¥ ì¤‘ìš”!)
        3. ë¸Œëœë“œëª… + ë§ˆì„ëª… ë³µí•© ë§¤ì¹­
        4. ì§€ë²ˆ ê¸°ë°˜ ë§¤ì¹­ (NEW!)
        5. ê±´ì¶•ë…„ë„ ê¸°ë°˜ ë§¤ì¹­ (NEW!)
        6. ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­ (SequenceMatcher)
        7. í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤ì¹­

        ì˜ˆì‹œ:
        - "í•œë¹›ë§ˆì„4ë‹¨ì§€ë¡¯ë°ìºìŠ¬â…¡" â†” "ë¡¯ë°ìºìŠ¬ íŒŒí¬íƒ€ìš´ â…¡" (ë¸Œëœë“œ+ë‹¨ì§€ë²ˆí˜¸ ë¬´ì‹œ, ê°™ì€ ë™)
        - "í•œë¹›9ë‹¨ì§€ ë¡¯ë°ìºìŠ¬íŒŒí¬íƒ€ìš´" â†” "í•œë¹›ë§ˆì„9ë‹¨ì§€ë¡¯ë°ìºìŠ¬1ì°¨" (ë¸Œëœë“œ+ë‹¨ì§€ë²ˆí˜¸)

        Args:
            apt_name_api: APIì—ì„œ ë°›ì€ ì•„íŒŒíŠ¸ ì´ë¦„
            candidates: í›„ë³´ ì•„íŒŒíŠ¸ ë¦¬ìŠ¤íŠ¸
            sgg_cd: 5ìë¦¬ ì‹œêµ°êµ¬ ì½”ë“œ
            umd_nm: ë™ ì´ë¦„ (ì„ íƒ)
            jibun: API ì§€ë²ˆ (ì„ íƒ)
            build_year: API ê±´ì¶•ë…„ë„ (ì„ íƒ)
            apt_details: ì•„íŒŒíŠ¸ ìƒì„¸ ì •ë³´ ë”•ì…”ë„ˆë¦¬ (ì„ íƒ)
            normalized_cache: ì •ê·œí™” ê²°ê³¼ ìºì‹œ (ì„±ëŠ¥ ìµœì í™”)
            all_regions: ì§€ì—­ ì •ë³´ ë”•ì…”ë„ˆë¦¬ - ë™ ê²€ì¦ìš© (ì„ íƒ)
            require_dong_match: Trueë©´ ë™ ì¼ì¹˜ ê²€ì¦ í•„ìˆ˜ (ê¸°ë³¸ê°’: True, ë™ ê²€ì¦ ê¸°ë³¸ í™œì„±í™”)

        Returns:
            ë§¤ì¹­ëœ Apartment ê°ì²´ ë˜ëŠ” None
        """
        if not apt_name_api or not candidates:
            return None
        
        # ì •ê·œí™” ê²°ê³¼ ìºì‹± (ì„±ëŠ¥ ìµœì í™”)
        if normalized_cache is None:
            normalized_cache = {}
        
        # API ì´ë¦„ ë¶„ì„ (ìºì‹±)
        cache_key_api = f"api:{apt_name_api}"
        if cache_key_api not in normalized_cache:
            cleaned_api = ApartmentMatcher.clean_apt_name(apt_name_api)
            normalized_api = ApartmentMatcher.normalize_apt_name(cleaned_api)
            normalized_strict_api = ApartmentMatcher.normalize_apt_name_strict(cleaned_api)
            brands_api = ApartmentMatcher.extract_all_brands(apt_name_api)
            danji_api = ApartmentMatcher.extract_danji_number(apt_name_api)
            cha_api = ApartmentMatcher.extract_cha_number(apt_name_api)
            village_api = ApartmentMatcher.extract_village_name(apt_name_api)
            core_api = ApartmentMatcher.extract_core_name(cleaned_api)
            # ê´„í˜¸ ì•ˆì˜ ë¸Œëœë“œëª…ê³¼ ë‹¨ì§€ ë²ˆí˜¸ ì¶”ì¶œ
            brand_in_parens_api = ApartmentMatcher.extract_brand_from_parentheses(apt_name_api)
            danji_in_parens_api = ApartmentMatcher.extract_danji_from_parentheses(apt_name_api)
            normalized_cache[cache_key_api] = {
                'cleaned': cleaned_api,
                'normalized': normalized_api,
                'strict': normalized_strict_api,
                'brands': brands_api,
                'danji': danji_api,
                'cha': cha_api,
                'village': village_api,
                'core': core_api,
                'brand_in_parens': brand_in_parens_api,
                'danji_in_parens': danji_in_parens_api
            }
        api_cache = normalized_cache[cache_key_api]
        
        if not api_cache['cleaned'] or not api_cache['normalized']:
            return None
        
        # API ì´ë¦„ì´ ì§€ë²ˆë§Œ ìˆëŠ”ì§€ í™•ì¸ (ì˜ˆ: "(1101-1)", "(627-41)")
        # í•œê¸€ ì—†ì´ ìˆ«ìì™€ íŠ¹ìˆ˜ë¬¸ìë§Œ ìˆìœ¼ë©´ ì§€ë²ˆìœ¼ë¡œ ê°„ì£¼
        api_is_jibun_only = not re.search(r'[ê°€-í£a-zA-Z]', api_cache['cleaned'])
        
        # í›„ë³´ ì•„íŒŒíŠ¸ ì •ê·œí™” ë° ì ìˆ˜ ê³„ì‚°
        best_match = None
        best_score = 0.0
        
        for apt in candidates:
            cache_key_db = f"db:{apt.apt_name}"
            if cache_key_db not in normalized_cache:
                cleaned_db = ApartmentMatcher.clean_apt_name(apt.apt_name)
                normalized_db = ApartmentMatcher.normalize_apt_name(cleaned_db)
                normalized_strict_db = ApartmentMatcher.normalize_apt_name_strict(cleaned_db)
                brands_db = ApartmentMatcher.extract_all_brands(apt.apt_name)
                danji_db = ApartmentMatcher.extract_danji_number(apt.apt_name)
                cha_db = ApartmentMatcher.extract_cha_number(apt.apt_name)
                village_db = ApartmentMatcher.extract_village_name(apt.apt_name)
                core_db = ApartmentMatcher.extract_core_name(cleaned_db)
                # ê´„í˜¸ ì•ˆì˜ ë¸Œëœë“œëª…ê³¼ ë‹¨ì§€ ë²ˆí˜¸ ì¶”ì¶œ
                brand_in_parens_db = ApartmentMatcher.extract_brand_from_parentheses(apt.apt_name)
                danji_in_parens_db = ApartmentMatcher.extract_danji_from_parentheses(apt.apt_name)
                normalized_cache[cache_key_db] = {
                    'cleaned': cleaned_db,
                    'normalized': normalized_db,
                    'strict': normalized_strict_db,
                    'brands': brands_db,
                    'danji': danji_db,
                    'cha': cha_db,
                    'village': village_db,
                    'core': core_db,
                    'brand_in_parens': brand_in_parens_db,
                    'danji_in_parens': danji_in_parens_db
                }
            db_cache = normalized_cache[cache_key_db]
            
            score = 0.0
            
            # === 0ë‹¨ê³„: ë‹¨ì§€ ë²ˆí˜¸ í•„í„°ë§ (ì¤‘ìš”!) ===
            # API ì´ë¦„ì— ë‹¨ì§€ ë²ˆí˜¸ê°€ ìˆìœ¼ë©´, ë‹¨ì§€ ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” í›„ë³´ëŠ” ì œì™¸
            api_danji = api_cache['danji']
            api_cha = api_cache['cha']
            db_danji = db_cache['danji']
            db_cha = db_cache['cha']
            
            # ğŸ”‘ ì´ë¦„ ì •í™• ë§¤ì¹­ ìš°ì„  ê²€ì‚¬ (ê±´ì¶•ë…„ë„ Veto ì „ì—!)
            # ì´ë¦„ì´ ì •í™•íˆ ì¼ì¹˜í•˜ë©´ ê±´ì¶•ë…„ë„ ì°¨ì´ì™€ ìƒê´€ì—†ì´ ë°”ë¡œ ë°˜í™˜
            if api_cache['normalized'] == db_cache['normalized']:
                return apt  # ì •í™• ë§¤ì¹­ì€ ë°”ë¡œ ë°˜í™˜
            
            # ê±´ì¶•ë…„ë„ Veto ê²€ì‚¬
            if build_year and apt_details and apt.apt_id in apt_details:
                detail = apt_details[apt.apt_id]
                if detail.use_approval_date:
                    try:
                        approval_year = detail.use_approval_date.split('-')[0]
                        year_diff = abs(int(build_year) - int(approval_year))
                        
                        # ğŸš« VETO: ê±´ì¶•ë…„ë„ 3ë…„ ì´ˆê³¼ ì°¨ì´ â†’ ì¦‰ì‹œ ì œì™¸
                        # (ë‹¨, ì´ë¦„ ì •í™• ë§¤ì¹­ì€ ìœ„ì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë¨)
                        if year_diff > BUILD_YEAR_TOLERANCE:
                            continue  # ë‹¤ë¥¸ ì•„íŒŒíŠ¸ì¼ ê°€ëŠ¥ì„± ë†’ìŒ
                    except (ValueError, AttributeError):
                        pass
            
            # === 0.5ë‹¨ê³„: ê´„í˜¸ ì•ˆì˜ ë¸Œëœë“œëª…ê³¼ ë‹¨ì§€ ë²ˆí˜¸ í•„í„°ë§ (ì¤‘ìš”!) ===
            brand_in_parens_api = api_cache.get('brand_in_parens')
            danji_in_parens_api = api_cache.get('danji_in_parens')
            brand_in_parens_db = db_cache.get('brand_in_parens')
            danji_in_parens_db = db_cache.get('danji_in_parens')
            
            # APIì— ê´„í˜¸ ì•ˆì˜ ë¸Œëœë“œëª…ì´ ìˆìœ¼ë©´, DBì—ë„ ê°™ì€ ë¸Œëœë“œëª…ì´ ìˆì–´ì•¼ í•¨
            # ë‹¨, ê´„í˜¸ ì•ˆ ë‚´ìš©ì´ DB ì•„íŒŒíŠ¸ëª…ì— í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ì§„í–‰ (ì‹¤ì œ ì•„íŒŒíŠ¸ëª…ì¸ ê²½ìš°)
            if brand_in_parens_api:
                if brand_in_parens_db:
                    # ë‘˜ ë‹¤ ê´„í˜¸ ì•ˆì— ë¸Œëœë“œëª…ì´ ìˆìœ¼ë©´ ì¼ì¹˜í•´ì•¼ í•¨
                    if brand_in_parens_api.lower() != brand_in_parens_db.lower():
                        # ê´„í˜¸ ì•ˆì˜ ë¸Œëœë“œëª…ì´ ë‹¤ë¥´ë©´ ì œì™¸ (ì˜ˆ: "íš¨ìì´Œ(í˜„ëŒ€)" vs "íš¨ìì´Œ(ëŒ€ìš°)")
                        continue
                else:
                    # APIì—ëŠ” ê´„í˜¸ ì•ˆ ë¸Œëœë“œëª…ì´ ìˆì§€ë§Œ DBì—ëŠ” ì—†ëŠ” ê²½ìš°
                    # ê´„í˜¸ ì•ˆ ì›ë³¸ ë‚´ìš©ì´ DB ì•„íŒŒíŠ¸ëª…ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
                    # (ì˜ˆ: "íŒêµì›ë§ˆì„6ë‹¨ì§€(íŒêµëŒ€ê´‘ë¡œì œë¹„ì•™)" vs "íŒêµëŒ€ê´‘ë¡œì œë¹„ì•™ì•„íŒŒíŠ¸")
                    
                    # ì›ë³¸ ê´„í˜¸ ë‚´ìš© ê°€ì ¸ì˜¤ê¸° (ë¸Œëœë“œ ì¶”ì¶œ ì „)
                    original_parens = ApartmentMatcher.extract_parentheses_content(apt_name_api) or ""
                    original_parens_lower = original_parens.lower()
                    parens_content_lower = brand_in_parens_api.lower()
                    
                    db_name_lower = db_cache['normalized'].lower()
                    db_cleaned_lower = db_cache['cleaned'].lower() if db_cache.get('cleaned') else ''
                    apt_name_db = apt.apt_name.lower()
                    
                    # 1. ì›ë³¸ ê´„í˜¸ ë‚´ìš©ì´ DB ì•„íŒŒíŠ¸ëª…ì— í¬í•¨
                    # (ì˜ˆ: "íŒêµëŒ€ê´‘ë¡œì œë¹„ì•™" in "íŒêµëŒ€ê´‘ë¡œì œë¹„ì•™ì•„íŒŒíŠ¸")
                    if original_parens_lower and (
                        original_parens_lower in db_name_lower or 
                        original_parens_lower in db_cleaned_lower or
                        original_parens_lower in apt_name_db
                    ):
                        pass  # ì§„í–‰ - ê´„í˜¸ ì•ˆ ë‚´ìš©ì´ ì‹¤ì œ ì•„íŒŒíŠ¸ëª…
                    # 2. ì¶”ì¶œëœ ë¸Œëœë“œëª…ì´ DB ì•„íŒŒíŠ¸ëª…ì— í¬í•¨
                    elif parens_content_lower in db_name_lower or parens_content_lower in db_cleaned_lower:
                        pass  # ì§„í–‰
                    # 3. DB ì•„íŒŒíŠ¸ëª…ì´ ê´„í˜¸ ë‚´ìš©ì— í¬í•¨ (ì—­ë°©í–¥)
                    elif db_name_lower in original_parens_lower or db_name_lower in parens_content_lower:
                        pass  # ì§„í–‰ (ì—­ë°©í–¥ í¬í•¨)
                    else:
                        # ë¸Œëœë“œ ì‚¬ì „ì— ìˆëŠ” ë¸Œëœë“œì¸ë° DBì— ì—†ìœ¼ë©´ ì œì™¸
                        # (ì˜ˆ: "íš¨ìì´Œ(í˜„ëŒ€)" vs "íš¨ìì´Œ" - ë‹¤ë¥¸ ì•„íŒŒíŠ¸)
                        if brand_in_parens_api.lower() in [b.lower() for b in APARTMENT_BRANDS]:
                            continue
            
            # === ë‹¨ì§€ ë²ˆí˜¸ í†µí•© ë¹„êµ ===
            # APIì™€ DBì˜ ë‹¨ì§€ ë²ˆí˜¸ë¥¼ í†µí•©í•˜ì—¬ ë¹„êµ (ì¼ë°˜ ë‹¨ì§€ ë²ˆí˜¸ + ê´„í˜¸ ì•ˆ ë‹¨ì§€ ë²ˆí˜¸)
            api_danji_final = api_danji if api_danji is not None else danji_in_parens_api
            db_danji_final = db_danji if db_danji is not None else danji_in_parens_db
            
            # APIì— ê´„í˜¸ ì•ˆì˜ ë‹¨ì§€ ë²ˆí˜¸ê°€ ìˆìœ¼ë©´, DBì—ë„ ê°™ì€ ë‹¨ì§€ ë²ˆí˜¸ê°€ ìˆì–´ì•¼ í•¨
            if danji_in_parens_api is not None:
                if danji_in_parens_db is not None:
                    if danji_in_parens_api != danji_in_parens_db:
                        # ê´„í˜¸ ì•ˆì˜ ë‹¨ì§€ ë²ˆí˜¸ê°€ ë‹¤ë¥´ë©´ ì œì™¸ (ì˜ˆ: "í›„ê³¡ë§ˆì„10ë‹¨ì§€" vs "í›„ê³¡ë§ˆì„(ê±´ì˜15)")
                        continue
            
            # APIì— ë‹¨ì§€ ë²ˆí˜¸ë‚˜ ì°¨ìˆ˜ê°€ ìˆìœ¼ë©´ ë¹„êµ
            # ğŸ”‘ í•µì‹¬ ë¡œì§ ê°•í™”: ë‹¨ì§€ ë²ˆí˜¸/ì°¨ìˆ˜ ë¶ˆì¼ì¹˜ ì‹œ ë¬´ì¡°ê±´ ì œì™¸
            # - DBì— ë‹¨ì§€ ë²ˆí˜¸ê°€ "ë‹¤ë¥´ë©´" ì œì™¸ (7ë‹¨ì§€ â†’ 4ë‹¨ì§€ X)
            # - ì§€ë²ˆ/ê±´ì¶•ë…„ë„ ì¼ì¹˜í•´ë„ ë‹¨ì§€ ë²ˆí˜¸ê°€ ë‹¤ë¥´ë©´ ì œì™¸ (ë§¤ì¹­ ë¶„ì„ ê²°ê³¼ ë°˜ì˜)
            # - DBì— ë‹¨ì§€ ë²ˆí˜¸ê°€ "ì—†ìœ¼ë©´" ì¡°ê±´ë¶€ í—ˆìš©:
            #   - ê´„í˜¸ ì•ˆ ë¸Œëœë“œëª…ì´ ìˆìœ¼ë©´ ì œì™¸ (í›„ê³¡ë§ˆì„10ë‹¨ì§€ vs í›„ê³¡ë§ˆì„(ëŒ€ì°½) X)
            #   - ê´„í˜¸ ì•ˆ ë¸Œëœë“œëª…ì´ ì—†ìœ¼ë©´ í—ˆìš© (ê²½ë‚¨ì•„ë„ˆìŠ¤ë¹Œ1ë‹¨ì§€ vs ê²½ë‚¨ì•„ë„ˆìŠ¤ë¹Œì•„íŒŒíŠ¸ O)
            if api_danji_final is not None:
                if db_danji_final is not None:
                    # ë‘˜ ë‹¤ ë‹¨ì§€ ë²ˆí˜¸ê°€ ìˆìœ¼ë©´ ë°˜ë“œì‹œ ê°™ì•„ì•¼ í•¨
                    if db_danji_final != api_danji_final:
                        # ğŸš« VETO: ë‹¨ì§€ ë²ˆí˜¸ ë¶ˆì¼ì¹˜ â†’ ì¦‰ì‹œ ì œì™¸
                        # ì§€ë²ˆ/ê±´ì¶•ë…„ë„ ì¼ì¹˜í•´ë„ ë‹¨ì§€ ë²ˆí˜¸ê°€ ë‹¤ë¥´ë©´ ë‹¤ë¥¸ ì•„íŒŒíŠ¸
                        continue
                else:
                    # DBì— ë‹¨ì§€ ë²ˆí˜¸ê°€ ì—†ëŠ” ê²½ìš°
                    # ê´„í˜¸ ì•ˆì— ë¸Œëœë“œëª…ì´ ìˆìœ¼ë©´ ë‹¤ë¥¸ ë‹¨ì§€ë¡œ ê°„ì£¼í•˜ì—¬ ì œì™¸
                    # (ì˜ˆ: "í›„ê³¡ë§ˆì„10ë‹¨ì§€" vs "í›„ê³¡ë§ˆì„(ëŒ€ì°½)" - ëŒ€ì°½ì€ ë³„ë„ ë‹¨ì§€)
                    if brand_in_parens_db:
                        continue
                    # ê´„í˜¸ ì•ˆì— ë¸Œëœë“œëª…ì´ ì—†ìœ¼ë©´ ì¼ë°˜ ì•„íŒŒíŠ¸ëª…ìœ¼ë¡œ ê°„ì£¼í•˜ì—¬ í—ˆìš©
                    # (ì˜ˆ: "ê²½ë‚¨ì•„ë„ˆìŠ¤ë¹Œ1ë‹¨ì§€" vs "ê²½ë‚¨ì•„ë„ˆìŠ¤ë¹Œì•„íŒŒíŠ¸" - ë§¤ì¹­ í—ˆìš©)
            elif api_cha is not None:
                # APIì— ì°¨ìˆ˜ê°€ ìˆìœ¼ë©´ ë¹„êµ
                if db_cha is not None:
                    # ë‘˜ ë‹¤ ì°¨ìˆ˜ê°€ ìˆìœ¼ë©´ ë°˜ë“œì‹œ ê°™ì•„ì•¼ í•¨
                    if db_cha != api_cha:
                        # ğŸš« VETO: ì°¨ìˆ˜ ë¶ˆì¼ì¹˜ â†’ ì¦‰ì‹œ ì œì™¸ (ë‹¨ì§€ ë²ˆí˜¸ì™€ ë™ì¼í•˜ê²Œ ì—„ê²©í•˜ê²Œ)
                        continue
                else:
                    # DBì— ì°¨ìˆ˜ê°€ ì—†ëŠ” ê²½ìš°
                    # ê´„í˜¸ ì•ˆì— ë¸Œëœë“œëª…ì´ ìˆìœ¼ë©´ ë‹¤ë¥¸ ë‹¨ì§€ë¡œ ê°„ì£¼í•˜ì—¬ ì œì™¸
                    if brand_in_parens_db:
                        continue
                    # ê´„í˜¸ ì•ˆì— ë¸Œëœë“œëª…ì´ ì—†ìœ¼ë©´ í—ˆìš©
            
            # ğŸ”‘ ì¶”ê°€ ê²€ì¦: ë‹¨ì§€ ë²ˆí˜¸ì™€ ì°¨ìˆ˜ê°€ ëª¨ë‘ ìˆëŠ” ê²½ìš° ë‘˜ ë‹¤ í™•ì¸
            # APIì— ë‹¨ì§€ ë²ˆí˜¸ê°€ ìˆê³  DBì— ì°¨ìˆ˜ê°€ ìˆê±°ë‚˜, ê·¸ ë°˜ëŒ€ì¸ ê²½ìš°ë„ í™•ì¸
            if api_danji_final is not None and db_cha is not None:
                # ë‹¨ì§€ ë²ˆí˜¸ì™€ ì°¨ìˆ˜ê°€ ë‹¤ë¥¸ ê°œë…ì´ë¯€ë¡œ, ë‘˜ ë‹¤ ìˆìœ¼ë©´ ë‘˜ ë‹¤ ì¼ì¹˜í•´ì•¼ í•¨
                # í•˜ì§€ë§Œ ì¼ë°˜ì ìœ¼ë¡œ ë‹¨ì§€ ë²ˆí˜¸ì™€ ì°¨ìˆ˜ëŠ” í•¨ê»˜ ì‚¬ìš©ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ, 
                # í•˜ë‚˜ë§Œ ì¼ì¹˜í•˜ë©´ í—ˆìš© (í˜„ì¬ ë¡œì§ ìœ ì§€)
                pass
            elif api_cha is not None and db_danji_final is not None:
                # APIì— ì°¨ìˆ˜ê°€ ìˆê³  DBì— ë‹¨ì§€ ë²ˆí˜¸ê°€ ìˆëŠ” ê²½ìš°ë„ í™•ì¸
                # ì¼ë°˜ì ìœ¼ë¡œ í˜¼ìš©ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ í˜„ì¬ ë¡œì§ ìœ ì§€
                pass
            
            # === 0.7ë‹¨ê³„: ë¸Œëœë“œ ê·¸ë£¹ ë¶ˆì¼ì¹˜ Veto (ê°•í™”) ===
            # ë‘˜ ë‹¤ ëª…í™•í•œ ë¸Œëœë“œê°€ ì‹ë³„ë˜ì—ˆëŠ”ë° ë‹¤ë¥´ë©´ â†’ VETO
            api_brands = set(api_cache['brands'])
            db_brands = set(db_cache['brands'])
            common_brands = api_brands & db_brands
            has_common_brand = len(common_brands) > 0
            
            # ì£¼ìš” ë¸Œëœë“œ ëª©ë¡ (ì´ ë¸Œëœë“œê°€ APIì— ìˆìœ¼ë©´ DBì—ë„ ìˆì–´ì•¼ í•¨)
            MAJOR_BRANDS = {
                'ìì´', 'ë˜ë¯¸ì•ˆ', 'í‘¸ë¥´ì§€ì˜¤', 'íìŠ¤í…Œì´íŠ¸', 'ì´í¸í•œì„¸ìƒ', 'eí¸í•œì„¸ìƒ',
                'ë”ìƒµ', 'ì•„ì´íŒŒí¬', 'ì„¼íŠ¸ë ˆë¹Œ', 'ë¡¯ë°ìºìŠ¬', 'ìœ„ë¸Œ', 'í˜¸ë°˜ì¨ë°‹',
                'ì•„í¬ë¡œ', 'í¬ë ˆë‚˜', 'ê¿ˆì—ê·¸ë¦°', 'ìŠ¤ìœ„ì²¸', 'íŠ¸ë¼íŒ°ë¦¬ìŠ¤', 'íœ´ë¨¼ì‹œì•„',
                'ë¹„ë°œë””', 'í•œë¼ë¹„ë°œë””', 'ìš°ë¯¸ë¦°', 'ë² ìŠ¤íŠ¸ë¹Œ', 'ì–´ìš¸ë¦¼', 'ë¡œì–„ë“€í¬',
                'ìŠ¤ìœ—ë‹·í™ˆ', 'ì˜ˆê°€', 'ì‚¬ë‘ìœ¼ë¡œ', 'sí´ë˜ìŠ¤', 'ì¤‘í¥sí´ë˜ìŠ¤', 'ì¤‘í¥',
                'ìˆ˜ìì¸', 'ë‚˜ë¹Œë˜', 'ìŠ¤íƒ€í´ë˜ìŠ¤', 'ë…¸ë¹Œë¦¬í‹°', 'ìŠ¤ì¹´ì´ë·°'
            }
            
            # ğŸ”‘ ê°•í™”: ë‘˜ ë‹¤ ë¸Œëœë“œê°€ ìˆëŠ”ë° ê³µí†µ ë¸Œëœë“œê°€ ì—†ìœ¼ë©´ Veto
            # ë‹¨, ë¸Œëœë“œê°€ í•˜ë‚˜ë„ ì—†ëŠ” ê²½ìš°ëŠ” í†µê³¼ (ì¼ë°˜ ì•„íŒŒíŠ¸ëª…)
            if api_brands and db_brands and not has_common_brand:
                # í‘œì¤€ ë¸Œëœë“œëª…ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë‹¤ì‹œ ë¹„êµ
                api_std = {BRAND_KEYWORD_TO_STANDARD.get(b.lower(), b) for b in api_brands}
                db_std = {BRAND_KEYWORD_TO_STANDARD.get(b.lower(), b) for b in db_brands}
                if api_std and db_std and not (api_std & db_std):
                    # ğŸš« VETO: ë¸Œëœë“œ ê·¸ë£¹ ë¶ˆì¼ì¹˜ (ìì´ vs ë˜ë¯¸ì•ˆ ë“±)
                    continue
            
            # ğŸ”‘ ê°•í™”: APIì— ì£¼ìš” ë¸Œëœë“œê°€ ìˆëŠ”ë° DBì— ì—†ìœ¼ë©´ Veto
            # (ì˜ˆ: "LGì‹ ì‚°ë³¸ìì´2ì°¨" vs "ë‹¹ì •ë§ˆì„ì—˜ì§€" - ìì´ê°€ ì—†ìœ¼ë¯€ë¡œ Veto)
            api_brands_lower = {b.lower() for b in api_brands}
            db_brands_lower = {b.lower() for b in db_brands}
            api_major_brands = api_brands_lower & {b.lower() for b in MAJOR_BRANDS}
            
            if api_major_brands:
                # APIì— ì£¼ìš” ë¸Œëœë“œê°€ ìˆìœ¼ë©´, DBì—ë„ í•´ë‹¹ ë¸Œëœë“œê°€ ìˆì–´ì•¼ í•¨
                db_has_api_major = bool(api_major_brands & db_brands_lower)
                if not db_has_api_major:
                    # ğŸš« VETO: APIì˜ ì£¼ìš” ë¸Œëœë“œê°€ DBì— ì—†ìŒ
                    # íŠ¹íˆ ìì´, ë˜ë¯¸ì•ˆ, í‘¸ë¥´ì§€ì˜¤ ë“± ëª…í™•í•œ ë¸Œëœë“œëŠ” ì ˆëŒ€ ìš°íšŒ ë¶ˆê°€
                    continue
            
            # ğŸ”‘ ê°•í™”: DBì— ì£¼ìš” ë¸Œëœë“œê°€ ìˆëŠ”ë° APIì— ì—†ìœ¼ë©´ Veto (ì–‘ë°©í–¥ ê²€ì¦)
            db_major_brands = db_brands_lower & {b.lower() for b in MAJOR_BRANDS}
            if db_major_brands:
                # DBì— ì£¼ìš” ë¸Œëœë“œê°€ ìˆìœ¼ë©´, APIì—ë„ í•´ë‹¹ ë¸Œëœë“œê°€ ìˆì–´ì•¼ í•¨
                api_has_db_major = bool(db_major_brands & api_brands_lower)
                if not api_has_db_major:
                    # ğŸš« VETO: DBì˜ ì£¼ìš” ë¸Œëœë“œê°€ APIì— ì—†ìŒ
                    # (ì˜ˆ: "ë‹¹ì •ë§ˆì„ì—˜ì§€"ì— ìì´ê°€ ì—†ëŠ”ë° "LGì‹ ì‚°ë³¸ìì´2ì°¨"ì™€ ë§¤ì¹­ ì‹œë„)
                    continue
            
            # ğŸ”‘ ì¶”ê°€ ê°•í™”: ì¼ë°˜ ë¸Œëœë“œë„ ë¶ˆì¼ì¹˜ ì‹œ Veto (ë” ì—„ê²©í•˜ê²Œ)
            # APIì™€ DB ëª¨ë‘ì— ë¸Œëœë“œê°€ ìˆëŠ”ë° ê³µí†µ ë¸Œëœë“œê°€ ì—†ìœ¼ë©´ ì œì™¸
            if api_brands and db_brands and not has_common_brand:
                # í‘œì¤€ ë¸Œëœë“œëª…ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë‹¤ì‹œ ë¹„êµ
                api_std_all = {BRAND_KEYWORD_TO_STANDARD.get(b.lower(), b.lower()) for b in api_brands}
                db_std_all = {BRAND_KEYWORD_TO_STANDARD.get(b.lower(), b.lower()) for b in db_brands}
                # í‘œì¤€í™” í›„ì—ë„ ê³µí†µ ë¸Œëœë“œê°€ ì—†ìœ¼ë©´ ì œì™¸
                if api_std_all and db_std_all and not (api_std_all & db_std_all):
                    # ğŸš« VETO: ëª¨ë“  ë¸Œëœë“œ ë¶ˆì¼ì¹˜
                    continue
            
            # === 1ë‹¨ê³„: ì •ê·œí™”ëœ ì´ë¦„ ì •í™• ë§¤ì¹­ (ìµœê³  ì ìˆ˜) ===
            if api_cache['normalized'] == db_cache['normalized']:
                return apt  # ì •í™• ë§¤ì¹­ì€ ë°”ë¡œ ë°˜í™˜
            
            # === 2ë‹¨ê³„: ì—„ê²© ì •ê·œí™” í›„ ì •í™• ë§¤ì¹­ ===
            # ë‹¨, ë‹¨ì§€ ë²ˆí˜¸ê°€ ìˆëŠ” ê²½ìš°ëŠ” ì—„ê²© ì •ê·œí™” ë§¤ì¹­ì„ ê±´ë„ˆë›°ì–´ì•¼ í•¨
            # (ë‹¨ì§€ ë²ˆí˜¸ê°€ ì œê±°ë˜ë©´ ë‹¤ë¥¸ ë‹¨ì§€ì™€ êµ¬ë¶„ì´ ì•ˆ ë¨)
            if api_danji is None and api_cha is None:
                if api_cache['strict'] == db_cache['strict']:
                    return apt  # ì°¨ìˆ˜/ë‹¨ì§€ ì œê±° í›„ ì •í™• ë§¤ì¹­ (ë‹¨ì§€ ë²ˆí˜¸ê°€ ì—†ëŠ” ê²½ìš°ë§Œ)
            
            # === 3ë‹¨ê³„: ë¸Œëœë“œëª… + ë‹¨ì§€ë²ˆí˜¸ ë³µí•© ë§¤ì¹­ (í•µì‹¬!) ===
            # (common_brands, has_common_brandëŠ” 0.7ë‹¨ê³„ì—ì„œ ì´ë¯¸ ê³„ì‚°ë¨)
            
            # ë‹¨ì§€ë²ˆí˜¸ ì¼ì¹˜ í™•ì¸ (ì´ë¯¸ 0ë‹¨ê³„ì—ì„œ í•„í„°ë§í–ˆìœ¼ë¯€ë¡œ ì¼ì¹˜í•¨)
            danji_match = (api_danji is not None and 
                          db_danji is not None and 
                          api_danji == db_danji)
            
            # ë§ˆì„ëª… ì¼ì¹˜ í™•ì¸
            village_match = False
            if api_cache['village'] and db_cache['village']:
                v_api = api_cache['village'].lower()
                v_db = db_cache['village'].lower()
                village_match = (v_api == v_db or v_api in v_db or v_db in v_api)
            
            # ë¸Œëœë“œ + ë‹¨ì§€ë²ˆí˜¸ ì¼ì¹˜ â†’ ë§¤ìš° ë†’ì€ ì ìˆ˜ (ê±°ì˜ í™•ì‹¤íˆ ê°™ì€ ì•„íŒŒíŠ¸)
            if has_common_brand and danji_match:
                score = max(score, 0.95)
            
            # ë¸Œëœë“œ + ë§ˆì„ëª… ì¼ì¹˜ â†’ ë†’ì€ ì ìˆ˜
            if has_common_brand and village_match:
                score = max(score, 0.90)
            
            # ë‹¨ì§€ë²ˆí˜¸ + ë§ˆì„ëª… ì¼ì¹˜ â†’ ë†’ì€ ì ìˆ˜ (ë¸Œëœë“œ ì—†ì–´ë„)
            if danji_match and village_match:
                score = max(score, 0.88)
            
            # ë¸Œëœë“œë§Œ ì¼ì¹˜ (ê°™ì€ ë™ì— í•´ë‹¹ ë¸Œëœë“œ ì•„íŒŒíŠ¸ê°€ í•˜ë‚˜ë¿ì¼ ê°€ëŠ¥ì„±)
            if has_common_brand and len(candidates) <= 3:
                score = max(score, 0.75)
            elif has_common_brand:
                score = max(score, 0.60)
            
            # ë‹¨ì§€ë²ˆí˜¸ë§Œ ì¼ì¹˜ (ê°™ì€ ë™ì— í•´ë‹¹ ë‹¨ì§€ê°€ í•˜ë‚˜ë¿ì¼ ê°€ëŠ¥ì„±)
            if danji_match and len(candidates) <= 3:
                score = max(score, 0.70)
            
            # === 3.5ë‹¨ê³„: ì§€ë²ˆ ê¸°ë°˜ ë§¤ì¹­ (ê°•í™” ë²„ì „) ===
            jibun_match = False
            jibun_full_match = False  # ë³¸ë²ˆ+ë¶€ë²ˆ ì™„ì „ ì¼ì¹˜
            jibun_dong_match = False  # ë™ ì´ë¦„ë„ ì¼ì¹˜í•˜ëŠ” ê²½ìš°
            jibun_apt_name_match = False  # ì§€ë²ˆ ì£¼ì†Œì— í¬í•¨ëœ ì•„íŒŒíŠ¸ëª… ì¼ì¹˜
            
            if jibun and apt_details and apt.apt_id in apt_details:
                detail = apt_details[apt.apt_id]
                if detail.jibun_address:
                    # ğŸ”‘ ê°œì„ : API ì§€ë²ˆì—ì„œ ë³¸ë²ˆ-ë¶€ë²ˆ ì¶”ì¶œ (ì‚°ì§€ë²ˆ, ì§€êµ¬ë²ˆí˜¸, ë³¸ë²ˆ-ë¶€ë²ˆ-ë¶€ë¶€ë²ˆ ì²˜ë¦¬)
                    jibun_clean = jibun.strip()
                    
                    # ì‚°ì§€ë²ˆ ì²˜ë¦¬: "ì‚°37-6" â†’ ë³¸ë²ˆ="37", ë¶€ë²ˆ="6"
                    if jibun_clean.startswith('ì‚°'):
                        jibun_clean = jibun_clean[1:]  # "ì‚°" ì œê±°
                    
                    # ì§€êµ¬ ë²ˆí˜¸ ì²˜ë¦¬: "ì§€êµ¬BL 34-7" â†’ ë³¸ë²ˆ="34", ë¶€ë²ˆ="7"
                    if 'ì§€êµ¬' in jibun_clean or 'BL' in jibun_clean.upper() or 'ë¸”ë¡' in jibun_clean:
                        jibun_parts = re.search(r'(\d+)(?:-(\d+))?(?:-(\d+))?', jibun_clean)
                        if jibun_parts:
                            api_main = jibun_parts.group(1).lstrip('0')
                            api_sub = jibun_parts.group(2).lstrip('0') if jibun_parts.group(2) else None
                        else:
                            api_main = None
                            api_sub = None
                    else:
                        # ì¼ë°˜ ì§€ë²ˆ ì²˜ë¦¬ (ë³¸ë²ˆ-ë¶€ë²ˆ-ë¶€ë¶€ë²ˆ í¬í•¨)
                        jibun_parts = re.match(r'(\d+)(?:-(\d+))?(?:-(\d+))?', jibun_clean)
                        if jibun_parts:
                            api_main = jibun_parts.group(1).lstrip('0')
                            # ë¶€ë¶€ë²ˆì´ ìˆìœ¼ë©´ ë¶€ë²ˆë§Œ ì‚¬ìš© (ë¶€ë¶€ë²ˆì€ ë¬´ì‹œ)
                            api_sub = jibun_parts.group(2).lstrip('0') if jibun_parts.group(2) else None
                        else:
                            api_main = None
                            api_sub = None
                    
                    # ğŸ”‘ ê°œì„ : DB ì§€ë²ˆ ì£¼ì†Œì—ì„œ ë™ ì´ë¦„ê³¼ ì§€ë²ˆì„ ë” ì •í™•íˆ ì¶”ì¶œ
                    # íŒ¨í„´: "ë™ì´ë¦„ ì§€ë²ˆ" ë˜ëŠ” "ë™ì´ë¦„ ì§€ë²ˆ-ë¶€ë²ˆ" ë˜ëŠ” "ë™ì´ë¦„ ì§€ë²ˆ-ë¶€ë²ˆ-ë¶€ë¶€ë²ˆ"
                    # ì‚°ì§€ë²ˆ, ì§€êµ¬ë²ˆí˜¸ë„ ì²˜ë¦¬
                    dong_jibun_pattern = r'([ê°€-í£]+(?:ë™|ê°€|ë¦¬|ì|ë©´))\s+(?:ì‚°)?(\d+)(?:-(\d+))?(?:-(\d+))?(?:\s|$)'
                    db_dong_jibun_match = re.search(dong_jibun_pattern, detail.jibun_address)
                    
                    if db_dong_jibun_match:
                        db_dong_name = db_dong_jibun_match.group(1)  # ë™ ì´ë¦„
                        db_main = db_dong_jibun_match.group(2).lstrip('0')  # ë³¸ë²ˆ
                        # ë¶€ë¶€ë²ˆì´ ìˆìœ¼ë©´ ë¶€ë²ˆë§Œ ì‚¬ìš© (ë¶€ë¶€ë²ˆì€ ë¬´ì‹œ)
                        db_sub = db_dong_jibun_match.group(3).lstrip('0') if db_dong_jibun_match.group(3) else None  # ë¶€ë²ˆ
                        
                        # ğŸ”‘ ë™ ì´ë¦„ ê²€ì¦ ê°•í™”
                        if umd_nm:
                            # API ë™ ì´ë¦„ê³¼ DB ì§€ë²ˆ ì£¼ì†Œì˜ ë™ ì´ë¦„ ë¹„êµ
                            normalized_umd = ApartmentMatcher.normalize_dong_name(umd_nm)
                            normalized_db_dong = ApartmentMatcher.normalize_dong_name(db_dong_name)
                            if normalized_umd == normalized_db_dong or normalized_umd in normalized_db_dong or normalized_db_dong in normalized_umd:
                                jibun_dong_match = True
                    else:
                        # ğŸ”‘ ê°œì„ : ì‚°ì§€ë²ˆ, ì§€êµ¬ë²ˆí˜¸, ë³¸ë²ˆ-ë¶€ë²ˆ-ë¶€ë¶€ë²ˆ ì²˜ë¦¬
                        # ì‚°ì§€ë²ˆ íŒ¨í„´: "ì‚°37-6"
                        san_match = re.search(r'ì‚°\s*(\d+)(?:-(\d+))?(?:-(\d+))?', detail.jibun_address)
                        if san_match:
                            db_dong_name = None
                            db_main = san_match.group(1).lstrip('0')
                            db_sub = san_match.group(2).lstrip('0') if san_match.group(2) else None
                        else:
                            # ì§€êµ¬ ë²ˆí˜¸ íŒ¨í„´: "ì§€êµ¬BL 34-7" ë˜ëŠ” "ê°€ì •2ì§€êµ¬34-7"
                            jigu_match = re.search(r'ì§€êµ¬[^\d]*(\d+)(?:-(\d+))?(?:-(\d+))?', detail.jibun_address)
                            if not jigu_match:
                                jigu_match = re.search(r'BL[^\d]*(\d+)(?:-(\d+))?(?:-(\d+))?', detail.jibun_address, re.IGNORECASE)
                            if jigu_match:
                                db_dong_name = None
                                db_main = jigu_match.group(1).lstrip('0')
                                db_sub = jigu_match.group(2).lstrip('0') if jigu_match.group(2) else None
                            else:
                                # ì¼ë°˜ ì§€ë²ˆ íŒ¨í„´ (ë³¸ë²ˆ-ë¶€ë²ˆ-ë¶€ë¶€ë²ˆ í¬í•¨)
                                db_jibun_match = re.search(r'(\d+)(?:-(\d+))?(?:-(\d+))?(?:\s|$)', detail.jibun_address)
                                db_dong_name = None
                                db_main = db_jibun_match.group(1).lstrip('0') if db_jibun_match else None
                                # ë¶€ë¶€ë²ˆì´ ìˆìœ¼ë©´ ë¶€ë²ˆë§Œ ì‚¬ìš© (ë¶€ë¶€ë²ˆì€ ë¬´ì‹œ)
                                db_sub = db_jibun_match.group(2).lstrip('0') if db_jibun_match and db_jibun_match.group(2) else None
                    
                    # ğŸ”‘ ì§€ë²ˆ ì£¼ì†Œì— í¬í•¨ëœ ì•„íŒŒíŠ¸ëª… ì¶”ì¶œ ë° í™œìš©
                    # ì§€ë²ˆ ì£¼ì†Œ í˜•ì‹: "ì‹œë„ ì‹œêµ°êµ¬ ë™ ì§€ë²ˆ ì•„íŒŒíŠ¸ëª…"
                    # ì•„íŒŒíŠ¸ëª… ë¶€ë¶„ ì¶”ì¶œ (ì§€ë²ˆ ë’¤ì˜ ë¶€ë¶„)
                    if db_dong_jibun_match:
                        jibun_end_pos = db_dong_jibun_match.end()
                        apt_name_in_jibun = detail.jibun_address[jibun_end_pos:].strip()
                        if apt_name_in_jibun:
                            # ì§€ë²ˆ ì£¼ì†Œì˜ ì•„íŒŒíŠ¸ëª… ì •ê·œí™”
                            normalized_apt_in_jibun = ApartmentMatcher.normalize_apt_name(
                                ApartmentMatcher.clean_apt_name(apt_name_in_jibun)
                            )
                            # API ì•„íŒŒíŠ¸ëª…ê³¼ ë¹„êµ
                            if normalized_apt_in_jibun and api_cache['normalized']:
                                apt_name_similarity = SequenceMatcher(
                                    None, normalized_apt_in_jibun, api_cache['normalized']
                                ).ratio()
                                if apt_name_similarity >= 0.70:
                                    jibun_apt_name_match = True
                    
                    # ë³¸ë²ˆ-ë¶€ë²ˆ ë¹„êµ
                    if api_main and db_main:
                        # ë³¸ë²ˆ ë¹„êµ
                        if api_main == db_main:
                            jibun_match = True
                            # ë¶€ë²ˆë„ ë¹„êµ (ë‘˜ ë‹¤ ìˆëŠ” ê²½ìš°)
                            if api_sub and db_sub and api_sub == db_sub:
                                jibun_full_match = True
                            elif not api_sub and not db_sub:
                                jibun_full_match = True
                    
                    # ê¸°ì¡´ í¬í•¨ í™•ì¸ë„ ìœ ì§€ (fallback)
                    if not jibun_match:
                        norm_jibun_api = re.sub(r'[\s\-]+', '', jibun)
                        norm_jibun_db = re.sub(r'[\s\-]+', '', detail.jibun_address)
                        if norm_jibun_api in norm_jibun_db or jibun in detail.jibun_address:
                            jibun_match = True
                    
                    # ğŸ”‘ ì§€ë²ˆ ì¼ì¹˜ ì‹œ ì ìˆ˜ ìƒìŠ¹ (ê°•í™” ë²„ì „)
                    # ì´ë¦„ì´ ì „í˜€ ë‹¤ë¥¸ë° ì§€ë²ˆë§Œ ê°™ì€ ê²½ìš° ë°©ì§€
                    name_similarity_for_jibun = SequenceMatcher(None, 
                        api_cache['normalized'], db_cache['normalized']).ratio()
                    
                    # ğŸ”‘ ì§€ë²ˆ ì£¼ì†Œì— í¬í•¨ëœ ì•„íŒŒíŠ¸ëª… ì¼ì¹˜ ì‹œ ì¶”ê°€ ë³´ë„ˆìŠ¤
                    if jibun_apt_name_match:
                        # ì§€ë²ˆ ì£¼ì†Œì˜ ì•„íŒŒíŠ¸ëª…ì´ APIì™€ ì¼ì¹˜í•˜ë©´ ë§¤ìš° ë†’ì€ ì‹ ë¢°ë„
                        name_similarity_for_jibun = max(name_similarity_for_jibun, 0.80)
                    
                    if jibun_full_match:
                        # ë³¸ë²ˆ+ë¶€ë²ˆ ì™„ì „ ì¼ì¹˜: ë†’ì€ ì ìˆ˜
                        if jibun_dong_match and jibun_apt_name_match:
                            # ë™ ì´ë¦„ + ì§€ë²ˆ + ì•„íŒŒíŠ¸ëª… ëª¨ë‘ ì¼ì¹˜ â†’ ë§¤ìš° ë†’ì€ ì ìˆ˜
                            score = max(score, 0.98)
                        elif jibun_dong_match or jibun_apt_name_match:
                            # ë™ ì´ë¦„ ë˜ëŠ” ì•„íŒŒíŠ¸ëª… ì¼ì¹˜ â†’ ë†’ì€ ì ìˆ˜
                            if name_similarity_for_jibun >= 0.10 or has_common_brand:
                                score = max(score, 0.96)
                        elif name_similarity_for_jibun >= 0.15 or has_common_brand:
                            score = max(score, 0.95)
                        elif name_similarity_for_jibun >= 0.10:
                            score = max(score, 0.85)
                        # ì´ë¦„ ìœ ì‚¬ë„ 0.10 ë¯¸ë§Œì´ë©´ ì§€ë²ˆë§Œìœ¼ë¡œëŠ” ë§¤ì¹­ ì•ˆ í•¨
                    elif jibun_match:
                        # ë³¸ë²ˆë§Œ ì¼ì¹˜: ì¤‘ê°„ ì ìˆ˜
                        if jibun_dong_match and jibun_apt_name_match:
                            # ë™ ì´ë¦„ + ì•„íŒŒíŠ¸ëª… ì¼ì¹˜ â†’ ë†’ì€ ì ìˆ˜
                            score = max(score, 0.95)
                        elif jibun_dong_match or jibun_apt_name_match:
                            # ë™ ì´ë¦„ ë˜ëŠ” ì•„íŒŒíŠ¸ëª… ì¼ì¹˜ â†’ ì¤‘ê°„ ì ìˆ˜
                            if name_similarity_for_jibun >= 0.15 or has_common_brand:
                                score = max(score, 0.90)
                            elif name_similarity_for_jibun >= 0.10:
                                score = max(score, 0.80)
                        elif name_similarity_for_jibun >= 0.25 or (score >= 0.5):
                            score = max(score, 0.90)
                        elif name_similarity_for_jibun >= 0.15 or has_common_brand:
                            score = max(score, 0.75)
                        # ì´ë¦„ ìœ ì‚¬ë„ 0.15 ë¯¸ë§Œì´ë©´ ì§€ë²ˆë§Œìœ¼ë¡œëŠ” ë§¤ì¹­ ì•ˆ í•¨
            
            # === 3.6ë‹¨ê³„: ê±´ì¶•ë…„ë„ ê¸°ë°˜ ê²€ì¦ (NEW!) ===
            build_year_match = False
            if build_year and apt_details and apt.apt_id in apt_details:
                detail = apt_details[apt.apt_id]
                # use_approval_dateì—ì„œ ë…„ë„ ì¶”ì¶œ (YYYY-MM-DD í˜•ì‹)
                if detail.use_approval_date:
                    try:
                        approval_year = detail.use_approval_date.split('-')[0]
                        # ê±´ì¶•ë…„ë„ ì¼ì¹˜ í™•ì¸ (Â±1ë…„ í—ˆìš©)
                        if abs(int(build_year) - int(approval_year)) <= 1:
                            build_year_match = True
                            # ê±´ì¶•ë…„ë„ ì¼ì¹˜ ì‹œ ì ìˆ˜ ë³´ì • (ì‹ ë¢°ë„ ì¦ê°€, 5% ë³´ë„ˆìŠ¤)
                            if score >= 0.5:
                                score = max(score, score * 1.05)
                    except (ValueError, AttributeError):
                        pass
            
            # ğŸ”‘ ì§€ë²ˆ + ê±´ì¶•ë…„ë„ ëª¨ë‘ ì¼ì¹˜ ì‹œ ë†’ì€ ì ìˆ˜ (ë‹¨, ì´ë¦„ ìœ ì‚¬ë„ ìµœì†Œ ê¸°ì¤€)
            # ì´ë¦„ì´ ì „í˜€ ë‹¤ë¥¸ë° ì§€ë²ˆ+ê±´ì¶•ë…„ë„ë§Œ ê°™ì€ ê²½ìš° ë°©ì§€
            if jibun_match and build_year_match:
                name_sim = SequenceMatcher(None, api_cache['normalized'], db_cache['normalized']).ratio()
                if name_sim >= 0.20 or has_common_brand:
                    score = max(score, 0.97)
                elif name_sim >= 0.15:
                    score = max(score, 0.90)
                # ì´ë¦„ ìœ ì‚¬ë„ 0.15 ë¯¸ë§Œì´ë©´ ì§€ë²ˆ+ê±´ì¶•ë…„ë„ë§Œìœ¼ë¡œ ë†’ì€ ì ìˆ˜ ë¶€ì—¬ ì•ˆ í•¨
            
            # === 4ë‹¨ê³„: í¬í•¨ ê´€ê³„ í™•ì¸ (ì–‘ë°©í–¥) ===
            norm_api = api_cache['normalized']
            norm_db = db_cache['normalized']
            if len(norm_api) >= 4 and len(norm_db) >= 4:
                if norm_api in norm_db:
                    ratio = len(norm_api) / len(norm_db)
                    score = max(score, 0.70 + ratio * 0.2)
                elif norm_db in norm_api:
                    ratio = len(norm_db) / len(norm_api)
                    score = max(score, 0.70 + ratio * 0.2)
            
            # === 5ë‹¨ê³„: ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­ ===
            similarity = ApartmentMatcher.calculate_similarity(norm_api, norm_db)
            if similarity >= 0.85:
                score = max(score, similarity)
            elif similarity >= 0.70:
                score = max(score, similarity * 0.95)
            elif similarity >= 0.60:
                score = max(score, similarity * 0.90)
            
            # === 6ë‹¨ê³„: ì—„ê²© ì •ê·œí™” ìœ ì‚¬ë„ ===
            # ë‹¨ì§€ ë²ˆí˜¸ê°€ ìˆëŠ” ê²½ìš°ëŠ” ì—„ê²© ì •ê·œí™” ìœ ì‚¬ë„ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
            # (ë‹¨ì§€ ë²ˆí˜¸ê°€ ì œê±°ë˜ë©´ ë‹¤ë¥¸ ë‹¨ì§€ì™€ êµ¬ë¶„ì´ ì•ˆ ë¨)
            strict_similarity = 0.0
            if api_danji is None and api_cha is None:
                strict_similarity = ApartmentMatcher.calculate_similarity(
                    api_cache['strict'], 
                    db_cache['strict']
                )
                if strict_similarity >= 0.75:
                    score = max(score, strict_similarity * 0.90)
                elif strict_similarity >= 0.60:
                    score = max(score, strict_similarity * 0.85)
            
            # === 7ë‹¨ê³„: í•µì‹¬ ì´ë¦„ ë§¤ì¹­ ===
            if api_cache['core'] and db_cache['core']:
                core_similarity = ApartmentMatcher.calculate_similarity(
                    api_cache['core'], 
                    db_cache['core']
                )
                if core_similarity >= 0.80:
                    score = max(score, core_similarity * 0.85)
            
            # === 8ë‹¨ê³„: í•œê¸€ í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤ì¹­ ===
            api_keywords = set(re.findall(r'[ê°€-í£]{2,}', norm_api))
            db_keywords = set(re.findall(r'[ê°€-í£]{2,}', norm_db))
            
            if api_keywords and db_keywords:
                # ì •í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­
                common_keywords = api_keywords & db_keywords
                
                # ë¶€ë¶„ í‚¤ì›Œë“œ ë§¤ì¹­ (í¬í•¨ ê´€ê³„)
                partial_matches = 0
                for api_kw in api_keywords:
                    for db_kw in db_keywords:
                        if api_kw != db_kw and len(api_kw) >= 2 and len(db_kw) >= 2:
                            if api_kw in db_kw or db_kw in api_kw:
                                partial_matches += 1
                                break
                
                total_matches = len(common_keywords) + partial_matches * 0.7
                total_keywords = max(len(api_keywords), len(db_keywords))
                
                if total_keywords > 0:
                    keyword_ratio = total_matches / total_keywords
                    if keyword_ratio >= 0.6:
                        score = max(score, 0.65 + keyword_ratio * 0.25)
                    elif keyword_ratio >= 0.4:
                        score = max(score, 0.55 + keyword_ratio * 0.20)
            
            # === 9ë‹¨ê³„: ë¸Œëœë“œ + ìœ ì‚¬ë„ ë³µí•© ì ìˆ˜ ===
            if has_common_brand and similarity >= 0.50:
                combined_score = 0.60 + similarity * 0.35
                score = max(score, combined_score)
            
            # === 10ë‹¨ê³„: í›„ë³´ê°€ ì ì„ ë•Œ ë” ê´€ëŒ€í•œ ë§¤ì¹­ ===
            # ğŸ”‘ í›„ë³´ê°€ ì ì–´ë„ ìµœì†Œí•œì˜ ì´ë¦„ ìœ ì‚¬ë„ ê¸°ì¤€ ì ìš© (ë¯¸ìŠ¤ë§¤ì¹­ ë°©ì§€)
            if len(candidates) == 1:
                # í›„ë³´ê°€ í•˜ë‚˜ë¿ì´ì–´ë„ ì´ë¦„ ìœ ì‚¬ë„ ìµœì†Œ 0.15 ì´ìƒ í•„ìš”
                if similarity >= 0.25 or strict_similarity >= 0.25 or has_common_brand:
                    score = max(score, 0.50)
                elif similarity >= 0.15 or strict_similarity >= 0.15:
                    score = max(score, 0.42)
                # ìœ ì‚¬ë„ 0.15 ë¯¸ë§Œì´ë©´ ë¬´ì¡°ê±´ ë§¤ì¹­ ì•ˆ í•¨ (í›„ë³´ê°€ 1ê°œì—¬ë„)
            elif len(candidates) <= 3:
                # í›„ë³´ê°€ 3ê°œ ì´í•˜: ìœ ì‚¬ë„ 0.20 ì´ìƒ ë˜ëŠ” ë¸Œëœë“œ ì¼ì¹˜ í•„ìš”
                if similarity >= 0.25 or strict_similarity >= 0.25 or has_common_brand:
                    score = max(score, 0.42)
                elif similarity >= 0.20 or strict_similarity >= 0.20:
                    score = max(score, 0.38)
            elif len(candidates) <= 5:
                # í›„ë³´ê°€ 5ê°œ ì´í•˜: ìœ ì‚¬ë„ 0.25 ì´ìƒ ë˜ëŠ” ë¸Œëœë“œ ì¼ì¹˜ í•„ìš”
                if similarity >= 0.30 or strict_similarity >= 0.30 or has_common_brand:
                    score = max(score, 0.38)
                elif similarity >= 0.25 or strict_similarity >= 0.25:
                    score = max(score, 0.35)
            elif len(candidates) <= 10:
                # í›„ë³´ê°€ 10ê°œ ì´í•˜: ìœ ì‚¬ë„ 0.30 ì´ìƒ í•„ìš”
                if similarity >= 0.35 or strict_similarity >= 0.35:
                    score = max(score, 0.35)
                elif similarity >= 0.30 or strict_similarity >= 0.30:
                    score = max(score, 0.32)
            
            # ìµœê³  ì ìˆ˜ ì—…ë°ì´íŠ¸
            if score > best_score:
                best_score = score
                best_match = apt
        
        # ë™ ê²€ì¦ì´ í•„ìš”í•œ ê²½ìš° (ì „ì²´ í›„ë³´ë¡œ ì¬ì‹œë„ ì‹œ)
        if require_dong_match and best_match and umd_nm and all_regions:
            # ë§¤ì¹­ëœ ì•„íŒŒíŠ¸ì˜ ë™ì´ APIì˜ ë™ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
            if best_match.region_id in all_regions:
                matched_region = all_regions[best_match.region_id]
                matched_dong = matched_region.region_name if matched_region else ""
                
                # ë™ ì´ë¦„ ì •ê·œí™” í›„ ë¹„êµ
                normalized_umd = ApartmentMatcher.normalize_dong_name(umd_nm)
                normalized_matched_dong = ApartmentMatcher.normalize_dong_name(matched_dong)
                
                # ë™ì´ ë¶ˆì¼ì¹˜í•˜ë©´ ë§¤ì¹­ ê±°ë¶€ (ë¯¸ìŠ¤ë§¤ì¹­ ë°©ì§€!)
                dong_matches = (
                    normalized_umd == normalized_matched_dong or
                    (normalized_umd and normalized_matched_dong and 
                     (normalized_umd in normalized_matched_dong or normalized_matched_dong in normalized_umd))
                )
                
                if not dong_matches:
                    logger.debug(f"âš ï¸ ë™ ë¶ˆì¼ì¹˜ë¡œ ë§¤ì¹­ ê±°ë¶€: APIë™={umd_nm}, ë§¤ì¹­ë™={matched_dong}, ì•„íŒŒíŠ¸={best_match.apt_name}")
                    return None
        
        # ë™ì  ì„ê³„ê°’ ì ìš© - ë™ ê²€ì¦ í•„ìš”ì‹œ ë” ì—„ê²©í•œ ê¸°ì¤€
        if require_dong_match:
            # ì „ì²´ í›„ë³´ ì¬ì‹œë„ ì‹œ ë” ë†’ì€ ì„ê³„ê°’ (ë¯¸ìŠ¤ë§¤ì¹­ ë°©ì§€)
            threshold = 0.70  # ë§¤ìš° ë†’ì€ ê¸°ì¤€
            if best_score >= 0.90:  # ê±°ì˜ í™•ì‹¤í•œ ê²½ìš°ë§Œ í—ˆìš©
                threshold = 0.70
            elif best_score >= 0.80:
                threshold = 0.75
            else:
                threshold = 0.80  # ê·¸ ì™¸ì—ëŠ” ë§¤ìš° ì—„ê²©
        else:
            # ì¼ë°˜ ë§¤ì¹­: í›„ë³´ ìˆ˜ì— ë”°ë¼ ë™ì  ì„ê³„ê°’ ì ìš©
            threshold = 0.40  # ê¸°ë³¸ ì„ê³„ê°’ ìƒí–¥ (0.30 â†’ 0.40)
            if len(candidates) == 1:
                threshold = 0.30  # í›„ë³´ 1ê°œ (0.10 â†’ 0.30 ìƒí–¥)
            elif len(candidates) <= 3:
                threshold = 0.35  # í›„ë³´ 3ê°œ ì´í•˜ (0.20 â†’ 0.35 ìƒí–¥)
            elif len(candidates) <= 5:
                threshold = 0.38  # í›„ë³´ 5ê°œ ì´í•˜ (0.25 â†’ 0.38 ìƒí–¥)
            elif len(candidates) <= 10:
                threshold = 0.40  # í›„ë³´ 10ê°œ ì´í•˜ (0.28 â†’ 0.40 ìƒí–¥)
        
        if best_score >= threshold:
            return best_match
        
        return None
